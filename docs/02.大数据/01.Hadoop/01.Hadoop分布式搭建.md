---
title: Hadoop分布式搭建
date: 2022-02-23 12:55:03
permalink: /pages/5d76a5/
categories: 
  - 大数据
  - Hadoop
tags: 
  - 
---

## 一、虚拟机环境准备

### 1.克隆虚拟机

### 2.修改克隆虚拟机的静态IP

`vim /etc/sysconfig/network-scripts/ifcfg-ens33`

### 3.修改主机名

查看主机名`hostname`
修改主机名`vi /etc/sysconfig/network`    (`hostnamectl set-hostname hadoop102`)
```
NETWORKING=yes
NETWORKING_IPV6=no
HOSTNAME= hadoop101
```

修改linux的主机映射文件（hosts文件）`vim /etc/hosts`
添加
```
8.8.8.101 hadoop101
8.8.8.102 hadoop102
8.8.8.103 hadoop103
```

修改完成后 **`重启设备`** `reboot`


### 4.关闭防火墙(centos 7)

查看防火墙状态    `firewall-cmd --state`  `systemctl status firewalld`
停止firewall    `systemctl stop firewalld.service`
禁止firewall开机启动    `systemctl disable firewalld `

### 5.创建banana用户

添加一个用户    `useradd banana`
设置用户密码    `passwd banana`
查看用户是否存在    `id banana`
查看创建了哪些用户    `cat  /etc/passwd`
删除用户    删除用户但保存用户主目录 `userdel banana`    删除用户和用户主目录 `userdel -r banana`
显示自身用户名称    `whoami`

### 6.sudo配置banana用户具有root权限

修改配置文件 `vi /etc/sudoers`

找到下面一行(91行)，在root下面添加一行
```
##  Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
banana   ALL=(ALL)     ALL
```

或者配置成采用sudo命令时，不需要输入密码
```
##  Allow root to run any commands anywhere
root      ALL=(ALL)     ALL
banana   ALL=(ALL)     NOPASSWD:ALL
```

修改完毕，现在可以用banana帐号登录，然后用命令 sudo ，即可获得root权限进行操作(`sudo useradd zhangsan`)

## 二、编写集群分发脚本xsync

### 1.scp（secure copy）安全拷贝    [推、拉、第三方]

定义：scp可以实现服务器与服务器之间的数据拷贝

语法：`scp -r $pdir/$fname $user@hadoop$host:$pdir/$fname`

即 `scp -r banana@hadoop101:/soft/module  root@hadoop103:/soft/module` (在102上把101的文件拷贝到103上)
![](https://img2018.cnblogs.com/blog/1798447/202001/1798447-20200119144619412-1760290722.png)

![](https://img2018.cnblogs.com/blog/1798447/202001/1798447-20200119144244303-521487935.png)

<p style="color:red">注意：拷贝过来的配置文件别忘了source一下/etc/profile
    注意：拷贝过来的/soft/module目录，别忘了在hadoop102、hadoop103上修改所有文件的，所有者和所有者组。`sudo chown banana:banana -R /soft/module` </p>

### 2.rsync 远程同步工具

用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去
语法:`rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname`

### 3.xsync集群分发脚本

定义：循环复制文件到所有节点的相同目录下
脚本实现

1.在/home/banana目录下创建bin目录，并在bin目录下xsync创建文件

2.文件内容
```
# !/bin/bash
# 1 获取输入参数个数，如果没有参数，直接退出
pcount=$
if((pcount==0)); then
echo no args;
exit;
fi

# 2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

# 3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

# 4 获取当前用户名称
user=`whoami`

# 5 循环
for((host=103; host<105; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```
3.修改脚本 xsync 具有执行权限    `chmod 777 xsync`

4.调用脚本形式    `xsync /home/banana/bin`

<p style="color:red">注意：如果将xsync放到/home/banana/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。</p>


## 三、完全分布式运行模式

### 1）准备3台客户机（关闭防火墙、静态ip、主机名称）

### 2）安装JDK并配置环境变量

解压 `tar -zxvf jdk-8u161-linux-x64.tar.gz -C /soft/module` (/soft/module是自己新建的目录)

配置环境变量 `vim /etc/profile`

```
文件尾部加入：
export JAVA_HOME=/soft/module/jdk1.8.0_161/    #安装jdk的路径
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar
```
使配置生效 `source /etc/profile`

### 3）安装Hadoop并配置环境变量

解压 `tar -zxvf hadoop-2.9.2.tar.gz -C /soft/module`

配置环境变量 `vim /etc/profile`

```
文件尾部加入：
export HADOOP_HOME=/soft/module/hadoop-2.9.2                #自己安装的Hadoop路径
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

使配置生效 `source /etc/profile`

### 4）配置集群

![](https://img2018.cnblogs.com/blog/1798447/202001/1798447-20200119145738419-411087081.png)

- **核心配置文件  `vi core-site.xml`**
```
<!-- 指定HDFS中NameNode的地址 -->
<property>
		<name>fs.defaultFS</name>
      <value>hdfs://hadoop101:9000</value>
</property>

<!-- 指定Hadoop运行时产生文件的存储目录 -->
<property>
		<name>hadoop.tmp.dir</name>
		<value>/soft/module/hadoop-2.9.2/data/tmp</value>
</property>
```

- **HDFS配置文件**

**配置hadoop-env.sh  `vi hadoop-env.sh`**
```
export JAVA_HOME=/soft/module/jdk1.8.0_161
```
  **配置hdfs-site.xml  `vi hdfs-site.xml`**
```
<property>
		<name>dfs.replication</name>
		<value>3</value>
</property>

<!-- 指定Hadoop辅助名称节点主机配置 -->
<property>
      <name>dfs.namenode.secondary.http-address</name>
      <value>hadoop103:50090</value>
</property>
```

- **YARN配置文件**

**`vi yarn-env.sh`**
```
export JAVA_HOME=/soft/module/jdk1.8.0_161
```
**`vi yarn-site.xml`**
```
<!-- Reducer获取数据的方式 -->
<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
</property>

<!-- 指定YARN的ResourceManager的地址 -->
<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>hadoop102</value>
</property>
```

- **MapReduce配置文件**

**配置mapred-env.sh `vi mapred-env.sh` **
```
export JAVA_HOME=/soft/module/jdk1.8.0_161
```
**配置mapred-site.xml `cp mapred-site.xml.template mapred-site.xml`  `vi mapred-site.xml`**
```
在该文件中增加如下配置

<!-- 指定MR运行在Yarn上 -->
<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
</property>
```
- **分发配置好的hadoop配置文件 `xsync /soft/module/hadoop-2.9.2/etc/hadoop`**
- **在另外的节点上查看文件分发情况 `cat /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml`**

### 5）单点启动

- **如果集群是第一次启动，需要格式化NameNode `hadoop namenode -format`**
- **在hadoop101上启动NameNode  `hadoop-daemon.sh start namenode`**
- **在hadoop101、hadoop102以及hadoop103上分别启动DataNode `hadoop-daemon.sh start datanode`  `jps`查看进程**

### 6）配置ssh、群起集群

- 各节点间无密登录()
```
生成公钥和私钥 (banana用户) (然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）)
ssh-keygen -t rsa

将公钥拷贝到要免密登录的目标机器上
ssh-copy-id hadoop101
ssh-copy-id hadoop102
ssh-copy-id hadoop103
```

ssh-copy-id的使用方法: https://blog.csdn.net/qianggezhishen/article/details/71249699
<p style="color:red">
还需要在hadoop101上采用root账号，配置一下无密登录到hadoop101、hadoop102、hadoop103；
还需要在hadoop102上采用banana账号配置一下无密登录到hadoop101、hadoop102、hadoop103服务器上
</p>
原因: NameNode和ResourceManager要远程启动其他节点,
或者参考链接: https://www.cnblogs.com/limaosheng/p/10444515.html#_label0
<br/>

- **配置从机DataNode 和 NodeManager(配置slaves)  `vim /soft/module/hadoop-2.9.2/etc/hadoop/slaves`**

```
加上
hadoop101
hadoop102
hadoop103

分发文件
xsync.sh /soft/module/hadoop-2.9.2/etc/hadoop/slaves
```

- **启动集群**
    - 如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） `hdfs namenode -format`
hdfs格式化注意事项:https://blog.csdn.net/gis_101/article/details/52821946?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
    - 启动HDFS 在namenode(hadoop101)节点上执行 `sbin/start-dfs.sh`
    - 启动YARN 在ResouceManager(hadoop102)节点上执行 `sbin/start-yarn.sh`
- 在网页上查看集群信息

### 7）测试集群

- 上传文件到集群
- 查看文件存放在什么位置 (HDFS文件存储路径)(HDFS在磁盘存储文件内容)
- 拼接文件
- 下载文件

##  四. 集群时间同步
hadoop101作为时间服务器,其它节点定时获取hadoop101的时间
![](https://img2020.cnblogs.com/blog/1798447/202003/1798447-20200302221504207-159898089.png)

###  1. 时间服务器配置 <span style="color:red">(必须root用户)</span>
- **检查ntp是否安装 `rpm -qa|grep ntp` 没有`ntp-4.2.6p5-28.el7.centos.x86_64`的话 安装ntp `yum install -y ntp`**
- **修改ntp配置文件 `vim /etc/ntp.conf`**
    修改内容:
    - **修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）**
```
# restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为
restrict 8.8.8.0 mask 255.255.255.0 nomodify notrap
```
    - **修改2（集群在局域网中，不使用其他互联网上的时间）**
```
server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst为
# server 0.centos.pool.ntp.org iburst
# server 1.centos.pool.ntp.org iburst
# server 2.centos.pool.ntp.org iburst
# server 3.centos.pool.ntp.org iburst
```
    - **添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）**
```
server 127.127.1.0
fudge 127.127.1.0 stratum 10
```
- **修改/etc/sysconfig/ntpd 文件  `vim /etc/sysconfig/ntpd`**
```
增加内容如下（让硬件时间与系统时间一起同步）
SYNC_HWCLOCK=yes
```
- **重新启动ntpd服务  `service ntpd status`    启动:`service ntpd start` `systemctl start ntpd`**
- **设置ntpd服务开机启动  `chkconfig ntpd on` `systemctl enable ntpd` (开放端口)**

###  2. 其他节点配置  <span style="color:red">(必须root用户)</span>

- **其他机器配置10分钟与时间服务器同步一次  ` crontab -e`**
    编写定时任务
```
*/10 * * * * /usr/sbin/ntpdate hadoop101
```
- **修改任意机器时间    `date -s "2017-9-11 11:11:11"`**
- **十分钟后查看机器是否与时间服务器同步  `date`(测试时时间可设置短些)**