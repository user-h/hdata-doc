---
title: Hive集群搭建
date: 2022-02-27 15:35:17
permalink: /pages/edf4cb/
---
安装hive的前提是先安装hadoop集群，并且hive只需要在hadoop的namenode节点中安装即可，可以不在datanode节点的机器上安装，启动hive的前提是需要hadoop在正常跑着
## 一. 先安装MySQL
### 1.检查卸载mariadb-lib(Centos自带mariadb数据库)
- 检查CentOS的mariadb版本 `rpm -qa|grep mariadb`
- 卸载: `rpm -e  mariadb-libs-5.5.60-1.el7_5.x86_64  --nodeps`
### 2.安装MySQL
- 安装(两个工具?): `yum -y install libaio` `yum -y install net-tools`
- 解压MySQL `tar -xvf mysql-5.7.18-1.el7.x86_64.rpm-bundle.tar.tar -C /soft/modlue`
- 安装(注意顺序不能变):
    - `rpm -ivh mysql-community-common-5.7.18-1.el7.x86_64.rpm `
    - `rpm -ivh mysql-community-libs-5.7.18-1.el7.x86_64.rpm`
    - `rpm -ivh mysql-community-client-5.7.18-1.el7.x86_64.rpm`
    - `rpm -ivh mysql-community-server-5.7.18-1.el7.x86_64.rpm（依赖于common, client）`
### 3.初始化并启动
- 初始化MySQL：`mysqld --initialize`
- mysql默认安装在`/var/lib`下。更改mysql数据库所属于用户及其所属于组:`chown mysql:mysql /var/lib/mysql -R`
- 启动MySQL：`systemctl start mysqld.service`
- 获得初始密码(在/var/log目录)：`grep 'password' mysqld.log `
- 更改密码:
    -  进入MySQL命令行: `mysql -u root -p` 输入刚才获取的初始密码
    - 更改密码:`set password=password('123456789');` `flush privileges;`
    - 注意:这里可能会出现`Your password does not satisfy the current policy requirements. `
<br/>可以设置密码强度为LOW:`set global validate_password_policy=0;`
<br/>设置密码长度:`set global validate_password_length=4;`(最少4位)
<br/>参考链接:https://blog.csdn.net/maxsky/article/details/51171474
- 授权: `grant all privileges on *.* to banana@'%' identified by ‘123456789' with grant option;`(最好手打命令,拷贝老出错)
- 用SQLyog等工具连接  测试


## 二.安装配置Hive
下载hive：https://downloads.apache.org/hive/
<br/>hadoop2.9.2 + hive-2.3.6
>Hive的运行模式
依据Hive的安装和metastore的设置机器，分为下面三个模式：
嵌入模式：使用自带的derby数据库
本地模式：将metastore放在mysql，并且mysql和hive安装在同一台机器上
远程模式：将metastore放在mysql，并且mysql和hive安装在不同一台机器上

### 1.解压安装
- 解压到/soft/module: `tar -zxvf apache-hive-2.3.6-bin.tar.gz -C /soft/module/`
- 重命名: `mv apache-hive-2.3.6-bin hive`

### 2.文件配置
1. 配置环境变量(略):`sudo vim /etc/profile`
2. hive-env.sh文件(conf目录下),拷贝样例 `cp hive-env.sh.template hive-env.sh` `vim hive-env.sh`
```
# 配置 HADOOP_HOME 路径
export HADOOP_HOME=/soft/module/hadoop-2.9.2
# 配置 HIVE_CONF_DIR 路径
export HIVE_CONF_DIR=/soft/module/hive/conf

export HIVE_AUX_JARS_PATH=/soft/module/hive/lib
```

### 3.Hadoop集群配置
1. 必须启动hdfs和yarn
`sbin/start-dfs.sh` `sbin/start-yarn.sh`
2. 创建目录
**因为在hive-site.xml中有这样的配置：**
```
<name>hive.metastore.warehouse.dir</name>
<value>/user/hive/warehouse</value>
<name>hive.exec.scratchdir</name>
<value>/tmp/hive</value>
```
**所以要在集群上新建目录**
- 在 HDFS 上创建/tmp 和/user/hive/warehouse 两个目录(可不操作，系统会自动创建)
<br/>`hadoop fs -mkdir /tmp` `hadoop fs -mkdir -p /user/hive/warehouse`
- 并修改他们的同组权限可写
<br/>`hadoop fs -chmod g+w /tmp` `hadoop fs -chmod g+w /user/hive/warehouse`

### 4.Hive 元数据配置到 MySql
1. 驱动拷贝
**拷贝 mysql-connector-java-5.1.48.jar 到/soft/module/hive/lib/ 
`cp mysql-connector-java-5.1.48.jar /soft/module/hive/lib/`**
2. 配置 Metastore 到 MySql
- **在/opt/module/hive/conf 目录下修改 hive-site.xml `vim hive-site.xml`**
- **根据官方文档配置参数，拷贝数据到 hive-site.xml 文件中**
    https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin
```
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!--将该name对应的value修改为MySQL的地址-->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://hadoop100:3306/metastore?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>
    <!--将该name对应的value修改为MySQL驱动类路径：-->
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>
    <!--将对应的value修改为MySQL数据库登录名-->
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
        <description>username to use against metastore database</description>
    </property>
    <!--将对应的value修改为MySQL数据库的登录密码-->
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123456789</value>
        <description>password to use against metastore database</description>
    </property>
</configuration>
```
2.1 第三步和第四步不做行吗??? 或者加上???(我自己没做3,4步)
```
<property>
   <name>system:java.io.tmpdir</name>
   <value>/soft/module/hive/tmpdir</value>
</property>
 
<property>
     <name>system:user.name</name>
     <value>root</value>
</property>
```
3. 修改hive-site.xml中的临时目录
将hive-site.xml文件中的`${system:java.io.tmpdir}`替换为hive的临时目录，例如我替换为`/soft/module/hive/tmp/`，该目录如果不存在则要自己手工创建，并且赋予读写权限。
4. 将配置文件中`${system:user.name}`都替换为`root`
5. **配置完毕后，如果启动 hive 异常，可以重新启动虚拟机。（重启后，别忘了启
动 hadoop 集群）**

### 5.启动和测试
https://www.jianshu.com/p/7b1b21bf05c2
>1、关闭防火墙
2、开启 mysql外链权限
3、jar包冲突，删除hive下
4、配置hive-site.xml

-  初始化数据库：`cd $HIVE_HOME/bin` `schematool -initSchema -dbType mysql`
-  启动Hive: `cd $HIVE_HOME/bin` 进入Hive的bin目录`./hive` 执行hive启动
-  测试Hive
    -  简单测试`show functions;` `desc function sum;`
    -  连接测试
<br/>在成功建立连接后，进入mysql数据库，会发现多了一个metastore数据库，这个数据库就是用来存储hive的元数据信息。
    -  执行新建库
`show databases;`
`create database test_db;`
` use test_db;`
`show tables;`
`create table student(id int,name string) row format delimited fields terminated by '\t';`
`load data local inpath '/soft/module/hive/student.txt' into table student;`
`insert into student values(1000,"ss");`
    -  Hadoop的HDFS页面上查看
    -  MySQL的hive数据库中查看(可视化工具)
---
1. 关闭
可以通过`ps -ef|grep hive` 来看hive 的端口号，然后kill 掉相关的进程。
2. 启动
命令
`hive --service metastore &`
`hive --service hiveserver2 &`
`nohup hive --service metastore  2>&1 &`  
用来启动metastore
`nohup  hive --service hiveserver2   2>&1 & `
用来启动hiveserver2
可以通过查看日志，来确认是否正常启动。
注意！如果 hiveserver2 不启动，jdbc将无法正常连接


### 6.Hive基本操作
- 启动 hive `bin/hive`
- 查看数据库`hive> show databases;`
- 打开默认数据库 `hive> use default;`
- 显示 default 数据库中的表`hive> show tables;`
- 创建一张表`hive> create table student(id int, name string);`
- 显示数据库中有几张表`hive> show tables;`
- 查看表的结构`hive> desc student;`
- 向表中插入数据`hive> insert into student values(1000,"ss");`
- 查询表中数据`hive> select * from student;`
- 退出 hive  `hive> quit;`
- 清空表 `truncate table student;`
- 导入数据三种方式(数据间以tab分隔)
    - hadoop -put方式: `hadoop fs -put student.txt /user/hive/warehouse/test_db.db/student`
    - hive命令行(本地): `load data local inpath '/soft/module/hive/student.txt' into table student;`
    - hive命令行(hdfs): `load data inpath 'hdfs路径(user/...)' into table student;`

---
## 三. java API环境准备
### 1. centos7启动服务
- 修改hadoop配置`vim core-site.xml`
```
<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>   
</property>  
<property>      
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>
```
<strong><span style="color:red">分发文件</span></strong>
- 启动命令 `/soft/module/hive/bin/hive --service hiveserver2 &`(在native的namenode启动)
<br/>命令启动后挂起,两种方式解决这种不便:
    - 重新打开一个xshell连接，做其他的Linux命令操作，服务启动的会话保留
    - 使用Linux nohup命令，可以防止服务启动挂起`nohup:ignoring input and appending output to 'nohup.out'`
它会将服务启动的日志输出到当前目录下的nohup.out文件内，我们查看下内容`cat nohup.out`
    - 启动后用jps`RunJar进程`或在UI界面查看

### 2. eclipse配置
-jar包配置
    - 挑选必须的jar包，编辑成自己的lib配置到工程中（推荐）
其实所有jar包都在${HIVE_HOME}/lib目录下，这里列示下需要的jar包名：
${HADOOP_HOME}/share/hadoop/common/hadoop-common-2.2.0.jar(mr工程中已存在，无需再次添加，如果新建项目需配置
$ { HIVE_HOME } /lib/hive-exec-0.11.0.jar 
$ { HIVE_HOME } /lib/hive-jdbc-0.11.0.jar 
$ { HIVE_HOME } /lib/hive-metastore-0.11.0.jar 
$ { HIVE_HOME } /lib/hive-service-0.11.0.jar 
$ { HIVE_HOME } /lib/libfb303-0.9.0.jar 
$ { HIVE_HOME } /lib/commons-logging-1.0.4.jar （此jar包已经存在就不要再次添加）
$ { HIVE_HOME } /lib/slf4j-api-1.6.1.jar（此jar包已经存在就不要再次添加）
    - 导入jar包
    - 修改pom.xml配置文件（不推荐，会下载额外很多无用包，而且时间很长在1小时左右）
```
<dependency>
    <groupId>org.apache.hive</groupId>
    <artifactId>hive-jdbc</artifactId>
    <version>2.3.6</version>
</dependency>
```

### 附:一个错误
- User: banana is not allowed to impersonate root
修改配置文件core-site.xml
```
<property>
    <name>hadoop.proxyuser.banana.groups</name>
    <value>*</value>   
</property>  
<property>      
    <name>hadoop.proxyuser.banana.hosts</name>
    <value>*</value>
</property>
```
- User: banana is not allowed to impersonate banana
<br/>这个应该是没在active的namenode上启动的原因,
但我自己就是在active上启动的啊,namenode总会莫名挂掉,最后直接把另一个namenode kill掉,就好使了
<br/>忘记分发文件`core-site.xml`两天了!!!!!!!!!!