(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{375:function(n,e,s){"use strict";s.r(e);var t=s(3),o=Object(t.a)({},(function(){var n=this,e=n._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":n.$parent.slotKey}},[e("p",[e("strong",[n._v("Flume NG: Flume next generation, 即flume 1.x版本")]),n._v(" "),e("strong",[n._v("多个agent连接到一个agent,此agent也就相当于collector,支持负载均衡")])]),n._v(" "),e("p",[n._v("集群架构")]),n._v(" "),e("table",[e("thead",[e("tr",[e("th",[n._v("角色")]),n._v(" "),e("th",[n._v("主机名")]),n._v(" "),e("th",[n._v("ip")])])]),n._v(" "),e("tbody",[e("tr",[e("td",[n._v("collector1")]),n._v(" "),e("td",[n._v("hadoop100")]),n._v(" "),e("td",[n._v("8.8.8.100")])]),n._v(" "),e("tr",[e("td",[n._v("collector2")]),n._v(" "),e("td",[n._v("hadoop101")]),n._v(" "),e("td",[n._v("8.8.8.101")])]),n._v(" "),e("tr",[e("td",[n._v("agent")]),n._v(" "),e("td",[n._v("hadoop102")]),n._v(" "),e("td",[n._v("8.8.8.102")])]),n._v(" "),e("tr",[e("td",[n._v("agent")]),n._v(" "),e("td",[n._v("hadoop103")]),n._v(" "),e("td",[n._v("8.8.8.103")])])])]),n._v(" "),e("h3",{attrs:{id:"_1-agent配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-agent配置"}},[n._v("#")]),n._v(" 1. agent配置")]),n._v(" "),e("p",[e("strong",[n._v("两台agent上所有配置相同")])]),n._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[n._v("#agent1 name\nagent1.channels = channel1\nagent1.sources = source1\nagent1.sinks = sink1 sink2\n#set gruop\nagent1.sinkgroups = sinkgroup1\n#set channel\nagent1.channels.channel1.type = memory\nagent1.channels.channel1.capacity = 1000\nagent1.channels.channel1.transactionCapacity = 100\nagent1.sources.source1.channels = channel1\nagent1.sources.source1.type = exec\nagent1.sources.source1.command = tail -F /soft/module/flume/logstestfile/test.txt\nagent1.sources.source1.interceptors = i1 i2\nagent1.sources.source1.interceptors.i1.type = static\nagent1.sources.source1.interceptors.i1.key = Type\nagent1.sources.source1.interceptors.i1.value = LOGIN\nagent1.sources.source1.interceptors.i2.type = timestamp\n# set sink1\nagent1.sinks.sink1.channel = channel1\nagent1.sinks.sink1.type = avro\nagent1.sinks.sink1.hostname = hadoop100\nagent1.sinks.sink1.port = 52020\n# set sink2\nagent1.sinks.sink2.channel = channel1\nagent1.sinks.sink2.type = avro\nagent1.sinks.sink2.hostname = hadoop101\nagent1.sinks.sink2.port = 52020\n#set sink group\nagent1.sinkgroups.sinkgroup1.sinks = sink1 sink2\n#set failover\nagent1.sinkgroups.sinkgroup1.processor.type = failover\nagent1.sinkgroups.sinkgroup1.processor.priority.sink1 = 10\nagent1.sinkgroups.sinkgroup1.processor.priority.sink2 = 1\nagent1.sinkgroups.sinkgroup1.processor.maxpenalty = 10000\n")])])]),e("h3",{attrs:{id:"_2-collector配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-collector配置"}},[n._v("#")]),n._v(" 2. collector配置")]),n._v(" "),e("p",[e("strong",[n._v("在两台collector上操作，除了修改hostname，其他配置项相同")])]),n._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[n._v('#set Agent name\nagent2.sources = source1\nagent2.channels = channel1\nagent2.sinks = sink1\n\n#set channel\nagent2.channels.channel1.type = memory\nagent2.channels.channel1.capacity = 1000\nagent2.channels.channel1.transactionCapacity = 100\n\n# other node,nna to nns\nagent2.sources.source1.type = avro\nagent2.sources.source1.bind = hadoop100   #此处修改\nagent2.sources.source1.port = 52020\n#增加拦截器 所有events,增加头,类似json格式里的"headers":{" key":" value"}\nagent2.sources.source1.interceptors = i1\nagent2.sources.source1.interceptors.i1.type = static\nagent2.sources.source1.interceptors.i1.key = Collector\nagent2.sources.source1.interceptors.i1.value = hadoop100  #此处修改\nagent2.sources.source1.channels = channel1\n#set sink to hdfs\n#agent2.sinks.sink1.type=logger\n#指定sink类型\nagent2.sinks.sink1.type=hdfs\nagent2.sinks.sink1.hdfs.path=hdfs://mycluster/flume\nagent2.sinks.sink1.hdfs.fileType=DataStream\nagent2.sinks.sink1.hdfs.writeFormat=TEXT\n#多久生成新的文件\nagent2.sinks.sink1.hdfs.rollInterval=5\nagent2.sinks.sink1.hdfs.rollSize=1000\nagent2.sinks.sink1.hdfs.rollCount=0\n#agent2.sinks.sink1.hdfs.rollCount=1\nagent2.sinks.sink1.hdfs.filePrefix=%Y-%m-%d\n#agent2.sinks.sink1.hdfs.filePrefix=%Y-%m-%d/%H%M/%S\nagent2.sinks.sink1.hdfs.fileSuffix=.txt\nagent2.sinks.sink1.channel=channel1\n')])])]),e("h3",{attrs:{id:"_3-先启动所有server-再启动所有client-否则会报错。"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-先启动所有server-再启动所有client-否则会报错。"}},[n._v("#")]),n._v(" 3. 先启动所有server，再启动所有client，否则会报错。")]),n._v(" "),e("p",[e("code",[n._v("[root@slave1] /usr/local/flume/conf$ ../bin/flume-ng agent -n agent1 -c ../conf -f flume-client.conf -Dflume.root.logger=DEBUG,console")]),n._v("\nflume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeHA_server.conf --name agent1 -Dflume.root.logger=INFO,console > /soft/module/flume/logs/flumeHA_server.log 2>&1 &")]),n._v(" "),e("p",[e("code",[n._v("[root@slave3] /usr/local/flume/conf$ ../bin/flume-ng agent --conf ../conf --conf-file flume-server.conf --name agent2 -Dflume.root.logger=INFO,console")]),n._v("\nflume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeHA_client.conf --name agent2 -Dflume.root.logger=DEBUG,console > /soft/module/flume/logs/flumeHA_client.log 2>&1 &")]),n._v(" "),e("h3",{attrs:{id:"_4-测试高可用功能"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-测试高可用功能"}},[n._v("#")]),n._v(" 4. 测试高可用功能")]),n._v(" "),e("ol",[e("li",[n._v("agent1上创建源消息\n"),e("code",[n._v('echo "hello failover" >> test.txt')])]),n._v(" "),e("li",[n._v("由于collector1的priority高，所以会收到，而collector2不会，查看控制台信息")]),n._v(" "),e("li",[n._v("停止collector1，在agent1上创建源消息\n"),e("code",[n._v('echo "hello failover1" >> test.txt')])]),n._v(" "),e("li",[n._v("查看collector2控制台")])]),n._v(" "),e("h3",{attrs:{id:"错误-配置文件没写对"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#错误-配置文件没写对"}},[n._v("#")]),n._v(" 错误: 配置文件没写对")]),n._v(" "),e("p",[e("strong",[n._v("error1: 因为网上的配置文件不全,所以sink部分是从之前的配置文件拷的, agent的名字忘记改了,所以引起了异常,修改之后重启了几次服务,就好使了")])])])}),[],!1,null,null,null);e.default=o.exports}}]);