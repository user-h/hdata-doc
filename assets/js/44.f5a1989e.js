(window.webpackJsonp=window.webpackJsonp||[]).push([[44],{374:function(e,n,a){"use strict";a.r(n);var t=a(3),s=Object(t.a)({},(function(){var e=this,n=e._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h3",{attrs:{id:"一-安装-flume-ng"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#一-安装-flume-ng"}},[e._v("#")]),e._v(" 一. 安装(flume-ng)")]),e._v(" "),n("ol",[n("li",[e._v("下载安装包 "),n("code",[e._v("apache-flume-1.9.0-bin.tar.gz")])]),e._v(" "),n("li",[e._v("上传 解压安装 "),n("code",[e._v("tar -zxvf apache-flume-1.9.0-bin.tar.gz")])]),e._v(" "),n("li",[e._v("重命名 "),n("code",[e._v("mv apache-flume-1.9.0-bin/ flume")])]),e._v(" "),n("li",[e._v("配置环境变量 "),n("code",[e._v("vim ~/.bashrc")])])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("# flume环境变量\nexport FLUME_HOME=/soft/flume\nexport PATH=$PATH:$FLUME_HOME/bin\n")])])]),n("p",[n("code",[e._v("source ~/.bashrc")])]),e._v(" "),n("h3",{attrs:{id:"安装-netcat-工具"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#安装-netcat-工具"}},[e._v("#")]),e._v(" 安装 netcat 工具")]),e._v(" "),n("p",[e._v("安装:"),n("code",[e._v("sudo yum install -y nc")]),e._v("\n判断 44444 端口是否被占用 "),n("code",[e._v("sudo netstat -tunlp | grep 44444")])]),e._v(" "),n("h3",{attrs:{id:"二-修改配置文件"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#二-修改配置文件"}},[e._v("#")]),e._v(" 二. 修改配置文件")]),e._v(" "),n("ol",[n("li",[e._v("flume-env.sh文件配置")])]),e._v(" "),n("ul",[n("li",[e._v("到${FLUME_HOME}/conf下，复制一份flume-env.sh文件\n"),n("code",[e._v("cp flume-env.sh.template flume-env.sh")])]),e._v(" "),n("li",[e._v("编辑"),n("code",[e._v("vim flume-env.sh")])])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("export JAVA_HOME=/soft/jdk1.8.0_161\n")])])]),n("ul",[n("li",[e._v("测试下flume是否能够正常运行\n"),n("code",[e._v("flume-ng version")])])]),e._v(" "),n("ol",{attrs:{start:"2"}},[n("li",[e._v("Flume服务启动")])]),e._v(" "),n("ul",[n("li",[e._v("创建文件夹  "),n("code",[e._v("mkdir logstodfs")])]),e._v(" "),n("li",[e._v("我们在conf文件夹下，创建一个"),n("code",[e._v("vim flume_hdfs.conf")]),e._v("\n添加内容")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("#source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#先配置单通道，定义source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#agent1 是该agent的名字，在启动的时候需要指定agent的名字\nagent1.sources=source1\nagent1.channels=channel1\nagent1.sinks=sink1\n\n##############配置source###################\n#source的类型\nagent1.sources.source1.type=spooldir\n#spooldir类型的source监控的目录\nagent1.sources.source1.spoolDir=/soft/flume/logstodfs\nagent1.sources.source1.fileHeader=false\nagent1.sources.source1.channels=channel1\nagent1.sources.source1.interceptors=i1\nagent1.sources.source1.interceptors.i1.type=timestamp\n#0.0.0.0表示本机\n#agent1.sources.source1.bind=0.0.0.0\n#使用的端口\n#agent1.sources.source1.port=44445\n#指定channel类型\nagent1.channels.channel1.type=file\n#file channle checkpoint文件的路径\nagent1.channels.channel1.checkpointDir=/soft/flume/tmp/point\n# file channel data文件的路径\nagent1.channels.channel1.dataDirs=/soft/flume/tmp\n\n#指定sink类型\nagent1.sinks.sink1.type=hdfs\nagent1.sinks.sink1.hdfs.path=hdfs://hadoop1:9000/flume\nagent1.sinks.sink1.hdfs.fileType=DataStream\nagent1.sinks.sink1.hdfs.writeFormat=TEXT\n#多久生成新的文件\nagent1.sinks.sink1.hdfs.rollInterval=5\nagent1.sinks.sink1.hdfs.rollSize=1000\nagent1.sinks.sink1.hdfs.rollCount=0\nagent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d\nagent1.sinks.sink1.hdfs.fileSuffix=.txt\n\nagent1.sinks.sink1.channel = channel1\n")])])]),n("ul",[n("li",[e._v("启动服务\n"),n("code",[e._v("flume-ng agent -c /soft/flume/conf -f /soft/flume/conf/flume_hdfs.conf -n agent1 -Dflume.root.logger=INFO,console")]),e._v("\n同")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("flume-ng agent -c $FLUME_HOME/conf/\n -f  $FLUME_HOME/conf/flume_hdfs.conf \n-n agent1\n-Dflume.root.logger=INFO,console\n")])])]),n("p",[e._v("其中flume-ng agent为固定写法\n-c指定flume-env.sh文件所在目录\n-f指定flume-hdfs.conf文件所在位置\n-n指定要启动的agent名称，我们在配置文件中配置的名称为agent1\n-Dflume.root.logger代表日志打印到控制台\n当然我们也可以使用nohup命令后台挂起程序")]),e._v(" "),n("h3",{attrs:{id:"三-数据采集"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#三-数据采集"}},[e._v("#")]),e._v(" 三. 数据采集")]),e._v(" "),n("ul",[n("li",[e._v("打开另一个终端")]),e._v(" "),n("li",[e._v("将某个文件（实验阶段建议不要太大）移动或复制到${FLUME_HOME}/logstohdfs目录下，那么flume就会自动读取该文件的数据并上传到hdfs\n"),n("code",[e._v("cp /soft/datas/short-student-utf8_classNO1.txt /soft/flume/logstodfs/")])]),e._v(" "),n("li",[e._v("查看第一个终端窗口(显示信息)")]),e._v(" "),n("li",[e._v("最后我们可以去hdfs系统查看我们采集到的数据文件")])]),e._v(" "),n("h3",{attrs:{id:"四-数据导入到hbase中"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#四-数据导入到hbase中"}},[e._v("#")]),e._v(" 四. 数据导入到hbase中")]),e._v(" "),n("ul",[n("li",[e._v("把jar包复制替换到/opt/flume/lib目录下面")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("/soft/hive/lib\nhbase-protocol-1.1.1.jar\nhbase-client-1.1.1.jar\nhbase-common-1.1.1.jar \nhbase-server-1.1.1.jar\nhbase-hadoop2-compat-1.1.1.jar \nhbase-hadoop-compat-1.1.1.jar\nhtrace-core-3.1.0-incubating.jar\n")])])]),n("p",[e._v("命令: "),n("code",[e._v("cp /soft/hive/lib/{hbase-protocol-1.1.1.jar,hbase-client-1.1.1.jar,hbase-common-1.1.1.jar,hbase-server-1.1.1.jar,hbase-hadoop2-compat-1.1.1.jar,hbase-hadoop-compat-1.1.1.jar,htrace-core-3.1.0-incubating.jar} /soft/flume/lib")])]),e._v(" "),n("ul",[n("li",[e._v("启动hbase,创建表 "),n("code",[e._v("hbase shell")]),e._v(" 创建表 "),n("code",[e._v('create "flume_hbase","info"')])]),e._v(" "),n("li",[e._v("写配置文件 flume_hbase.conf")]),e._v(" "),n("li",[e._v("启动服务 "),n("code",[e._v("flume-ng agent --conf-file /soft/flume/conf/flume-hbase.conf -n agent2 -Dflume.root.logger=INFO,console")])]),e._v(" "),n("li",[e._v("生成数据:\n"),n("code",[e._v('echo "hello flume">>/soft/flume/tmp/datas/flume_hbase.txt')]),e._v(" "),n("code",[e._v('echo "hello hbase">>/soft/flume/tmp/datas/flume_hbase.txt')])])]),e._v(" "),n("h3",{attrs:{id:"五-数据导入到hive中"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#五-数据导入到hive中"}},[e._v("#")]),e._v(" 五. 数据导入到hive中")]),e._v(" "),n("ol",[n("li",[e._v("写配置文件 flume_hive.conf")]),e._v(" "),n("li",[e._v("Flume 端服务器 hosts 配置文件修改(不整可否???)")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("vim /etc/hosts\n\n# myCluster 是你的集群名称，hdfs://myCluster/hellowold 通常用于 HDFS NameNode HA 模式下会用到这个地址\n192.168.1.1 node1.hadoop.com myCluster\n192.168.1.2 ndoe2.hadoop.com myCluster\n192.168.1.3 node3.hadoop.com\n")])])]),n("ol",{attrs:{start:"3"}},[n("li",[e._v("Hive 建表")])]),e._v(" "),n("ul",[n("li",[e._v("需要开启的策略 - ORC 格式存储 - 分桶 - 支持事务性 - 显式声明 transtions(也可以修改配置文件hive-site.xml)\n实测建表的时候不需要分桶。分桶会将文件分散,一个桶编号一个文件。日志收集写到 Hive 中就是为了实现数据聚合，解决小文件问题。")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("-- 是否支持并发\nSET hive.support.concurrency = true;\n-- 分桶是否被强制执行\nSET hive.enforce.bucketing = true;\n-- 非严格模式\nSET hive.exec.dynamic.partition.mode = nonstrict;\nSET hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;\n-- 是否开启事务性\nSET hive.compactor.initiator.on = true;\n\n-- 工作线程\nSET hive.compactor.worker.threads = 1;\n\n-- 建表\nCREATE TABLE <MY_HIVE_DB>.<MY_HIVE_TABLE>(\n  name string comment '姓名'\n  age string comment '年龄'\n  role string comment '角色'\n)\n-- 表明备注 \nCOMMENT '你好,中国'\n-- 创建分区\nPARTITIONED BY (\n    country STRING comment '国家',\n    month STRING comment '月份'\n)\n-- ORC 支持\nSTORED AS ORC TBLPROPERTIES ('transactional'='true');\n\nCREATE TABLE flume_hive.flume_hive(name string comment '姓名',age string comment '年龄',role string comment '角色')\nCOMMENT '你好,中国'\nPARTITIONED BY (country STRING comment '国家',month STRING comment '月份')\nSTORED AS ORC;\n")])])]),n("ol",{attrs:{start:"4"}},[n("li",[e._v("HDFS 目录权限修改\n"),n("code",[e._v("hadoop fs -chmod 777 -R /usr")]),e._v("(未测试)")]),e._v(" "),n("li",[e._v("Flume 写 Hive 依赖包(一说/soft/hive/hcatalog/share/hcatalog/下所有包)")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("calcite-core-1.16.0.3.0.0.0-1634.jar\nlibfb303-0.9.3.jar\nhive-hcatalog-core-3.1.0.3.0.0.0-1634.jar\nhadoop-mapreduce-client-core-3.1.0.3.0.0.0-1634.jar\nhive-exec-3.1.0.3.0.0.0-1634.jar\nhive-standalone-metastore-3.1.0.3.0.0.0-1634.jar\nhive-hcatalog-streaming-3.1.0.3.0.0.0-1634.jar\n")])])]),n("ol",{attrs:{start:"6"}},[n("li",[e._v("启动 Flume 服务\n"),n("code",[e._v("flume-ng agent -c conf/ -f /soft/flume/conf/flume_hive.conf -n agent3 -Dflume.root.logger=INFO,console")])]),e._v(" "),n("li",[e._v("趁热打铁：记录自己查错的思考方向")])]),e._v(" "),n("ul",[n("li",[e._v("输入文件格式必须为csv 或json")]),e._v(" "),n("li",[e._v("输出格式必须为orc格式")]),e._v(" "),n("li",[e._v("看日志文件(呃 暂时没找到)")]),e._v(" "),n("li",[e._v("修改hive-site配置文件(永久参数)")]),e._v(" "),n("li",[e._v("建表时必须分桶 分区 orc (挖坑记得加上)")]),e._v(" "),n("li",[e._v("flume配置文件sink的配置(端口号9083 必须有分区(partation)？)  最好参考官方文档")]),e._v(" "),n("li",[e._v("channel配置(连接 内存) source监控文件夹")]),e._v(" "),n("li",[e._v("MySQL下hive元数据(metastore)插入值 然后 commit;？")]),e._v(" "),n("li",[e._v("启动时hive (hive --service metastore -p 9083) hive --service hiveserver2")]),e._v(" "),n("li",[e._v("hive命令行设置临时参数")])])])}),[],!1,null,null,null);n.default=s.exports}}]);