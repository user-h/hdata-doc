(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{378:function(t,s,a){"use strict";a.r(s);var n=a(3),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"sql-to-hadoop"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sql-to-hadoop"}},[t._v("#")]),t._v(" sql to hadoop")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("导出数据：从Hadoop 的文件系统中导出数据到关系数据库mysql 等\nSqoop的本质还是一个命令行工具，和HDFS，Hive 相比，并没有什么高深的理论。")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("测试连接\nsqoop list-databases --connect jdbc:mysql://hadoop100 --username root --password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v("\n把数据导入hdfs\nsqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" --connect jdbc:mysql://8.8.8.100/test --username root --password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" --table emp --delete-target-dir\n\nsqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://8.8.8.100/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table emp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir\n\nsqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop100:3306/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table emp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v("\n数据导入到hive\nsqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop100:3306/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table emp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-import "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-overwrite "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-table emp_hive\n数据导入hbase"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("手动建表"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop100:3306/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table emp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id,name,degree,salary,dept"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--column-family "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"info"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-create-table "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-row-key "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-table "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase_emp"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--split-by "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v("\n\nhdfs数据导出\n先建表\nsqoop "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" --connect "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbc:mysql://192.168.94.137/test?useUnicode=true&characterEncoding=utf-8"')]),t._v("  --username root -password lishy2019 --export-dir /user/root/emp1/part-m-00000 --table EMP  --fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("','")]),t._v("\nsqoop作业\n")])])]),s("h2",{attrs:{id:"_1-导入数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-导入数据"}},[t._v("#")]),t._v(" 1.导入数据")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("在Sqoop中，“导入”概念指：从非大数据集群（RDBMS）向大数据集群（HDFS，HIVE，HBASE）中传输数据，叫做：导入，即使用import关键字。")]),t._v(" "),s("h3",{attrs:{id:"关系型数据库-rdbms-导入到hdfs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关系型数据库-rdbms-导入到hdfs"}},[t._v("#")]),t._v(" 关系型数据库(RDBMS)导入到HDFS")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("在mysql新建一张表并插入数据\nmysql -uroot -p123456789\ncreate database company"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ncreate table company.staff"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v(" int"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" primary key not null auto_increment, \n    name varchar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(", \n    sex varchar"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("255")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("))")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ninsert into company.staff"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name, sex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Thomas'")]),t._v(", "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Male'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\ninsert into company.staff"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("name, sex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" values"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Catalina'")]),t._v(", "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'FeMale'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n\n关系型数据库到HDFS\n全部导入\nbin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v("\n\n查询导入\nbin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--query "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'select name,sex from staff where id <=1 and $CONDITIONS;'")]),t._v("\n如果query后使用的是双引号，则"),s("span",{pre:!0,attrs:{class:"token variable"}},[t._v("$CONDITIONS")]),t._v("前必须加转移符，防止shell识别为自己的变量。\n\n导入指定列\nbin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns id,sex "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff\n\n使用sqoop关键字筛选查询导入数据\nbin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--where "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id=1"')]),t._v("\n")])])]),s("blockquote",[s("p",[t._v("[banana@hadoop100 ~]$ sqoop import --connect jdbc:mysql://8.8.8.100/test --username root --password 123456789 --table emp --delete-target-dir\n省略一万字\n20/03/30 15:27:08 ERROR tool.ImportTool: Import failed: No primary key could be found for table emp. Please specify one with --split-by or perform a sequential import with '-m 1'.\n原因:未加参数--num-mappers\n提示可以看出，在我们从mysql中导出的表没有设定主键，提示我们使用把--split-by或者把参数-m设置为1，这里大家会不会问到，这倒是是为什么呢？\nSqoop通可以过–split-by指定切分的字段，–m设置mapper的数量。通过这两个参数分解生成m个where子句，进行分段查询。\nsplit-by 根据不同的参数类型有不同的切分方法，如表共有100条数据其中id为int类型，并且我们指定–split-by id，我们不设置map数量使用默认的为四个，首先Sqoop会取获取切分字段的MIN()和MAX()即（–split -by），再根据map数量进行划分，这是字段值就会分为四个map：（1-25）（26-50）（51-75）（75-100）。\n根据MIN和MAX不同的类型采用不同的切分方式支持有Date,Text,Float,Integer， Boolean,NText,BigDecimal等等。\n所以，若导入的表中没有主键，将-m 设置称1或者设置split-by，即只有一个map运行，缺点是不能并行map录入数据。（注意，当-m 设置的值大于1时，split-by必须设置字段） 。\nsplit-by即便是int型，若不是连续有规律递增的话，各个map分配的数据是不均衡的，可能会有些map很忙，有些map几乎没有数据处理的情况。\n————————————————\n原文链接(错误集锦)：https://blog.csdn.net/yu0_zhang0/article/details/79069251")])]),t._v(" "),s("h3",{attrs:{id:"关系型数据库-rdbms-到hive"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#关系型数据库-rdbms-到hive"}},[t._v("#")]),t._v(" 关系型数据库(RDBMS)到Hive")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("bin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-import "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-overwrite "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hive-table staff_hive\n\n该过程分为两步，第一步将数据导入到HDFS，第二步将导入到HDFS的数据迁移到Hive仓库，第一步默认的临时目录是/user/用户名/表名\n")])])]),s("blockquote",[s("p",[t._v("ERROR hive.HiveConfig: Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is set correctly\n原因: 未设置HIVE_CONF_DIR\nvim ~/.bashrc\nhive环境变量配置\nexport HIVE_HOME=/soft/hive\nexport HIVE_CONF_DIR=$HIVE_HOME/conf\nexport PATH=$PATH:$HIVE_HOME/bin")])]),t._v(" "),s("blockquote",[s("p",[t._v("20/03/29 20:40:06 INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\nCaused by: java.net.ConnectException: Your endpoint configuration is wrong;\n原因:主机10020端口连接不上，应该是hadoop集群中datanode访问namenode的10020端口的问题，使用10020端口是jobhistory服务，在检查配置文件mapred-site.xml未发现错误\n"),s("property",[s("name",[t._v("mapreduce.jobhistory.address")]),t._v(" "),s("value",[t._v("主机名:10020")])],1),t._v(" "),s("property",[s("name",[t._v("mapreduce.jobhistory.webapp.address")]),t._v(" "),s("value",[t._v("主机名:19888")])],1),t._v("\n执行$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver\n主机10020端口开放")],1)]),t._v(" "),s("blockquote",[s("p",[t._v("Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf\n原因：缺少了hive-common-2.3.3.jar包，在hive的lib目录下，拷贝到sqoop的lib目录下即可。\ncp /soft/hive/lib/hive-common-2.3.6.jar /soft/sqoop/lib/\nhbase环境变量配置配置\nexport HBASE_HOME=/soft/hbase\nexport PATH=$PATH:$HBASE_HOME/bin\nZookeeper环境变量配置\nexport ZOOKEEPER_HOME=/soft/zookeeper\nexport PATH=$ZOOKEEPER_HOME/bin:$PATH")])]),t._v(" "),s("h3",{attrs:{id:"rdbms到hbase"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rdbms到hbase"}},[t._v("#")]),t._v(" RDBMS到Hbase")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("bin/sqoop "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--columns "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id,name,sex"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--column-family "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"info"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-create-table "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-row-key "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--hbase-table "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hbase_company"')]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--split-by "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("id")]),t._v("\n\n若没有自动创建 需手动创建\n")])])]),s("blockquote",[s("p",[t._v('Exception in thread "main" java.lang.NoSuchMethodError: org.apache.hadoop.hbase.client.HBaseAdmin.'),s("init"),t._v("(Lorg/apache/hadoop/conf/Configuration;)\n我已经将以下提到的jar手动添加到SQOOP_HOME/lib中-\n1: hbase-client-1.2.0.jar\n2: hbase-common-1.2.0.jar\n3: hbase-mapreduce-2.2.0.jar\n4: hbase-protocol-1.2.0.jar\n5: hbase-server-1.2.0.jar\n6: hbase-zookeeper-2.2.0.jar\n7: protobuf-java-2.5.0.jar")],1)]),t._v(" "),s("blockquote",[s("p",[t._v("版本不兼容???(sqoop1.4.7手动创建都不好使???)\nsqoop1.4.6只支持hbase1.0.1之前的版本自动创建表")])]),t._v(" "),s("h2",{attrs:{id:"_2-导出数据"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-导出数据"}},[t._v("#")]),t._v(" 2.导出数据")]),t._v(" "),s("hr"),t._v(" "),s("h3",{attrs:{id:"hive-hdfs到rdbms"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hive-hdfs到rdbms"}},[t._v("#")]),t._v(" HIVE/HDFS到RDBMS")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("bin/sqoop "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff1 "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--export-dir /user/hive/warehouse/staff_hive "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--input-fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v("\n\nMySQL表如果不存在 不会自动创建?useUnicode"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("true"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&")]),s("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t._v("characterEncoding")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("utf-8\n")])])]),s("h2",{attrs:{id:"sqoop-job"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-job"}},[t._v("#")]),t._v(" sqoop job")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("sqoop job命令的基本用法：")]),t._v(" "),s("ul",[s("li",[t._v("创建job：--create")]),t._v(" "),s("li",[t._v("删除job：--delete")]),t._v(" "),s("li",[t._v("执行job：--exec")]),t._v(" "),s("li",[t._v("显示job：--show")]),t._v(" "),s("li",[t._v("列出job：--list")])]),t._v(" "),s("p",[t._v("创建一个job(注意-- import中间有个空格,切勿忽视)")]),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("sqoop job --create firstjob "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n-- "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--connect jdbc:mysql://hadoop1:3306/company "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--username root "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--password "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--table staff "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--target-dir /user/test "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--delete-target-dir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--num-mappers "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("\n--fields-terminated-by "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v("\n\nsqoop job --list\n")])])]),s("h2",{attrs:{id:"sqoop-job安全配置"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#sqoop-job安全配置"}},[t._v("#")]),t._v(" Sqoop job安全配置")]),t._v(" "),s("hr"),t._v(" "),s("p",[t._v("默认情况下，创建的每个job在运行的时候都不会进行安全的认证。如果我们希望限制指定的sqoop job的执行，只有经过认证以后才能执行，这时候可以使用sqoop job的安全选项。Sqoop安装目录下，通过修改配置文件conf/sqoop-site.xml可以对job进行更高级的配置。实际上，我们使用了Sqoop的metastore工具，它能够对Sqoop进行细粒度的配置。\n我们要将MySQL数据库中的数据同步到Hive表，每次执行sqoop job都需要输入访问MySQL数据库的连接账号信息，可以设置sqoop.metastore.client.record.password的值为true。如果在conf/sqoop-site.xml中增加如下配置，会将连接账号信息存储到Sqoop的metastore中：")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("record"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("password"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("If")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" allow saved passwords in the metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("如果想要限制从外部调用执行Sqoop job，如将Sqoop job提交给Oozie调度程序，也会通过上面Sqoop的metastore配置的内容来进行验证。\n另外，Sqoop的metastore工具，可以允许我们指定为外部，例如使用外部主机上的MySQL数据库来存储元数据，可以在conf/sqoop-site.xml配置如下：")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autoconnect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("url"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("jdbc"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("mysql"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("10.95")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".3")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".49")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3306")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sqoop_metastore"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("The")]),t._v(" connect string "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("use")]),t._v(" when connecting "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("a")]),t._v("\n        job"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("management "),s("span",{pre:!0,attrs:{class:"token class-name"}},[s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")])]),t._v(" If")]),t._v(" unspecified"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("uses")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("~")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("You")]),t._v(" can specify a different path here"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autoconnect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("username"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("shirdrn"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("The")]),t._v(" username "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("bind")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("the")]),t._v(" metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autoconnect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("password"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("108l")]),t._v("oIOL"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("The")]),t._v(" password "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("bind")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("the")]),t._v(" metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("还有一个可与选择的配置项是，可以设置是否自动连接到外部metastore数据库，通过如下配置指定：")]),t._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("sqoop"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("metastore"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("enable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("autoconnect"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("If")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Sqoop")]),t._v(" will connect "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("to")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("a")]),t._v(" local metastore "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" job management when no other metastore arguments are provided"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("description"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("h2",{attrs:{id:"脚本打包"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#脚本打包"}},[t._v("#")]),t._v(" 脚本打包")]),t._v(" "),s("hr"),t._v(" "),s("div",{staticClass:"language-shell script extra-class"},[s("pre",{pre:!0,attrs:{class:"language-shell"}},[s("code",[t._v("编写脚本\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("vim")]),t._v(" job_HDFS_RDBMS.opt\n脚本内容"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("导出数据到mysql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v("export")]),t._v("\n--connect\njdbc:mysql://hadoop1:3306/company\n--username\nroot\n--password\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123456789")]),t._v("\n--table\nstaff\n--num-mappers\n"),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n--export-dir\n/user/hive/warehouse/staff_hive\n--input-fields-terminated-by\n"),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"'),s("span",{pre:!0,attrs:{class:"token entity",title:"\\t"}},[t._v("\\t")]),t._v('"')]),t._v("\n\n执行脚本\nbin/sqoop --options-file opt/job_HDFS2RDBMS.opt\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);