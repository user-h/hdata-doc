(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var a,s,o=e[0],l=e[1],c=e[2],p=0,m=[];p<o.length;p++)s=o[p],Object.prototype.hasOwnProperty.call(r,s)&&r[s]&&m.push(r[s][0]),r[s]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(n[a]=l[a]);for(d&&d(e);m.length;)m.shift()();return i.push.apply(i,c||[]),t()}function t(){for(var n,e=0;e<i.length;e++){for(var t=i[e],a=!0,o=1;o<t.length;o++){var l=t[o];0!==r[l]&&(a=!1)}a&&(i.splice(e--,1),n=s(s.s=t[0]))}return n}var a={},r={1:0},i=[];function s(e){if(a[e])return a[e].exports;var t=a[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,s),t.l=!0,t.exports}s.e=function(n){var e=[],t=r[n];if(0!==t)if(t)e.push(t[2]);else{var a=new Promise((function(e,a){t=r[n]=[e,a]}));e.push(t[2]=a);var i,o=document.createElement("script");o.charset="utf-8",o.timeout=120,s.nc&&o.setAttribute("nonce",s.nc),o.src=function(n){return s.p+"assets/js/"+({}[n]||n)+"."+{2:"82afd9cb",3:"5c0f818a",4:"528973e8",5:"53dd3ef1",6:"22885e2c",7:"814d9e01",8:"a242d330",9:"c7938acd",10:"7b061388",11:"3d84b622",12:"f524e450",13:"b3ff7d26",14:"3675e190",15:"676eac9f",16:"c546644f",17:"d80c3241",18:"bfa024db",19:"c4ebe893",20:"0c06c705",21:"e586d4fc",22:"d4747bce",23:"cfa91ca4",24:"77c960d1",25:"cc923a02",26:"432e9cf4",27:"3248ab2a",28:"67efb541",29:"e500a45f",30:"27916467",31:"db03022b",32:"40451343",33:"57a8afa5",34:"e8da6dc5",35:"25dea1e4",36:"ecc28683",37:"976e826a",38:"f1f7e891",39:"6daaca2d",40:"3766a207",41:"515be286",42:"87e45d55",43:"0eea2c15",44:"f5a1989e",45:"96eaa743",46:"6db88dae",47:"f3e98870",48:"138b9428",49:"b4e2bdb7",50:"6624a71f",51:"4273468b",52:"d69c448e",53:"3e61789b",54:"ed81b599",55:"a2edf6d0",56:"324986ae",57:"640caf90",58:"344d4730",59:"d9078674",60:"2afcb1b9",61:"996c28ca",62:"cb5e8bee",63:"146ed62c",64:"8bb9c50a",65:"460effd7",66:"f5294e94",67:"0da1dddd",68:"64117a5a",69:"ed33359f",70:"1250ab19",71:"f6a79a2a",72:"683057b4",73:"94e5450b",74:"fa587d94",75:"48871ae9",76:"447894b5",77:"da5dadf2",78:"a8553a08",79:"bd712952"}[n]+".js"}(n);var l=new Error;i=function(e){o.onerror=o.onload=null,clearTimeout(c);var t=r[n];if(0!==t){if(t){var a=e&&("load"===e.type?"missing":e.type),i=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+a+": "+i+")",l.name="ChunkLoadError",l.type=a,l.request=i,t[1](l)}r[n]=void 0}};var c=setTimeout((function(){i({type:"timeout",target:o})}),12e4);o.onerror=o.onload=i,document.head.appendChild(o)}return Promise.all(e)},s.m=n,s.c=a,s.d=function(n,e,t){s.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},s.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},s.t=function(n,e){if(1&e&&(n=s(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(s.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var a in n)s.d(t,a,function(e){return n[e]}.bind(null,a));return t},s.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return s.d(e,"a",e),e},s.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},s.p="/hdata-doc/",s.oe=function(n){throw console.error(n),n};var o=window.webpackJsonp=window.webpackJsonp||[],l=o.push.bind(o);o.push=e,o=o.slice();for(var c=0;c<o.length;c++)e(o[c]);var d=l;i.push([102,0]),t()}([function(n,e){n.exports=function(n){return"function"==typeof n}},function(n,e,t){var a=t(25),r=Function.prototype,i=r.bind,s=r.call,o=a&&i.bind(s,s);n.exports=a?function(n){return n&&o(n)}:function(n){return n&&function(){return s.apply(n,arguments)}}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e,t){"use strict";function a(n,e,t,a,r,i,s,o){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),a&&(c.functional=!0),i&&(c._scopeId="data-v-"+i),s?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),r&&r.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(s)},c._ssrRegister=l):r&&(l=o?function(){r.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:r),l)if(c.functional){c._injectStyles=l;var d=c.render;c.render=function(n,e){return l.call(e),d(n,e)}}else{var p=c.beforeCreate;c.beforeCreate=p?[].concat(p,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return a}))},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var a=t(67),r="object"==typeof self&&self&&self.Object===Object&&self,i=a||r||Function("return this")();n.exports=i},function(n,e,t){var a=t(4);n.exports=!a((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var a=t(1),r=t(45),i=a({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return i(r(n),e)}},function(n,e,t){var a=t(0);n.exports=function(n){return"object"==typeof n?null!==n:a(n)}},function(n,e,t){var a=t(157),r=t(160);n.exports=function(n,e){var t=r(n,e);return a(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return a})),t.d(e,"b",(function(){return i})),t.d(e,"j",(function(){return s})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return d})),t.d(e,"c",(function(){return p})),t.d(e,"f",(function(){return m})),t.d(e,"l",(function(){return u})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return g})),t.d(e,"k",(function(){return b})),t.d(e,"n",(function(){return y})),t.d(e,"a",(function(){return _}));const a=/#.*$/,r=/\.(md|html)$/,i=/\/$/,s=/^[a-z]+:/i;function o(n){return decodeURI(n).replace(a,"").replace(r,"")}function l(n){return s.test(n)}function c(n){return/^mailto:/.test(n)}function d(n){return/^tel:/.test(n)}function p(n){if(l(n))return n;if(!n)return"404";const e=n.match(a),t=e?e[0]:"",r=o(n);return i.test(r)?n:r+".html"+t}function m(n,e){const t=n.hash,r=function(n){const e=n&&n.match(a);if(e)return e[0]}(e);if(r&&t!==r)return!1;return o(n.path)===o(e)}function u(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const a=n.charAt(0);if("/"===a)return n;if("?"===a||"#"===a)return e+n;const r=e.split("/");t&&r[r.length-1]||r.pop();const i=n.replace(/^\//,"").split("/");for(let n=0;n<i.length;n++){const e=i[n];".."===e?r.pop():"."!==e&&r.push(e)}""!==r[0]&&r.unshift("");return r.join("/")}(e,t));const a=o(e);for(let e=0;e<n.length;e++)if(o(n[e].regularPath)===a)return Object.assign({},n[e],{type:"page",path:p(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function h(n,e,t,a){const{pages:r,themeConfig:i}=t,s=a&&i.locales&&i.locales[a]||i;if("auto"===(n.frontmatter.sidebar||s.sidebar||i.sidebar))return f(n);const o=s.sidebar||i.sidebar;if(o){const{base:t,config:a}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const a in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(a)))return{base:a,config:e[a]};var t;return{}}(e,o);return"auto"===a?f(n):a?a.map(n=>function n(e,t,a,r=1){if("string"==typeof e)return u(t,e,a);if(Array.isArray(e))return Object.assign(u(t,e[0],a),{title:e[1]});{r>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const i=e.children||[];return 0===i.length&&e.path?Object.assign(u(t,e.path,a),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:i.map(e=>n(e,t,a,r+1)),collapsable:!1!==e.collapsable}}}(n,r,t)):[]}return[]}function f(n){const e=g(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function g(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function b(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function y(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function v(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function _(n,e){return v(e)-v(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var a=t(14),r=t(142),i=t(143),s=a?a.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":s&&s in Object(n)?r(n):i(n)}},function(n,e,t){var a=t(6).Symbol;n.exports=a},function(n,e,t){var a=t(7),r=t(61),i=t(98),s=t(24),o=t(52),l=TypeError,c=Object.defineProperty,d=Object.getOwnPropertyDescriptor;e.f=a?i?function(n,e,t){if(s(n),e=o(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var a=d(n,e);a&&a.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:a.configurable,enumerable:"enumerable"in t?t.enumerable:a.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(s(n),e=o(e),s(t),r)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var a=t(2),r=t(0),i=function(n){return r(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?i(a[n]):a[n]&&a[n][e]}},function(n,e,t){var a=t(7),r=t(15),i=t(29);n.exports=a?function(n,e,t){return r.f(n,e,i(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var a=t(147),r=t(148),i=t(149),s=t(150),o=t(151);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=s,l.prototype.set=o,n.exports=l},function(n,e,t){var a=t(69);n.exports=function(n,e){for(var t=n.length;t--;)if(a(n[t][0],e))return t;return-1}},function(n,e,t){var a=t(10)(Object,"create");n.exports=a},function(n,e,t){var a=t(169);n.exports=function(n,e){var t=n.__data__;return a(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var a=t(40);n.exports=function(n){if("string"==typeof n||a(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var a,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(a=function(){var n,e,t={version:"0.2.0"},a=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(n,e,t){return n<e?e:n>t?t:n}function i(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(a[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=r(n,a.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(a.barSelector),d=a.speed,p=a.easing;return l.offsetWidth,s((function(e){""===a.positionUsing&&(a.positionUsing=t.getPositioningCSS()),o(c,function(n,e,t){var r;return(r="translate3d"===a.positionUsing?{transform:"translate3d("+i(n)+"%,0,0)"}:"translate"===a.positionUsing?{transform:"translate("+i(n)+"%,0)"}:{"margin-left":i(n)+"%"}).transition="all "+e+"ms "+t,r}(n,d,p)),1===n?(o(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){o(l,{transition:"all "+d+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),d)}),d)):setTimeout(e,d)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),a.trickleSpeed)};return a.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*r(Math.random()*e,.1,.95)),e=r(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*a.trickleRate)},n=0,e=0,t.promise=function(a){return a&&"resolved"!==a.state()?(0===e&&t.start(),n++,e++,a.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=a.template;var r,s=e.querySelector(a.barSelector),l=n?"-100":i(t.status||0),d=document.querySelector(a.parent);return o(s,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),a.showSpinner||(r=e.querySelector(a.spinnerSelector))&&m(r),d!=document.body&&c(d,"nprogress-custom-parent"),d.appendChild(e),e},t.remove=function(){d(document.documentElement,"nprogress-busy"),d(document.querySelector(a.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&m(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var s=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),o=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var a,r=n.length,i=e.charAt(0).toUpperCase()+e.slice(1);r--;)if((a=n[r]+i)in t)return a;return e}(t))}function a(n,e,a){e=t(e),n.style[e]=a}return function(n,e){var t,r,i=arguments;if(2==i.length)for(t in e)void 0!==(r=e[t])&&e.hasOwnProperty(t)&&a(n,t,r);else a(n,i[1],i[2])}}();function l(n,e){return("string"==typeof n?n:p(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=p(n),a=t+e;l(t,e)||(n.className=a.substring(1))}function d(n,e){var t,a=p(n);l(n,e)&&(t=a.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function p(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function m(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?a.call(e,t,e,n):a)||(n.exports=r)},function(n,e,t){var a=t(9),r=String,i=TypeError;n.exports=function(n){if(a(n))return n;throw i(r(n)+" is not an object")}},function(n,e,t){var a=t(4);n.exports=!a((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var a=t(43),r=t(51);n.exports=function(n){return a(r(n))}},function(n,e,t){var a=t(2),r=t(58),i=t(8),s=t(60),o=t(56),l=t(55),c=r("wks"),d=a.Symbol,p=d&&d.for,m=l?d:d&&d.withoutSetter||s;n.exports=function(n){if(!i(c,n)||!o&&"string"!=typeof c[n]){var e="Symbol."+n;o&&i(d,n)?c[n]=d[n]:c[n]=l&&p?p(e):m(e)}return c[n]}},function(n,e,t){var a=t(25),r=Function.prototype.call;n.exports=a?r.bind(r):function(){return r.apply(r,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var a=t(1),r=a({}.toString),i=a("".slice);n.exports=function(n){return i(r(n),8,-1)}},function(n,e,t){var a=t(2),r=t(32),i=a["__core-js_shared__"]||r("__core-js_shared__",{});n.exports=i},function(n,e,t){var a=t(2),r=Object.defineProperty;n.exports=function(n,e){try{r(a,n,{value:e,configurable:!0,writable:!0})}catch(t){a[n]=e}return e}},function(n,e,t){var a=t(141),r=t(12),i=Object.prototype,s=i.hasOwnProperty,o=i.propertyIsEnumerable,l=a(function(){return arguments}())?a:function(n){return r(n)&&s.call(n,"callee")&&!o.call(n,"callee")};n.exports=l},function(n,e,t){var a=t(10)(t(6),"Map");n.exports=a},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var a=t(161),r=t(168),i=t(170),s=t(171),o=t(172);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=s,l.prototype.set=o,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var a=t(5),r=t(40),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,s=/^\w*$/;n.exports=function(n,e){if(a(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!r(n))||(s.test(n)||!i.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var a=t(13),r=t(12);n.exports=function(n){return"symbol"==typeof n||r(n)&&"[object Symbol]"==a(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var a=t(2),r=t(50).f,i=t(17),s=t(110),o=t(32),l=t(63),c=t(122);n.exports=function(n,e){var t,d,p,m,u,h=n.target,f=n.global,g=n.stat;if(t=f?a:g?a[h]||o(h,{}):(a[h]||{}).prototype)for(d in e){if(m=e[d],p=n.dontCallGetSet?(u=r(t,d))&&u.value:t[d],!c(f?d:h+(g?".":"#")+d,n.forced)&&void 0!==p){if(typeof m==typeof p)continue;l(m,p)}(n.sham||p&&p.sham)&&i(m,"sham",!0),s(t,d,m,n)}}},function(n,e,t){var a=t(1),r=t(4),i=t(30),s=Object,o=a("".split);n.exports=r((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"==i(n)?o(n,""):s(n)}:s},function(n,e,t){var a=t(0),r=t(108),i=TypeError;n.exports=function(n){if(a(n))return n;throw i(r(n)+" is not a function")}},function(n,e,t){var a=t(51),r=Object;n.exports=function(n){return r(a(n))}},function(n,e){n.exports={}},function(n,e,t){var a=t(120);n.exports=function(n){return a(n.length)}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,i=/^0o[0-7]+$/i,s=parseInt,o="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=o||l||Function("return this")(),d=Object.prototype.toString,p=Math.max,m=Math.min,u=function(){return c.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function f(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==d.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var o=r.test(n);return o||i.test(n)?s(n.slice(2),o?2:8):a.test(n)?NaN:+n}n.exports=function(n,e,t){var a,r,i,s,o,l,c=0,d=!1,g=!1,b=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function y(e){var t=a,i=r;return a=r=void 0,c=e,s=n.apply(i,t)}function v(n){return c=n,o=setTimeout(x,e),d?y(n):s}function _(n){var t=n-l;return void 0===l||t>=e||t<0||g&&n-c>=i}function x(){var n=u();if(_(n))return k(n);o=setTimeout(x,function(n){var t=e-(n-l);return g?m(t,i-(n-c)):t}(n))}function k(n){return o=void 0,b&&a?y(n):(a=r=void 0,s)}function S(){var n=u(),t=_(n);if(a=arguments,r=this,l=n,t){if(void 0===o)return v(l);if(g)return o=setTimeout(x,e),y(l)}return void 0===o&&(o=setTimeout(x,e)),s}return e=f(e)||0,h(t)&&(d=!!t.leading,i=(g="maxWait"in t)?p(f(t.maxWait)||0,e):i,b="trailing"in t?!!t.trailing:b),S.cancel=function(){void 0!==o&&clearTimeout(o),c=0,a=l=r=o=void 0},S.flush=function(){return void 0===o?s:k(u())},S}},function(n,e,t){var a=t(7),r=t(28),i=t(104),s=t(29),o=t(26),l=t(52),c=t(8),d=t(61),p=Object.getOwnPropertyDescriptor;e.f=a?p:function(n,e){if(n=o(n),e=l(e),d)try{return p(n,e)}catch(n){}if(c(n,e))return s(!r(i.f,n,e),n[e])}},function(n,e){var t=TypeError;n.exports=function(n){if(null==n)throw t("Can't call method on "+n);return n}},function(n,e,t){var a=t(105),r=t(53);n.exports=function(n){var e=a(n,"string");return r(e)?e:e+""}},function(n,e,t){var a=t(16),r=t(0),i=t(54),s=t(55),o=Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=a("Symbol");return r(e)&&i(e.prototype,o(n))}},function(n,e,t){var a=t(1);n.exports=a({}.isPrototypeOf)},function(n,e,t){var a=t(56);n.exports=a&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var a=t(57),r=t(4);n.exports=!!Object.getOwnPropertySymbols&&!r((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&a&&a<41}))},function(n,e,t){var a,r,i=t(2),s=t(106),o=i.process,l=i.Deno,c=o&&o.versions||l&&l.version,d=c&&c.v8;d&&(r=(a=d.split("."))[0]>0&&a[0]<4?1:+(a[0]+a[1])),!r&&s&&(!(a=s.match(/Edge\/(\d+)/))||a[1]>=74)&&(a=s.match(/Chrome\/(\d+)/))&&(r=+a[1]),n.exports=r},function(n,e,t){var a=t(59),r=t(31);(n.exports=function(n,e){return r[n]||(r[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.23.4",mode:a?"pure":"global",copyright:"© 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.23.4/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var a=t(1),r=0,i=Math.random(),s=a(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+s(++r+i,36)}},function(n,e,t){var a=t(7),r=t(4),i=t(97);n.exports=!a&&!r((function(){return 7!=Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var a=t(1),r=t(0),i=t(31),s=a(Function.toString);r(i.inspectSource)||(i.inspectSource=function(n){return s(n)}),n.exports=i.inspectSource},function(n,e,t){var a=t(8),r=t(115),i=t(50),s=t(15);n.exports=function(n,e,t){for(var o=r(e),l=s.f,c=i.f,d=0;d<o.length;d++){var p=o[d];a(n,p)||t&&a(t,p)||l(n,p,c(e,p))}}},function(n,e,t){var a=t(119);n.exports=function(n){var e=+n;return e!=e||0===e?0:a(e)}},function(n,e,t){var a=t(1),r=t(24),i=t(129);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=a(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(t,[]),e=t instanceof Array}catch(n){}return function(t,a){return r(t),i(a),e?n(t,a):t.__proto__=a,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,a=e.length,r=n.length;++t<a;)n[r+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var a=t(18),r=t(152),i=t(153),s=t(154),o=t(155),l=t(156);function c(n){var e=this.__data__=new a(n);this.size=e.size}c.prototype.clear=r,c.prototype.delete=i,c.prototype.get=s,c.prototype.has=o,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var a=t(13),r=t(35);n.exports=function(n){if(!r(n))return!1;var e=a(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var a=t(173),r=t(12);n.exports=function n(e,t,i,s,o){return e===t||(null==e||null==t||!r(e)&&!r(t)?e!=e&&t!=t:a(e,t,i,s,n,o))}},function(n,e,t){var a=t(74),r=t(176),i=t(75);n.exports=function(n,e,t,s,o,l){var c=1&t,d=n.length,p=e.length;if(d!=p&&!(c&&p>d))return!1;var m=l.get(n),u=l.get(e);if(m&&u)return m==e&&u==n;var h=-1,f=!0,g=2&t?new a:void 0;for(l.set(n,e),l.set(e,n);++h<d;){var b=n[h],y=e[h];if(s)var v=c?s(y,b,h,e,n,l):s(b,y,h,n,e,l);if(void 0!==v){if(v)continue;f=!1;break}if(g){if(!r(e,(function(n,e){if(!i(g,e)&&(b===n||o(b,n,t,s,l)))return g.push(e)}))){f=!1;break}}else if(b!==y&&!o(b,y,t,s,l)){f=!1;break}}return l.delete(n),l.delete(e),f}},function(n,e,t){var a=t(36),r=t(174),i=t(175);function s(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new a;++e<t;)this.add(n[e])}s.prototype.add=s.prototype.push=r,s.prototype.has=i,n.exports=s},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var a=t(186),r=t(192),i=t(80);n.exports=function(n){return i(n)?a(n):r(n)}},function(n,e,t){(function(n){var a=t(6),r=t(188),i=e&&!e.nodeType&&e,s=i&&"object"==typeof n&&n&&!n.nodeType&&n,o=s&&s.exports===i?a.Buffer:void 0,l=(o?o.isBuffer:void 0)||r;n.exports=l}).call(this,t(48)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var a=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==a||"symbol"!=a&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var a=t(189),r=t(190),i=t(191),s=i&&i.isTypedArray,o=s?r(s):a;n.exports=o},function(n,e,t){var a=t(70),r=t(38);n.exports=function(n){return null!=n&&r(n.length)&&!a(n)}},function(n,e,t){var a=t(10)(t(6),"Set");n.exports=a},function(n,e,t){var a=t(35);n.exports=function(n){return n==n&&!a(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var a=t(85),r=t(22);n.exports=function(n,e){for(var t=0,i=(e=a(e,n)).length;null!=n&&t<i;)n=n[r(e[t++])];return t&&t==i?n:void 0}},function(n,e,t){var a=t(5),r=t(39),i=t(203),s=t(206);n.exports=function(n,e){return a(n)?n:r(n,e)?[n]:i(s(n))}},function(n,e){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var a=t(139),r=t(144),i=t(215),s=t(223),o=t(232),l=t(101),c=i((function(n){var e=l(n);return o(e)&&(e=void 0),s(a(n,1,o,!0),r(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var a=/["'&<>]/;n.exports=function(n){var e,t=""+n,r=a.exec(t);if(!r)return t;var i="",s=0,o=0;for(s=r.index;s<t.length;s++){switch(t.charCodeAt(s)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}o!==s&&(i+=t.substring(o,s)),o=s+1,i+=e}return o!==s?i+t.substring(o,s):i}},function(n,e,t){"use strict";t.r(e);var a={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},r=(t(235),t(3)),i=Object(r.a)(a,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=i.exports},function(n,e,t){"use strict";t.r(e);var a={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},r=(t(236),t(3)),i=Object(r.a)(a,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,a){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":a===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(a)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=i.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var a=t(2),r=t(9),i=a.document,s=r(i)&&r(i.createElement);n.exports=function(n){return s?i.createElement(n):{}}},function(n,e,t){var a=t(7),r=t(4);n.exports=a&&r((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var a=t(58),r=t(60),i=a("keys");n.exports=function(n){return i[n]||(i[n]=r(n))}},function(n,e,t){var a=t(1),r=t(8),i=t(26),s=t(117).indexOf,o=t(46),l=a([].push);n.exports=function(n,e){var t,a=i(n),c=0,d=[];for(t in a)!r(o,t)&&r(a,t)&&l(d,t);for(;e.length>c;)r(a,t=e[c++])&&(~s(d,t)||l(d,t));return d}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(242)},function(n,e,t){"use strict";var a=t(42),r=t(123).left,i=t(124),s=t(57),o=t(125);a({target:"Array",proto:!0,forced:!i("reduce")||!o&&s>79&&s<83},{reduce:function(n){var e=arguments.length;return r(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var a={}.propertyIsEnumerable,r=Object.getOwnPropertyDescriptor,i=r&&!a.call({1:2},1);e.f=i?function(n){var e=r(this,n);return!!e&&e.enumerable}:a},function(n,e,t){var a=t(28),r=t(9),i=t(53),s=t(107),o=t(109),l=t(27),c=TypeError,d=l("toPrimitive");n.exports=function(n,e){if(!r(n)||i(n))return n;var t,l=s(n,d);if(l){if(void 0===e&&(e="default"),t=a(l,n,e),!r(t)||i(t))return t;throw c("Can't convert object to primitive value")}return void 0===e&&(e="number"),o(n,e)}},function(n,e,t){var a=t(16);n.exports=a("navigator","userAgent")||""},function(n,e,t){var a=t(44);n.exports=function(n,e){var t=n[e];return null==t?void 0:a(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var a=t(28),r=t(0),i=t(9),s=TypeError;n.exports=function(n,e){var t,o;if("string"===e&&r(t=n.toString)&&!i(o=a(t,n)))return o;if(r(t=n.valueOf)&&!i(o=a(t,n)))return o;if("string"!==e&&r(t=n.toString)&&!i(o=a(t,n)))return o;throw s("Can't convert object to primitive value")}},function(n,e,t){var a=t(0),r=t(15),i=t(111),s=t(32);n.exports=function(n,e,t,o){o||(o={});var l=o.enumerable,c=void 0!==o.name?o.name:e;if(a(t)&&i(t,c,o),o.global)l?n[e]=t:s(e,t);else{try{o.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:r.f(n,e,{value:t,enumerable:!1,configurable:!o.nonConfigurable,writable:!o.nonWritable})}return n}},function(n,e,t){var a=t(4),r=t(0),i=t(8),s=t(7),o=t(112).CONFIGURABLE,l=t(62),c=t(113),d=c.enforce,p=c.get,m=Object.defineProperty,u=s&&!a((function(){return 8!==m((function(){}),"length",{value:8}).length})),h=String(String).split("String"),f=n.exports=function(n,e,t){"Symbol("===String(e).slice(0,7)&&(e="["+String(e).replace(/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!i(n,"name")||o&&n.name!==e)&&(s?m(n,"name",{value:e,configurable:!0}):n.name=e),u&&t&&i(t,"arity")&&n.length!==t.arity&&m(n,"length",{value:t.arity});try{t&&i(t,"constructor")&&t.constructor?s&&m(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var a=d(n);return i(a,"source")||(a.source=h.join("string"==typeof e?e:"")),n};Function.prototype.toString=f((function(){return r(this)&&p(this).source||l(this)}),"toString")},function(n,e,t){var a=t(7),r=t(8),i=Function.prototype,s=a&&Object.getOwnPropertyDescriptor,o=r(i,"name"),l=o&&"something"===function(){}.name,c=o&&(!a||a&&s(i,"name").configurable);n.exports={EXISTS:o,PROPER:l,CONFIGURABLE:c}},function(n,e,t){var a,r,i,s=t(114),o=t(2),l=t(1),c=t(9),d=t(17),p=t(8),m=t(31),u=t(99),h=t(46),f=o.TypeError,g=o.WeakMap;if(s||m.state){var b=m.state||(m.state=new g),y=l(b.get),v=l(b.has),_=l(b.set);a=function(n,e){if(v(b,n))throw new f("Object already initialized");return e.facade=n,_(b,n,e),e},r=function(n){return y(b,n)||{}},i=function(n){return v(b,n)}}else{var x=u("state");h[x]=!0,a=function(n,e){if(p(n,x))throw new f("Object already initialized");return e.facade=n,d(n,x,e),e},r=function(n){return p(n,x)?n[x]:{}},i=function(n){return p(n,x)}}n.exports={set:a,get:r,has:i,enforce:function(n){return i(n)?r(n):a(n,{})},getterFor:function(n){return function(e){var t;if(!c(e)||(t=r(e)).type!==n)throw f("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var a=t(2),r=t(0),i=t(62),s=a.WeakMap;n.exports=r(s)&&/native code/.test(i(s))},function(n,e,t){var a=t(16),r=t(1),i=t(116),s=t(121),o=t(24),l=r([].concat);n.exports=a("Reflect","ownKeys")||function(n){var e=i.f(o(n)),t=s.f;return t?l(e,t(n)):e}},function(n,e,t){var a=t(100),r=t(96).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return a(n,r)}},function(n,e,t){var a=t(26),r=t(118),i=t(47),s=function(n){return function(e,t,s){var o,l=a(e),c=i(l),d=r(s,c);if(n&&t!=t){for(;c>d;)if((o=l[d++])!=o)return!0}else for(;c>d;d++)if((n||d in l)&&l[d]===t)return n||d||0;return!n&&-1}};n.exports={includes:s(!0),indexOf:s(!1)}},function(n,e,t){var a=t(64),r=Math.max,i=Math.min;n.exports=function(n,e){var t=a(n);return t<0?r(t+e,0):i(t,e)}},function(n,e){var t=Math.ceil,a=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?a:t)(e)}},function(n,e,t){var a=t(64),r=Math.min;n.exports=function(n){return n>0?r(a(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var a=t(4),r=t(0),i=/#|\.prototype\./,s=function(n,e){var t=l[o(n)];return t==d||t!=c&&(r(e)?a(e):!!e)},o=s.normalize=function(n){return String(n).replace(i,".").toLowerCase()},l=s.data={},c=s.NATIVE="N",d=s.POLYFILL="P";n.exports=s},function(n,e,t){var a=t(44),r=t(45),i=t(43),s=t(47),o=TypeError,l=function(n){return function(e,t,l,c){a(t);var d=r(e),p=i(d),m=s(d),u=n?m-1:0,h=n?-1:1;if(l<2)for(;;){if(u in p){c=p[u],u+=h;break}if(u+=h,n?u<0:m<=u)throw o("Reduce of empty array with no initial value")}for(;n?u>=0:m>u;u+=h)u in p&&(c=t(c,p[u],u,d));return c}};n.exports={left:l(!1),right:l(!0)}},function(n,e,t){"use strict";var a=t(4);n.exports=function(n,e){var t=[][n];return!!t&&a((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var a=t(30),r=t(2);n.exports="process"==a(r.process)},function(n,e,t){var a=t(42),r=t(2),i=t(127),s=t(128),o=r.WebAssembly,l=7!==Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=s(n,e,l),a({global:!0,constructor:!0,arity:1,forced:l},t)},d=function(n,e){if(o&&o[n]){var t={};t[n]=s("WebAssembly."+n,e,l),a({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return i(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return i(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return i(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return i(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return i(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return i(n,this,arguments)}})),c("URIError",(function(n){return function(e){return i(n,this,arguments)}})),d("CompileError",(function(n){return function(e){return i(n,this,arguments)}})),d("LinkError",(function(n){return function(e){return i(n,this,arguments)}})),d("RuntimeError",(function(n){return function(e){return i(n,this,arguments)}}))},function(n,e,t){var a=t(25),r=Function.prototype,i=r.apply,s=r.call;n.exports="object"==typeof Reflect&&Reflect.apply||(a?s.bind(i):function(){return s.apply(i,arguments)})},function(n,e,t){"use strict";var a=t(16),r=t(8),i=t(17),s=t(54),o=t(65),l=t(63),c=t(130),d=t(131),p=t(132),m=t(136),u=t(137),h=t(138),f=t(7),g=t(59);n.exports=function(n,e,t,b){var y=b?2:1,v=n.split("."),_=v[v.length-1],x=a.apply(null,v);if(x){var k=x.prototype;if(!g&&r(k,"cause")&&delete k.cause,!t)return x;var S=a("Error"),w=e((function(n,e){var t=p(b?e:n,void 0),a=b?new x(n):new x;return void 0!==t&&i(a,"message",t),h&&i(a,"stack",u(a.stack,2)),this&&s(k,this)&&d(a,this,w),arguments.length>y&&m(a,arguments[y]),a}));if(w.prototype=k,"Error"!==_?o?o(w,S):l(w,S,{name:!0}):f&&"stackTraceLimit"in x&&(c(w,x,"stackTraceLimit"),c(w,x,"prepareStackTrace")),l(w,x),!g)try{k.name!==_&&i(k,"name",_),k.constructor=w}catch(n){}return w}}},function(n,e,t){var a=t(0),r=String,i=TypeError;n.exports=function(n){if("object"==typeof n||a(n))return n;throw i("Can't set "+r(n)+" as a prototype")}},function(n,e,t){var a=t(15).f;n.exports=function(n,e,t){t in n||a(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var a=t(0),r=t(9),i=t(65);n.exports=function(n,e,t){var s,o;return i&&a(s=e.constructor)&&s!==t&&r(o=s.prototype)&&o!==t.prototype&&i(n,o),n}},function(n,e,t){var a=t(133);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:a(n)}},function(n,e,t){var a=t(134),r=String;n.exports=function(n){if("Symbol"===a(n))throw TypeError("Cannot convert a Symbol value to a string");return r(n)}},function(n,e,t){var a=t(135),r=t(0),i=t(30),s=t(27)("toStringTag"),o=Object,l="Arguments"==i(function(){return arguments}());n.exports=a?i:function(n){var e,t,a;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=o(n),s))?t:l?i(e):"Object"==(a=i(e))&&r(e.callee)?"Arguments":a}},function(n,e,t){var a={};a[t(27)("toStringTag")]="z",n.exports="[object z]"===String(a)},function(n,e,t){var a=t(9),r=t(17);n.exports=function(n,e){a(e)&&"cause"in e&&r(n,"cause",e.cause)}},function(n,e,t){var a=t(1),r=Error,i=a("".replace),s=String(r("zxcasd").stack),o=/\n\s*at [^:]*:[^\n]*/,l=o.test(s);n.exports=function(n,e){if(l&&"string"==typeof n&&!r.prepareStackTrace)for(;e--;)n=i(n,o,"");return n}},function(n,e,t){var a=t(4),r=t(29);n.exports=!a((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",r(1,7)),7!==n.stack)}))},function(n,e,t){var a=t(66),r=t(140);n.exports=function n(e,t,i,s,o){var l=-1,c=e.length;for(i||(i=r),o||(o=[]);++l<c;){var d=e[l];t>0&&i(d)?t>1?n(d,t-1,i,s,o):a(o,d):s||(o[o.length]=d)}return o}},function(n,e,t){var a=t(14),r=t(33),i=t(5),s=a?a.isConcatSpreadable:void 0;n.exports=function(n){return i(n)||r(n)||!!(s&&n&&n[s])}},function(n,e,t){var a=t(13),r=t(12);n.exports=function(n){return r(n)&&"[object Arguments]"==a(n)}},function(n,e,t){var a=t(14),r=Object.prototype,i=r.hasOwnProperty,s=r.toString,o=a?a.toStringTag:void 0;n.exports=function(n){var e=i.call(n,o),t=n[o];try{n[o]=void 0;var a=!0}catch(n){}var r=s.call(n);return a&&(e?n[o]=t:delete n[o]),r}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var a=t(145),r=t(201),i=t(41),s=t(5),o=t(212);n.exports=function(n){return"function"==typeof n?n:null==n?i:"object"==typeof n?s(n)?r(n[0],n[1]):a(n):o(n)}},function(n,e,t){var a=t(146),r=t(200),i=t(83);n.exports=function(n){var e=r(n);return 1==e.length&&e[0][2]?i(e[0][0],e[0][1]):function(t){return t===n||a(t,n,e)}}},function(n,e,t){var a=t(68),r=t(72);n.exports=function(n,e,t,i){var s=t.length,o=s,l=!i;if(null==n)return!o;for(n=Object(n);s--;){var c=t[s];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++s<o;){var d=(c=t[s])[0],p=n[d],m=c[1];if(l&&c[2]){if(void 0===p&&!(d in n))return!1}else{var u=new a;if(i)var h=i(p,m,d,n,e,u);if(!(void 0===h?r(m,p,3,i,u):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var a=t(19),r=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=a(e,n);return!(t<0)&&(t==e.length-1?e.pop():r.call(e,t,1),--this.size,!0)}},function(n,e,t){var a=t(19);n.exports=function(n){var e=this.__data__,t=a(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var a=t(19);n.exports=function(n){return a(this.__data__,n)>-1}},function(n,e,t){var a=t(19);n.exports=function(n,e){var t=this.__data__,r=a(t,n);return r<0?(++this.size,t.push([n,e])):t[r][1]=e,this}},function(n,e,t){var a=t(18);n.exports=function(){this.__data__=new a,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var a=t(18),r=t(34),i=t(36);n.exports=function(n,e){var t=this.__data__;if(t instanceof a){var s=t.__data__;if(!r||s.length<199)return s.push([n,e]),this.size=++t.size,this;t=this.__data__=new i(s)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var a=t(70),r=t(158),i=t(35),s=t(71),o=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,d=l.toString,p=c.hasOwnProperty,m=RegExp("^"+d.call(p).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!i(n)||r(n))&&(a(n)?m:o).test(s(n))}},function(n,e,t){var a,r=t(159),i=(a=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+a:"";n.exports=function(n){return!!i&&i in n}},function(n,e,t){var a=t(6)["__core-js_shared__"];n.exports=a},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var a=t(162),r=t(18),i=t(34);n.exports=function(){this.size=0,this.__data__={hash:new a,map:new(i||r),string:new a}}},function(n,e,t){var a=t(163),r=t(164),i=t(165),s=t(166),o=t(167);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var a=n[e];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=r,l.prototype.get=i,l.prototype.has=s,l.prototype.set=o,n.exports=l},function(n,e,t){var a=t(20);n.exports=function(){this.__data__=a?a(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var a=t(20),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(a){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(e,n)?e[n]:void 0}},function(n,e,t){var a=t(20),r=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return a?void 0!==e[n]:r.call(e,n)}},function(n,e,t){var a=t(20);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=a&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var a=t(21);n.exports=function(n){var e=a(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var a=t(21);n.exports=function(n){return a(this,n).get(n)}},function(n,e,t){var a=t(21);n.exports=function(n){return a(this,n).has(n)}},function(n,e,t){var a=t(21);n.exports=function(n,e){var t=a(this,n),r=t.size;return t.set(n,e),this.size+=t.size==r?0:1,this}},function(n,e,t){var a=t(68),r=t(73),i=t(177),s=t(180),o=t(196),l=t(5),c=t(77),d=t(79),p="[object Object]",m=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,u,h,f){var g=l(n),b=l(e),y=g?"[object Array]":o(n),v=b?"[object Array]":o(e),_=(y="[object Arguments]"==y?p:y)==p,x=(v="[object Arguments]"==v?p:v)==p,k=y==v;if(k&&c(n)){if(!c(e))return!1;g=!0,_=!1}if(k&&!_)return f||(f=new a),g||d(n)?r(n,e,t,u,h,f):i(n,e,y,t,u,h,f);if(!(1&t)){var S=_&&m.call(n,"__wrapped__"),w=x&&m.call(e,"__wrapped__");if(S||w){var E=S?n.value():n,T=w?e.value():e;return f||(f=new a),h(E,T,t,u,f)}}return!!k&&(f||(f=new a),s(n,e,t,u,h,f))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length;++t<a;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var a=t(14),r=t(178),i=t(69),s=t(73),o=t(179),l=t(37),c=a?a.prototype:void 0,d=c?c.valueOf:void 0;n.exports=function(n,e,t,a,c,p,m){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!p(new r(n),new r(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var u=o;case"[object Set]":var h=1&a;if(u||(u=l),n.size!=e.size&&!h)return!1;var f=m.get(n);if(f)return f==e;a|=2,m.set(n,e);var g=s(u(n),u(e),a,c,p,m);return m.delete(n),g;case"[object Symbol]":if(d)return d.call(n)==d.call(e)}return!1}},function(n,e,t){var a=t(6).Uint8Array;n.exports=a},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,a){t[++e]=[a,n]})),t}},function(n,e,t){var a=t(181),r=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,i,s,o){var l=1&t,c=a(n),d=c.length;if(d!=a(e).length&&!l)return!1;for(var p=d;p--;){var m=c[p];if(!(l?m in e:r.call(e,m)))return!1}var u=o.get(n),h=o.get(e);if(u&&h)return u==e&&h==n;var f=!0;o.set(n,e),o.set(e,n);for(var g=l;++p<d;){var b=n[m=c[p]],y=e[m];if(i)var v=l?i(y,b,m,e,n,o):i(b,y,m,n,e,o);if(!(void 0===v?b===y||s(b,y,t,i,o):v)){f=!1;break}g||(g="constructor"==m)}if(f&&!g){var _=n.constructor,x=e.constructor;_==x||!("constructor"in n)||!("constructor"in e)||"function"==typeof _&&_ instanceof _&&"function"==typeof x&&x instanceof x||(f=!1)}return o.delete(n),o.delete(e),f}},function(n,e,t){var a=t(182),r=t(183),i=t(76);n.exports=function(n){return a(n,i,r)}},function(n,e,t){var a=t(66),r=t(5);n.exports=function(n,e,t){var i=e(n);return r(n)?i:a(i,t(n))}},function(n,e,t){var a=t(184),r=t(185),i=Object.prototype.propertyIsEnumerable,s=Object.getOwnPropertySymbols,o=s?function(n){return null==n?[]:(n=Object(n),a(s(n),(function(e){return i.call(n,e)})))}:r;n.exports=o},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length,r=0,i=[];++t<a;){var s=n[t];e(s,t,n)&&(i[r++]=s)}return i}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var a=t(187),r=t(33),i=t(5),s=t(77),o=t(78),l=t(79),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=i(n),d=!t&&r(n),p=!t&&!d&&s(n),m=!t&&!d&&!p&&l(n),u=t||d||p||m,h=u?a(n.length,String):[],f=h.length;for(var g in n)!e&&!c.call(n,g)||u&&("length"==g||p&&("offset"==g||"parent"==g)||m&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||o(g,f))||h.push(g);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,a=Array(n);++t<n;)a[t]=e(t);return a}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var a=t(13),r=t(38),i=t(12),s={};s["[object Float32Array]"]=s["[object Float64Array]"]=s["[object Int8Array]"]=s["[object Int16Array]"]=s["[object Int32Array]"]=s["[object Uint8Array]"]=s["[object Uint8ClampedArray]"]=s["[object Uint16Array]"]=s["[object Uint32Array]"]=!0,s["[object Arguments]"]=s["[object Array]"]=s["[object ArrayBuffer]"]=s["[object Boolean]"]=s["[object DataView]"]=s["[object Date]"]=s["[object Error]"]=s["[object Function]"]=s["[object Map]"]=s["[object Number]"]=s["[object Object]"]=s["[object RegExp]"]=s["[object Set]"]=s["[object String]"]=s["[object WeakMap]"]=!1,n.exports=function(n){return i(n)&&r(n.length)&&!!s[a(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var a=t(67),r=e&&!e.nodeType&&e,i=r&&"object"==typeof n&&n&&!n.nodeType&&n,s=i&&i.exports===r&&a.process,o=function(){try{var n=i&&i.require&&i.require("util").types;return n||s&&s.binding&&s.binding("util")}catch(n){}}();n.exports=o}).call(this,t(48)(n))},function(n,e,t){var a=t(193),r=t(194),i=Object.prototype.hasOwnProperty;n.exports=function(n){if(!a(n))return r(n);var e=[];for(var t in Object(n))i.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var a=t(195)(Object.keys,Object);n.exports=a},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var a=t(197),r=t(34),i=t(198),s=t(81),o=t(199),l=t(13),c=t(71),d=c(a),p=c(r),m=c(i),u=c(s),h=c(o),f=l;(a&&"[object DataView]"!=f(new a(new ArrayBuffer(1)))||r&&"[object Map]"!=f(new r)||i&&"[object Promise]"!=f(i.resolve())||s&&"[object Set]"!=f(new s)||o&&"[object WeakMap]"!=f(new o))&&(f=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,a=t?c(t):"";if(a)switch(a){case d:return"[object DataView]";case p:return"[object Map]";case m:return"[object Promise]";case u:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=f},function(n,e,t){var a=t(10)(t(6),"DataView");n.exports=a},function(n,e,t){var a=t(10)(t(6),"Promise");n.exports=a},function(n,e,t){var a=t(10)(t(6),"WeakMap");n.exports=a},function(n,e,t){var a=t(82),r=t(76);n.exports=function(n){for(var e=r(n),t=e.length;t--;){var i=e[t],s=n[i];e[t]=[i,s,a(s)]}return e}},function(n,e,t){var a=t(72),r=t(202),i=t(209),s=t(39),o=t(82),l=t(83),c=t(22);n.exports=function(n,e){return s(n)&&o(e)?l(c(n),e):function(t){var s=r(t,n);return void 0===s&&s===e?i(t,n):a(e,s,3)}}},function(n,e,t){var a=t(84);n.exports=function(n,e,t){var r=null==n?void 0:a(n,e);return void 0===r?t:r}},function(n,e,t){var a=t(204),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,s=a((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(r,(function(n,t,a,r){e.push(a?r.replace(i,"$1"):t||n)})),e}));n.exports=s},function(n,e,t){var a=t(205);n.exports=function(n){var e=a(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var a=t(36);function r(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var a=arguments,r=e?e.apply(this,a):a[0],i=t.cache;if(i.has(r))return i.get(r);var s=n.apply(this,a);return t.cache=i.set(r,s)||i,s};return t.cache=new(r.Cache||a),t}r.Cache=a,n.exports=r},function(n,e,t){var a=t(207);n.exports=function(n){return null==n?"":a(n)}},function(n,e,t){var a=t(14),r=t(208),i=t(5),s=t(40),o=a?a.prototype:void 0,l=o?o.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(i(e))return r(e,n)+"";if(s(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,a=null==n?0:n.length,r=Array(a);++t<a;)r[t]=e(n[t],t,n);return r}},function(n,e,t){var a=t(210),r=t(211);n.exports=function(n,e){return null!=n&&r(n,e,a)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var a=t(85),r=t(33),i=t(5),s=t(78),o=t(38),l=t(22);n.exports=function(n,e,t){for(var c=-1,d=(e=a(e,n)).length,p=!1;++c<d;){var m=l(e[c]);if(!(p=null!=n&&t(n,m)))break;n=n[m]}return p||++c!=d?p:!!(d=null==n?0:n.length)&&o(d)&&s(m,d)&&(i(n)||r(n))}},function(n,e,t){var a=t(213),r=t(214),i=t(39),s=t(22);n.exports=function(n){return i(n)?a(s(n)):r(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var a=t(84);n.exports=function(n){return function(e){return a(e,n)}}},function(n,e,t){var a=t(41),r=t(216),i=t(218);n.exports=function(n,e){return i(r(n,e,a),n+"")}},function(n,e,t){var a=t(217),r=Math.max;n.exports=function(n,e,t){return e=r(void 0===e?n.length-1:e,0),function(){for(var i=arguments,s=-1,o=r(i.length-e,0),l=Array(o);++s<o;)l[s]=i[e+s];s=-1;for(var c=Array(e+1);++s<e;)c[s]=i[s];return c[e]=t(l),a(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var a=t(219),r=t(222)(a);n.exports=r},function(n,e,t){var a=t(220),r=t(221),i=t(41),s=r?function(n,e){return r(n,"toString",{configurable:!0,enumerable:!1,value:a(e),writable:!0})}:i;n.exports=s},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var a=t(10),r=function(){try{var n=a(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=r},function(n,e){var t=Date.now;n.exports=function(n){var e=0,a=0;return function(){var r=t(),i=16-(r-a);if(a=r,i>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var a=t(74),r=t(224),i=t(229),s=t(75),o=t(230),l=t(37);n.exports=function(n,e,t){var c=-1,d=r,p=n.length,m=!0,u=[],h=u;if(t)m=!1,d=i;else if(p>=200){var f=e?null:o(n);if(f)return l(f);m=!1,d=s,h=new a}else h=e?[]:u;n:for(;++c<p;){var g=n[c],b=e?e(g):g;if(g=t||0!==g?g:0,m&&b==b){for(var y=h.length;y--;)if(h[y]===b)continue n;e&&h.push(b),u.push(g)}else d(h,b,t)||(h!==u&&h.push(b),u.push(g))}return u}},function(n,e,t){var a=t(225);n.exports=function(n,e){return!!(null==n?0:n.length)&&a(n,e,0)>-1}},function(n,e,t){var a=t(226),r=t(227),i=t(228);n.exports=function(n,e,t){return e==e?i(n,e,t):a(n,r,t)}},function(n,e){n.exports=function(n,e,t,a){for(var r=n.length,i=t+(a?1:-1);a?i--:++i<r;)if(e(n[i],i,n))return i;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var a=t-1,r=n.length;++a<r;)if(n[a]===e)return a;return-1}},function(n,e){n.exports=function(n,e,t){for(var a=-1,r=null==n?0:n.length;++a<r;)if(t(e,n[a]))return!0;return!1}},function(n,e,t){var a=t(81),r=t(231),i=t(37),s=a&&1/i(new a([,-0]))[1]==1/0?function(n){return new a(n)}:r;n.exports=s},function(n,e){n.exports=function(){}},function(n,e,t){var a=t(80),r=t(12);n.exports=function(n){return r(n)&&a(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(87)},function(n,e,t){"use strict";t(88)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(89)},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.4
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var a=Object.freeze({}),r=Array.isArray;function i(n){return null==n}function s(n){return null!=n}function o(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function d(n){return null!==n&&"object"==typeof n}var p=Object.prototype.toString;function m(n){return"[object Object]"===p.call(n)}function u(n){return"[object RegExp]"===p.call(n)}function h(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function f(n){return s(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function g(n){return null==n?"":Array.isArray(n)||m(n)&&n.toString===p?JSON.stringify(n,null,2):String(n)}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function y(n,e){for(var t=Object.create(null),a=n.split(","),r=0;r<a.length;r++)t[a[r]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}y("slot,component",!0);var v=y("key,ref,slot,slot-scope,is");function _(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var x=Object.prototype.hasOwnProperty;function k(n,e){return x.call(n,e)}function S(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var w=/-(\w)/g,E=S((function(n){return n.replace(w,(function(n,e){return e?e.toUpperCase():""}))})),T=S((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),I=/\B([A-Z])/g,A=S((function(n){return n.replace(I,"-$1").toLowerCase()}));var j=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var a=arguments.length;return a?a>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function z(n,e){e=e||0;for(var t=n.length-e,a=new Array(t);t--;)a[t]=n[t+e];return a}function O(n,e){for(var t in e)n[t]=e[t];return n}function C(n){for(var e={},t=0;t<n.length;t++)n[t]&&O(e,n[t]);return e}function D(n,e,t){}var N=function(n,e,t){return!1},L=function(n){return n};function M(n,e){if(n===e)return!0;var t=d(n),a=d(e);if(!t||!a)return!t&&!a&&String(n)===String(e);try{var r=Array.isArray(n),i=Array.isArray(e);if(r&&i)return n.length===e.length&&n.every((function(n,t){return M(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(r||i)return!1;var s=Object.keys(n),o=Object.keys(e);return s.length===o.length&&s.every((function(t){return M(n[t],e[t])}))}catch(n){return!1}}function R(n,e){for(var t=0;t<n.length;t++)if(M(n[t],e))return t;return-1}function q(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function P(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var B=["component","directive","filter"],F=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],$={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:N,isReservedAttr:N,isUnknownElement:N,getTagNamespace:D,parsePlatformTagName:L,mustUseProp:N,async:!0,_lifecycleHooks:F},H=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function U(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function G(n,e,t,a){Object.defineProperty(n,e,{value:t,enumerable:!!a,writable:!0,configurable:!0})}var W=new RegExp("[^".concat(H.source,".$_\\d]"));var Q="__proto__"in{},Y="undefined"!=typeof window,V=Y&&window.navigator.userAgent.toLowerCase(),J=V&&/msie|trident/.test(V),X=V&&V.indexOf("msie 9.0")>0,K=V&&V.indexOf("edge/")>0;V&&V.indexOf("android");var Z=V&&/iphone|ipad|ipod|ios/.test(V);V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V);var nn,en=V&&V.match(/firefox\/(\d+)/),tn={}.watch,an=!1;if(Y)try{var rn={};Object.defineProperty(rn,"passive",{get:function(){an=!0}}),window.addEventListener("test-passive",null,rn)}catch(n){}var sn=function(){return void 0===nn&&(nn=!Y&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},on=Y&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ln(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,dn="undefined"!=typeof Symbol&&ln(Symbol)&&"undefined"!=typeof Reflect&&ln(Reflect.ownKeys);cn="undefined"!=typeof Set&&ln(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var pn=null;function mn(n){void 0===n&&(n=null),n||pn&&pn._scope.off(),pn=n,n&&n._scope.on()}var un=D,hn=0,fn=function(){function n(){this.id=hn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){_(this.subs,n)},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.slice();for(var t=0,a=e.length;t<a;t++){e[t].update()}},n}();fn.target=null;var gn=[];function bn(n){gn.push(n),fn.target=n}function yn(){gn.pop(),fn.target=gn[gn.length-1]}var vn=function(){function n(n,e,t,a,r,i,s,o){this.tag=n,this.data=e,this.children=t,this.text=a,this.elm=r,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=s,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=o,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),_n=function(n){void 0===n&&(n="");var e=new vn;return e.text=n,e.isComment=!0,e};function xn(n){return new vn(void 0,void 0,void 0,String(n))}function kn(n){var e=new vn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var Sn=Array.prototype,wn=Object.create(Sn);function En(n){return Tn(n,!0),G(n,"__v_isShallow",!0),n}function Tn(n,e){if(!In(n)){ft(n,e,sn());0}}function In(n){return!(!n||!n.__v_isReadonly)}["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=Sn[n];G(wn,n,(function(){for(var t=[],a=0;a<arguments.length;a++)t[a]=arguments[a];var r,i=e.apply(this,t),s=this.__ob__;switch(n){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&s.observeArray(r),s.dep.notify(),i}))}));function An(n){return!(!n||!0!==n.__v_isRef)}function jn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){return function(n){return An(n)?n.value:n}(e[t])},set:function(n){var a=e[t];An(a)&&!An(n)?a.value=n:e[t]=n}})}var zn=new cn;function On(n){return function n(e,t){var a,i,s=r(e);if(!s&&!d(e)||Object.isFrozen(e)||e instanceof vn)return;if(e.__ob__){var o=e.__ob__.dep.id;if(t.has(o))return;t.add(o)}if(s)for(a=e.length;a--;)n(e[a],t);else for(i=Object.keys(e),a=i.length;a--;)n(e[i[a]],t)}(n,zn),zn.clear(),n}var Cn=S((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),a="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=a?n.slice(1):n,once:t,capture:a,passive:e}}));function Dn(n,e){function t(){var n=t.fns;if(!r(n))return Ve(n,null,arguments,e,"v-on handler");for(var a=n.slice(),i=0;i<a.length;i++)Ve(a[i],null,arguments,e,"v-on handler")}return t.fns=n,t}function Nn(n,e,t,a,r,s){var l,c,d,p;for(l in n)c=n[l],d=e[l],p=Cn(l),i(c)||(i(d)?(i(c.fns)&&(c=n[l]=Dn(c,s)),o(p.once)&&(c=n[l]=r(p.name,c,p.capture)),t(p.name,c,p.capture,p.passive,p.params)):c!==d&&(d.fns=c,n[l]=d));for(l in e)i(n[l])&&a((p=Cn(l)).name,e[l],p.capture)}function Ln(n,e,t){var a;n instanceof vn&&(n=n.data.hook||(n.data.hook={}));var r=n[e];function l(){t.apply(this,arguments),_(a.fns,l)}i(r)?a=Dn([l]):s(r.fns)&&o(r.merged)?(a=r).fns.push(l):a=Dn([r,l]),a.merged=!0,n[e]=a}function Mn(n,e,t,a,r){if(s(e)){if(k(e,t))return n[t]=e[t],r||delete e[t],!0;if(k(e,a))return n[t]=e[a],r||delete e[a],!0}return!1}function Rn(n){return l(n)?[xn(n)]:r(n)?function n(e,t){var a,c,d,p,m=[];for(a=0;a<e.length;a++)i(c=e[a])||"boolean"==typeof c||(d=m.length-1,p=m[d],r(c)?c.length>0&&(qn((c=n(c,"".concat(t||"","_").concat(a)))[0])&&qn(p)&&(m[d]=xn(p.text+c[0].text),c.shift()),m.push.apply(m,c)):l(c)?qn(p)?m[d]=xn(p.text+c):""!==c&&m.push(xn(c)):qn(c)&&qn(p)?m[d]=xn(p.text+c.text):(o(e._isVList)&&s(c.tag)&&i(c.key)&&s(t)&&(c.key="__vlist".concat(t,"_").concat(a,"__")),m.push(c)));return m}(n):void 0}function qn(n){return s(n)&&s(n.text)&&!1===n.isComment}function Pn(n,e){if(pn){var t=pn._provided,a=pn.$parent&&pn.$parent._provided;a===t&&(t=pn._provided=Object.create(a)),t[n]=e}else 0}function Bn(n,e){if(n){for(var t=Object.create(null),a=dn?Reflect.ownKeys(n):Object.keys(n),r=0;r<a.length;r++){var i=a[r];if("__ob__"!==i){var s=n[i].from;if(s in e._provided)t[i]=e._provided[s];else if("default"in n[i]){var o=n[i].default;t[i]=c(o)?o.call(e):o}else 0}}return t}}function Fn(n,e){if(!n||!n.length)return{};for(var t={},a=0,r=n.length;a<r;a++){var i=n[a],s=i.data;if(s&&s.attrs&&s.attrs.slot&&delete s.attrs.slot,i.context!==e&&i.fnContext!==e||!s||null==s.slot)(t.default||(t.default=[])).push(i);else{var o=s.slot,l=t[o]||(t[o]=[]);"template"===i.tag?l.push.apply(l,i.children||[]):l.push(i)}}for(var c in t)t[c].every($n)&&delete t[c];return t}function $n(n){return n.isComment&&!n.asyncFactory||" "===n.text}function Hn(n){return n.isComment&&n.asyncFactory}function Un(n,e,t,r){var i,s=Object.keys(t).length>0,o=e?!!e.$stable:!s,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(o&&r&&r!==a&&l===r.$key&&!s&&!r.$hasNormal)return r;for(var c in i={},e)e[c]&&"$"!==c[0]&&(i[c]=Gn(n,t,c,e[c]))}else i={};for(var d in t)d in i||(i[d]=Wn(t,d));return e&&Object.isExtensible(e)&&(e._normalized=i),G(i,"$stable",o),G(i,"$key",l),G(i,"$hasNormal",s),i}function Gn(n,e,t,a){var i=function(){var e=pn;mn(n);var t=arguments.length?a.apply(null,arguments):a({}),i=(t=t&&"object"==typeof t&&!r(t)?[t]:Rn(t))&&t[0];return mn(e),t&&(!i||1===t.length&&i.isComment&&!Hn(i))?void 0:t};return a.proxy&&Object.defineProperty(e,t,{get:i,enumerable:!0,configurable:!0}),i}function Wn(n,e){return function(){return n[e]}}function Qn(n,e){var t,a,i,o,l=null;if(r(n)||"string"==typeof n)for(l=new Array(n.length),t=0,a=n.length;t<a;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(d(n))if(dn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),p=c.next();!p.done;)l.push(e(p.value,l.length)),p=c.next()}else for(i=Object.keys(n),l=new Array(i.length),t=0,a=i.length;t<a;t++)o=i[t],l[t]=e(n[o],o,t);return s(l)||(l=[]),l._isVList=!0,l}function Yn(n,e,t,a){var r,i=this.$scopedSlots[n];i?(t=t||{},a&&(t=O(O({},a),t)),r=i(t)||(c(e)?e():e)):r=this.$slots[n]||(c(e)?e():e);var s=t&&t.slot;return s?this.$createElement("template",{slot:s},r):r}function Vn(n){return It(this.$options,"filters",n,!0)||L}function Jn(n,e){return r(n)?-1===n.indexOf(e):n!==e}function Xn(n,e,t,a,r){var i=$.keyCodes[e]||t;return r&&a&&!$.keyCodes[e]?Jn(r,a):i?Jn(i,n):a?A(a)!==e:void 0===n}function Kn(n,e,t,a,i){if(t)if(d(t)){r(t)&&(t=C(t));var s=void 0,o=function(r){if("class"===r||"style"===r||v(r))s=n;else{var o=n.attrs&&n.attrs.type;s=a||$.mustUseProp(e,o,r)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=E(r),c=A(r);l in s||c in s||(s[r]=t[r],i&&((n.on||(n.on={}))["update:".concat(r)]=function(n){t[r]=n}))};for(var l in t)o(l)}else;return n}function Zn(n,e){var t=this._staticTrees||(this._staticTrees=[]),a=t[n];return a&&!e||ee(a=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),a}function ne(n,e,t){return ee(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ee(n,e,t){if(r(n))for(var a=0;a<n.length;a++)n[a]&&"string"!=typeof n[a]&&te(n[a],"".concat(e,"_").concat(a),t);else te(n,e,t)}function te(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function ae(n,e){if(e)if(m(e)){var t=n.on=n.on?O({},n.on):{};for(var a in e){var r=t[a],i=e[a];t[a]=r?[].concat(r,i):i}}else;return n}function re(n,e,t,a){e=e||{$stable:!t};for(var i=0;i<n.length;i++){var s=n[i];r(s)?re(s,e,t):s&&(s.proxy&&(s.fn.proxy=!0),e[s.key]=s.fn)}return a&&(e.$key=a),e}function ie(n,e){for(var t=0;t<e.length;t+=2){var a=e[t];"string"==typeof a&&a&&(n[e[t]]=e[t+1])}return n}function se(n,e){return"string"==typeof n?e+n:n}function oe(n){n._o=ne,n._n=b,n._s=g,n._l=Qn,n._t=Yn,n._q=M,n._i=R,n._m=Zn,n._f=Vn,n._k=Xn,n._b=Kn,n._v=xn,n._e=_n,n._u=re,n._g=ae,n._d=ie,n._p=se}function le(n,e,t,i,s){var l,c=this,d=s.options;k(i,"_uid")?(l=Object.create(i))._original=i:(l=i,i=i._original);var p=o(d._compiled),m=!p;this.data=n,this.props=e,this.children=t,this.parent=i,this.listeners=n.on||a,this.injections=Bn(d.inject,i),this.slots=function(){return c.$slots||Un(i,n.scopedSlots,c.$slots=Fn(t,i)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return Un(i,n.scopedSlots,this.slots())}}),p&&(this.$options=d,this.$slots=this.slots(),this.$scopedSlots=Un(i,n.scopedSlots,this.$slots)),d._scopeId?this._c=function(n,e,t,a){var s=fe(l,n,e,t,a,m);return s&&!r(s)&&(s.fnScopeId=d._scopeId,s.fnContext=i),s}:this._c=function(n,e,t,a){return fe(l,n,e,t,a,m)}}function ce(n,e,t,a,r){var i=kn(n);return i.fnContext=t,i.fnOptions=a,e.slot&&((i.data||(i.data={})).slot=e.slot),i}function de(n,e){for(var t in e)n[E(t)]=e[t]}oe(le.prototype);var pe={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;pe.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},a=n.data.inlineTemplate;s(a)&&(t.render=a.render,t.staticRenderFns=a.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Ae)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,r,i){0;var s=r.data.scopedSlots,o=n.$scopedSlots,l=!!(s&&!s.$stable||o!==a&&!o.$stable||s&&n.$scopedSlots.$key!==s.$key||!s&&n.$scopedSlots.$key),c=!!(i||n.$options._renderChildren||l),d=n.$vnode;n.$options._parentVnode=r,n.$vnode=r,n._vnode&&(n._vnode.parent=r);n.$options._renderChildren=i;var p=r.data.attrs||a;n._attrsProxy&&be(n._attrsProxy,p,d.data&&d.data.attrs||a,n)&&(c=!0);if(n.$attrs=p,n.$listeners=t||a,e&&n.$options.props){mt(!1);for(var m=n._props,u=n.$options._propKeys||[],h=0;h<u.length;h++){var f=u[h],g=n.$options.props;m[f]=At(f,g,e,n)}mt(!0),n.$options.propsData=e}t=t||a;var b=n.$options._parentListeners;n.$options._parentListeners=t,Ie(n,t,b),c&&(n.$slots=Fn(i,r.context),n.$forceUpdate());0}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,a=n.componentInstance;a._isMounted||(a._isMounted=!0,Ce(a,"mounted")),n.data.keepAlive&&(t._isMounted?((e=a)._inactive=!1,Ne.push(e)):Oe(a,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(t&&(e._directInactive=!0,ze(e)))return;if(!e._inactive){e._inactive=!0;for(var a=0;a<e.$children.length;a++)n(e.$children[a]);Ce(e,"deactivated")}}(e,!0):e.$destroy())}},me=Object.keys(pe);function ue(n,e,t,l,c){if(!i(n)){var p=t.$options._base;if(d(n)&&(n=p.extend(n)),"function"==typeof n){var m;if(i(n.cid)&&void 0===(n=function(n,e){if(o(n.error)&&s(n.errorComp))return n.errorComp;if(s(n.resolved))return n.resolved;var t=xe;t&&s(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t);if(o(n.loading)&&s(n.loadingComp))return n.loadingComp;if(t&&!s(n.owners)){var a=n.owners=[t],r=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return _(a,t)}));var p=function(n){for(var e=0,t=a.length;e<t;e++)a[e].$forceUpdate();n&&(a.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},m=q((function(t){n.resolved=ke(t,e),r?a.length=0:p(!0)})),u=q((function(e){s(n.errorComp)&&(n.error=!0,p(!0))})),h=n(m,u);return d(h)&&(f(h)?i(n.resolved)&&h.then(m,u):f(h.component)&&(h.component.then(m,u),s(h.error)&&(n.errorComp=ke(h.error,e)),s(h.loading)&&(n.loadingComp=ke(h.loading,e),0===h.delay?n.loading=!0:l=setTimeout((function(){l=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,p(!1))}),h.delay||200)),s(h.timeout)&&(c=setTimeout((function(){c=null,i(n.resolved)&&u(null)}),h.timeout)))),r=!1,n.loading?n.loadingComp:n.resolved}}(m=n,p)))return function(n,e,t,a,r){var i=_n();return i.asyncFactory=n,i.asyncMeta={data:e,context:t,children:a,tag:r},i}(m,e,t,l,c);e=e||{},$t(n),s(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",a=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var i=e.on||(e.on={}),o=i[a],l=e.model.callback;s(o)?(r(o)?-1===o.indexOf(l):o!==l)&&(i[a]=[l].concat(o)):i[a]=l}(n.options,e);var u=function(n,e,t){var a=e.options.props;if(!i(a)){var r={},o=n.attrs,l=n.props;if(s(o)||s(l))for(var c in a){var d=A(c);Mn(r,l,c,d,!0)||Mn(r,o,c,d,!1)}return r}}(e,n);if(o(n.options.functional))return function(n,e,t,i,o){var l=n.options,c={},d=l.props;if(s(d))for(var p in d)c[p]=At(p,d,e||a);else s(t.attrs)&&de(c,t.attrs),s(t.props)&&de(c,t.props);var m=new le(t,c,o,i,n),u=l.render.call(null,m._c,m);if(u instanceof vn)return ce(u,t,m.parent,l,m);if(r(u)){for(var h=Rn(u)||[],f=new Array(h.length),g=0;g<h.length;g++)f[g]=ce(h[g],t,m.parent,l,m);return f}}(n,u,e,t,l);var h=e.on;if(e.on=e.nativeOn,o(n.options.abstract)){var g=e.slot;e={},g&&(e.slot=g)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<me.length;t++){var a=me[t],r=e[a],i=pe[a];r===i||r&&r._merged||(e[a]=r?he(i,r):i)}}(e);var b=n.options.name||c;return new vn("vue-component-".concat(n.cid).concat(b?"-".concat(b):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:u,listeners:h,tag:c,children:l},m)}}}function he(n,e){var t=function(t,a){n(t,a),e(t,a)};return t._merged=!0,t}function fe(n,e,t,a,p,m){return(r(t)||l(t))&&(p=a,a=t,t=void 0),o(m)&&(p=2),function(n,e,t,a,l){if(s(t)&&s(t.__ob__))return _n();s(t)&&s(t.is)&&(e=t.is);if(!e)return _n();0;r(a)&&c(a[0])&&((t=t||{}).scopedSlots={default:a[0]},a.length=0);2===l?a=Rn(a):1===l&&(a=function(n){for(var e=0;e<n.length;e++)if(r(n[e]))return Array.prototype.concat.apply([],n);return n}(a));var p,m;if("string"==typeof e){var u=void 0;m=n.$vnode&&n.$vnode.ns||$.getTagNamespace(e),p=$.isReservedTag(e)?new vn($.parsePlatformTagName(e),t,a,void 0,void 0,n):t&&t.pre||!s(u=It(n.$options,"components",e))?new vn(e,t,a,void 0,void 0,n):ue(u,t,n,a,e)}else p=ue(e,t,n,a);return r(p)?p:s(p)?(s(m)&&function n(e,t,a){e.ns=t,"foreignObject"===e.tag&&(t=void 0,a=!0);if(s(e.children))for(var r=0,l=e.children.length;r<l;r++){var c=e.children[r];s(c.tag)&&(i(c.ns)||o(a)&&"svg"!==c.tag)&&n(c,t,a)}}(p,m),s(t)&&function(n){d(n.style)&&On(n.style);d(n.class)&&On(n.class)}(t),p):_n()}(n,e,t,a,p)}function ge(n){return{get attrs(){return function(n){if(!n._attrsProxy){var e=n._attrsProxy={};G(e,"_v_attr_proxy",!0),be(e,n.$attrs,a,n)}return n._attrsProxy}(n)},get slots(){return function(n){n._slotsProxy||ve(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:j(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return jn(n,e,t)}))}}}function be(n,e,t,a){var r=!1;for(var i in e)i in n?e[i]!==t[i]&&(r=!0):(r=!0,ye(n,i,a));for(var i in n)i in e||(r=!0,delete n[i]);return r}function ye(n,e,t){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t.$attrs[e]}})}function ve(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var _e,xe=null;function ke(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),d(n)?e.extend(n):n}function Se(n){if(r(n))for(var e=0;e<n.length;e++){var t=n[e];if(s(t)&&(s(t.componentOptions)||Hn(t)))return t}}function we(n,e){_e.$on(n,e)}function Ee(n,e){_e.$off(n,e)}function Te(n,e){var t=_e;return function a(){var r=e.apply(null,arguments);null!==r&&t.$off(n,a)}}function Ie(n,e,t){_e=n,Nn(e,t||{},we,Ee,Te,n),_e=void 0}var Ae=null;function je(n){var e=Ae;return Ae=n,function(){Ae=e}}function ze(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Oe(n,e){if(e){if(n._directInactive=!1,ze(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Oe(n.$children[t]);Ce(n,"activated")}}function Ce(n,e,t){bn();var a=pn;mn(n);var r=n.$options[e],i="".concat(e," hook");if(r)for(var s=0,o=r.length;s<o;s++)Ve(r[s],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),mn(a),yn()}var De=[],Ne=[],Le={},Me=!1,Re=!1,qe=0;var Pe,Be=0,Fe=Date.now;if(Y&&!J){var $e=window.performance;$e&&"function"==typeof $e.now&&Fe()>document.createEvent("Event").timeStamp&&(Fe=function(){return $e.now()})}function He(){var n,e;for(Be=Fe(),Re=!0,De.sort((function(n,e){return n.id-e.id})),qe=0;qe<De.length;qe++)(n=De[qe]).before&&n.before(),e=n.id,Le[e]=null,n.run();var t=Ne.slice(),a=De.slice();qe=De.length=Ne.length=0,Le={},Me=Re=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Oe(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],a=t.vm;a&&a._watcher===t&&a._isMounted&&!a._isDestroyed&&Ce(a,"updated")}}(a),on&&$.devtools&&on.emit("flush")}function Ue(n){var e=n.id;if(null==Le[e]&&(n!==fn.target||!n.noRecurse)){if(Le[e]=!0,Re){for(var t=De.length-1;t>qe&&De[t].id>n.id;)t--;De.splice(t+1,0,n)}else De.push(n);Me||(Me=!0,ot(He))}}var Ge=function(){function n(n){void 0===n&&(n=!1),this.active=!0,this.effects=[],this.cleanups=[],!n&&Pe&&(this.parent=Pe,this.index=(Pe.scopes||(Pe.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Pe;try{return Pe=this,n()}finally{Pe=e}}else 0},n.prototype.on=function(){Pe=this},n.prototype.off=function(){Pe=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(this.parent&&!n){var a=this.parent.scopes.pop();a&&a!==this&&(this.parent.scopes[this.index]=a,a.index=this.index)}this.active=!1}},n}();var We=0,Qe=function(){function n(n,e,t,a,r){var i,s;i=this,void 0===(s=Pe||(n?n._scope:void 0))&&(s=Pe),s&&s.active&&s.effects.push(i),(this.vm=n)&&r&&(n._watcher=this),a?(this.deep=!!a.deep,this.user=!!a.user,this.lazy=!!a.lazy,this.sync=!!a.sync,this.before=a.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++We,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!W.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=D)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;bn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Ye(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&On(n),yn(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():Ue(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||d(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Ve(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&_(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");function Ye(n,e,t){bn();try{if(e)for(var a=e;a=a.$parent;){var r=a.$options.errorCaptured;if(r)for(var i=0;i<r.length;i++)try{if(!1===r[i].call(a,n,e,t))return}catch(n){Je(n,a,"errorCaptured hook")}}Je(n,e,t)}finally{yn()}}function Ve(n,e,t,a,r){var i;try{(i=t?n.apply(e,t):n.call(e))&&!i._isVue&&f(i)&&!i._handled&&(i.catch((function(n){return Ye(n,a,r+" (Promise/async)")})),i._handled=!0)}catch(n){Ye(n,a,r)}return i}function Je(n,e,t){if($.errorHandler)try{return $.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Xe(e,null,"config.errorHandler")}Xe(n,e,t)}function Xe(n,e,t){if(!Y||"undefined"==typeof console)throw n;console.error(n)}var Ke,Ze=!1,nt=[],et=!1;function tt(){et=!1;var n=nt.slice(0);nt.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&ln(Promise)){var at=Promise.resolve();Ke=function(){at.then(tt),Z&&setTimeout(D)},Ze=!0}else if(J||"undefined"==typeof MutationObserver||!ln(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ke="undefined"!=typeof setImmediate&&ln(setImmediate)?function(){setImmediate(tt)}:function(){setTimeout(tt,0)};else{var rt=1,it=new MutationObserver(tt),st=document.createTextNode(String(rt));it.observe(st,{characterData:!0}),Ke=function(){rt=(rt+1)%2,st.data=String(rt)},Ze=!0}function ot(n,e){var t;if(nt.push((function(){if(n)try{n.call(e)}catch(n){Ye(n,e,"nextTick")}else t&&t(e)})),et||(et=!0,Ke()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function lt(n){return function(e,t){if(void 0===t&&(t=pn),t)return function(n,e,t){var a=n.$options;a[e]=St(a[e],t)}(t,n,e)}}lt("beforeMount"),lt("mounted"),lt("beforeUpdate"),lt("updated"),lt("beforeDestroy"),lt("destroyed"),lt("errorCaptured"),lt("activated"),lt("deactivated"),lt("serverPrefetch"),lt("renderTracked"),lt("renderTriggered");var ct=Object.getOwnPropertyNames(wn),dt={},pt=!0;function mt(n){pt=n}var ut={notify:D,depend:D,addSub:D,removeSub:D},ht=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?ut:new fn,this.vmCount=0,G(n,"__ob__",this),r(n)){if(!t)if(Q)n.__proto__=wn;else for(var a=0,i=ct.length;a<i;a++){G(n,o=ct[a],wn[o])}e||this.observeArray(n)}else{var s=Object.keys(n);for(a=0;a<s.length;a++){var o;gt(n,o=s[a],dt,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)ft(n[e],!1,this.mock)},n}();function ft(n,e,t){var a;if(!(!d(n)||An(n)||n instanceof vn))return k(n,"__ob__")&&n.__ob__ instanceof ht?a=n.__ob__:!pt||!t&&sn()||!r(n)&&!m(n)||!Object.isExtensible(n)||n.__v_skip||(a=new ht(n,e,t)),a}function gt(n,e,t,a,i,s){var o=new fn,l=Object.getOwnPropertyDescriptor(n,e);if(!l||!1!==l.configurable){var c=l&&l.get,d=l&&l.set;c&&!d||t!==dt&&2!==arguments.length||(t=n[e]);var p=!i&&ft(t,!1,s);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=c?c.call(n):t;return fn.target&&(o.depend(),p&&(p.dep.depend(),r(e)&&vt(e))),An(e)&&!i?e.value:e},set:function(e){var a=c?c.call(n):t;if(P(a,e)){if(d)d.call(n,e);else{if(c)return;if(An(a)&&!An(e))return void(a.value=e);t=e}p=!i&&ft(e,!1,s),o.notify()}}}),o}}function bt(n,e,t){if(!In(n)){var a=n.__ob__;return r(n)&&h(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),a&&!a.shallow&&a.mock&&ft(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||a&&a.vmCount?t:a?(gt(a.value,e,t,void 0,a.shallow,a.mock),a.dep.notify(),t):(n[e]=t,t)}}function yt(n,e){if(r(n)&&h(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||In(n)||k(n,e)&&(delete n[e],t&&t.dep.notify())}}function vt(n){for(var e=void 0,t=0,a=n.length;t<a;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),r(e)&&vt(e)}var _t=$.optionMergeStrategies;function xt(n,e){if(!e)return n;for(var t,a,r,i=dn?Reflect.ownKeys(e):Object.keys(e),s=0;s<i.length;s++)"__ob__"!==(t=i[s])&&(a=n[t],r=e[t],k(n,t)?a!==r&&m(a)&&m(r)&&xt(a,r):bt(n,t,r));return n}function kt(n,e,t){return t?function(){var a=c(e)?e.call(t,t):e,r=c(n)?n.call(t,t):n;return a?xt(a,r):r}:e?n?function(){return xt(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function St(n,e){var t=e?n?n.concat(e):r(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function wt(n,e,t,a){var r=Object.create(n||null);return e?O(r,e):r}_t.data=function(n,e,t){return t?kt(n,e,t):e&&"function"!=typeof e?n:kt(n,e)},F.forEach((function(n){_t[n]=St})),B.forEach((function(n){_t[n+"s"]=wt})),_t.watch=function(n,e,t,a){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var i={};for(var s in O(i,n),e){var o=i[s],l=e[s];o&&!r(o)&&(o=[o]),i[s]=o?o.concat(l):r(l)?l:[l]}return i},_t.props=_t.methods=_t.inject=_t.computed=function(n,e,t,a){if(!n)return e;var r=Object.create(null);return O(r,n),e&&O(r,e),r},_t.provide=kt;var Et=function(n,e){return void 0===e?n:e};function Tt(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var a,i,s={};if(r(t))for(a=t.length;a--;)"string"==typeof(i=t[a])&&(s[E(i)]={type:null});else if(m(t))for(var o in t)i=t[o],s[E(o)]=m(i)?i:{type:i};else 0;n.props=s}}(e),function(n,e){var t=n.inject;if(t){var a=n.inject={};if(r(t))for(var i=0;i<t.length;i++)a[t[i]]={from:t[i]};else if(m(t))for(var s in t){var o=t[s];a[s]=m(o)?O({from:s},o):{from:o}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var a=e[t];c(a)&&(e[t]={bind:a,update:a})}}(e),!e._base&&(e.extends&&(n=Tt(n,e.extends,t)),e.mixins))for(var a=0,i=e.mixins.length;a<i;a++)n=Tt(n,e.mixins[a],t);var s,o={};for(s in n)l(s);for(s in e)k(n,s)||l(s);function l(a){var r=_t[a]||Et;o[a]=r(n[a],e[a],t,a)}return o}function It(n,e,t,a){if("string"==typeof t){var r=n[e];if(k(r,t))return r[t];var i=E(t);if(k(r,i))return r[i];var s=T(i);return k(r,s)?r[s]:r[t]||r[i]||r[s]}}function At(n,e,t,a){var r=e[n],i=!k(t,n),s=t[n],o=Ct(Boolean,r.type);if(o>-1)if(i&&!k(r,"default"))s=!1;else if(""===s||s===A(n)){var l=Ct(String,r.type);(l<0||o<l)&&(s=!0)}if(void 0===s){s=function(n,e,t){if(!k(e,"default"))return;var a=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(a)&&"Function"!==zt(e.type)?a.call(n):a}(a,r,n);var d=pt;mt(!0),ft(s),mt(d)}return s}var jt=/^\s*function (\w+)/;function zt(n){var e=n&&n.toString().match(jt);return e?e[1]:""}function Ot(n,e){return zt(n)===zt(e)}function Ct(n,e){if(!r(e))return Ot(e,n)?0:-1;for(var t=0,a=e.length;t<a;t++)if(Ot(e[t],n))return t;return-1}var Dt={enumerable:!0,configurable:!0,get:D,set:D};function Nt(n,e,t){Dt.get=function(){return this[e][t]},Dt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Dt)}function Lt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},a=n._props=En({}),r=n.$options._propKeys=[];n.$parent&&mt(!1);var i=function(i){r.push(i);var s=At(i,e,t,n);gt(a,i,s),i in n||Nt(n,"_props",i)};for(var s in e)i(s);mt(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var a=n._setupContext=ge(n);mn(n),bn();var r=Ve(t,null,[n._props||En({}),a],n,"setup");if(yn(),mn(),c(r))e.render=r;else if(d(r))if(n._setupState=r,r.__sfc){var i=n._setupProxy={};for(var s in r)"__sfc"!==s&&jn(i,r,s)}else for(var s in r)U(s)||jn(n,r,s);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?D:j(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;m(e=n._data=c(e)?function(n,e){bn();try{return n.call(e,e)}catch(n){return Ye(n,e,"data()"),{}}finally{yn()}}(e,n):e||{})||(e={});var t=Object.keys(e),a=n.$options.props,r=(n.$options.methods,t.length);for(;r--;){var i=t[r];0,a&&k(a,i)||U(i)||Nt(n,"_data",i)}var s=ft(e);s&&s.vmCount++}(n);else{var t=ft(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),a=sn();for(var r in e){var i=e[r],s=c(i)?i:i.get;0,a||(t[r]=new Qe(n,s||D,D,Mt)),r in n||Rt(n,r,i)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var a=e[t];if(r(a))for(var i=0;i<a.length;i++)Bt(n,t,a[i]);else Bt(n,t,a)}}(n,e.watch)}var Mt={lazy:!0};function Rt(n,e,t){var a=!sn();c(t)?(Dt.get=a?qt(e):Pt(t),Dt.set=D):(Dt.get=t.get?a&&!1!==t.cache?qt(e):Pt(t.get):D,Dt.set=t.set||D),Object.defineProperty(n,e,Dt)}function qt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),fn.target&&e.depend(),e.value}}function Pt(n){return function(){return n.call(this,this)}}function Bt(n,e,t,a){return m(t)&&(a=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,a)}var Ft=0;function $t(n){var e=n.options;if(n.super){var t=$t(n.super);if(t!==n.superOptions){n.superOptions=t;var a=function(n){var e,t=n.options,a=n.sealedOptions;for(var r in t)t[r]!==a[r]&&(e||(e={}),e[r]=t[r]);return e}(n);a&&O(n.extendOptions,a),(e=n.options=Tt(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Ht(n){this._init(n)}function Ut(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,a=t.cid,r=n._Ctor||(n._Ctor={});if(r[a])return r[a];var i=n.name||t.options.name;var s=function(n){this._init(n)};return(s.prototype=Object.create(t.prototype)).constructor=s,s.cid=e++,s.options=Tt(t.options,n),s.super=t,s.options.props&&function(n){var e=n.options.props;for(var t in e)Nt(n.prototype,"_props",t)}(s),s.options.computed&&function(n){var e=n.options.computed;for(var t in e)Rt(n.prototype,t,e[t])}(s),s.extend=t.extend,s.mixin=t.mixin,s.use=t.use,B.forEach((function(n){s[n]=t[n]})),i&&(s.options.components[i]=s),s.superOptions=t.options,s.extendOptions=n,s.sealedOptions=O({},s.options),r[a]=s,s}}function Gt(n){return n&&(n.Ctor.options.name||n.tag)}function Wt(n,e){return r(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!u(n)&&n.test(e)}function Qt(n,e){var t=n.cache,a=n.keys,r=n._vnode;for(var i in t){var s=t[i];if(s){var o=s.name;o&&!e(o)&&Yt(t,i,a,r)}}}function Yt(n,e,t,a){var r=n[e];!r||a&&r.tag===a.tag||r.componentInstance.$destroy(),n[e]=null,_(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Ft++,e._isVue=!0,e.__v_skip=!0,e._scope=new Ge(!0),n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),a=e._parentVnode;t.parent=e.parent,t._parentVnode=a;var r=a.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Tt($t(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ie(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,r=t&&t.context;n.$slots=Fn(e._renderChildren,r),n.$scopedSlots=a,n._c=function(e,t,a,r){return fe(n,e,t,a,r,!1)},n.$createElement=function(e,t,a,r){return fe(n,e,t,a,r,!0)};var i=t&&t.data;gt(n,"$attrs",i&&i.attrs||a,null,!0),gt(n,"$listeners",e._parentListeners||a,null,!0)}(e),Ce(e,"beforeCreate"),function(n){var e=Bn(n.$options.inject,n);e&&(mt(!1),Object.keys(e).forEach((function(t){gt(n,t,e[t])})),mt(!0))}(e),Lt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!d(t))return;var a=dn?Reflect.ownKeys(t):Object.keys(t);mn(n);for(var r=0;r<a.length;r++)Pn(a[r],t[a[r]]);mn()}}(e),Ce(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Ht),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=bt,n.prototype.$delete=yt,n.prototype.$watch=function(n,e,t){if(m(e))return Bt(this,n,e,t);(t=t||{}).user=!0;var a=new Qe(this,n,e,t);if(t.immediate){var r='callback for immediate watcher "'.concat(a.expression,'"');bn(),Ve(e,this,[a.value],this,r),yn()}return function(){a.teardown()}}}(Ht),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var a=this;if(r(n))for(var i=0,s=n.length;i<s;i++)a.$on(n[i],t);else(a._events[n]||(a._events[n]=[])).push(t),e.test(n)&&(a._hasHookEvent=!0);return a},n.prototype.$once=function(n,e){var t=this;function a(){t.$off(n,a),e.apply(t,arguments)}return a.fn=e,t.$on(n,a),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(r(n)){for(var a=0,i=n.length;a<i;a++)t.$off(n[a],e);return t}var s,o=t._events[n];if(!o)return t;if(!e)return t._events[n]=null,t;for(var l=o.length;l--;)if((s=o[l])===e||s.fn===e){o.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?z(t):t;for(var a=z(arguments,1),r='event handler for "'.concat(n,'"'),i=0,s=t.length;i<s;i++)Ve(t[i],e,a,e,r)}return e}}(Ht),function(n){n.prototype._update=function(n,e){var t=this,a=t.$el,r=t._vnode,i=je(t);t._vnode=n,t.$el=r?t.__patch__(r,n):t.__patch__(t.$el,n,e,!1),i(),a&&(a.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){Ce(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||_(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),Ce(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Ht),function(n){oe(n.prototype),n.prototype.$nextTick=function(n){return ot(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,a=t.render,i=t._parentVnode;i&&(e.$scopedSlots=Un(e.$parent,i.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&ve(e._slotsProxy,e.$scopedSlots)),e.$vnode=i;try{mn(e),xe=e,n=a.call(e._renderProxy,e.$createElement)}catch(t){Ye(t,e,"render"),n=e._vnode}finally{xe=null,mn()}return r(n)&&1===n.length&&(n=n[0]),n instanceof vn||(n=_n()),n.parent=i,n}}(Ht);var Vt=[String,RegExp,Array],Jt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Vt,exclude:Vt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,a=this.keyToCache;if(t){var r=t.tag,i=t.componentInstance,s=t.componentOptions;n[a]={name:Gt(s),tag:r,componentInstance:i},e.push(a),this.max&&e.length>parseInt(this.max)&&Yt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Yt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Qt(n,(function(n){return Wt(e,n)}))})),this.$watch("exclude",(function(e){Qt(n,(function(n){return!Wt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Se(n),t=e&&e.componentOptions;if(t){var a=Gt(t),r=this.include,i=this.exclude;if(r&&(!a||!Wt(r,a))||i&&a&&Wt(i,a))return e;var s=this.cache,o=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;s[l]?(e.componentInstance=s[l].componentInstance,_(o,l),o.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return $}};Object.defineProperty(n,"config",e),n.util={warn:un,extend:O,mergeOptions:Tt,defineReactive:gt},n.set=bt,n.delete=yt,n.nextTick=ot,n.observable=function(n){return ft(n),n},n.options=Object.create(null),B.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,O(n.options.components,Jt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=z(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Tt(this.options,n),this}}(n),Ut(n),function(n){B.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&m(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Ht),Object.defineProperty(Ht.prototype,"$isServer",{get:sn}),Object.defineProperty(Ht.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Ht,"FunctionalRenderContext",{value:le}),Ht.version="2.7.4";var Xt=y("style,class"),Kt=y("input,textarea,option,select,progress"),Zt=y("contenteditable,draggable,spellcheck"),na=y("events,caret,typing,plaintext-only"),ea=y("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ta="http://www.w3.org/1999/xlink",aa=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},ra=function(n){return aa(n)?n.slice(6,n.length):""},ia=function(n){return null==n||!1===n};function sa(n){for(var e=n.data,t=n,a=n;s(a.componentInstance);)(a=a.componentInstance._vnode)&&a.data&&(e=oa(a.data,e));for(;s(t=t.parent);)t&&t.data&&(e=oa(e,t.data));return function(n,e){if(s(n)||s(e))return la(n,ca(e));return""}(e.staticClass,e.class)}function oa(n,e){return{staticClass:la(n.staticClass,e.staticClass),class:s(n.class)?[n.class,e.class]:e.class}}function la(n,e){return n?e?n+" "+e:n:e||""}function ca(n){return Array.isArray(n)?function(n){for(var e,t="",a=0,r=n.length;a<r;a++)s(e=ca(n[a]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):d(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var da={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},pa=y("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),ma=y("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),ua=function(n){return pa(n)||ma(n)};var ha=Object.create(null);var fa=y("text,number,password,search,email,tel,url");var ga=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(da[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),ba={create:function(n,e){ya(e)},update:function(n,e){n.data.ref!==e.data.ref&&(ya(n,!0),ya(e))},destroy:function(n){ya(n,!0)}};function ya(n,e){var t=n.data.ref;if(s(t)){var a=n.context,i=n.componentInstance||n.elm,o=e?null:i,l=e?void 0:i;if(c(t))Ve(t,a,[o],a,"template ref function");else{var d=n.data.refInFor,p="string"==typeof t||"number"==typeof t,m=An(t),u=a.$refs;if(p||m)if(d){var h=p?u[t]:t.value;e?r(h)&&_(h,i):r(h)?h.includes(i)||h.push(i):p?(u[t]=[i],va(a,t,u[t])):t.value=[i]}else if(p){if(e&&u[t]!==i)return;u[t]=l,va(a,t,o)}else if(m){if(e&&t.value!==i)return;t.value=o}else 0}}}function va(n,e,t){var a=n._setupState;a&&k(a,e)&&(An(a[e])?a[e].value=t:a[e]=t)}var _a=new vn("",{},[]),xa=["create","activate","update","remove","destroy"];function ka(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&s(n.data)===s(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,a=s(t=n.data)&&s(t=t.attrs)&&t.type,r=s(t=e.data)&&s(t=t.attrs)&&t.type;return a===r||fa(a)&&fa(r)}(n,e)||o(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function Sa(n,e,t){var a,r,i={};for(a=e;a<=t;++a)s(r=n[a].key)&&(i[r]=a);return i}var wa={create:Ea,update:Ea,destroy:function(n){Ea(n,_a)}};function Ea(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,a,r,i=n===_a,s=e===_a,o=Ia(n.data.directives,n.context),l=Ia(e.data.directives,e.context),c=[],d=[];for(t in l)a=o[t],r=l[t],a?(r.oldValue=a.value,r.oldArg=a.arg,ja(r,"update",e,n),r.def&&r.def.componentUpdated&&d.push(r)):(ja(r,"bind",e,n),r.def&&r.def.inserted&&c.push(r));if(c.length){var p=function(){for(var t=0;t<c.length;t++)ja(c[t],"inserted",e,n)};i?Ln(e,"insert",p):p()}d.length&&Ln(e,"postpatch",(function(){for(var t=0;t<d.length;t++)ja(d[t],"componentUpdated",e,n)}));if(!i)for(t in o)l[t]||ja(o[t],"unbind",n,n,s)}(n,e)}var Ta=Object.create(null);function Ia(n,e){var t,a,r=Object.create(null);if(!n)return r;for(t=0;t<n.length;t++)(a=n[t]).modifiers||(a.modifiers=Ta),r[Aa(a)]=a,e._setupState&&e._setupState.__sfc&&(a.def=a.def||It(e,"_setupState","v-"+a.name)),a.def=a.def||It(e.$options,"directives",a.name);return r}function Aa(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function ja(n,e,t,a,r){var i=n.def&&n.def[e];if(i)try{i(t.elm,n,t,a,r)}catch(a){Ye(a,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var za=[ba,wa];function Oa(n,e){var t=e.componentOptions;if(!(s(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var a,r,l=e.elm,c=n.data.attrs||{},d=e.data.attrs||{};for(a in(s(d.__ob__)||o(d._v_attr_proxy))&&(d=e.data.attrs=O({},d)),d)r=d[a],c[a]!==r&&Ca(l,a,r,e.data.pre);for(a in(J||K)&&d.value!==c.value&&Ca(l,"value",d.value),c)i(d[a])&&(aa(a)?l.removeAttributeNS(ta,ra(a)):Zt(a)||l.removeAttribute(a))}}function Ca(n,e,t,a){a||n.tagName.indexOf("-")>-1?Da(n,e,t):ea(e)?ia(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):Zt(e)?n.setAttribute(e,function(n,e){return ia(e)||"false"===e?"false":"contenteditable"===n&&na(e)?e:"true"}(e,t)):aa(e)?ia(t)?n.removeAttributeNS(ta,ra(e)):n.setAttributeNS(ta,e,t):Da(n,e,t)}function Da(n,e,t){if(ia(t))n.removeAttribute(e);else{if(J&&!X&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var a=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",a)};n.addEventListener("input",a),n.__ieph=!0}n.setAttribute(e,t)}}var Na={create:Oa,update:Oa};function La(n,e){var t=e.elm,a=e.data,r=n.data;if(!(i(a.staticClass)&&i(a.class)&&(i(r)||i(r.staticClass)&&i(r.class)))){var o=sa(e),l=t._transitionClasses;s(l)&&(o=la(o,ca(l))),o!==t._prevClass&&(t.setAttribute("class",o),t._prevClass=o)}}var Ma,Ra={create:La,update:La};function qa(n,e,t){var a=Ma;return function r(){var i=e.apply(null,arguments);null!==i&&Fa(n,r,t,a)}}var Pa=Ze&&!(en&&Number(en[1])<=53);function Ba(n,e,t,a){if(Pa){var r=Be,i=e;e=i._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=r||n.timeStamp<=0||n.target.ownerDocument!==document)return i.apply(this,arguments)}}Ma.addEventListener(n,e,an?{capture:t,passive:a}:t)}function Fa(n,e,t,a){(a||Ma).removeEventListener(n,e._wrapper||e,t)}function $a(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},a=n.data.on||{};Ma=e.elm||n.elm,function(n){if(s(n.__r)){var e=J?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}s(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Nn(t,a,Ba,Fa,qa,e.context),Ma=void 0}}var Ha,Ua={create:$a,update:$a,destroy:function(n){return $a(n,_a)}};function Ga(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,a,r=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(s(c.__ob__)||o(c._v_attr_proxy))&&(c=e.data.domProps=O({},c)),l)t in c||(r[t]="");for(t in c){if(a=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),a===l[t])continue;1===r.childNodes.length&&r.removeChild(r.childNodes[0])}if("value"===t&&"PROGRESS"!==r.tagName){r._value=a;var d=i(a)?"":String(a);Wa(r,d)&&(r.value=d)}else if("innerHTML"===t&&ma(r.tagName)&&i(r.innerHTML)){(Ha=Ha||document.createElement("div")).innerHTML="<svg>".concat(a,"</svg>");for(var p=Ha.firstChild;r.firstChild;)r.removeChild(r.firstChild);for(;p.firstChild;)r.appendChild(p.firstChild)}else if(a!==l[t])try{r[t]=a}catch(n){}}}}function Wa(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,a=n._vModifiers;if(s(a)){if(a.number)return b(t)!==b(e);if(a.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Qa={create:Ga,update:Ga},Ya=S((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var a=n.split(t);a.length>1&&(e[a[0].trim()]=a[1].trim())}})),e}));function Va(n){var e=Ja(n.style);return n.staticStyle?O(n.staticStyle,e):e}function Ja(n){return Array.isArray(n)?C(n):"string"==typeof n?Ya(n):n}var Xa,Ka=/^--/,Za=/\s*!important$/,nr=function(n,e,t){if(Ka.test(e))n.style.setProperty(e,t);else if(Za.test(t))n.style.setProperty(A(e),t.replace(Za,""),"important");else{var a=tr(e);if(Array.isArray(t))for(var r=0,i=t.length;r<i;r++)n.style[a]=t[r];else n.style[a]=t}},er=["Webkit","Moz","ms"],tr=S((function(n){if(Xa=Xa||document.createElement("div").style,"filter"!==(n=E(n))&&n in Xa)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<er.length;t++){var a=er[t]+e;if(a in Xa)return a}}));function ar(n,e){var t=e.data,a=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(a.staticStyle)&&i(a.style))){var r,o,l=e.elm,c=a.staticStyle,d=a.normalizedStyle||a.style||{},p=c||d,m=Ja(e.data.style)||{};e.data.normalizedStyle=s(m.__ob__)?O({},m):m;var u=function(n,e){var t,a={};if(e)for(var r=n;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=Va(r.data))&&O(a,t);(t=Va(n.data))&&O(a,t);for(var i=n;i=i.parent;)i.data&&(t=Va(i.data))&&O(a,t);return a}(e,!0);for(o in p)i(u[o])&&nr(l,o,"");for(o in u)(r=u[o])!==p[o]&&nr(l,o,null==r?"":r)}}var rr={create:ar,update:ar},ir=/\s+/;function sr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ir).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function or(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ir).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),a=" "+e+" ";t.indexOf(a)>=0;)t=t.replace(a," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function lr(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&O(e,cr(n.name||"v")),O(e,n),e}return"string"==typeof n?cr(n):void 0}}var cr=S((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),dr=Y&&!X,pr="transition",mr="transitionend",ur="animation",hr="animationend";dr&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(pr="WebkitTransition",mr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(ur="WebkitAnimation",hr="webkitAnimationEnd"));var fr=Y?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function gr(n){fr((function(){fr(n)}))}function br(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),sr(n,e))}function yr(n,e){n._transitionClasses&&_(n._transitionClasses,e),or(n,e)}function vr(n,e,t){var a=xr(n,e),r=a.type,i=a.timeout,s=a.propCount;if(!r)return t();var o="transition"===r?mr:hr,l=0,c=function(){n.removeEventListener(o,d),t()},d=function(e){e.target===n&&++l>=s&&c()};setTimeout((function(){l<s&&c()}),i+1),n.addEventListener(o,d)}var _r=/\b(transform|all)(,|$)/;function xr(n,e){var t,a=window.getComputedStyle(n),r=(a[pr+"Delay"]||"").split(", "),i=(a[pr+"Duration"]||"").split(", "),s=kr(r,i),o=(a[ur+"Delay"]||"").split(", "),l=(a[ur+"Duration"]||"").split(", "),c=kr(o,l),d=0,p=0;return"transition"===e?s>0&&(t="transition",d=s,p=i.length):"animation"===e?c>0&&(t="animation",d=c,p=l.length):p=(t=(d=Math.max(s,c))>0?s>c?"transition":"animation":null)?"transition"===t?i.length:l.length:0,{type:t,timeout:d,propCount:p,hasTransform:"transition"===t&&_r.test(a[pr+"Property"])}}function kr(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Sr(e)+Sr(n[t])})))}function Sr(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function wr(n,e){var t=n.elm;s(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var a=lr(n.data.transition);if(!i(a)&&!s(t._enterCb)&&1===t.nodeType){for(var r=a.css,o=a.type,l=a.enterClass,p=a.enterToClass,m=a.enterActiveClass,u=a.appearClass,h=a.appearToClass,f=a.appearActiveClass,g=a.beforeEnter,y=a.enter,v=a.afterEnter,_=a.enterCancelled,x=a.beforeAppear,k=a.appear,S=a.afterAppear,w=a.appearCancelled,E=a.duration,T=Ae,I=Ae.$vnode;I&&I.parent;)T=I.context,I=I.parent;var A=!T._isMounted||!n.isRootInsert;if(!A||k||""===k){var j=A&&u?u:l,z=A&&f?f:m,O=A&&h?h:p,C=A&&x||g,D=A&&c(k)?k:y,N=A&&S||v,L=A&&w||_,M=b(d(E)?E.enter:E);0;var R=!1!==r&&!X,P=Ir(D),B=t._enterCb=q((function(){R&&(yr(t,O),yr(t,z)),B.cancelled?(R&&yr(t,j),L&&L(t)):N&&N(t),t._enterCb=null}));n.data.show||Ln(n,"insert",(function(){var e=t.parentNode,a=e&&e._pending&&e._pending[n.key];a&&a.tag===n.tag&&a.elm._leaveCb&&a.elm._leaveCb(),D&&D(t,B)})),C&&C(t),R&&(br(t,j),br(t,z),gr((function(){yr(t,j),B.cancelled||(br(t,O),P||(Tr(M)?setTimeout(B,M):vr(t,o,B)))}))),n.data.show&&(e&&e(),D&&D(t,B)),R||P||B()}}}function Er(n,e){var t=n.elm;s(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var a=lr(n.data.transition);if(i(a)||1!==t.nodeType)return e();if(!s(t._leaveCb)){var r=a.css,o=a.type,l=a.leaveClass,c=a.leaveToClass,p=a.leaveActiveClass,m=a.beforeLeave,u=a.leave,h=a.afterLeave,f=a.leaveCancelled,g=a.delayLeave,y=a.duration,v=!1!==r&&!X,_=Ir(u),x=b(d(y)?y.leave:y);0;var k=t._leaveCb=q((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),v&&(yr(t,c),yr(t,p)),k.cancelled?(v&&yr(t,l),f&&f(t)):(e(),h&&h(t)),t._leaveCb=null}));g?g(S):S()}function S(){k.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),m&&m(t),v&&(br(t,l),br(t,p),gr((function(){yr(t,l),k.cancelled||(br(t,c),_||(Tr(x)?setTimeout(k,x):vr(t,o,k)))}))),u&&u(t,k),v||_||k())}}function Tr(n){return"number"==typeof n&&!isNaN(n)}function Ir(n){if(i(n))return!1;var e=n.fns;return s(e)?Ir(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Ar(n,e){!0!==e.data.show&&wr(e)}var jr=function(n){var e,t,a={},c=n.modules,d=n.nodeOps;for(e=0;e<xa.length;++e)for(a[xa[e]]=[],t=0;t<c.length;++t)s(c[t][xa[e]])&&a[xa[e]].push(c[t][xa[e]]);function p(n){var e=d.parentNode(n);s(e)&&d.removeChild(e,n)}function m(n,e,t,r,i,l,c){if(s(n.elm)&&s(l)&&(n=l[c]=kn(n)),n.isRootInsert=!i,!function(n,e,t,r){var i=n.data;if(s(i)){var l=s(n.componentInstance)&&i.keepAlive;if(s(i=i.hook)&&s(i=i.init)&&i(n,!1),s(n.componentInstance))return u(n,e),h(t,n.elm,r),o(l)&&function(n,e,t,r){var i,o=n;for(;o.componentInstance;)if(o=o.componentInstance._vnode,s(i=o.data)&&s(i=i.transition)){for(i=0;i<a.activate.length;++i)a.activate[i](_a,o);e.push(o);break}h(t,n.elm,r)}(n,e,t,r),!0}}(n,e,t,r)){var p=n.data,m=n.children,g=n.tag;s(g)?(n.elm=n.ns?d.createElementNS(n.ns,g):d.createElement(g,n),v(n),f(n,m,e),s(p)&&b(n,e),h(t,n.elm,r)):o(n.isComment)?(n.elm=d.createComment(n.text),h(t,n.elm,r)):(n.elm=d.createTextNode(n.text),h(t,n.elm,r))}}function u(n,e){s(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,g(n)?(b(n,e),v(n)):(ya(n),e.push(n))}function h(n,e,t){s(n)&&(s(t)?d.parentNode(t)===n&&d.insertBefore(n,e,t):d.appendChild(n,e))}function f(n,e,t){if(r(e)){0;for(var a=0;a<e.length;++a)m(e[a],t,n.elm,null,!0,e,a)}else l(n.text)&&d.appendChild(n.elm,d.createTextNode(String(n.text)))}function g(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return s(n.tag)}function b(n,t){for(var r=0;r<a.create.length;++r)a.create[r](_a,n);s(e=n.data.hook)&&(s(e.create)&&e.create(_a,n),s(e.insert)&&t.push(n))}function v(n){var e;if(s(e=n.fnScopeId))d.setStyleScope(n.elm,e);else for(var t=n;t;)s(e=t.context)&&s(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e),t=t.parent;s(e=Ae)&&e!==n.context&&e!==n.fnContext&&s(e=e.$options._scopeId)&&d.setStyleScope(n.elm,e)}function _(n,e,t,a,r,i){for(;a<=r;++a)m(t[a],i,n,e,!1,t,a)}function x(n){var e,t,r=n.data;if(s(r))for(s(e=r.hook)&&s(e=e.destroy)&&e(n),e=0;e<a.destroy.length;++e)a.destroy[e](n);if(s(e=n.children))for(t=0;t<n.children.length;++t)x(n.children[t])}function k(n,e,t){for(;e<=t;++e){var a=n[e];s(a)&&(s(a.tag)?(S(a),x(a)):p(a.elm))}}function S(n,e){if(s(e)||s(n.data)){var t,r=a.remove.length+1;for(s(e)?e.listeners+=r:e=function(n,e){function t(){0==--t.listeners&&p(n)}return t.listeners=e,t}(n.elm,r),s(t=n.componentInstance)&&s(t=t._vnode)&&s(t.data)&&S(t,e),t=0;t<a.remove.length;++t)a.remove[t](n,e);s(t=n.data.hook)&&s(t=t.remove)?t(n,e):e()}else p(n.elm)}function w(n,e,t,a){for(var r=t;r<a;r++){var i=e[r];if(s(i)&&ka(n,i))return r}}function E(n,e,t,r,l,c){if(n!==e){s(e.elm)&&s(r)&&(e=r[l]=kn(e));var p=e.elm=n.elm;if(o(n.isAsyncPlaceholder))s(e.asyncFactory.resolved)?A(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(o(e.isStatic)&&o(n.isStatic)&&e.key===n.key&&(o(e.isCloned)||o(e.isOnce)))e.componentInstance=n.componentInstance;else{var u,h=e.data;s(h)&&s(u=h.hook)&&s(u=u.prepatch)&&u(n,e);var f=n.children,b=e.children;if(s(h)&&g(e)){for(u=0;u<a.update.length;++u)a.update[u](n,e);s(u=h.hook)&&s(u=u.update)&&u(n,e)}i(e.text)?s(f)&&s(b)?f!==b&&function(n,e,t,a,r){var o,l,c,p=0,u=0,h=e.length-1,f=e[0],g=e[h],b=t.length-1,y=t[0],v=t[b],x=!r;for(0;p<=h&&u<=b;)i(f)?f=e[++p]:i(g)?g=e[--h]:ka(f,y)?(E(f,y,a,t,u),f=e[++p],y=t[++u]):ka(g,v)?(E(g,v,a,t,b),g=e[--h],v=t[--b]):ka(f,v)?(E(f,v,a,t,b),x&&d.insertBefore(n,f.elm,d.nextSibling(g.elm)),f=e[++p],v=t[--b]):ka(g,y)?(E(g,y,a,t,u),x&&d.insertBefore(n,g.elm,f.elm),g=e[--h],y=t[++u]):(i(o)&&(o=Sa(e,p,h)),i(l=s(y.key)?o[y.key]:w(y,e,p,h))?m(y,a,n,f.elm,!1,t,u):ka(c=e[l],y)?(E(c,y,a,t,u),e[l]=void 0,x&&d.insertBefore(n,c.elm,f.elm)):m(y,a,n,f.elm,!1,t,u),y=t[++u]);p>h?_(n,i(t[b+1])?null:t[b+1].elm,t,u,b,a):u>b&&k(e,p,h)}(p,f,b,t,c):s(b)?(s(n.text)&&d.setTextContent(p,""),_(p,null,b,0,b.length-1,t)):s(f)?k(f,0,f.length-1):s(n.text)&&d.setTextContent(p,""):n.text!==e.text&&d.setTextContent(p,e.text),s(h)&&s(u=h.hook)&&s(u=u.postpatch)&&u(n,e)}}}function T(n,e,t){if(o(t)&&s(n.parent))n.parent.data.pendingInsert=e;else for(var a=0;a<e.length;++a)e[a].data.hook.insert(e[a])}var I=y("attrs,class,staticClass,staticStyle,key");function A(n,e,t,a){var r,i=e.tag,l=e.data,c=e.children;if(a=a||l&&l.pre,e.elm=n,o(e.isComment)&&s(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(s(l)&&(s(r=l.hook)&&s(r=r.init)&&r(e,!0),s(r=e.componentInstance)))return u(e,t),!0;if(s(i)){if(s(c))if(n.hasChildNodes())if(s(r=l)&&s(r=r.domProps)&&s(r=r.innerHTML)){if(r!==n.innerHTML)return!1}else{for(var d=!0,p=n.firstChild,m=0;m<c.length;m++){if(!p||!A(p,c[m],t,a)){d=!1;break}p=p.nextSibling}if(!d||p)return!1}else f(e,c,t);if(s(l)){var h=!1;for(var g in l)if(!I(g)){h=!0,b(e,t);break}!h&&l.class&&On(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,r){if(!i(e)){var l,c=!1,p=[];if(i(n))c=!0,m(e,p);else{var u=s(n.nodeType);if(!u&&ka(n,e))E(n,e,p,null,null,r);else{if(u){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),o(t)&&A(n,e,p))return T(e,p,!0),n;l=n,n=new vn(d.tagName(l).toLowerCase(),{},[],void 0,l)}var h=n.elm,f=d.parentNode(h);if(m(e,p,h._leaveCb?null:f,d.nextSibling(h)),s(e.parent))for(var b=e.parent,y=g(e);b;){for(var v=0;v<a.destroy.length;++v)a.destroy[v](b);if(b.elm=e.elm,y){for(var _=0;_<a.create.length;++_)a.create[_](_a,b);var S=b.data.hook.insert;if(S.merged)for(var w=1;w<S.fns.length;w++)S.fns[w]()}else ya(b);b=b.parent}s(f)?k([n],0,0):s(n.tag)&&x(n)}}return T(e,p,c),e.elm}s(n)&&x(n)}}({nodeOps:ga,modules:[Na,Ra,Ua,Qa,rr,Y?{create:Ar,activate:Ar,remove:function(n,e){!0!==n.data.show?Er(n,e):e()}}:{}].concat(za)});X&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Rr(n,"input")}));var zr={inserted:function(n,e,t,a){"select"===t.tag?(a.elm&&!a.elm._vOptions?Ln(t,"postpatch",(function(){zr.componentUpdated(n,e,t)})):Or(n,e,t.context),n._vOptions=[].map.call(n.options,Nr)):("textarea"===t.tag||fa(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",Lr),n.addEventListener("compositionend",Mr),n.addEventListener("change",Mr),X&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Or(n,e,t.context);var a=n._vOptions,r=n._vOptions=[].map.call(n.options,Nr);if(r.some((function(n,e){return!M(n,a[e])})))(n.multiple?e.value.some((function(n){return Dr(n,r)})):e.value!==e.oldValue&&Dr(e.value,r))&&Rr(n,"change")}}};function Or(n,e,t){Cr(n,e,t),(J||K)&&setTimeout((function(){Cr(n,e,t)}),0)}function Cr(n,e,t){var a=e.value,r=n.multiple;if(!r||Array.isArray(a)){for(var i,s,o=0,l=n.options.length;o<l;o++)if(s=n.options[o],r)i=R(a,Nr(s))>-1,s.selected!==i&&(s.selected=i);else if(M(Nr(s),a))return void(n.selectedIndex!==o&&(n.selectedIndex=o));r||(n.selectedIndex=-1)}}function Dr(n,e){return e.every((function(e){return!M(e,n)}))}function Nr(n){return"_value"in n?n._value:n.value}function Lr(n){n.target.composing=!0}function Mr(n){n.target.composing&&(n.target.composing=!1,Rr(n.target,"input"))}function Rr(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function qr(n){return!n.componentInstance||n.data&&n.data.transition?n:qr(n.componentInstance._vnode)}var Pr={model:zr,show:{bind:function(n,e,t){var a=e.value,r=(t=qr(t)).data&&t.data.transition,i=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;a&&r?(t.data.show=!0,wr(t,(function(){n.style.display=i}))):n.style.display=a?i:"none"},update:function(n,e,t){var a=e.value;!a!=!e.oldValue&&((t=qr(t)).data&&t.data.transition?(t.data.show=!0,a?wr(t,(function(){n.style.display=n.__vOriginalDisplay})):Er(t,(function(){n.style.display="none"}))):n.style.display=a?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,a,r){r||(n.style.display=n.__vOriginalDisplay)}}},Br={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Fr(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Fr(Se(e.children)):n}function $r(n){var e={},t=n.$options;for(var a in t.propsData)e[a]=n[a];var r=t._parentListeners;for(var a in r)e[E(a)]=r[a];return e}function Hr(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Ur=function(n){return n.tag||Hn(n)},Gr=function(n){return"show"===n.name},Wr={name:"transition",props:Br,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Ur)).length){0;var a=this.mode;0;var r=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return r;var i=Fr(r);if(!i)return r;if(this._leaving)return Hr(n,r);var s="__transition-".concat(this._uid,"-");i.key=null==i.key?i.isComment?s+"comment":s+i.tag:l(i.key)?0===String(i.key).indexOf(s)?i.key:s+i.key:i.key;var o=(i.data||(i.data={})).transition=$r(this),c=this._vnode,d=Fr(c);if(i.data.directives&&i.data.directives.some(Gr)&&(i.data.show=!0),d&&d.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(i,d)&&!Hn(d)&&(!d.componentInstance||!d.componentInstance._vnode.isComment)){var p=d.data.transition=O({},o);if("out-in"===a)return this._leaving=!0,Ln(p,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Hr(n,r);if("in-out"===a){if(Hn(i))return c;var m,u=function(){m()};Ln(o,"afterEnter",u),Ln(o,"enterCancelled",u),Ln(p,"delayLeave",(function(n){m=n}))}}return r}}},Qr=O({tag:String,moveClass:String},Br);function Yr(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Vr(n){n.data.newPos=n.elm.getBoundingClientRect()}function Jr(n){var e=n.data.pos,t=n.data.newPos,a=e.left-t.left,r=e.top-t.top;if(a||r){n.data.moved=!0;var i=n.elm.style;i.transform=i.WebkitTransform="translate(".concat(a,"px,").concat(r,"px)"),i.transitionDuration="0s"}}delete Qr.mode;var Xr={Transition:Wr,TransitionGroup:{props:Qr,beforeMount:function(){var n=this,e=this._update;this._update=function(t,a){var r=je(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,r(),e.call(n,t,a)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),a=this.prevChildren=this.children,r=this.$slots.default||[],i=this.children=[],s=$r(this),o=0;o<r.length;o++){if((d=r[o]).tag)if(null!=d.key&&0!==String(d.key).indexOf("__vlist"))i.push(d),t[d.key]=d,(d.data||(d.data={})).transition=s;else;}if(a){var l=[],c=[];for(o=0;o<a.length;o++){var d;(d=a[o]).data.transition=s,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):c.push(d)}this.kept=n(e,null,l),this.removed=c}return n(e,null,i)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Yr),n.forEach(Vr),n.forEach(Jr),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,a=t.style;br(t,e),a.transform=a.WebkitTransform=a.transitionDuration="",t.addEventListener(mr,t._moveCb=function n(a){a&&a.target!==t||a&&!/transform$/.test(a.propertyName)||(t.removeEventListener(mr,n),t._moveCb=null,yr(t,e))})}})))},methods:{hasMove:function(n,e){if(!dr)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){or(t,n)})),sr(t,e),t.style.display="none",this.$el.appendChild(t);var a=xr(t);return this.$el.removeChild(t),this._hasMove=a.hasTransform}}}};function Kr(n,e){for(var t in e)n[t]=e[t];return n}Ht.config.mustUseProp=function(n,e,t){return"value"===t&&Kt(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Ht.config.isReservedTag=ua,Ht.config.isReservedAttr=Xt,Ht.config.getTagNamespace=function(n){return ma(n)?"svg":"math"===n?"math":void 0},Ht.config.isUnknownElement=function(n){if(!Y)return!0;if(ua(n))return!1;if(n=n.toLowerCase(),null!=ha[n])return ha[n];var e=document.createElement(n);return n.indexOf("-")>-1?ha[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:ha[n]=/HTMLUnknownElement/.test(e.toString())},O(Ht.options.directives,Pr),O(Ht.options.components,Xr),Ht.prototype.__patch__=Y?jr:D,Ht.prototype.$mount=function(n,e){return function(n,e,t){var a;n.$el=e,n.$options.render||(n.$options.render=_n),Ce(n,"beforeMount"),a=function(){n._update(n._render(),t)},new Qe(n,a,D,{before:function(){n._isMounted&&!n._isDestroyed&&Ce(n,"beforeUpdate")}},!0),t=!1;var r=n._preWatchers;if(r)for(var i=0;i<r.length;i++)r[i].run();return null==n.$vnode&&(n._isMounted=!0,Ce(n,"mounted")),n}(this,n=n&&Y?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Y&&setTimeout((function(){$.devtools&&on&&on.emit("init",Ht)}),0);var Zr=/[!'()*]/g,ni=function(n){return"%"+n.charCodeAt(0).toString(16)},ei=/%2C/g,ti=function(n){return encodeURIComponent(n).replace(Zr,ni).replace(ei,",")};function ai(n){try{return decodeURIComponent(n)}catch(n){0}return n}var ri=function(n){return null==n||"object"==typeof n?n:String(n)};function ii(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),a=ai(t.shift()),r=t.length>0?ai(t.join("=")):null;void 0===e[a]?e[a]=r:Array.isArray(e[a])?e[a].push(r):e[a]=[e[a],r]})),e):e}function si(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ti(e);if(Array.isArray(t)){var a=[];return t.forEach((function(n){void 0!==n&&(null===n?a.push(ti(e)):a.push(ti(e)+"="+ti(n)))})),a.join("&")}return ti(e)+"="+ti(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var oi=/\/?$/;function li(n,e,t,a){var r=a&&a.options.stringifyQuery,i=e.query||{};try{i=ci(i)}catch(n){}var s={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:i,params:e.params||{},fullPath:mi(e,r),matched:n?pi(n):[]};return t&&(s.redirectedFrom=mi(t,r)),Object.freeze(s)}function ci(n){if(Array.isArray(n))return n.map(ci);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=ci(n[t]);return e}return n}var di=li(null,{path:"/"});function pi(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function mi(n,e){var t=n.path,a=n.query;void 0===a&&(a={});var r=n.hash;return void 0===r&&(r=""),(t||"/")+(e||si)(a)+r}function ui(n,e,t){return e===di?n===e:!!e&&(n.path&&e.path?n.path.replace(oi,"")===e.path.replace(oi,"")&&(t||n.hash===e.hash&&hi(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&hi(n.query,e.query)&&hi(n.params,e.params))))}function hi(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),a=Object.keys(e).sort();return t.length===a.length&&t.every((function(t,r){var i=n[t];if(a[r]!==t)return!1;var s=e[t];return null==i||null==s?i===s:"object"==typeof i&&"object"==typeof s?hi(i,s):String(i)===String(s)}))}function fi(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var a in t.instances){var r=t.instances[a],i=t.enteredCbs[a];if(r&&i){delete t.enteredCbs[a];for(var s=0;s<i.length;s++)r._isBeingDestroyed||i[s](r)}}}}var gi={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,a=e.children,r=e.parent,i=e.data;i.routerView=!0;for(var s=r.$createElement,o=t.name,l=r.$route,c=r._routerViewCache||(r._routerViewCache={}),d=0,p=!1;r&&r._routerRoot!==r;){var m=r.$vnode?r.$vnode.data:{};m.routerView&&d++,m.keepAlive&&r._directInactive&&r._inactive&&(p=!0),r=r.$parent}if(i.routerViewDepth=d,p){var u=c[o],h=u&&u.component;return h?(u.configProps&&bi(h,i,u.route,u.configProps),s(h,i,a)):s()}var f=l.matched[d],g=f&&f.components[o];if(!f||!g)return c[o]=null,s();c[o]={component:g},i.registerRouteInstance=function(n,e){var t=f.instances[o];(e&&t!==n||!e&&t===n)&&(f.instances[o]=e)},(i.hook||(i.hook={})).prepatch=function(n,e){f.instances[o]=e.componentInstance},i.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==f.instances[o]&&(f.instances[o]=n.componentInstance),fi(l)};var b=f.props&&f.props[o];return b&&(Kr(c[o],{route:l,configProps:b}),bi(g,i,l,b)),s(g,i,a)}};function bi(n,e,t,a){var r=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,a);if(r){r=e.props=Kr({},r);var i=e.attrs=e.attrs||{};for(var s in r)n.props&&s in n.props||(i[s]=r[s],delete r[s])}}function yi(n,e,t){var a=n.charAt(0);if("/"===a)return n;if("?"===a||"#"===a)return e+n;var r=e.split("/");t&&r[r.length-1]||r.pop();for(var i=n.replace(/^\//,"").split("/"),s=0;s<i.length;s++){var o=i[s];".."===o?r.pop():"."!==o&&r.push(o)}return""!==r[0]&&r.unshift(""),r.join("/")}function vi(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var _i=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},xi=Li,ki=Ii,Si=function(n,e){return ji(Ii(n,e),e)},wi=ji,Ei=Ni,Ti=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Ii(n,e){for(var t,a=[],r=0,i=0,s="",o=e&&e.delimiter||"/";null!=(t=Ti.exec(n));){var l=t[0],c=t[1],d=t.index;if(s+=n.slice(i,d),i=d+l.length,c)s+=c[1];else{var p=n[i],m=t[2],u=t[3],h=t[4],f=t[5],g=t[6],b=t[7];s&&(a.push(s),s="");var y=null!=m&&null!=p&&p!==m,v="+"===g||"*"===g,_="?"===g||"*"===g,x=t[2]||o,k=h||f;a.push({name:u||r++,prefix:m||"",delimiter:x,optional:_,repeat:v,partial:y,asterisk:!!b,pattern:k?Oi(k):b?".*":"[^"+zi(x)+"]+?"})}}return i<n.length&&(s+=n.substr(i)),s&&a.push(s),a}function Ai(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function ji(n,e){for(var t=new Array(n.length),a=0;a<n.length;a++)"object"==typeof n[a]&&(t[a]=new RegExp("^(?:"+n[a].pattern+")$",Di(e)));return function(e,a){for(var r="",i=e||{},s=(a||{}).pretty?Ai:encodeURIComponent,o=0;o<n.length;o++){var l=n[o];if("string"!=typeof l){var c,d=i[l.name];if(null==d){if(l.optional){l.partial&&(r+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(_i(d)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(d)+"`");if(0===d.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var p=0;p<d.length;p++){if(c=s(d[p]),!t[o].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");r+=(0===p?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(d).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):s(d),!t[o].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');r+=l.prefix+c}}else r+=l}return r}}function zi(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Oi(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Ci(n,e){return n.keys=e,n}function Di(n){return n&&n.sensitive?"":"i"}function Ni(n,e,t){_i(e)||(t=e||t,e=[]);for(var a=(t=t||{}).strict,r=!1!==t.end,i="",s=0;s<n.length;s++){var o=n[s];if("string"==typeof o)i+=zi(o);else{var l=zi(o.prefix),c="(?:"+o.pattern+")";e.push(o),o.repeat&&(c+="(?:"+l+c+")*"),i+=c=o.optional?o.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var d=zi(t.delimiter||"/"),p=i.slice(-d.length)===d;return a||(i=(p?i.slice(0,-d.length):i)+"(?:"+d+"(?=$))?"),i+=r?"$":a&&p?"":"(?="+d+"|$)",Ci(new RegExp("^"+i,Di(t)),e)}function Li(n,e,t){return _i(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var a=0;a<t.length;a++)e.push({name:a,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Ci(n,e)}(n,e):_i(n)?function(n,e,t){for(var a=[],r=0;r<n.length;r++)a.push(Li(n[r],e,t).source);return Ci(new RegExp("(?:"+a.join("|")+")",Di(t)),e)}(n,e,t):function(n,e,t){return Ni(Ii(n,t),e,t)}(n,e,t)}xi.parse=ki,xi.compile=Si,xi.tokensToFunction=wi,xi.tokensToRegExp=Ei;var Mi=Object.create(null);function Ri(n,e,t){e=e||{};try{var a=Mi[n]||(Mi[n]=xi.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),a(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function qi(n,e,t,a){var r="string"==typeof n?{path:n}:n;if(r._normalized)return r;if(r.name){var i=(r=Kr({},n)).params;return i&&"object"==typeof i&&(r.params=Kr({},i)),r}if(!r.path&&r.params&&e){(r=Kr({},r))._normalized=!0;var s=Kr(Kr({},e.params),r.params);if(e.name)r.name=e.name,r.params=s;else if(e.matched.length){var o=e.matched[e.matched.length-1].path;r.path=Ri(o,s,e.path)}else 0;return r}var l=function(n){var e="",t="",a=n.indexOf("#");a>=0&&(e=n.slice(a),n=n.slice(0,a));var r=n.indexOf("?");return r>=0&&(t=n.slice(r+1),n=n.slice(0,r)),{path:n,query:t,hash:e}}(r.path||""),c=e&&e.path||"/",d=l.path?yi(l.path,c,t||r.append):c,p=function(n,e,t){void 0===e&&(e={});var a,r=t||ii;try{a=r(n||"")}catch(n){a={}}for(var i in e){var s=e[i];a[i]=Array.isArray(s)?s.map(ri):ri(s)}return a}(l.query,r.query,a&&a.options.parseQuery),m=r.hash||l.hash;return m&&"#"!==m.charAt(0)&&(m="#"+m),{_normalized:!0,path:d,query:p,hash:m}}var Pi,Bi=function(){},Fi={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,a=this.$route,r=t.resolve(this.to,a,this.append),i=r.location,s=r.route,o=r.href,l={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,p=null==c?"router-link-active":c,m=null==d?"router-link-exact-active":d,u=null==this.activeClass?p:this.activeClass,h=null==this.exactActiveClass?m:this.exactActiveClass,f=s.redirectedFrom?li(null,qi(s.redirectedFrom),null,t):s;l[h]=ui(a,f,this.exactPath),l[u]=this.exact||this.exactPath?l[h]:function(n,e){return 0===n.path.replace(oi,"/").indexOf(e.path.replace(oi,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(a,f);var g=l[h]?this.ariaCurrentValue:null,b=function(n){$i(n)&&(e.replace?t.replace(i,Bi):t.push(i,Bi))},y={click:$i};Array.isArray(this.event)?this.event.forEach((function(n){y[n]=b})):y[this.event]=b;var v={class:l},_=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:o,route:s,navigate:b,isActive:l[u],isExactActive:l[h]});if(_){if(1===_.length)return _[0];if(_.length>1||!_.length)return 0===_.length?n():n("span",{},_)}if("a"===this.tag)v.on=y,v.attrs={href:o,"aria-current":g};else{var x=function n(e){var t;if(e)for(var a=0;a<e.length;a++){if("a"===(t=e[a]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(x){x.isStatic=!1;var k=x.data=Kr({},x.data);for(var S in k.on=k.on||{},k.on){var w=k.on[S];S in y&&(k.on[S]=Array.isArray(w)?w:[w])}for(var E in y)E in k.on?k.on[E].push(y[E]):k.on[E]=b;var T=x.data.attrs=Kr({},x.data.attrs);T.href=o,T["aria-current"]=g}else v.on=y}return n(this.tag,v,this.$slots.default)}};function $i(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Hi="undefined"!=typeof window;function Ui(n,e,t,a,r){var i=e||[],s=t||Object.create(null),o=a||Object.create(null);n.forEach((function(n){!function n(e,t,a,r,i,s){var o=r.path,l=r.name;0;var c=r.pathToRegexpOptions||{},d=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return vi(e.path+"/"+n)}(o,i,c.strict);"boolean"==typeof r.caseSensitive&&(c.sensitive=r.caseSensitive);var p={path:d,regex:Gi(d,c),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:l,parent:i,matchAs:s,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var i=s?vi(s+"/"+r.path):void 0;n(e,t,a,r,p,i)}));t[p.path]||(e.push(p.path),t[p.path]=p);if(void 0!==r.alias)for(var m=Array.isArray(r.alias)?r.alias:[r.alias],u=0;u<m.length;++u){0;var h={path:m[u],children:r.children};n(e,t,a,h,i,p.path||"/")}l&&(a[l]||(a[l]=p))}(i,s,o,n,r)}));for(var l=0,c=i.length;l<c;l++)"*"===i[l]&&(i.push(i.splice(l,1)[0]),c--,l--);return{pathList:i,pathMap:s,nameMap:o}}function Gi(n,e){return xi(n,[],e)}function Wi(n,e){var t=Ui(n),a=t.pathList,r=t.pathMap,i=t.nameMap;function s(n,t,s){var o=qi(n,t,!1,e),c=o.name;if(c){var d=i[c];if(!d)return l(null,o);var p=d.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof o.params&&(o.params={}),t&&"object"==typeof t.params)for(var m in t.params)!(m in o.params)&&p.indexOf(m)>-1&&(o.params[m]=t.params[m]);return o.path=Ri(d.path,o.params),l(d,o,s)}if(o.path){o.params={};for(var u=0;u<a.length;u++){var h=a[u],f=r[h];if(Qi(f.regex,o.path,o.params))return l(f,o,s)}}return l(null,o)}function o(n,t){var a=n.redirect,r="function"==typeof a?a(li(n,t,null,e)):a;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return l(null,t);var o=r,c=o.name,d=o.path,p=t.query,m=t.hash,u=t.params;if(p=o.hasOwnProperty("query")?o.query:p,m=o.hasOwnProperty("hash")?o.hash:m,u=o.hasOwnProperty("params")?o.params:u,c){i[c];return s({_normalized:!0,name:c,query:p,hash:m,params:u},void 0,t)}if(d){var h=function(n,e){return yi(n,e.parent?e.parent.path:"/",!0)}(d,n);return s({_normalized:!0,path:Ri(h,u),query:p,hash:m},void 0,t)}return l(null,t)}function l(n,t,a){return n&&n.redirect?o(n,a||t):n&&n.matchAs?function(n,e,t){var a=s({_normalized:!0,path:Ri(t,e.params)});if(a){var r=a.matched,i=r[r.length-1];return e.params=a.params,l(i,e)}return l(null,e)}(0,t,n.matchAs):li(n,t,a,e)}return{match:s,addRoute:function(n,e){var t="object"!=typeof n?i[n]:void 0;Ui([e||n],a,r,i,t),t&&t.alias.length&&Ui(t.alias.map((function(n){return{path:n,children:[e]}})),a,r,i,t)},getRoutes:function(){return a.map((function(n){return r[n]}))},addRoutes:function(n){Ui(n,a,r,i)}}}function Qi(n,e,t){var a=e.match(n);if(!a)return!1;if(!t)return!0;for(var r=1,i=a.length;r<i;++r){var s=n.keys[r-1];s&&(t[s.name||"pathMatch"]="string"==typeof a[r]?ai(a[r]):a[r])}return!0}var Yi=Hi&&window.performance&&window.performance.now?window.performance:Date;function Vi(){return Yi.now().toFixed(3)}var Ji=Vi();function Xi(){return Ji}function Ki(n){return Ji=n}var Zi=Object.create(null);function ns(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=Kr({},window.history.state);return t.key=Xi(),window.history.replaceState(t,"",e),window.addEventListener("popstate",as),function(){window.removeEventListener("popstate",as)}}function es(n,e,t,a){if(n.app){var r=n.options.scrollBehavior;r&&n.app.$nextTick((function(){var i=function(){var n=Xi();if(n)return Zi[n]}(),s=r.call(n,e,t,a?i:null);s&&("function"==typeof s.then?s.then((function(n){ls(n,i)})).catch((function(n){0})):ls(s,i))}))}}function ts(){var n=Xi();n&&(Zi[n]={x:window.pageXOffset,y:window.pageYOffset})}function as(n){ts(),n.state&&n.state.key&&Ki(n.state.key)}function rs(n){return ss(n.x)||ss(n.y)}function is(n){return{x:ss(n.x)?n.x:window.pageXOffset,y:ss(n.y)?n.y:window.pageYOffset}}function ss(n){return"number"==typeof n}var os=/^#\d/;function ls(n,e){var t,a="object"==typeof n;if(a&&"string"==typeof n.selector){var r=os.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(r){var i=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),a=n.getBoundingClientRect();return{x:a.left-t.left-e.x,y:a.top-t.top-e.y}}(r,i={x:ss((t=i).x)?t.x:0,y:ss(t.y)?t.y:0})}else rs(n)&&(e=is(n))}else a&&rs(n)&&(e=is(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var cs,ds=Hi&&((-1===(cs=window.navigator.userAgent).indexOf("Android 2.")&&-1===cs.indexOf("Android 4.0")||-1===cs.indexOf("Mobile Safari")||-1!==cs.indexOf("Chrome")||-1!==cs.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function ps(n,e){ts();var t=window.history;try{if(e){var a=Kr({},t.state);a.key=Xi(),t.replaceState(a,"",n)}else t.pushState({key:Ki(Vi())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function ms(n){ps(n,!0)}function us(n,e,t){var a=function(r){r>=n.length?t():n[r]?e(n[r],(function(){a(r+1)})):a(r+1)};a(0)}var hs={redirected:2,aborted:4,cancelled:8,duplicated:16};function fs(n,e){return bs(n,e,hs.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ys.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function gs(n,e){return bs(n,e,hs.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function bs(n,e,t,a){var r=new Error(a);return r._isRouter=!0,r.from=n,r.to=e,r.type=t,r}var ys=["params","query","hash"];function vs(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function _s(n,e){return vs(n)&&n._isRouter&&(null==e||n.type===e)}function xs(n){return function(e,t,a){var r=!1,i=0,s=null;ks(n,(function(n,e,t,o){if("function"==typeof n&&void 0===n.cid){r=!0,i++;var l,c=Es((function(e){var r;((r=e).__esModule||ws&&"Module"===r[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Pi.extend(e),t.components[o]=e,--i<=0&&a()})),d=Es((function(n){var e="Failed to resolve async component "+o+": "+n;s||(s=vs(n)?n:new Error(e),a(s))}));try{l=n(c,d)}catch(n){d(n)}if(l)if("function"==typeof l.then)l.then(c,d);else{var p=l.component;p&&"function"==typeof p.then&&p.then(c,d)}}})),r||a()}}function ks(n,e){return Ss(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ss(n){return Array.prototype.concat.apply([],n)}var ws="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Es(n){var e=!1;return function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];if(!e)return e=!0,n.apply(this,t)}}var Ts=function(n,e){this.router=n,this.base=function(n){if(!n)if(Hi){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=di,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Is(n,e,t,a){var r=ks(n,(function(n,a,r,i){var s=function(n,e){"function"!=typeof n&&(n=Pi.extend(n));return n.options[e]}(n,e);if(s)return Array.isArray(s)?s.map((function(n){return t(n,a,r,i)})):t(s,a,r,i)}));return Ss(a?r.reverse():r)}function As(n,e){if(e)return function(){return n.apply(e,arguments)}}Ts.prototype.listen=function(n){this.cb=n},Ts.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Ts.prototype.onError=function(n){this.errorCbs.push(n)},Ts.prototype.transitionTo=function(n,e,t){var a,r=this;try{a=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var i=this.current;this.confirmTransition(a,(function(){r.updateRoute(a),e&&e(a),r.ensureURL(),r.router.afterHooks.forEach((function(n){n&&n(a,i)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(n){n(a)})))}),(function(n){t&&t(n),n&&!r.ready&&(_s(n,hs.redirected)&&i===di||(r.ready=!0,r.readyErrorCbs.forEach((function(e){e(n)}))))}))},Ts.prototype.confirmTransition=function(n,e,t){var a=this,r=this.current;this.pending=n;var i,s,o=function(n){!_s(n)&&vs(n)&&(a.errorCbs.length?a.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=r.matched.length-1;if(ui(n,r)&&l===c&&n.matched[l]===r.matched[c])return this.ensureURL(),n.hash&&es(this.router,r,n,!1),o(((s=bs(i=r,n,hs.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",s));var d=function(n,e){var t,a=Math.max(n.length,e.length);for(t=0;t<a&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),p=d.updated,m=d.deactivated,u=d.activated,h=[].concat(function(n){return Is(n,"beforeRouteLeave",As,!0)}(m),this.router.beforeHooks,function(n){return Is(n,"beforeRouteUpdate",As)}(p),u.map((function(n){return n.beforeEnter})),xs(u)),f=function(e,t){if(a.pending!==n)return o(gs(r,n));try{e(n,r,(function(e){!1===e?(a.ensureURL(!0),o(function(n,e){return bs(n,e,hs.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(r,n))):vs(e)?(a.ensureURL(!0),o(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(o(fs(r,n)),"object"==typeof e&&e.replace?a.replace(e):a.push(e)):t(e)}))}catch(n){o(n)}};us(h,f,(function(){us(function(n){return Is(n,"beforeRouteEnter",(function(n,e,t,a){return function(n,e,t){return function(a,r,i){return n(a,r,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),i(n)}))}}(n,t,a)}))}(u).concat(a.router.resolveHooks),f,(function(){if(a.pending!==n)return o(gs(r,n));a.pending=null,e(n),a.router.app&&a.router.app.$nextTick((function(){fi(n)}))}))}))},Ts.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Ts.prototype.setupListeners=function(){},Ts.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=di,this.pending=null};var js=function(n){function e(e,t){n.call(this,e,t),this._startLocation=zs(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,a=ds&&t;a&&this.listeners.push(ns());var r=function(){var t=n.current,r=zs(n.base);n.current===di&&r===n._startLocation||n.transitionTo(r,(function(n){a&&es(e,n,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){ps(vi(a.base+n.fullPath)),es(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){ms(vi(a.base+n.fullPath)),es(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(zs(this.base)!==this.current.fullPath){var e=vi(this.base+this.current.fullPath);n?ps(e):ms(e)}},e.prototype.getCurrentLocation=function(){return zs(this.base)},e}(Ts);function zs(n){var e=window.location.pathname,t=e.toLowerCase(),a=n.toLowerCase();return!n||t!==a&&0!==t.indexOf(vi(a+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Os=function(n){function e(e,t,a){n.call(this,e,t),a&&function(n){var e=zs(n);if(!/^\/#/.test(e))return window.location.replace(vi(n+"/#"+e)),!0}(this.base)||Cs()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=ds&&e;t&&this.listeners.push(ns());var a=function(){var e=n.current;Cs()&&n.transitionTo(Ds(),(function(a){t&&es(n.router,a,e,!0),ds||Ms(a.fullPath)}))},r=ds?"popstate":"hashchange";window.addEventListener(r,a),this.listeners.push((function(){window.removeEventListener(r,a)}))}},e.prototype.push=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){Ls(n.fullPath),es(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this,r=this.current;this.transitionTo(n,(function(n){Ms(n.fullPath),es(a.router,n,r,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Ds()!==e&&(n?Ls(e):Ms(e))},e.prototype.getCurrentLocation=function(){return Ds()},e}(Ts);function Cs(){var n=Ds();return"/"===n.charAt(0)||(Ms("/"+n),!1)}function Ds(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Ns(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Ls(n){ds?ps(Ns(n)):window.location.hash=n}function Ms(n){ds?ms(Ns(n)):window.location.replace(Ns(n))}var Rs=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var a=this;this.transitionTo(n,(function(n){a.stack=a.stack.slice(0,a.index+1).concat(n),a.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var a=this;this.transitionTo(n,(function(n){a.stack=a.stack.slice(0,a.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var a=this.stack[t];this.confirmTransition(a,(function(){var n=e.current;e.index=t,e.updateRoute(a),e.router.afterHooks.forEach((function(e){e&&e(a,n)}))}),(function(n){_s(n,hs.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Ts),qs=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Wi(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!ds&&!1!==n.fallback,this.fallback&&(e="hash"),Hi||(e="abstract"),this.mode=e,e){case"history":this.history=new js(this,n.base);break;case"hash":this.history=new Os(this,n.base,this.fallback);break;case"abstract":this.history=new Rs(this,n.base);break;default:0}},Ps={currentRoute:{configurable:!0}};function Bs(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}qs.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Ps.currentRoute.get=function(){return this.history&&this.history.current},qs.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof js||t instanceof Os){var a=function(n){t.setupListeners(),function(n){var a=t.current,r=e.options.scrollBehavior;ds&&r&&"fullPath"in n&&es(e,n,a,!1)}(n)};t.transitionTo(t.getCurrentLocation(),a,a)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},qs.prototype.beforeEach=function(n){return Bs(this.beforeHooks,n)},qs.prototype.beforeResolve=function(n){return Bs(this.resolveHooks,n)},qs.prototype.afterEach=function(n){return Bs(this.afterHooks,n)},qs.prototype.onReady=function(n,e){this.history.onReady(n,e)},qs.prototype.onError=function(n){this.history.onError(n)},qs.prototype.push=function(n,e,t){var a=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){a.history.push(n,e,t)}));this.history.push(n,e,t)},qs.prototype.replace=function(n,e,t){var a=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){a.history.replace(n,e,t)}));this.history.replace(n,e,t)},qs.prototype.go=function(n){this.history.go(n)},qs.prototype.back=function(){this.go(-1)},qs.prototype.forward=function(){this.go(1)},qs.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},qs.prototype.resolve=function(n,e,t){var a=qi(n,e=e||this.history.current,t,this),r=this.match(a,e),i=r.redirectedFrom||r.fullPath;return{location:a,route:r,href:function(n,e,t){var a="hash"===t?"#"+e:e;return n?vi(n+"/"+a):a}(this.history.base,i,this.mode),normalizedTo:a,resolved:r}},qs.prototype.getRoutes=function(){return this.matcher.getRoutes()},qs.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==di&&this.history.transitionTo(this.history.getCurrentLocation())},qs.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==di&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(qs.prototype,Ps),qs.install=function n(e){if(!n.installed||Pi!==e){n.installed=!0,Pi=e;var t=function(n){return void 0!==n},a=function(n,e){var a=n.$options._parentVnode;t(a)&&t(a=a.data)&&t(a=a.registerRouteInstance)&&a(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,a(this,this)},destroyed:function(){a(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",gi),e.component("RouterLink",Fi);var r=e.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},qs.version="3.5.4",qs.isNavigationFailure=_s,qs.NavigationFailureType=hs,qs.START_LOCATION=di,Hi&&window.Vue&&window.Vue.use(qs);var Fs=qs;t(103);t(126);var $s={NotFound:()=>Promise.all([t.e(0),t.e(5)]).then(t.bind(null,337)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,336))},Hs={"v-2df947ea":()=>t.e(11).then(t.bind(null,350)),"v-d2fb2a82":()=>t.e(13).then(t.bind(null,351)),"v-689808d8":()=>t.e(14).then(t.bind(null,352)),"v-29791135":()=>t.e(15).then(t.bind(null,353)),"v-4c2230e8":()=>t.e(16).then(t.bind(null,354)),"v-1a0eb102":()=>t.e(17).then(t.bind(null,355)),"v-2c168266":()=>t.e(18).then(t.bind(null,338)),"v-c32a4ba6":()=>t.e(19).then(t.bind(null,339)),"v-1d12c416":()=>t.e(12).then(t.bind(null,356)),"v-8aa2b0da":()=>t.e(21).then(t.bind(null,340)),"v-81b6555c":()=>t.e(20).then(t.bind(null,341)),"v-830992f8":()=>t.e(23).then(t.bind(null,342)),"v-f5852fb2":()=>t.e(22).then(t.bind(null,343)),"v-11fe809f":()=>t.e(24).then(t.bind(null,344)),"v-74435332":()=>t.e(25).then(t.bind(null,345)),"v-0469e89f":()=>t.e(26).then(t.bind(null,346)),"v-3ed5a0cf":()=>t.e(27).then(t.bind(null,347)),"v-7487d51a":()=>t.e(28).then(t.bind(null,348)),"v-bed51406":()=>t.e(29).then(t.bind(null,357)),"v-42c6f9fa":()=>t.e(30).then(t.bind(null,358)),"v-30099682":()=>t.e(31).then(t.bind(null,359)),"v-f9f8fc5c":()=>t.e(32).then(t.bind(null,360)),"v-2fa3e257":()=>t.e(33).then(t.bind(null,361)),"v-5063a9cb":()=>t.e(34).then(t.bind(null,362)),"v-7f6942cf":()=>t.e(35).then(t.bind(null,363)),"v-786d75c7":()=>t.e(36).then(t.bind(null,364)),"v-bb3e9386":()=>t.e(37).then(t.bind(null,365)),"v-555e21cf":()=>t.e(38).then(t.bind(null,366)),"v-92803bde":()=>t.e(39).then(t.bind(null,367)),"v-9b1324b0":()=>t.e(3).then(t.bind(null,368)),"v-a16758b4":()=>t.e(40).then(t.bind(null,369)),"v-6c2b8593":()=>t.e(8).then(t.bind(null,370)),"v-e35d4030":()=>t.e(42).then(t.bind(null,371)),"v-0221b7b2":()=>t.e(41).then(t.bind(null,372)),"v-356e286c":()=>t.e(43).then(t.bind(null,373)),"v-e9baf2c8":()=>t.e(44).then(t.bind(null,374)),"v-db83fd4c":()=>t.e(45).then(t.bind(null,375)),"v-51040124":()=>t.e(47).then(t.bind(null,376)),"v-d4ddf460":()=>t.e(48).then(t.bind(null,377)),"v-2c5956be":()=>t.e(49).then(t.bind(null,378)),"v-1fd37798":()=>t.e(46).then(t.bind(null,379)),"v-63f04fc0":()=>t.e(50).then(t.bind(null,349)),"v-599d1974":()=>t.e(51).then(t.bind(null,380)),"v-0c3bcc96":()=>t.e(53).then(t.bind(null,381)),"v-a5e93828":()=>t.e(52).then(t.bind(null,382)),"v-f125018c":()=>t.e(55).then(t.bind(null,383)),"v-01457896":()=>t.e(56).then(t.bind(null,384)),"v-7ea7fc0c":()=>t.e(54).then(t.bind(null,385)),"v-4448404b":()=>t.e(57).then(t.bind(null,386)),"v-227c94e8":()=>t.e(58).then(t.bind(null,387)),"v-1e74358a":()=>t.e(9).then(t.bind(null,388)),"v-656f9cf6":()=>t.e(59).then(t.bind(null,389)),"v-5a91a923":()=>t.e(60).then(t.bind(null,390)),"v-50566ea5":()=>t.e(10).then(t.bind(null,391)),"v-00c7823d":()=>t.e(61).then(t.bind(null,392)),"v-2a8f5aa8":()=>t.e(63).then(t.bind(null,393)),"v-a4ab2664":()=>t.e(62).then(t.bind(null,394)),"v-2bc194fa":()=>t.e(64).then(t.bind(null,395)),"v-1dc96cde":()=>t.e(66).then(t.bind(null,396)),"v-152fe1e4":()=>t.e(65).then(t.bind(null,397)),"v-547abcde":()=>t.e(67).then(t.bind(null,398)),"v-6ece5467":()=>t.e(68).then(t.bind(null,399)),"v-e244ce58":()=>t.e(69).then(t.bind(null,400)),"v-412d7d01":()=>t.e(70).then(t.bind(null,401)),"v-0499277d":()=>t.e(71).then(t.bind(null,402)),"v-00f00e91":()=>Promise.all([t.e(0),t.e(6)]).then(t.bind(null,403)),"v-48901c43":()=>t.e(72).then(t.bind(null,404)),"v-68f50c4e":()=>t.e(73).then(t.bind(null,405)),"v-5e6eb6cd":()=>t.e(74).then(t.bind(null,406)),"v-acb49e1a":()=>t.e(76).then(t.bind(null,407)),"v-90e7de80":()=>t.e(75).then(t.bind(null,408)),"v-447f8646":()=>t.e(77).then(t.bind(null,409)),"v-460c88ea":()=>t.e(78).then(t.bind(null,410)),"v-5111c592":()=>Promise.all([t.e(0),t.e(7)]).then(t.bind(null,411))};function Us(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Gs=/-(\w)/g,Ws=Us(n=>n.replace(Gs,(n,e)=>e?e.toUpperCase():"")),Qs=/\B([A-Z])/g,Ys=Us(n=>n.replace(Qs,"-$1").toLowerCase()),Vs=Us(n=>n.charAt(0).toUpperCase()+n.slice(1));function Js(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Vs(Ws(e))):n(Vs(e))||n(Ys(e))}const Xs=Object.assign({},$s,Hs),Ks=n=>Xs[n],Zs=n=>Hs[n],no=n=>$s[n],eo=n=>Ht.component(n);function to(n){return Js(Zs,n)}function ao(n){return Js(no,n)}function ro(n){return Js(Ks,n)}function io(n){return Js(eo,n)}function so(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!io(n)&&ro(n)){const e=await ro(n)();Ht.component(n,e.default)}}))}function oo(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var lo=t(92),co=t.n(lo),po=t(93),mo=t.n(po),uo={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${mo()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=fo(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=go(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return co()([{name:"description",content:this.$description}],n,this.siteMeta,bo)},updateCanonicalLink(){ho(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",fo(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){go(null,this.currentMetaTags),ho()}};function ho(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function fo(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function go(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function bo(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var yo=t(49),vo={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(yo)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),a=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+t;for(let n=0;n<e.length;n++){const i=e[n],s=e[n+1],o=0===n&&0===t||t>=i.parentElement.offsetTop+10&&(!s||t<s.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(o&&l!==decodeURIComponent(i.hash)){const t=i;if(r===a)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},_o=t(23),xo=t.n(_o),ko={mounted(){xo.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Ht.component(n.name)||xo.a.start(),t()}),this.$router.afterEach(()=>{xo.a.done(),this.isSidebarOpen=!1})}};t(233),t(234);class So{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var wo={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new So).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var a=document.head||document.getElementsByTagName("head")[0],r=document.createElement("style");r.type="text/css","top"===t&&a.firstChild?a.insertBefore(r,a.firstChild):a.appendChild(r),r.styleSheet?r.styleSheet.cssText=n:r.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Eo={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},To={},Io=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Ao=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Eo[n]},jo=function n(e,t,a){var r=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))r[n]=t[n];else{var e=n.replace("data","");r.dataset[e]=t[n]}})),a&&a.forEach((function(e){var t=e.tag,a=e.attrs,i=e.children;r.appendChild(n(t,a,i))})),r},zo=function(n,e,t){var a,r=(a=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(a));return 1!==r.length||t?r:r[0]},Oo=function(n,e){var t,a,r=n.match(/<style>([\s\S]+)<\/style>/),i=n.match(/<template>([\s\S]+)<\/template>/),s=n.match(/<script>([\s\S]+)<\/script>/),o={css:r&&r[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:s&&s[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};o.htmlTpl=Io(o.html),o.jsTpl=(t=o.js,a=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(a,"\n})")),o.script=function(n,e){var t=n.split(/export\s+default/),a="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),r=window.Babel?window.Babel.transform(a,{presets:["es2015"]}).code:a,i=[eval][0](r);return i.template=e,i}(o.js,o.html);var l=Ao("vue");return o.jsLib.unshift(l),o},Co=function(n,e){var t,a=n.match(/<style>([\s\S]+)<\/style>/),r=n.match(/<html>([\s\S]+)<\/html>/),i=n.match(/<script>([\s\S]+)<\/script>/),s={css:a&&a[1].replace(/^\n|\n$/g,""),html:r&&r[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return s.htmlTpl=s.html,s.jsTpl=s.js,s.script=(t=s.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),s},Do=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function No(){var n=zo(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=zo(n,"vuepress-plugin-demo-block__code"),t=zo(n,"vuepress-plugin-demo-block__display"),a=zo(n,"vuepress-plugin-demo-block__footer"),r=zo(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(n.dataset.code),s=decodeURIComponent(n.dataset.config),o=decodeURIComponent(n.dataset.type);s=s?JSON.parse(s):{};var l=e.querySelector("div").clientHeight,c="react"===o?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,a="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),r=new Function("return ".concat(a))(),i={js:r,css:r.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Do(n),htmlTpl:Io("")},s=Ao("react"),o=Ao("reactDOM");return i.jsLib.unshift(s,o),i}(i,s):"vanilla"===o?Co(i,s):Oo(i,s),d=jo("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(a.appendChild(d),d.addEventListener("click",Lo.bind(null,d,l,e,a)),Ao("jsfiddle")&&a.appendChild(function(n){var e=n.css,t=n.htmlTpl,a=n.jsTpl,r=n.jsLib,i=n.cssLib,s=r.concat(i).concat(Ao("cssLib")).concat(Ao("jsLib")).join(",");return jo("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:a}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:s}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Ao("codepen")&&a.appendChild(function(n){var e=n.css,t=n.htmlTpl,a=n.jsTpl,r=n.jsLib,i=n.cssLib,s=JSON.stringify({css:e,html:t,js:a,js_external:r.concat(Ao("jsLib")).join(";"),css_external:i.concat(Ao("cssLib")).join(";"),layout:Ao("codepenLayout"),js_pre_processor:Ao("codepenJsProcessor"),editors:Ao("codepenEditors")});return jo("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:s}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==s.horizontal?s.horizontal:Ao("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var p=e.firstChild.cloneNode(!0);p.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(p)}if(c.css&&function(n){if(!To[n]){var e=jo("style",{innerHTML:n});document.body.appendChild(e),To[n]=!0}}(c.css),"react"===o)ReactDOM.render(React.createElement(c.js),r);else if("vue"===o){var m=(new(Vue.extend(c.script))).$mount();r.appendChild(m.$el)}else"vanilla"===o&&(r.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){No()}),300)}function Lo(n,e,t,a){var r="1"!==n.dataset.isExpand;t.style.height=r?"".concat(e,"px"):0,r?a.classList.add("vuepress-plugin-demo-block__show-link"):a.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=r?"1":"0"}var Mo={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},No()},updated:function(){No()}},Ro="auto",qo="zoom-in",Po="zoom-out",Bo="grab",Fo="move";function $o(n,e,t){var a=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],r={passive:!1};a?n.addEventListener(e,t,r):n.removeEventListener(e,t,r)}function Ho(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Uo(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Go(n,e,t){!function(n){var e=Wo,t=Qo;if(n.transition){var a=n.transition;delete n.transition,n[e]=a}if(n.transform){var r=n.transform;delete n.transform,n[t]=r}}(e);var a=n.style,r={};for(var i in e)t&&(r[i]=a[i]||""),a[i]=e[i];return r}var Wo="transition",Qo="transform",Yo="transform",Vo="transitionend";var Jo=function(){},Xo={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Jo,onClose:Jo,onGrab:Jo,onMove:Jo,onRelease:Jo,onBeforeOpen:Jo,onBeforeClose:Jo,onBeforeGrab:Jo,onBeforeRelease:Jo,onImageLoading:Jo,onImageLoaded:Jo},Ko={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),nl(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var a=this.lastScrollPosition.x-e,r=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(r)>=i||Math.abs(a)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(Zo(n)&&!nl(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){Zo(n)&&!nl(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,a=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,a)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,a=e.clientY;this.move(t,a)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function Zo(n){return 0===n.button}function nl(n){return n.metaKey||n.ctrlKey}var el={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Go(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),$o(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Go(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},tl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},al=function(){function n(n,e){for(var t=0;t<e.length;t++){var a=e[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(n,a.key,a)}}return function(e,t,a){return t&&n(e.prototype,t),a&&n(e,a),e}}(),rl=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var a in t)Object.prototype.hasOwnProperty.call(t,a)&&(n[a]=t[a])}return n},il={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Uo(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,a=n.transitionDuration,r=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Bo:Po,transition:Yo+"\n        "+a+"s\n        "+r,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Go(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Go(this.el,{transform:"none"})},grab:function(n,e,t){var a=sl(),r=a.x-n,i=a.y-e;Go(this.el,{cursor:Fo,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var a=sl(),r=a.x-n,i=a.y-e;Go(this.el,{transition:Yo,transform:"translate3d(\n        "+(this.translate.x+r)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Go(this.el,this.styleClose)},restoreOpenStyle:function(){Go(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=sl(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,a=this.instance.options,r=a.customSize,i=a.scaleBase;if(!r&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(r&&"object"===(void 0===r?"undefined":tl(r)))return{x:r.width/this.rect.width,y:r.height/this.rect.height};var s=this.rect.width/2,o=this.rect.height/2,l=sl(),c={x:l.x-s,y:l.y-o},d=c.x/s,p=c.y/o,m=i+Math.min(d,p);if(r&&"string"==typeof r){var u=t||this.el.naturalWidth,h=e||this.el.naturalHeight,f=parseFloat(r)*u/(100*this.rect.width),g=parseFloat(r)*h/(100*this.rect.height);if(m>f||m>g)return{x:f,y:g}}return{x:m,y:m}}};function sl(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function ol(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(a){$o(n,a,e[a],t)}))}var ll=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(il),this.overlay=Object.create(el),this.handler=Object.create(Ko),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=rl({},Xo,e),this.overlay.init(this),this.handler.init(this)}return al(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=qo,$o(n,"click",this.handler.click),this.options.preloadImage&&Ho(Uo(n)));return this}},{key:"config",value:function(n){return n?(rl(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var a="string"==typeof n?document.querySelector(n):n;if("IMG"===a.tagName){if(this.options.onBeforeOpen(a),this.target.init(a,this),!this.options.preloadImage){var r=this.target.srcOriginal;null!=r&&(this.options.onImageLoading(a),Ho(r,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),$o(document,"scroll",this.handler.scroll),$o(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&$o(window,"resize",this.handler.resizeWindow);var i=function n(){$o(a,Vo,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&ol(document,e.handler,!0),t(a)};return $o(a,Vo,i),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Ro,this.overlay.fadeOut(),this.target.zoomOut(),$o(document,"scroll",this.handler.scroll,!1),$o(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&$o(window,"resize",this.handler.resizeWindow,!1);var a=function a(){$o(t,Vo,a,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&ol(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return $o(t,Vo,a),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var r=this.target.el;this.options.onBeforeGrab(r),this.released=!1,this.target.grab(n,e,t);var i=function n(){$o(r,Vo,n,!1),a(r)};return $o(r,Vo,i),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Fo,this.target.move(n,e,t);var r=this.target.el,i=function n(){$o(r,Vo,n,!1),a(r)};return $o(r,Vo,i),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Ro,this.target.restoreOpenStyle();var a=function a(){$o(t,Vo,a,!1),n.lock=!1,n.released=!0,e(t)};return $o(t,Vo,a),this}}}]),n}();const cl=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),dl=Number("500");class pl{constructor(){this.instance=new ll(cl)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=dl){setTimeout(()=>this.update(n),e)}}var ml=[uo,vo,ko,wo,Mo,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new pl,this.$vuepress.zooming.updateDelay()}}],ul={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return oo("layout",n),Ht.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},hl=t(3),fl=Object(hl.a)(ul,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(fl,"mixins",ml);const gl=[{name:"v-2df947ea",path:"/pages/de9b5e/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2df947ea").then(t)}},{path:"/pages/de9b5e/index.html",redirect:"/pages/de9b5e/"},{path:"/01.Java相关/00.Java相关知识.html",redirect:"/pages/de9b5e/"},{name:"v-d2fb2a82",path:"/pages/035171/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-d2fb2a82").then(t)}},{path:"/pages/035171/index.html",redirect:"/pages/035171/"},{path:"/01.Java相关/01.基础/02.Java扩展.html",redirect:"/pages/035171/"},{name:"v-689808d8",path:"/pages/1d1863/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-689808d8").then(t)}},{path:"/pages/1d1863/index.html",redirect:"/pages/1d1863/"},{path:"/01.Java相关/02.工具/001.hutool工具包.html",redirect:"/pages/1d1863/"},{name:"v-29791135",path:"/pages/1d1864/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-29791135").then(t)}},{path:"/pages/1d1864/index.html",redirect:"/pages/1d1864/"},{path:"/01.Java相关/02.工具/002.Apache Commons工具包.html",redirect:"/pages/1d1864/"},{name:"v-4c2230e8",path:"/pages/2e9bb7/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-4c2230e8").then(t)}},{path:"/pages/2e9bb7/index.html",redirect:"/pages/2e9bb7/"},{path:"/01.Java相关/02.工具/010.SQL解析工具.html",redirect:"/pages/2e9bb7/"},{name:"v-1a0eb102",path:"/pages/1e9420/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-1a0eb102").then(t)}},{path:"/pages/1e9420/index.html",redirect:"/pages/1e9420/"},{path:"/01.Java相关/03.框架/01.Spring Boot相关.html",redirect:"/pages/1e9420/"},{name:"v-2c168266",path:"/pages/bdceb5/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2c168266").then(t)}},{path:"/pages/bdceb5/index.html",redirect:"/pages/bdceb5/"},{path:"/01.Java相关/04.设计模式/006.设计模式入门.html",redirect:"/pages/bdceb5/"},{name:"v-c32a4ba6",path:"/pages/676d02/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-c32a4ba6").then(t)}},{path:"/pages/676d02/index.html",redirect:"/pages/676d02/"},{path:"/01.Java相关/04.设计模式/011.策略模式.html",redirect:"/pages/676d02/"},{name:"v-1d12c416",path:"/pages/768c32/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-1d12c416").then(t)}},{path:"/pages/768c32/index.html",redirect:"/pages/768c32/"},{path:"/01.Java相关/01.基础/01.Java基础.html",redirect:"/pages/768c32/"},{name:"v-8aa2b0da",path:"/pages/116f8a/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-8aa2b0da").then(t)}},{path:"/pages/116f8a/index.html",redirect:"/pages/116f8a/"},{path:"/01.Java相关/04.设计模式/030.装饰者模式.html",redirect:"/pages/116f8a/"},{name:"v-81b6555c",path:"/pages/d0e23d/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-81b6555c").then(t)}},{path:"/pages/d0e23d/index.html",redirect:"/pages/d0e23d/"},{path:"/01.Java相关/04.设计模式/020.观察者模式.html",redirect:"/pages/d0e23d/"},{name:"v-830992f8",path:"/pages/4e0678/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-830992f8").then(t)}},{path:"/pages/4e0678/index.html",redirect:"/pages/4e0678/"},{path:"/01.Java相关/04.设计模式/050.单例模式.html",redirect:"/pages/4e0678/"},{name:"v-f5852fb2",path:"/pages/668a2b/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-f5852fb2").then(t)}},{path:"/pages/668a2b/index.html",redirect:"/pages/668a2b/"},{path:"/01.Java相关/04.设计模式/040.工厂模式.html",redirect:"/pages/668a2b/"},{name:"v-11fe809f",path:"/pages/5d365c/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-11fe809f").then(t)}},{path:"/pages/5d365c/index.html",redirect:"/pages/5d365c/"},{path:"/01.Java相关/04.设计模式/060.命令模式.html",redirect:"/pages/5d365c/"},{name:"v-74435332",path:"/pages/c7cf8b/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-74435332").then(t)}},{path:"/pages/c7cf8b/index.html",redirect:"/pages/c7cf8b/"},{path:"/01.Java相关/04.设计模式/070.适配器模式与外观模式.html",redirect:"/pages/c7cf8b/"},{name:"v-0469e89f",path:"/pages/93ef90/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-0469e89f").then(t)}},{path:"/pages/93ef90/index.html",redirect:"/pages/93ef90/"},{path:"/01.Java相关/04.设计模式/080.模板方法模式.html",redirect:"/pages/93ef90/"},{name:"v-3ed5a0cf",path:"/pages/4372f2/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-3ed5a0cf").then(t)}},{path:"/pages/4372f2/index.html",redirect:"/pages/4372f2/"},{path:"/01.Java相关/04.设计模式/090.迭代器与组合模式.html",redirect:"/pages/4372f2/"},{name:"v-7487d51a",path:"/pages/463f44/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-7487d51a").then(t)}},{path:"/pages/463f44/index.html",redirect:"/pages/463f44/"},{path:"/01.Java相关/04.设计模式/110.状态模式.html",redirect:"/pages/463f44/"},{name:"v-bed51406",path:"/pages/cb203f/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-bed51406").then(t)}},{path:"/pages/cb203f/index.html",redirect:"/pages/cb203f/"},{path:"/01.Java相关/04.设计模式/120.代理模式.html",redirect:"/pages/cb203f/"},{name:"v-42c6f9fa",path:"/pages/5d76a5/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-42c6f9fa").then(t)}},{path:"/pages/5d76a5/index.html",redirect:"/pages/5d76a5/"},{path:"/02.大数据/01.Hadoop/01.Hadoop分布式搭建.html",redirect:"/pages/5d76a5/"},{name:"v-30099682",path:"/pages/f9f70f/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-30099682").then(t)}},{path:"/pages/f9f70f/index.html",redirect:"/pages/f9f70f/"},{path:"/02.大数据/01.Hadoop/02.Hadoop高可用搭建.html",redirect:"/pages/f9f70f/"},{name:"v-f9f8fc5c",path:"/pages/3e77b2/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-f9f8fc5c").then(t)}},{path:"/pages/3e77b2/index.html",redirect:"/pages/3e77b2/"},{path:"/02.大数据/01.Hadoop/03.集群端口.html",redirect:"/pages/3e77b2/"},{name:"v-2fa3e257",path:"/pages/03a2bd/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2fa3e257").then(t)}},{path:"/pages/03a2bd/index.html",redirect:"/pages/03a2bd/"},{path:"/02.大数据/01.Hadoop/04.代码demo（mr hbase hive redis）.html",redirect:"/pages/03a2bd/"},{name:"v-5063a9cb",path:"/pages/e2226d/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-5063a9cb").then(t)}},{path:"/pages/e2226d/index.html",redirect:"/pages/e2226d/"},{path:"/02.大数据/02.Zookeeper/01.Zookeeper集群搭建.html",redirect:"/pages/e2226d/"},{name:"v-7f6942cf",path:"/pages/edf4cb/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-7f6942cf").then(t)}},{path:"/pages/edf4cb/index.html",redirect:"/pages/edf4cb/"},{path:"/02.大数据/03.Hive/01.Hive集群搭建.html",redirect:"/pages/edf4cb/"},{name:"v-786d75c7",path:"/pages/dd806a/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-786d75c7").then(t)}},{path:"/pages/dd806a/index.html",redirect:"/pages/dd806a/"},{path:"/02.大数据/03.Hive/02.Hive相关.html",redirect:"/pages/dd806a/"},{name:"v-bb3e9386",path:"/pages/dd807a/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-bb3e9386").then(t)}},{path:"/pages/dd807a/index.html",redirect:"/pages/dd807a/"},{path:"/02.大数据/03.Hive/03.HSQL.html",redirect:"/pages/dd807a/"},{name:"v-555e21cf",path:"/pages/bfa383/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-555e21cf").then(t)}},{path:"/pages/bfa383/index.html",redirect:"/pages/bfa383/"},{path:"/02.大数据/04.Kafka/01.Kafka集群搭建.html",redirect:"/pages/bfa383/"},{name:"v-92803bde",path:"/pages/b22228/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-92803bde").then(t)}},{path:"/pages/b22228/index.html",redirect:"/pages/b22228/"},{path:"/02.大数据/05.HBase/01.HBase集群搭建.html",redirect:"/pages/b22228/"},{name:"v-9b1324b0",path:"/pages/e15afa/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-9b1324b0").then(t)}},{path:"/pages/e15afa/index.html",redirect:"/pages/e15afa/"},{path:"/02.大数据/05.HBase/02.HBase基础学习.html",redirect:"/pages/e15afa/"},{name:"v-a16758b4",path:"/pages/7d157d/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-a16758b4").then(t)}},{path:"/pages/7d157d/index.html",redirect:"/pages/7d157d/"},{path:"/02.大数据/06.Spark/01.Spark环境搭建.html",redirect:"/pages/7d157d/"},{name:"v-6c2b8593",path:"/pages/b3ba00/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-6c2b8593").then(t)}},{path:"/pages/b3ba00/index.html",redirect:"/pages/b3ba00/"},{path:"/02.大数据/06.Spark/02.Spark相关知识.html",redirect:"/pages/b3ba00/"},{name:"v-e35d4030",path:"/pages/415096/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-e35d4030").then(t)}},{path:"/pages/415096/index.html",redirect:"/pages/415096/"},{path:"/02.大数据/07.Flink/01.Flink环境搭建.html",redirect:"/pages/415096/"},{name:"v-0221b7b2",path:"/pages/70f03f/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-0221b7b2").then(t)}},{path:"/pages/70f03f/index.html",redirect:"/pages/70f03f/"},{path:"/02.大数据/06.Spark/10.Spark内核学习.html",redirect:"/pages/70f03f/"},{name:"v-356e286c",path:"/pages/415097/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-356e286c").then(t)}},{path:"/pages/415097/index.html",redirect:"/pages/415097/"},{path:"/02.大数据/07.Flink/02.Flink学习.html",redirect:"/pages/415097/"},{name:"v-e9baf2c8",path:"/pages/e4166e/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-e9baf2c8").then(t)}},{path:"/pages/e4166e/index.html",redirect:"/pages/e4166e/"},{path:"/02.大数据/10.Flume/01.Flume安装配置.html",redirect:"/pages/e4166e/"},{name:"v-db83fd4c",path:"/pages/0376ec/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-db83fd4c").then(t)}},{path:"/pages/0376ec/index.html",redirect:"/pages/0376ec/"},{path:"/02.大数据/10.Flume/02.Flume高可用集群安装.html",redirect:"/pages/0376ec/"},{name:"v-51040124",path:"/pages/eeda49/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-51040124").then(t)}},{path:"/pages/eeda49/index.html",redirect:"/pages/eeda49/"},{path:"/02.大数据/10.Flume/04.Flume把数据导入hive（文件方式）.html",redirect:"/pages/eeda49/"},{name:"v-d4ddf460",path:"/pages/60b3d7/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-d4ddf460").then(t)}},{path:"/pages/60b3d7/index.html",redirect:"/pages/60b3d7/"},{path:"/02.大数据/11.数据集成工具/01.Sqoop安装配置.html",redirect:"/pages/60b3d7/"},{name:"v-2c5956be",path:"/pages/40f7a3/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2c5956be").then(t)}},{path:"/pages/40f7a3/index.html",redirect:"/pages/40f7a3/"},{path:"/02.大数据/11.数据集成工具/02.Sqoop使用.html",redirect:"/pages/40f7a3/"},{name:"v-1fd37798",path:"/pages/3408a8/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-1fd37798").then(t)}},{path:"/pages/3408a8/index.html",redirect:"/pages/3408a8/"},{path:"/02.大数据/10.Flume/03.Flume相关学习.html",redirect:"/pages/3408a8/"},{name:"v-63f04fc0",path:"/pages/b76fc1/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-63f04fc0").then(t)}},{path:"/pages/b76fc1/index.html",redirect:"/pages/b76fc1/"},{path:"/02.大数据/11.数据集成工具/09.数据集成框架.html",redirect:"/pages/b76fc1/"},{name:"v-599d1974",path:"/pages/4d39ac/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-599d1974").then(t)}},{path:"/pages/4d39ac/index.html",redirect:"/pages/4d39ac/"},{path:"/02.大数据/12. Impala/01.Impala.html",redirect:"/pages/4d39ac/"},{name:"v-0c3bcc96",path:"/pages/d89b45/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-0c3bcc96").then(t)}},{path:"/pages/d89b45/index.html",redirect:"/pages/d89b45/"},{path:"/02.大数据/20.其他/01.docker.html",redirect:"/pages/d89b45/"},{name:"v-a5e93828",path:"/pages/a04438/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-a5e93828").then(t)}},{path:"/pages/a04438/index.html",redirect:"/pages/a04438/"},{path:"/02.大数据/16.调度/01.调度工具.html",redirect:"/pages/a04438/"},{name:"v-f125018c",path:"/pages/b5c27a/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-f125018c").then(t)}},{path:"/pages/b5c27a/index.html",redirect:"/pages/b5c27a/"},{path:"/03.数据库/01.Oracle/02.系统函数篇.html",redirect:"/pages/b5c27a/"},{name:"v-01457896",path:"/pages/c2df29/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-01457896").then(t)}},{path:"/pages/c2df29/index.html",redirect:"/pages/c2df29/"},{path:"/03.数据库/01.Oracle/06.与MySQL语法区别.html",redirect:"/pages/c2df29/"},{name:"v-7ea7fc0c",path:"/pages/7e6951/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-7ea7fc0c").then(t)}},{path:"/pages/7e6951/index.html",redirect:"/pages/7e6951/"},{path:"/03.数据库/01.Oracle/01.Oracle相关知识杂记.html",redirect:"/pages/7e6951/"},{name:"v-4448404b",path:"/pages/e0cc49/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-4448404b").then(t)}},{path:"/pages/e0cc49/index.html",redirect:"/pages/e0cc49/"},{path:"/03.数据库/0101.数据库.html",redirect:"/pages/e0cc49/"},{name:"v-227c94e8",path:"/pages/36476d/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-227c94e8").then(t)}},{path:"/pages/36476d/index.html",redirect:"/pages/36476d/"},{path:"/03.数据库/02.MySQL/02.MySQL琐碎知识点.html",redirect:"/pages/36476d/"},{name:"v-1e74358a",path:"/pages/086761/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-1e74358a").then(t)}},{path:"/pages/086761/index.html",redirect:"/pages/086761/"},{path:"/03.数据库/06.国产数据库/03.达梦数据库.html",redirect:"/pages/086761/"},{name:"v-656f9cf6",path:"/pages/e461e3/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-656f9cf6").then(t)}},{path:"/pages/e461e3/index.html",redirect:"/pages/e461e3/"},{path:"/03.数据库/06.国产数据库/09.华为高斯数据库.html",redirect:"/pages/e461e3/"},{name:"v-5a91a923",path:"/pages/ca5c12/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-5a91a923").then(t)}},{path:"/pages/ca5c12/index.html",redirect:"/pages/ca5c12/"},{path:"/03.数据库/09.Redis/01.Redis命令学习.html",redirect:"/pages/ca5c12/"},{name:"v-50566ea5",path:"/pages/265b1a/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-50566ea5").then(t)}},{path:"/pages/265b1a/index.html",redirect:"/pages/265b1a/"},{path:"/03.数据库/10.Excel/01.Excel技巧.html",redirect:"/pages/265b1a/"},{name:"v-00c7823d",path:"/pages/e02b49/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-00c7823d").then(t)}},{path:"/pages/e02b49/index.html",redirect:"/pages/e02b49/"},{path:"/03.数据库/1000.SQL非常规用法集锦.html",redirect:"/pages/e02b49/"},{name:"v-2a8f5aa8",path:"/pages/f2a330/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2a8f5aa8").then(t)}},{path:"/pages/f2a330/index.html",redirect:"/pages/f2a330/"},{path:"/04.其他/01.Python/01.Python简单语法学习.html",redirect:"/pages/f2a330/"},{name:"v-a4ab2664",path:"/pages/d5b8e9/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-a4ab2664").then(t)}},{path:"/pages/d5b8e9/index.html",redirect:"/pages/d5b8e9/"},{path:"/03.数据库/1006.SQL练习题.html",redirect:"/pages/d5b8e9/"},{name:"v-2bc194fa",path:"/pages/f2a340/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-2bc194fa").then(t)}},{path:"/pages/f2a340/index.html",redirect:"/pages/f2a340/"},{path:"/04.其他/01.Python/02.Python操作Office.html",redirect:"/pages/f2a340/"},{name:"v-1dc96cde",path:"/pages/c2b99b/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-1dc96cde").then(t)}},{path:"/pages/c2b99b/index.html",redirect:"/pages/c2b99b/"},{path:"/04.其他/01.Python/04.自己写的python程序.html",redirect:"/pages/c2b99b/"},{name:"v-152fe1e4",path:"/pages/f2a341/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-152fe1e4").then(t)}},{path:"/pages/f2a341/index.html",redirect:"/pages/f2a341/"},{path:"/04.其他/01.Python/03.Python类库学习.html",redirect:"/pages/f2a341/"},{name:"v-547abcde",path:"/pages/f799c7/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-547abcde").then(t)}},{path:"/pages/f799c7/index.html",redirect:"/pages/f799c7/"},{path:"/04.其他/01.Python/05.Python爬虫.html",redirect:"/pages/f799c7/"},{name:"v-6ece5467",path:"/pages/5704cc/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-6ece5467").then(t)}},{path:"/pages/5704cc/index.html",redirect:"/pages/5704cc/"},{path:"/04.其他/02.Shell/01.Shell基础.html",redirect:"/pages/5704cc/"},{name:"v-e244ce58",path:"/pages/5765cc/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-e244ce58").then(t)}},{path:"/pages/5765cc/index.html",redirect:"/pages/5765cc/"},{path:"/04.其他/02.Shell/02.Shell小工具.html",redirect:"/pages/5765cc/"},{name:"v-412d7d01",path:"/pages/c917bd/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-412d7d01").then(t)}},{path:"/pages/c917bd/index.html",redirect:"/pages/c917bd/"},{path:"/04.其他/03.Scala/01.语法学习.html",redirect:"/pages/c917bd/"},{name:"v-0499277d",path:"/pages/e4e158/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-0499277d").then(t)}},{path:"/pages/e4e158/index.html",redirect:"/pages/e4e158/"},{path:"/04.其他/04.正则表达式/01.正则基础.html",redirect:"/pages/e4e158/"},{name:"v-00f00e91",path:"/pages/AXI4oJ/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-00f00e91").then(t)}},{path:"/pages/AXI4oJ/index.html",redirect:"/pages/AXI4oJ/"},{path:"/04.其他/100.摘录/01.摘录.html",redirect:"/pages/AXI4oJ/"},{name:"v-48901c43",path:"/pages/gxfmrs/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-48901c43").then(t)}},{path:"/pages/gxfmrs/index.html",redirect:"/pages/gxfmrs/"},{path:"/04.其他/06.前端/01.前端相关.html",redirect:"/pages/gxfmrs/"},{name:"v-68f50c4e",path:"/pages/e6d5cb/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-68f50c4e").then(t)}},{path:"/pages/e6d5cb/index.html",redirect:"/pages/e6d5cb/"},{path:"/04.其他/98.资料/98.资料.html",redirect:"/pages/e6d5cb/"},{name:"v-5e6eb6cd",path:"/pages/414e9c/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-5e6eb6cd").then(t)}},{path:"/pages/414e9c/index.html",redirect:"/pages/414e9c/"},{path:"/04.其他/99.杂记/01.常用工具或网站.html",redirect:"/pages/414e9c/"},{name:"v-acb49e1a",path:"/pages/378bb1/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-acb49e1a").then(t)}},{path:"/pages/378bb1/index.html",redirect:"/pages/378bb1/"},{path:"/04.其他/99.杂记/03.快捷键.html",redirect:"/pages/378bb1/"},{name:"v-90e7de80",path:"/pages/c0e729/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-90e7de80").then(t)}},{path:"/pages/c0e729/index.html",redirect:"/pages/c0e729/"},{path:"/04.其他/99.杂记/02.琐碎知识.html",redirect:"/pages/c0e729/"},{name:"v-447f8646",path:"/pages/3cec6c/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-447f8646").then(t)}},{path:"/pages/3cec6c/index.html",redirect:"/pages/3cec6c/"},{path:"/04.其他/99.杂记/10.FAQ.html",redirect:"/pages/3cec6c/"},{name:"v-460c88ea",path:"/archives/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-460c88ea").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-5111c592",path:"/",component:fl,beforeEnter:(n,e,t)=>{so("Layout","v-5111c592").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:fl}],bl={title:"唐宋元明清",description:"",base:"/hdata-doc/",headTags:[["link",{rel:"icon",href:"/hdata-doc/img/favicon.ico"}],["meta",{name:"keywords",content:"vuepress,theme,blog,vdoing"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"Java相关知识",frontmatter:{title:"Java相关知识",date:"2022-02-23T13:45:00.000Z",permalink:"/pages/de9b5e/",categories:["Java相关"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/00.Java%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86.html",relativePath:"01.Java相关/00.Java相关知识.md",key:"v-2df947ea",path:"/pages/de9b5e/",headers:[{level:2,title:"Java相关知识积累",slug:"java相关知识积累",normalizedTitle:"java相关知识积累",charIndex:2},{level:4,title:"如何保证数据库和缓存双写一致性",slug:"如何保证数据库和缓存双写一致性",normalizedTitle:"如何保证数据库和缓存双写一致性",charIndex:58}],headersStr:"Java相关知识积累 如何保证数据库和缓存双写一致性",content:"# Java相关知识积累\n\n----------------------------------------\n\n# 如何保证数据库和缓存双写一致性\n\n * 先写缓存，再写数据库\n * 先写数据库，再写缓存\n * 先删缓存，再写数据库\n * 先写数据库，再删缓存\n\n原文链接",normalizedContent:"# java相关知识积累\n\n----------------------------------------\n\n# 如何保证数据库和缓存双写一致性\n\n * 先写缓存，再写数据库\n * 先写数据库，再写缓存\n * 先删缓存，再写数据库\n * 先写数据库，再删缓存\n\n原文链接",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Java扩展",frontmatter:{title:"Java扩展",date:"2022-04-15T22:20:30.000Z",permalink:"/pages/035171/",categories:["Java相关","基础"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/01.%E5%9F%BA%E7%A1%80/02.Java%E6%89%A9%E5%B1%95.html",relativePath:"01.Java相关/01.基础/02.Java扩展.md",key:"v-d2fb2a82",path:"/pages/035171/",headers:[{level:3,title:"基础",slug:"基础",normalizedTitle:"基础",charIndex:2},{level:4,title:"Java Docs",slug:"java-docs",normalizedTitle:"java docs",charIndex:8},{level:5,title:"Java 文档注释",slug:"java-文档注释",normalizedTitle:"java 文档注释",charIndex:21},{level:5,title:"idea生成项目帮助文档",slug:"idea生成项目帮助文档",normalizedTitle:"idea生成项目帮助文档",charIndex:1876},{level:4,title:"idea Debugger使用",slug:"idea-debugger使用",normalizedTitle:"idea debugger使用",charIndex:2076},{level:4,title:"数据类型知识点",slug:"数据类型知识点",normalizedTitle:"数据类型知识点",charIndex:2101},{level:5,title:"Java中valueOf与parseInt方法比较",slug:"java中valueof与parseint方法比较",normalizedTitle:"java中valueof与parseint方法比较",charIndex:2112},{level:5,title:"HashMap",slug:"hashmap",normalizedTitle:"hashmap",charIndex:2235},{level:3,title:"小游戏2048",slug:"小游戏2048",normalizedTitle:"小游戏2048",charIndex:2264}],headersStr:"基础 Java Docs Java 文档注释 idea生成项目帮助文档 idea Debugger使用 数据类型知识点 Java中valueOf与parseInt方法比较 HashMap 小游戏2048",content:'# 基础\n\n# Java Docs\n\n# Java 文档注释\n\nJava 支持三种注释方式。前两种分别是 // 和 /* /，第三种被称作说明注释，它以 /* 开始，以 */结束。\n\n说明注释允许你在程序中嵌入关于程序的信息。你可以使用 javadoc 工具软件来生成信息，并输出到HTML文件中。\n\n说明注释，使你更加方便的记录你的程序信息。\n\njavadoc 标签\n\n标签              描述                                            示例\n@author         标识一个类的作者                                      @author description\n@deprecated     指名一个过期的类或成员                                   @deprecated description\n{@docRoot}      指明当前文档根目录的路径                                  Directory Path\n@exception      标志一个类抛出的异常                                    @exception exception-name explanation\n{@inheritDoc}   从直接父类继承的注释                                    Inherits a comment from the immediate surperclass.\n{@link}         插入一个到另一个主题的链接                                 {@link name text}\n{@linkplain}    插入一个到另一个主题的链接，但是该链接显示纯文本字体                    Inserts an in-line link to another topic.\n@param          说明一个方法的参数                                     @param parameter-name explanation\n@return         说明返回值类型                                       @return explanation\n@see            指定一个到另一个主题的链接                                 @see anchor\n@serial         说明一个序列化属性                                     @serial description\n@serialData     说明通过writeObject( ) 和 writeExternal( )方法写的数据   @serialData description\n@serialField    说明一个ObjectStreamField组件                       @serialField name type description\n@since          标记当引入一个特定的变化时                                 @since release\n@throws         和 @exception标签一样.                             The @throws tag has the same meaning as the @exception tag.\n{@value}        显示常量的值，该常量必须是static属性。                        Displays the value of a constant, which must be a static\n                                                              field.\n@version        指定类的版本                                        @version info\n\n# idea生成项目帮助文档\n\n可以帮助理解源码\n\n * 打开项目 ->\n * Tools ->\n * Generate JavaDoc ->\n * 在Output directory选择文档输出目录 ->\n * 设置Locale:zh_CN ->\n * 设置Other command line arguments:-encoding UTF-8 -charset UTF-8 ->\n * OK\n\n# idea Debugger使用\n\n博客链接\n\n# 数据类型知识点\n\n# Java中valueOf与parseInt方法比较\n\n * 从返回类型可以看出parseInt返回的是基本类型int，而valueOf返回的是对象Integer（new Integer(Integer.parseInt(s))）。原文地址\n\n# HashMap\n\nHashMap详解\n\n原文地址\n\n\n# 小游戏2048\n\n点击查看\n\n以下为代码\n\nimport javax.swing.*;\nimport java.awt.*;\npublic class Block extends JLabel \n{\n  private int value;\n  public Block() \n  {\n    value = 0;//初始化值为0\n    setFont(new Font("font", Font.PLAIN, 40));//设定字体\n    setBackground(Color.gray);//设定初始颜色为灰色\n  }\n \n  public int getValue()//获取值\n  {\n    return value;\n  }\n \n  public void setValue(int value)\n  {\n    this.value = value;\n    String text = String.valueOf(value);\n    if (value != 0)\n      setText(text);\n    else\n      setText("");//如果值为0则不显示\n    setColor();\n  }\n \n  public void setColor() //根据值的不同设定不同的背景颜色、label字体\n  {\n    switch (value) \n      {\n    case 0:\n      setBackground(Color.gray);\n      break;\n    case 2:\n      setBackground(new Color(238, 228, 218));\n      break;\n    case 4:\n      setBackground(new Color(238, 224, 198));\n      break;\n    case 8:\n      setBackground(new Color(243, 177, 116));\n      break;\n    case 16:\n      setBackground(new Color(243, 177, 116));\n      break;\n    case 32:\n      setBackground(new Color(248, 149, 90));\n      break;\n    case 64:\n      setBackground(new Color(249, 94, 50));\n      break;\n    case 128:\n      setBackground(new Color(239, 207, 108));\n      break;\n    case 256:\n      setBackground(new Color(239, 207, 99));\n      break;\n    case 512:\n      setBackground(new Color(239, 203, 82));\n      break;\n    case 1024:\n      setBackground(new Color(239, 199, 57));\n      break;\n    case 2048:\n      setBackground(new Color(239, 195, 41));\n      break;\n    case 4096:\n      setBackground(new Color(255, 60, 57));\n      break;\n      }\n  }\n}\n\n\nimport java.awt.*;\nimport javax.swing.*;\npublic class My2048 extends JFrame \n{ \n  public My2048()//构造函数 \n  {\n    setTitle("2048");//设置标题\n    setSize(400, 400);//设定窗口大小\n    setLocation(500, 200);//设定窗口起始位置\n    setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    getContentPane().setLayout(new GridLayout(4, 4, 5, 5));//设定布局方式为GridLayout型\n    new Operation(this);\n    this.setVisible(true);//设为可视\n  }\n \n  public static void main(String args]) //程序入口点\n  {\n    try\n    {\n      UIManager.setLookAndFeel("org.jvnet.substance.skin.SubstanceRavenGraphiteLookAndFeel");//设定UI\n    } //接受抛出的异常\n    catch (ClassNotFoundException | InstantiationException| IllegalAccessException | UnsupportedLookAndFeelException e)\n    {\n      e.printStackTrace();\n    }\n    JFrame.setDefaultLookAndFeelDecorated(true);//设定Frame的缺省外观\n    new My2048();\n  }\n \n}\n\n\nimport java.awt.event.*;\nimport javax.swing.*;\npublic class Operation implements KeyListener\n{\n  Block] block;//用于储存16个数据\n  JPanel panel;\n  public boolean up,down,left,right;\n  int moveFlag;//用于累计移动的次数\n  boolean numFlag;//用于判断是否还能加入新的数字\n  public Operation(JFrame frame) \n  {\n    this.panel = (JPanel)frame.getContentPane();//构造出panel\n    block = new Block16];//构造出长度为16的数组\n    numFlag = true;//初始化\n    moveFlag = 0;\n    up=true;down=true;left=true;right=true;\n    addBlock();\n    for (int i = 0; i < 2; i++)\n      appearBlock();\n    frame.addKeyListener(this);\n  }\n \n  private void addBlock() \n  {\n    for (int i = 0; i < 16; i++) //往panel里加入block\n    {\n      blocki] = new Block();\n      blocki].setHorizontalAlignment(JLabel.CENTER);// 不透明的标签\n      blocki].setOpaque(true);\n      panel.add(blocki]);  \n    }\n  } \n  public void appearBlock() \n  {\n    while (numFlag) //当还能加入随机的一个新的值得时候\n    {\n      int index = (int) (Math.random() * 16);//取一个0到15的随机整数，这个数作为随机加入盘中的2或4的位置\n      if (blockindex].getValue() == 0)//如果这个数所在的block数组中值为0，即在为空的时候，加入一个2或4的数字\n      {\n        if (Math.random() < 0.5)\n        {\n          blockindex].setValue(2);\n        }\n        else\n        {\n          blockindex].setValue(4);\n        }\n        break;//跳出while\n      }\n    }\n  }\n \n  public void judgeAppear() //统计block数组中是否含有值为0的元素，若没有，则numFlag变为false\n  {\n    int sum = 0;\n    for (int i = 0; i < 16; i++) \n    {\n      if (blocki].getValue() != 0)\n      {\n        sum++;\n      }\n    }\n    if (sum == 16)\n      numFlag = false;\n \n  }\n \n  public int Find(int i,int j,int a,int b)\n  {\n    while(i<b&&i>=a)\n    {\n       if(blocki].getValue()!=0)\n       {\n        return i;\n       }\n       i=i+j;\n    }\n    return -1;\n  }\n  public void upBlock()\n  {\n    int i=0,j=0;int t=0;int valueJ=0;int valueI=0;int index=0;\n    for(i=0;i<4;i++)\n    {\n      index=i;\n      for(j=i+4;j<16;j+=4)\n      {  \n        valueJ=0; valueI=0;\n        if(blockindex].getValue()==0)\n        {\n          t=Find(index,4,0,16);\n          if(t!=-1)\n          {\n            blockindex].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueI=blockindex].getValue();\n        if(blockj].getValue()==0)\n        {\n          t=Find(j,4,0,16);\n          if(t!=-1)\n          {\n            blockj].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueJ=blockj].getValue();\n        if(valueI==valueJ&&valueI!=0&&valueJ!=0)\n        {\n          blockindex].setValue(valueI+valueJ);\n          blockj].setValue(0);\n          numFlag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void downBlock() {\n \n    int i=0,j=0;int t=0;int valueJ=0;int valueI=0;int index=0;\n    for(i=12;i<16;i++)\n    {\n      index=i;\n      for(j=i-4;j>=0;j-=4)\n      {  \n        valueJ=0; valueI=0;\n        if(blockindex].getValue()==0)\n        {\n          t=Find(index,-4,0,16);\n          if(t!=-1)\n          {\n            blockindex].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueI=blockindex].getValue();\n        if(blockj].getValue()==0)\n        {\n          t=Find(j,-4,0,16);\n          if(t!=-1)\n          {\n            blockj].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueJ=blockj].getValue();\n        if(valueI==valueJ&&valueI!=0&&valueJ!=0)\n        {\n          blockindex].setValue(valueI+valueJ);\n          blockj].setValue(0);\n          numFlag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void rightBlock() \n  {\n    int i=0,j=0;int t=0;int valueJ=0;int valueI=0;int index=0;\n    for(i=3;i<16;i+=4)\n    {\n      index=i;\n      for(j=i-1;j>i-4;j--)\n      {  \n        valueJ=0; valueI=0;\n        if(blockindex].getValue()==0)\n        {\n          t=Find(index,-1,i-3,index+1);\n          if(t!=-1)\n          {\n            blockindex].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueI=blockindex].getValue();\n        if(blockj].getValue()==0)\n        {\n          t=Find(j,-1,i-3,j+1);\n          if(t!=-1)\n          {\n            blockj].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueJ=blockj].getValue();\n        if(valueI==valueJ&&valueI!=0&&valueJ!=0)\n        {\n          blockindex].setValue(valueI+valueJ);\n          blockj].setValue(0);\n          numFlag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void leftBlock() \n  {\n    int i=0,j=0;int t=0;int valueJ=0;int valueI=0;int index=0;\n    for(i=0;i<16;i+=4)\n    {\n      index=i;\n      for(j=i+1;j<i+4;j++)\n      {  \n        valueJ=0; valueI=0;\n        if(blockindex].getValue()==0)\n        {\n          t=Find(index,1,index,i+4);\n          if(t!=-1)\n          {\n            blockindex].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueI=blockindex].getValue();\n        if(blockj].getValue()==0)\n        {\n          t=Find(j,1,j,i+4);\n          if(t!=-1)\n          {\n            blockj].setValue(blockt].getValue());\n            blockt].setValue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valueJ=blockj].getValue();\n        if(valueI==valueJ&&valueI!=0&&valueJ!=0)\n        {\n          blockindex].setValue(valueI+valueJ);\n          blockj].setValue(0);\n          numFlag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void over() \n  {\n    if (numFlag ==false&& up==false&&down==false&&left==false&&right==false) //当不能添加元素，并且不可移动的步数超过36就输了，输了的时候在盘中央显示GAMEOVER\n    {\n      block4].setText("G");\n      block5].setText("A");\n      block6].setText("M");\n      block7].setText("E");\n      block8].setText("O");\n      block9].setText("V");\n      block10].setText("E");\n      block11].setText("R"); \n      block11].addMouseListener(new MouseAdapter() {public void mousePressed(MouseEvent e){reStart();}});\n    }\n  }\n   \n  public void win() //同OVER\n  { \n    block0].setText("Y");\n    block1].setText("O");\n    block2].setText("U");\n    block13].setText("W");\n    block14].setText("I");\n    block15].setText("N");\n    block15].addMouseListener(new MouseAdapter() {\n      public void mousePressed(MouseEvent e) {\n        reStart();\n      }\n    });\n  }\n  public void reStart()//重启游戏，和构造函数类似，不在累述\n  {\n    numFlag=true;\n    moveFlag=0;\n    up=true;down=true;left=true;right=true;\n    for(int i=0;i<16;i++)\n      blocki].setValue(0);\n    for (int i = 0; i < 2; i++)\n      appearBlock();\n  }\n  public void keyPressed(KeyEvent e) //判断按的上下左右键，并依次调用移动函数、判断函数、添加函数、判断是否输掉的函数\n  {\n    switch (e.getKeyCode()) {\n    case KeyEvent.VK_UP:\n      if(up){\n      upBlock();}\n      judgeAppear();\n      appearBlock();\n      over();\n       \n      if(numFlag==false)\n      {\n        up=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case KeyEvent.VK_DOWN:\n      if(down){\n      downBlock();}\n      judgeAppear();\n      appearBlock();\n      over();\n      if(numFlag==false)\n      {\n        down=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case KeyEvent.VK_LEFT:\n      if(left){\n      leftBlock();}\n      judgeAppear();\n      appearBlock();\n      over();\n       \n      if(numFlag==false)\n      {\n        left=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case KeyEvent.VK_RIGHT:\n      if(right){\n      rightBlock();}\n      judgeAppear();\n      appearBlock();\n      over();\n       \n      if(numFlag==false)\n      {\n        right=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    }\n \n  }\n  public void keyTyped(KeyEvent e) {\n \n  }\n  public void keyReleased(KeyEvent e) {\n \n  }\n \n}\n',normalizedContent:'# 基础\n\n# java docs\n\n# java 文档注释\n\njava 支持三种注释方式。前两种分别是 // 和 /* /，第三种被称作说明注释，它以 /* 开始，以 */结束。\n\n说明注释允许你在程序中嵌入关于程序的信息。你可以使用 javadoc 工具软件来生成信息，并输出到html文件中。\n\n说明注释，使你更加方便的记录你的程序信息。\n\njavadoc 标签\n\n标签              描述                                            示例\n@author         标识一个类的作者                                      @author description\n@deprecated     指名一个过期的类或成员                                   @deprecated description\n{@docroot}      指明当前文档根目录的路径                                  directory path\n@exception      标志一个类抛出的异常                                    @exception exception-name explanation\n{@inheritdoc}   从直接父类继承的注释                                    inherits a comment from the immediate surperclass.\n{@link}         插入一个到另一个主题的链接                                 {@link name text}\n{@linkplain}    插入一个到另一个主题的链接，但是该链接显示纯文本字体                    inserts an in-line link to another topic.\n@param          说明一个方法的参数                                     @param parameter-name explanation\n@return         说明返回值类型                                       @return explanation\n@see            指定一个到另一个主题的链接                                 @see anchor\n@serial         说明一个序列化属性                                     @serial description\n@serialdata     说明通过writeobject( ) 和 writeexternal( )方法写的数据   @serialdata description\n@serialfield    说明一个objectstreamfield组件                       @serialfield name type description\n@since          标记当引入一个特定的变化时                                 @since release\n@throws         和 @exception标签一样.                             the @throws tag has the same meaning as the @exception tag.\n{@value}        显示常量的值，该常量必须是static属性。                        displays the value of a constant, which must be a static\n                                                              field.\n@version        指定类的版本                                        @version info\n\n# idea生成项目帮助文档\n\n可以帮助理解源码\n\n * 打开项目 ->\n * tools ->\n * generate javadoc ->\n * 在output directory选择文档输出目录 ->\n * 设置locale:zh_cn ->\n * 设置other command line arguments:-encoding utf-8 -charset utf-8 ->\n * ok\n\n# idea debugger使用\n\n博客链接\n\n# 数据类型知识点\n\n# java中valueof与parseint方法比较\n\n * 从返回类型可以看出parseint返回的是基本类型int，而valueof返回的是对象integer（new integer(integer.parseint(s))）。原文地址\n\n# hashmap\n\nhashmap详解\n\n原文地址\n\n\n# 小游戏2048\n\n点击查看\n\n以下为代码\n\nimport javax.swing.*;\nimport java.awt.*;\npublic class block extends jlabel \n{\n  private int value;\n  public block() \n  {\n    value = 0;//初始化值为0\n    setfont(new font("font", font.plain, 40));//设定字体\n    setbackground(color.gray);//设定初始颜色为灰色\n  }\n \n  public int getvalue()//获取值\n  {\n    return value;\n  }\n \n  public void setvalue(int value)\n  {\n    this.value = value;\n    string text = string.valueof(value);\n    if (value != 0)\n      settext(text);\n    else\n      settext("");//如果值为0则不显示\n    setcolor();\n  }\n \n  public void setcolor() //根据值的不同设定不同的背景颜色、label字体\n  {\n    switch (value) \n      {\n    case 0:\n      setbackground(color.gray);\n      break;\n    case 2:\n      setbackground(new color(238, 228, 218));\n      break;\n    case 4:\n      setbackground(new color(238, 224, 198));\n      break;\n    case 8:\n      setbackground(new color(243, 177, 116));\n      break;\n    case 16:\n      setbackground(new color(243, 177, 116));\n      break;\n    case 32:\n      setbackground(new color(248, 149, 90));\n      break;\n    case 64:\n      setbackground(new color(249, 94, 50));\n      break;\n    case 128:\n      setbackground(new color(239, 207, 108));\n      break;\n    case 256:\n      setbackground(new color(239, 207, 99));\n      break;\n    case 512:\n      setbackground(new color(239, 203, 82));\n      break;\n    case 1024:\n      setbackground(new color(239, 199, 57));\n      break;\n    case 2048:\n      setbackground(new color(239, 195, 41));\n      break;\n    case 4096:\n      setbackground(new color(255, 60, 57));\n      break;\n      }\n  }\n}\n\n\nimport java.awt.*;\nimport javax.swing.*;\npublic class my2048 extends jframe \n{ \n  public my2048()//构造函数 \n  {\n    settitle("2048");//设置标题\n    setsize(400, 400);//设定窗口大小\n    setlocation(500, 200);//设定窗口起始位置\n    setdefaultcloseoperation(jframe.exit_on_close);\n    getcontentpane().setlayout(new gridlayout(4, 4, 5, 5));//设定布局方式为gridlayout型\n    new operation(this);\n    this.setvisible(true);//设为可视\n  }\n \n  public static void main(string args]) //程序入口点\n  {\n    try\n    {\n      uimanager.setlookandfeel("org.jvnet.substance.skin.substanceravengraphitelookandfeel");//设定ui\n    } //接受抛出的异常\n    catch (classnotfoundexception | instantiationexception| illegalaccessexception | unsupportedlookandfeelexception e)\n    {\n      e.printstacktrace();\n    }\n    jframe.setdefaultlookandfeeldecorated(true);//设定frame的缺省外观\n    new my2048();\n  }\n \n}\n\n\nimport java.awt.event.*;\nimport javax.swing.*;\npublic class operation implements keylistener\n{\n  block] block;//用于储存16个数据\n  jpanel panel;\n  public boolean up,down,left,right;\n  int moveflag;//用于累计移动的次数\n  boolean numflag;//用于判断是否还能加入新的数字\n  public operation(jframe frame) \n  {\n    this.panel = (jpanel)frame.getcontentpane();//构造出panel\n    block = new block16];//构造出长度为16的数组\n    numflag = true;//初始化\n    moveflag = 0;\n    up=true;down=true;left=true;right=true;\n    addblock();\n    for (int i = 0; i < 2; i++)\n      appearblock();\n    frame.addkeylistener(this);\n  }\n \n  private void addblock() \n  {\n    for (int i = 0; i < 16; i++) //往panel里加入block\n    {\n      blocki] = new block();\n      blocki].sethorizontalalignment(jlabel.center);// 不透明的标签\n      blocki].setopaque(true);\n      panel.add(blocki]);  \n    }\n  } \n  public void appearblock() \n  {\n    while (numflag) //当还能加入随机的一个新的值得时候\n    {\n      int index = (int) (math.random() * 16);//取一个0到15的随机整数，这个数作为随机加入盘中的2或4的位置\n      if (blockindex].getvalue() == 0)//如果这个数所在的block数组中值为0，即在为空的时候，加入一个2或4的数字\n      {\n        if (math.random() < 0.5)\n        {\n          blockindex].setvalue(2);\n        }\n        else\n        {\n          blockindex].setvalue(4);\n        }\n        break;//跳出while\n      }\n    }\n  }\n \n  public void judgeappear() //统计block数组中是否含有值为0的元素，若没有，则numflag变为false\n  {\n    int sum = 0;\n    for (int i = 0; i < 16; i++) \n    {\n      if (blocki].getvalue() != 0)\n      {\n        sum++;\n      }\n    }\n    if (sum == 16)\n      numflag = false;\n \n  }\n \n  public int find(int i,int j,int a,int b)\n  {\n    while(i<b&&i>=a)\n    {\n       if(blocki].getvalue()!=0)\n       {\n        return i;\n       }\n       i=i+j;\n    }\n    return -1;\n  }\n  public void upblock()\n  {\n    int i=0,j=0;int t=0;int valuej=0;int valuei=0;int index=0;\n    for(i=0;i<4;i++)\n    {\n      index=i;\n      for(j=i+4;j<16;j+=4)\n      {  \n        valuej=0; valuei=0;\n        if(blockindex].getvalue()==0)\n        {\n          t=find(index,4,0,16);\n          if(t!=-1)\n          {\n            blockindex].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuei=blockindex].getvalue();\n        if(blockj].getvalue()==0)\n        {\n          t=find(j,4,0,16);\n          if(t!=-1)\n          {\n            blockj].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuej=blockj].getvalue();\n        if(valuei==valuej&&valuei!=0&&valuej!=0)\n        {\n          blockindex].setvalue(valuei+valuej);\n          blockj].setvalue(0);\n          numflag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void downblock() {\n \n    int i=0,j=0;int t=0;int valuej=0;int valuei=0;int index=0;\n    for(i=12;i<16;i++)\n    {\n      index=i;\n      for(j=i-4;j>=0;j-=4)\n      {  \n        valuej=0; valuei=0;\n        if(blockindex].getvalue()==0)\n        {\n          t=find(index,-4,0,16);\n          if(t!=-1)\n          {\n            blockindex].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuei=blockindex].getvalue();\n        if(blockj].getvalue()==0)\n        {\n          t=find(j,-4,0,16);\n          if(t!=-1)\n          {\n            blockj].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuej=blockj].getvalue();\n        if(valuei==valuej&&valuei!=0&&valuej!=0)\n        {\n          blockindex].setvalue(valuei+valuej);\n          blockj].setvalue(0);\n          numflag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void rightblock() \n  {\n    int i=0,j=0;int t=0;int valuej=0;int valuei=0;int index=0;\n    for(i=3;i<16;i+=4)\n    {\n      index=i;\n      for(j=i-1;j>i-4;j--)\n      {  \n        valuej=0; valuei=0;\n        if(blockindex].getvalue()==0)\n        {\n          t=find(index,-1,i-3,index+1);\n          if(t!=-1)\n          {\n            blockindex].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuei=blockindex].getvalue();\n        if(blockj].getvalue()==0)\n        {\n          t=find(j,-1,i-3,j+1);\n          if(t!=-1)\n          {\n            blockj].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuej=blockj].getvalue();\n        if(valuei==valuej&&valuei!=0&&valuej!=0)\n        {\n          blockindex].setvalue(valuei+valuej);\n          blockj].setvalue(0);\n          numflag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void leftblock() \n  {\n    int i=0,j=0;int t=0;int valuej=0;int valuei=0;int index=0;\n    for(i=0;i<16;i+=4)\n    {\n      index=i;\n      for(j=i+1;j<i+4;j++)\n      {  \n        valuej=0; valuei=0;\n        if(blockindex].getvalue()==0)\n        {\n          t=find(index,1,index,i+4);\n          if(t!=-1)\n          {\n            blockindex].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuei=blockindex].getvalue();\n        if(blockj].getvalue()==0)\n        {\n          t=find(j,1,j,i+4);\n          if(t!=-1)\n          {\n            blockj].setvalue(blockt].getvalue());\n            blockt].setvalue(0);\n          }\n          else\n          {\n            break;\n          }\n        }\n        valuej=blockj].getvalue();\n        if(valuei==valuej&&valuei!=0&&valuej!=0)\n        {\n          blockindex].setvalue(valuei+valuej);\n          blockj].setvalue(0);\n          numflag = true;\n        }\n        index=j;\n      }\n       \n    }\n  }\n  public void over() \n  {\n    if (numflag ==false&& up==false&&down==false&&left==false&&right==false) //当不能添加元素，并且不可移动的步数超过36就输了，输了的时候在盘中央显示gameover\n    {\n      block4].settext("g");\n      block5].settext("a");\n      block6].settext("m");\n      block7].settext("e");\n      block8].settext("o");\n      block9].settext("v");\n      block10].settext("e");\n      block11].settext("r"); \n      block11].addmouselistener(new mouseadapter() {public void mousepressed(mouseevent e){restart();}});\n    }\n  }\n   \n  public void win() //同over\n  { \n    block0].settext("y");\n    block1].settext("o");\n    block2].settext("u");\n    block13].settext("w");\n    block14].settext("i");\n    block15].settext("n");\n    block15].addmouselistener(new mouseadapter() {\n      public void mousepressed(mouseevent e) {\n        restart();\n      }\n    });\n  }\n  public void restart()//重启游戏，和构造函数类似，不在累述\n  {\n    numflag=true;\n    moveflag=0;\n    up=true;down=true;left=true;right=true;\n    for(int i=0;i<16;i++)\n      blocki].setvalue(0);\n    for (int i = 0; i < 2; i++)\n      appearblock();\n  }\n  public void keypressed(keyevent e) //判断按的上下左右键，并依次调用移动函数、判断函数、添加函数、判断是否输掉的函数\n  {\n    switch (e.getkeycode()) {\n    case keyevent.vk_up:\n      if(up){\n      upblock();}\n      judgeappear();\n      appearblock();\n      over();\n       \n      if(numflag==false)\n      {\n        up=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case keyevent.vk_down:\n      if(down){\n      downblock();}\n      judgeappear();\n      appearblock();\n      over();\n      if(numflag==false)\n      {\n        down=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case keyevent.vk_left:\n      if(left){\n      leftblock();}\n      judgeappear();\n      appearblock();\n      over();\n       \n      if(numflag==false)\n      {\n        left=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    case keyevent.vk_right:\n      if(right){\n      rightblock();}\n      judgeappear();\n      appearblock();\n      over();\n       \n      if(numflag==false)\n      {\n        right=false;\n      }\n      else\n      {\n        up=true;down=true;left=true;right=true;\n      }\n      break;\n    }\n \n  }\n  public void keytyped(keyevent e) {\n \n  }\n  public void keyreleased(keyevent e) {\n \n  }\n \n}\n',charsets:{cjk:!0},lastUpdated:"2022/07/03, 15:32:16",lastUpdatedTimestamp:1656833536e3},{title:"hutool工具包",frontmatter:{title:"hutool工具包",date:"2022-02-23T13:02:26.000Z",permalink:"/pages/1d1863/",categories:["Java相关","工具"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/02.%E5%B7%A5%E5%85%B7/001.hutool%E5%B7%A5%E5%85%B7%E5%8C%85.html",relativePath:"01.Java相关/02.工具/001.hutool工具包.md",key:"v-689808d8",path:"/pages/1d1863/",headers:[{level:2,title:"难得糊涂",slug:"难得糊涂",normalizedTitle:"难得糊涂",charIndex:2},{level:3,title:"定时任务",slug:"定时任务",normalizedTitle:"定时任务",charIndex:242},{level:3,title:"二维码工具",slug:"二维码工具",normalizedTitle:"二维码工具",charIndex:1183},{level:3,title:"邮件工具",slug:"邮件工具",normalizedTitle:"邮件工具",charIndex:2108},{level:3,title:"Json工具",slug:"json工具",normalizedTitle:"json工具",charIndex:3458},{level:3,title:"信息脱敏工具",slug:"信息脱敏工具",normalizedTitle:"信息脱敏工具",charIndex:5677},{level:3,title:"压缩工具",slug:"压缩工具",normalizedTitle:"压缩工具",charIndex:6187},{level:3,title:"唯一ID工具",slug:"唯一id工具",normalizedTitle:"唯一id工具",charIndex:7668},{level:3,title:"正则工具",slug:"正则工具",normalizedTitle:"正则工具",charIndex:8736},{level:3,title:"身份证工具",slug:"身份证工具",normalizedTitle:"身份证工具",charIndex:10611},{level:3,title:"EasyExcel工具类",slug:"easyexcel工具类",normalizedTitle:"easyexcel工具类",charIndex:12004},{level:4,title:"代码实现过程",slug:"代码实现过程",normalizedTitle:"代码实现过程",charIndex:12020}],headersStr:"难得糊涂 定时任务 二维码工具 邮件工具 Json工具 信息脱敏工具 压缩工具 唯一ID工具 正则工具 身份证工具 EasyExcel工具类 代码实现过程",content:'# 难得糊涂\n\n导入依赖\n\n        <dependency>\n            <groupId>cn.hutool</groupId>\n            <artifactId>hutool-all</artifactId>\n            <version>${hutool.version}</version>\n        </dependency>\n\n\n----------------------------------------\n\n\n# 定时任务\n\n点击查看\n\ncron.setting\n\n\n# 我是注释  == com.company.aaa.job.TestJob.run = */10 * * * *\n[com.hrbu.cron]\n定时任务.Test = */10 * * * * *\n\n\npackage com.hrbu.cron;\n\nimport cn.hutool.core.lang.Console;\nimport cn.hutool.cron.CronUtil;\nimport cn.hutool.cron.task.Task;\nimport org.junit.Test;\n\n/**\n * 配置文件cron.setting\n */\npublic class 定时任务 {\n\n\n    @Test\n    public void Main() throws InterruptedException {\n        // 配置文件写法不需要调用就可以执行？\n        Test2();\n        Thread.currentThread().sleep(30000);\n    }\n\n    /**\n     * 定时任务\n     */\n    public void Test() {\n        System.out.println("hello world!!!");\n    }\n\n    /**\n     * 动态添加定时任务\n     */\n    public void Test2() {\n        CronUtil.schedule("*/2 * * * * *", new Task() {\n            @Override\n            public void execute() {\n                Console.log("Task excuted.");\n            }\n        });\n\n        // 支持秒级别定时任务\n        CronUtil.setMatchSecond(true);\n        CronUtil.start();\n    }\n}\n\n\n\n\n# 二维码工具\n\n点击查看\n\n        \x3c!-- 二维码依赖 --\x3e\n        <dependency>\n            <groupId>com.google.zxing</groupId>\n            <artifactId>core</artifactId>\n            <version>${qrcode.version}</version>\n        </dependency>\n\n\npackage com.hrbu.extra;\n\nimport cn.hutool.core.io.FileUtil;\nimport cn.hutool.extra.qrcode.QrCodeUtil;\nimport org.junit.Test;\n\npublic class 二维码工具 {\n    /**\n     * 生成二维码\n     *\n     * 也可以自行设置 1.样式（颜色，边距） 2.logo小图标 3.调整纠错级别\n     */\n    @Test\n    public void Test() {\n        // 生成指定url对应的二维码到文件(也可以到流)，宽和高都是300像素\n        QrCodeUtil.generate("http://aihb.top/", 300, 300, FileUtil.file("D:\\\\Program Files\\\\JetBrains\\\\project\\\\utils\\\\a_common\\\\qrcode.jpg"));\n\n    }\n\n    /**\n     * 识别二维码\n     */\n    @Test\n    public void Test2() {\n        String decode = QrCodeUtil.decode(FileUtil.file("D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\qrcode.jpg"));\n        System.out.println(decode);\n    }\n}\n\n\n\n\n# 邮件工具\n\n点击查看\n\n        \x3c!-- 邮件依赖 --\x3e\n        <dependency>\n            <groupId>com.sun.mail</groupId>\n            <artifactId>javax.mail</artifactId>\n            <version>${mail.version}</version>\n        </dependency>\n\n\nmail.setting\n\n# 发件人（必须正确，否则发送失败）\n# from = hutool@yeah.net\nfrom = 1714686225@qq.com\n# 密码（注意，某些邮箱需要为SMTP服务单独设置密码，详情查看相关帮助）\npass = mmmggnsqvstrdjhe\n# 使用SSL安全连接\nsslEnable = true\n# 邮件服务器的SMTP端口，可选，默认25\nport = 465  # 465 587\n\n# 邮件服务器的SMTP地址，可选，默认为smtp.<发件人邮箱后缀>\n# host = smtp.qq.com\n# 用户名，默认为发件人邮箱前缀\n# user = hutool\n\n\npackage com.hrbu.extra;\n\nimport cn.hutool.core.collection.CollUtil;\nimport cn.hutool.core.io.FileUtil;\nimport cn.hutool.extra.mail.MailAccount;\nimport cn.hutool.extra.mail.MailUtil;\nimport org.junit.Test;\n\n/**\n * 配置文件mail.setting\n */\npublic class 邮件工具 {\n\n    /**\n     * 普通文本\n     */\n    @Test\n    public void Test() {\n        MailUtil.send("xxx@qq.com", "测试", "邮件来自Hutool测试", false);\n    }\n\n    /**\n     * 群发\n     */\n    @Test\n    public void Test2() {\n        MailUtil.send(CollUtil.newArrayList("xxx@qq.com", "zzz@qq.com"), "测试", "邮件来自Hutool测试", false);\n    }\n\n    /**\n     * html格式邮件，并增加附件  465端口\n     */\n    @Test\n    public void Test3() {\n        MailUtil.send(CollUtil.newArrayList("xxx@qq.com"), "遮天", "遮天第一章", true, FileUtil.file("D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\zt.txt"));\n    }\n}\n\n\n\n\n# Json工具\n\n点击查看\n\npackage com.hrbu.io.json;\n\nimport cn.hutool.json.JSON;\nimport cn.hutool.json.JSONObject;\nimport cn.hutool.json.JSONUtil;\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\nimport org.junit.Test;\n\nimport java.io.File;\nimport java.nio.charset.Charset;\nimport java.nio.charset.StandardCharsets;\n\npublic class Json相关 {\n\n    private String jsonStr = "{\\"appId\\":\\"\\",\\"timestamp\\":1642926098,\\"nonceStr\\":\\"VLyigbixrv\\",\\"signature\\":\\"e57e0fdf59ce34efda440153656b72194d3bd9c5\\",\\"jsApiList\\":[\\"updateAppMessageShareData\\",\\"updateTimelineShareData\\"]}";\n\n    /**\n     * java对象转为Json\n     */\n    @Test\n    public void Test3()  {\n        Student student = new Student("1", "ahb", "男", "24");\n\n        // javaBean转为json (不忽略空值)\n        JSONObject jsonObject = JSONUtil.parseObj(student, false);\n        System.out.println(JSONUtil.toJsonPrettyStr(jsonObject));\n\n        // jsonObject.setDateFormat("yyyy-MM-dd HH:mm:ss"); // 设置时间格式\n    }\n\n    /**\n     * XML字符串转换为JSON\n     * JSON转换为XML\n     *\n     * JSON转Bean\n     * readXXX ： 从JSON文件中读取JSON对象的快捷方法\n     */\n    @Test\n    public void Test2()  {\n        // 从文件中读取\n        JSON json = JSONUtil.readJSON(new File("src/main/resources/test.json"), StandardCharsets.UTF_8);\n        // System.out.println(JSONUtil.toJsonPrettyStr(json));\n        System.out.println(JSONUtil.parseObj(json).getJSONArray("jsApiList"));\n    }\n\n    /**\n     * 根据字符串创建一个json对象\n     */\n    @Test\n    public void Test() {\n        // 字符串解析\n        JSONObject json1 = JSONUtil.parseObj(jsonStr);\n        System.out.println(json1.getStr("timestamp"));\n        System.out.println(json1.getInt("timestamp"));\n        System.out.println(json1.getLong("timestamp"));\n        System.out.println(json1.getDouble("timestamp"));\n        System.out.println(json1.getBigDecimal("timestamp"));\n\n        // 格式化json(格式化JSON字符串，此方法并不严格检查JSON的格式正确与否)\n        System.out.println(JSONUtil.formatJsonStr(jsonStr));\n\n        // 转换为格式化后的JSON字符串\n        System.out.println(JSONUtil.toJsonPrettyStr(jsonStr));\n    }\n}\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\nclass Student{\n    private String id;\n    private String name;\n    private String sex;\n    private String age;\n}\n\n\n\n# 信息脱敏工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.util.DesensitizedUtil;\nimport org.junit.Test;\n\n/**\n * 现阶段支持的脱敏数据类型包括：\n *\n * 用户id\n * 中文姓名\n * 身份证号\n * 座机号\n * 手机号\n * 地址\n * 电子邮件\n * 密码\n * 中国大陆车牌，包含普通车辆、新能源车辆\n * 银行卡\n * 整体来说，所谓脱敏就是隐藏掉信息中的一部分关键信息，用*代替，自定义隐藏可以使用StrUtil.hide方法完成。\n */\npublic class 信息脱敏工具 {\n\n    /**\n     * 身份证号脱敏\n     */\n    @Test\n    public void Test() {\n        String idCardNum = DesensitizedUtil.idCardNum("51343620000320711X", 1, 2);\n        System.out.println(idCardNum);\n    }\n}\n\n\n\n\n# 压缩工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.io.FileUtil;\nimport cn.hutool.core.util.ZipUtil;\nimport org.junit.Test;\n\nimport java.io.File;\nimport java.util.Collections;\nimport java.util.zip.ZipEntry;\n\npublic class 压缩工具 {\n\n    final String sourceFile = "D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\zt.txt";\n    final String sourceFile2 = "D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\num.csv";\n    final String tagFile = "D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\all.zip";\n    final String tagFile2 = "D:\\\\Program Files\\\\JetBrains\\\\project\\\\Utils\\\\a_common\\\\all";\n\n    /**\n     *  zip压缩\n     */\n    @Test\n    public void Test() {\n        // ZipUtil.zip(sourceFile, tagFile);\n\n        File zip = ZipUtil.zip(FileUtil.file(tagFile), false,\n                FileUtil.file(sourceFile),\n                FileUtil.file(sourceFile2));    // 多文件或目录压缩\n        System.out.println(zip);\n    }\n\n    /**\n     *  zip解压缩\n     */\n    @Test\n    public void Test2() {\n        File unzip = ZipUtil.unzip(tagFile, tagFile2);\n        System.out.println(unzip);\n    }\n\n\n    /**\n     * Gzip是网页传输中广泛使用的压缩方式，Hutool同样提供其工具方法简化其过程。\n     * ZipUtil.gzip 压缩，可压缩字符串，也可压缩文件 ZipUtil.unGzip 解压Gzip文件\n     *\n     *\n     * ZipUtil.zlib 压缩，可压缩字符串，也可压缩文件 ZipUtil.unZlib 解压zlib文件\n     * 注意 ZipUtil默认情况下使用系统编码，也就是说：\n     * 如果你在命令行下运行，则调用系统编码（一般Windows下为GBK、Linux下为UTF-8）\n     * 如果你在IDE（如Eclipse）下运行代码，则读取的是当前项目的编码（详细请查阅IDE设置，我的项目默认都是UTF-8编码，因此解压和压缩都是用这个编码）\n     */\n}\n\n\n\n\n# 唯一ID工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.lang.Snowflake;\nimport cn.hutool.core.util.IdUtil;\nimport cn.hutool.core.util.ObjectUtil;\nimport org.junit.Test;\n\npublic class 唯一ID工具 {\n    /**\n     * UUID\n     */\n    @Test\n    public void Test() {\n        System.out.println(IdUtil.fastUUID());          // 带-的UUID\n        System.out.println(IdUtil.fastSimpleUUID());    // 不带-的UUID\n    }\n\n    /**\n     * ObjectId\n     * ObjectId是MongoDB数据库的一种唯一ID生成策略\n     */\n    @Test\n    public void Test2() {\n        System.out.println(IdUtil.objectId());\n    }\n\n    /**\n     * 雪花算法\n     * 分布式系统中，有一些需要使用全局唯一ID的场景，有些时候我们希望能使用一种简单一些的ID，并且希望ID能够按照时间有序生成。Twitter的Snowflake 算法就是这种生成器。\n     * 注意: IdUtil.createSnowflake每次调用会创建一个新的Snowflake对象，不同的Snowflake对象创建的ID可能会有重复，因此请自行维护此对象为单例，或者使用IdUtil.getSnowflake使用全局单例对象。\n     */\n    @Test\n    public void Test3() {\n        // 参数1为终端ID\n        // 参数2为数据中心ID\n        Snowflake snowflake = IdUtil.getSnowflake(1, 2);\n        for (int i = 0; i < 200; i++) {\n            System.out.println(snowflake.nextId());\n        }\n    }\n\n}\n\n\n\n\n# 正则工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.util.ReUtil;\nimport org.junit.Assert;\nimport org.junit.Test;\n\nimport java.util.ArrayList;\n\npublic class 正则工具 {\n\n    private final String[] strs = {\n            "ZZZaaabbbccc中文1234",\n            "ZZZaaabbbccc中文1234,:345/"\n    };\n    /**\n     * 正则提取匹配到的数据\n     */\n    @Test\n    public void Test() {\n        String str1 = ReUtil.extractMulti("(\\\\w+).*(\\\\d+)", strs[0], "$1\\t$2");      // 提取出匹配到的内容\n        ArrayList<String> list = ReUtil.findAll("([\\\\u4e00-\\\\u9fa5]+)(\\\\d{2})", strs[0], 2, new ArrayList<String>());     //查找所有匹配文本(0所有 1第一个括号内 2第二个括号内)\n\n        Integer firstNumber = ReUtil.getFirstNumber(strs[1]);                 // 找到匹配到的第一段数字\n        boolean match = ReUtil.isMatch("\\\\w{12}.*\\\\d{4}", strs[0]);     // 正则式是否完全匹配字符串\n\n        String str2 = ReUtil.replaceAll(strs[1], "(\\\\d+)", "($1)");// 将匹配到的部分替换为指定值\n\n        String str3 = ReUtil.escape("hello ${world}!!");        // 正则关键字转义\n\n\n        System.out.println(str1);\n        list.forEach(v -> System.out.printf(v + " "));\n        System.out.println();\n        System.out.println(firstNumber);\n        System.out.println(match);\n        System.out.println(str2);\n        System.out.println(str3);\n        // Assert.assertEquals("A-z", str);\n    }\n\n    /**\n     * 删除匹配到的内容\n     */\n    @Test\n    public void Test2() {\n        String str1 = ReUtil.delFirst("\\\\w+", strs[0]);         // 删除第一次匹配到的内容\n        String str2 = ReUtil.delFirst("[\\\\u4e00-\\\\u9fa5]+", strs[0]);\n\n        String str3 = ReUtil.delAll("[0-9]{1}", strs[0]);       // 删除所有匹配到的内容\n        String str4 = ReUtil.delLast("[0-9]{1}", strs[0]);      // 删除最后一次匹配到的内容\n        String str5 = ReUtil.delPre("[0-9]{1}", strs[0]);       // 第一次匹配到字符之前的所有内容\n\n        System.out.println(str1 + "\\n" + str2 + "\\n" + str3 + "\\n" + str4 + "\\n" + str5 );\n        // Assert.assertEquals("A-z", str);\n    }\n}\n\n\n\n\n# 身份证工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.date.DateTime;\nimport cn.hutool.core.date.DateUtil;\nimport cn.hutool.core.util.IdcardUtil;\nimport org.junit.Assert;\nimport org.junit.Test;\n\npublic class 身份证工具 {\n\n    /**\n     * 身份证相关校验\n     */\n    @Test\n    public void Main(){\n        String ID_18 = "321083197812162119";\n        String ID_15 = "150102880730303";\n\n        //是否有效\n        boolean valid = IdcardUtil.isValidCard(ID_18);\n        boolean valid15 = IdcardUtil.isValidCard(ID_15);\n\n        //转换\n        String convert15To18 = IdcardUtil.convert15To18(ID_15);\n        Assert.assertEquals(convert15To18, "150102198807303035");\n\n        //年龄\n        DateTime date = DateUtil.parse("2017-04-10");\n\n        int age = IdcardUtil.getAgeByIdCard(ID_18, date);\n        Assert.assertEquals(age, 38);\n\n        int age2 = IdcardUtil.getAgeByIdCard(ID_15, date);\n        Assert.assertEquals(age2, 28);\n\n        //生日\n        String birth = IdcardUtil.getBirthByIdCard(ID_18);\n        Assert.assertEquals(birth, "19781216");\n\n        String birth2 = IdcardUtil.getBirthByIdCard(ID_15);\n        Assert.assertEquals(birth2, "19880730");\n\n        //省份\n        String province = IdcardUtil.getProvinceByIdCard(ID_18);\n        Assert.assertEquals(province, "江苏");\n\n        String province2 = IdcardUtil.getProvinceByIdCard(ID_15);\n        Assert.assertEquals(province2, "内蒙古");\n\n    }\n}\n\n\n\n\n# EasyExcel工具类\n\n# 代码实现过程\n\n点击查看\n\n        \x3c!-- start 学习Excel --\x3e\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>easyexcel</artifactId>\n            <version>3.0.5</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>fastjson</artifactId>\n            <version>1.2.75</version>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <version>RELEASE</version>\n            <scope>compile</scope>\n        </dependency>\n        \x3c!-- end 学习Excel --\x3e\n\n\n1. 实体类\n\n * 首先需要新建实体类，来将excel中每一行数据对应到一个对象中。\n * 注解学习\n   * @HeadRowHeight(20) 设置行高\n   * @ColumnWidth(25) 设置列宽\n   * @ExcelProperty(value = "BAL_ID", index = 0) head名称、下标\n   * @ExcelIgnore 处理中忽略的列\n   * @DateTimeFormat("yyyy-MM-dd HH:mm:ss") 时间格式化\n   * @NumberFormat("#.##%") 接收百分比数据\n\n----------------------------------------\n\n2. 监听器\n\n * 继承AnalysisEventListener<实体>类（重写其中两个方法）\n   * invoke 读取一条数据，执行一次该方法。可处理每一行数据\n   * doAfterAllAnalysed 读取结束后，执行一次该方法\n\n----------------------------------------\n\n3. 读取\n\nMyDataReadListener myDataReadListener = new MyDataReadListener();\n// 封装工作薄对象\nExcelReaderBuilder workBook = EasyExcel.read(sourceFile, MyData.class, myDataReadListener);\n// 封装工作表对象\nExcelReaderSheetBuilder sheet = workBook.sheet();\n// 读取\nsheet.doRead();\nreturn myDataReadListener.getAllData();\n\n\n----------------------------------------\n\n4. 自定义拦截器\n\n * 可以用于指定特定单元格样式\n * 这里实现了RowWriteHandler接口，重写afterRowDispose方法，将对比结果不同的单元格置上不同的前景色\n\n需要了解的类或接口\nWorkbookWriteHandler\nSheetWriteHandler\nRowWriteHandler\nCellWriteHandler\nDefaultWriteHandlerLoader\n\n\n----------------------------------------\n\n5. 写入\n\nEasyExcel.write(tagFile, MyData.class)\n        .registerWriteHandler(new 自定义拦截器())\n        .sheet()\n        .doWrite(数据集(List));\n\n\n----------------------------------------',normalizedContent:'# 难得糊涂\n\n导入依赖\n\n        <dependency>\n            <groupid>cn.hutool</groupid>\n            <artifactid>hutool-all</artifactid>\n            <version>${hutool.version}</version>\n        </dependency>\n\n\n----------------------------------------\n\n\n# 定时任务\n\n点击查看\n\ncron.setting\n\n\n# 我是注释  == com.company.aaa.job.testjob.run = */10 * * * *\n[com.hrbu.cron]\n定时任务.test = */10 * * * * *\n\n\npackage com.hrbu.cron;\n\nimport cn.hutool.core.lang.console;\nimport cn.hutool.cron.cronutil;\nimport cn.hutool.cron.task.task;\nimport org.junit.test;\n\n/**\n * 配置文件cron.setting\n */\npublic class 定时任务 {\n\n\n    @test\n    public void main() throws interruptedexception {\n        // 配置文件写法不需要调用就可以执行？\n        test2();\n        thread.currentthread().sleep(30000);\n    }\n\n    /**\n     * 定时任务\n     */\n    public void test() {\n        system.out.println("hello world!!!");\n    }\n\n    /**\n     * 动态添加定时任务\n     */\n    public void test2() {\n        cronutil.schedule("*/2 * * * * *", new task() {\n            @override\n            public void execute() {\n                console.log("task excuted.");\n            }\n        });\n\n        // 支持秒级别定时任务\n        cronutil.setmatchsecond(true);\n        cronutil.start();\n    }\n}\n\n\n\n\n# 二维码工具\n\n点击查看\n\n        \x3c!-- 二维码依赖 --\x3e\n        <dependency>\n            <groupid>com.google.zxing</groupid>\n            <artifactid>core</artifactid>\n            <version>${qrcode.version}</version>\n        </dependency>\n\n\npackage com.hrbu.extra;\n\nimport cn.hutool.core.io.fileutil;\nimport cn.hutool.extra.qrcode.qrcodeutil;\nimport org.junit.test;\n\npublic class 二维码工具 {\n    /**\n     * 生成二维码\n     *\n     * 也可以自行设置 1.样式（颜色，边距） 2.logo小图标 3.调整纠错级别\n     */\n    @test\n    public void test() {\n        // 生成指定url对应的二维码到文件(也可以到流)，宽和高都是300像素\n        qrcodeutil.generate("http://aihb.top/", 300, 300, fileutil.file("d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\qrcode.jpg"));\n\n    }\n\n    /**\n     * 识别二维码\n     */\n    @test\n    public void test2() {\n        string decode = qrcodeutil.decode(fileutil.file("d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\qrcode.jpg"));\n        system.out.println(decode);\n    }\n}\n\n\n\n\n# 邮件工具\n\n点击查看\n\n        \x3c!-- 邮件依赖 --\x3e\n        <dependency>\n            <groupid>com.sun.mail</groupid>\n            <artifactid>javax.mail</artifactid>\n            <version>${mail.version}</version>\n        </dependency>\n\n\nmail.setting\n\n# 发件人（必须正确，否则发送失败）\n# from = hutool@yeah.net\nfrom = 1714686225@qq.com\n# 密码（注意，某些邮箱需要为smtp服务单独设置密码，详情查看相关帮助）\npass = mmmggnsqvstrdjhe\n# 使用ssl安全连接\nsslenable = true\n# 邮件服务器的smtp端口，可选，默认25\nport = 465  # 465 587\n\n# 邮件服务器的smtp地址，可选，默认为smtp.<发件人邮箱后缀>\n# host = smtp.qq.com\n# 用户名，默认为发件人邮箱前缀\n# user = hutool\n\n\npackage com.hrbu.extra;\n\nimport cn.hutool.core.collection.collutil;\nimport cn.hutool.core.io.fileutil;\nimport cn.hutool.extra.mail.mailaccount;\nimport cn.hutool.extra.mail.mailutil;\nimport org.junit.test;\n\n/**\n * 配置文件mail.setting\n */\npublic class 邮件工具 {\n\n    /**\n     * 普通文本\n     */\n    @test\n    public void test() {\n        mailutil.send("xxx@qq.com", "测试", "邮件来自hutool测试", false);\n    }\n\n    /**\n     * 群发\n     */\n    @test\n    public void test2() {\n        mailutil.send(collutil.newarraylist("xxx@qq.com", "zzz@qq.com"), "测试", "邮件来自hutool测试", false);\n    }\n\n    /**\n     * html格式邮件，并增加附件  465端口\n     */\n    @test\n    public void test3() {\n        mailutil.send(collutil.newarraylist("xxx@qq.com"), "遮天", "遮天第一章", true, fileutil.file("d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\zt.txt"));\n    }\n}\n\n\n\n\n# json工具\n\n点击查看\n\npackage com.hrbu.io.json;\n\nimport cn.hutool.json.json;\nimport cn.hutool.json.jsonobject;\nimport cn.hutool.json.jsonutil;\nimport lombok.allargsconstructor;\nimport lombok.data;\nimport lombok.noargsconstructor;\nimport org.junit.test;\n\nimport java.io.file;\nimport java.nio.charset.charset;\nimport java.nio.charset.standardcharsets;\n\npublic class json相关 {\n\n    private string jsonstr = "{\\"appid\\":\\"\\",\\"timestamp\\":1642926098,\\"noncestr\\":\\"vlyigbixrv\\",\\"signature\\":\\"e57e0fdf59ce34efda440153656b72194d3bd9c5\\",\\"jsapilist\\":[\\"updateappmessagesharedata\\",\\"updatetimelinesharedata\\"]}";\n\n    /**\n     * java对象转为json\n     */\n    @test\n    public void test3()  {\n        student student = new student("1", "ahb", "男", "24");\n\n        // javabean转为json (不忽略空值)\n        jsonobject jsonobject = jsonutil.parseobj(student, false);\n        system.out.println(jsonutil.tojsonprettystr(jsonobject));\n\n        // jsonobject.setdateformat("yyyy-mm-dd hh:mm:ss"); // 设置时间格式\n    }\n\n    /**\n     * xml字符串转换为json\n     * json转换为xml\n     *\n     * json转bean\n     * readxxx ： 从json文件中读取json对象的快捷方法\n     */\n    @test\n    public void test2()  {\n        // 从文件中读取\n        json json = jsonutil.readjson(new file("src/main/resources/test.json"), standardcharsets.utf_8);\n        // system.out.println(jsonutil.tojsonprettystr(json));\n        system.out.println(jsonutil.parseobj(json).getjsonarray("jsapilist"));\n    }\n\n    /**\n     * 根据字符串创建一个json对象\n     */\n    @test\n    public void test() {\n        // 字符串解析\n        jsonobject json1 = jsonutil.parseobj(jsonstr);\n        system.out.println(json1.getstr("timestamp"));\n        system.out.println(json1.getint("timestamp"));\n        system.out.println(json1.getlong("timestamp"));\n        system.out.println(json1.getdouble("timestamp"));\n        system.out.println(json1.getbigdecimal("timestamp"));\n\n        // 格式化json(格式化json字符串，此方法并不严格检查json的格式正确与否)\n        system.out.println(jsonutil.formatjsonstr(jsonstr));\n\n        // 转换为格式化后的json字符串\n        system.out.println(jsonutil.tojsonprettystr(jsonstr));\n    }\n}\n\n@data\n@allargsconstructor\n@noargsconstructor\nclass student{\n    private string id;\n    private string name;\n    private string sex;\n    private string age;\n}\n\n\n\n# 信息脱敏工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.util.desensitizedutil;\nimport org.junit.test;\n\n/**\n * 现阶段支持的脱敏数据类型包括：\n *\n * 用户id\n * 中文姓名\n * 身份证号\n * 座机号\n * 手机号\n * 地址\n * 电子邮件\n * 密码\n * 中国大陆车牌，包含普通车辆、新能源车辆\n * 银行卡\n * 整体来说，所谓脱敏就是隐藏掉信息中的一部分关键信息，用*代替，自定义隐藏可以使用strutil.hide方法完成。\n */\npublic class 信息脱敏工具 {\n\n    /**\n     * 身份证号脱敏\n     */\n    @test\n    public void test() {\n        string idcardnum = desensitizedutil.idcardnum("51343620000320711x", 1, 2);\n        system.out.println(idcardnum);\n    }\n}\n\n\n\n\n# 压缩工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.io.fileutil;\nimport cn.hutool.core.util.ziputil;\nimport org.junit.test;\n\nimport java.io.file;\nimport java.util.collections;\nimport java.util.zip.zipentry;\n\npublic class 压缩工具 {\n\n    final string sourcefile = "d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\zt.txt";\n    final string sourcefile2 = "d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\num.csv";\n    final string tagfile = "d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\all.zip";\n    final string tagfile2 = "d:\\\\program files\\\\jetbrains\\\\project\\\\utils\\\\a_common\\\\all";\n\n    /**\n     *  zip压缩\n     */\n    @test\n    public void test() {\n        // ziputil.zip(sourcefile, tagfile);\n\n        file zip = ziputil.zip(fileutil.file(tagfile), false,\n                fileutil.file(sourcefile),\n                fileutil.file(sourcefile2));    // 多文件或目录压缩\n        system.out.println(zip);\n    }\n\n    /**\n     *  zip解压缩\n     */\n    @test\n    public void test2() {\n        file unzip = ziputil.unzip(tagfile, tagfile2);\n        system.out.println(unzip);\n    }\n\n\n    /**\n     * gzip是网页传输中广泛使用的压缩方式，hutool同样提供其工具方法简化其过程。\n     * ziputil.gzip 压缩，可压缩字符串，也可压缩文件 ziputil.ungzip 解压gzip文件\n     *\n     *\n     * ziputil.zlib 压缩，可压缩字符串，也可压缩文件 ziputil.unzlib 解压zlib文件\n     * 注意 ziputil默认情况下使用系统编码，也就是说：\n     * 如果你在命令行下运行，则调用系统编码（一般windows下为gbk、linux下为utf-8）\n     * 如果你在ide（如eclipse）下运行代码，则读取的是当前项目的编码（详细请查阅ide设置，我的项目默认都是utf-8编码，因此解压和压缩都是用这个编码）\n     */\n}\n\n\n\n\n# 唯一id工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.lang.snowflake;\nimport cn.hutool.core.util.idutil;\nimport cn.hutool.core.util.objectutil;\nimport org.junit.test;\n\npublic class 唯一id工具 {\n    /**\n     * uuid\n     */\n    @test\n    public void test() {\n        system.out.println(idutil.fastuuid());          // 带-的uuid\n        system.out.println(idutil.fastsimpleuuid());    // 不带-的uuid\n    }\n\n    /**\n     * objectid\n     * objectid是mongodb数据库的一种唯一id生成策略\n     */\n    @test\n    public void test2() {\n        system.out.println(idutil.objectid());\n    }\n\n    /**\n     * 雪花算法\n     * 分布式系统中，有一些需要使用全局唯一id的场景，有些时候我们希望能使用一种简单一些的id，并且希望id能够按照时间有序生成。twitter的snowflake 算法就是这种生成器。\n     * 注意: idutil.createsnowflake每次调用会创建一个新的snowflake对象，不同的snowflake对象创建的id可能会有重复，因此请自行维护此对象为单例，或者使用idutil.getsnowflake使用全局单例对象。\n     */\n    @test\n    public void test3() {\n        // 参数1为终端id\n        // 参数2为数据中心id\n        snowflake snowflake = idutil.getsnowflake(1, 2);\n        for (int i = 0; i < 200; i++) {\n            system.out.println(snowflake.nextid());\n        }\n    }\n\n}\n\n\n\n\n# 正则工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.util.reutil;\nimport org.junit.assert;\nimport org.junit.test;\n\nimport java.util.arraylist;\n\npublic class 正则工具 {\n\n    private final string[] strs = {\n            "zzzaaabbbccc中文1234",\n            "zzzaaabbbccc中文1234,:345/"\n    };\n    /**\n     * 正则提取匹配到的数据\n     */\n    @test\n    public void test() {\n        string str1 = reutil.extractmulti("(\\\\w+).*(\\\\d+)", strs[0], "$1\\t$2");      // 提取出匹配到的内容\n        arraylist<string> list = reutil.findall("([\\\\u4e00-\\\\u9fa5]+)(\\\\d{2})", strs[0], 2, new arraylist<string>());     //查找所有匹配文本(0所有 1第一个括号内 2第二个括号内)\n\n        integer firstnumber = reutil.getfirstnumber(strs[1]);                 // 找到匹配到的第一段数字\n        boolean match = reutil.ismatch("\\\\w{12}.*\\\\d{4}", strs[0]);     // 正则式是否完全匹配字符串\n\n        string str2 = reutil.replaceall(strs[1], "(\\\\d+)", "($1)");// 将匹配到的部分替换为指定值\n\n        string str3 = reutil.escape("hello ${world}!!");        // 正则关键字转义\n\n\n        system.out.println(str1);\n        list.foreach(v -> system.out.printf(v + " "));\n        system.out.println();\n        system.out.println(firstnumber);\n        system.out.println(match);\n        system.out.println(str2);\n        system.out.println(str3);\n        // assert.assertequals("a-z", str);\n    }\n\n    /**\n     * 删除匹配到的内容\n     */\n    @test\n    public void test2() {\n        string str1 = reutil.delfirst("\\\\w+", strs[0]);         // 删除第一次匹配到的内容\n        string str2 = reutil.delfirst("[\\\\u4e00-\\\\u9fa5]+", strs[0]);\n\n        string str3 = reutil.delall("[0-9]{1}", strs[0]);       // 删除所有匹配到的内容\n        string str4 = reutil.dellast("[0-9]{1}", strs[0]);      // 删除最后一次匹配到的内容\n        string str5 = reutil.delpre("[0-9]{1}", strs[0]);       // 第一次匹配到字符之前的所有内容\n\n        system.out.println(str1 + "\\n" + str2 + "\\n" + str3 + "\\n" + str4 + "\\n" + str5 );\n        // assert.assertequals("a-z", str);\n    }\n}\n\n\n\n\n# 身份证工具\n\n点击查看\n\npackage com.hrbu.util;\n\nimport cn.hutool.core.date.datetime;\nimport cn.hutool.core.date.dateutil;\nimport cn.hutool.core.util.idcardutil;\nimport org.junit.assert;\nimport org.junit.test;\n\npublic class 身份证工具 {\n\n    /**\n     * 身份证相关校验\n     */\n    @test\n    public void main(){\n        string id_18 = "321083197812162119";\n        string id_15 = "150102880730303";\n\n        //是否有效\n        boolean valid = idcardutil.isvalidcard(id_18);\n        boolean valid15 = idcardutil.isvalidcard(id_15);\n\n        //转换\n        string convert15to18 = idcardutil.convert15to18(id_15);\n        assert.assertequals(convert15to18, "150102198807303035");\n\n        //年龄\n        datetime date = dateutil.parse("2017-04-10");\n\n        int age = idcardutil.getagebyidcard(id_18, date);\n        assert.assertequals(age, 38);\n\n        int age2 = idcardutil.getagebyidcard(id_15, date);\n        assert.assertequals(age2, 28);\n\n        //生日\n        string birth = idcardutil.getbirthbyidcard(id_18);\n        assert.assertequals(birth, "19781216");\n\n        string birth2 = idcardutil.getbirthbyidcard(id_15);\n        assert.assertequals(birth2, "19880730");\n\n        //省份\n        string province = idcardutil.getprovincebyidcard(id_18);\n        assert.assertequals(province, "江苏");\n\n        string province2 = idcardutil.getprovincebyidcard(id_15);\n        assert.assertequals(province2, "内蒙古");\n\n    }\n}\n\n\n\n\n# easyexcel工具类\n\n# 代码实现过程\n\n点击查看\n\n        \x3c!-- start 学习excel --\x3e\n        <dependency>\n            <groupid>com.alibaba</groupid>\n            <artifactid>easyexcel</artifactid>\n            <version>3.0.5</version>\n        </dependency>\n        <dependency>\n            <groupid>com.alibaba</groupid>\n            <artifactid>fastjson</artifactid>\n            <version>1.2.75</version>\n        </dependency>\n        <dependency>\n            <groupid>org.projectlombok</groupid>\n            <artifactid>lombok</artifactid>\n            <version>release</version>\n            <scope>compile</scope>\n        </dependency>\n        \x3c!-- end 学习excel --\x3e\n\n\n1. 实体类\n\n * 首先需要新建实体类，来将excel中每一行数据对应到一个对象中。\n * 注解学习\n   * @headrowheight(20) 设置行高\n   * @columnwidth(25) 设置列宽\n   * @excelproperty(value = "bal_id", index = 0) head名称、下标\n   * @excelignore 处理中忽略的列\n   * @datetimeformat("yyyy-mm-dd hh:mm:ss") 时间格式化\n   * @numberformat("#.##%") 接收百分比数据\n\n----------------------------------------\n\n2. 监听器\n\n * 继承analysiseventlistener<实体>类（重写其中两个方法）\n   * invoke 读取一条数据，执行一次该方法。可处理每一行数据\n   * doafterallanalysed 读取结束后，执行一次该方法\n\n----------------------------------------\n\n3. 读取\n\nmydatareadlistener mydatareadlistener = new mydatareadlistener();\n// 封装工作薄对象\nexcelreaderbuilder workbook = easyexcel.read(sourcefile, mydata.class, mydatareadlistener);\n// 封装工作表对象\nexcelreadersheetbuilder sheet = workbook.sheet();\n// 读取\nsheet.doread();\nreturn mydatareadlistener.getalldata();\n\n\n----------------------------------------\n\n4. 自定义拦截器\n\n * 可以用于指定特定单元格样式\n * 这里实现了rowwritehandler接口，重写afterrowdispose方法，将对比结果不同的单元格置上不同的前景色\n\n需要了解的类或接口\nworkbookwritehandler\nsheetwritehandler\nrowwritehandler\ncellwritehandler\ndefaultwritehandlerloader\n\n\n----------------------------------------\n\n5. 写入\n\neasyexcel.write(tagfile, mydata.class)\n        .registerwritehandler(new 自定义拦截器())\n        .sheet()\n        .dowrite(数据集(list));\n\n\n----------------------------------------',charsets:{cjk:!0},lastUpdated:"2022/08/21, 00:20:31",lastUpdatedTimestamp:1661012431e3},{title:"Commons类库",frontmatter:{title:"Commons类库",date:"2022-02-23T13:02:26.000Z",permalink:"/pages/1d1864/",categories:["Java相关","工具"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/02.%E5%B7%A5%E5%85%B7/002.Apache%20Commons%E5%B7%A5%E5%85%B7%E5%8C%85.html",relativePath:"01.Java相关/02.工具/002.Apache Commons工具包.md",key:"v-29791135",path:"/pages/1d1864/",headers:[{level:2,title:"Apache Commons类库",slug:"apache-commons类库",normalizedTitle:"apache commons类库",charIndex:2},{level:3,title:"官方文档",slug:"官方文档",normalizedTitle:"官方文档",charIndex:65},{level:4,title:"读取 Excel 数据学习",slug:"读取-excel-数据学习",normalizedTitle:"读取 excel 数据学习",charIndex:79}],headersStr:"Apache Commons类库 官方文档 读取 Excel 数据学习",content:"# Apache Commons类库\n\n----------------------------------------\n\n\n# 官方文档\n\n访问地址\n\n# 读取 Excel 数据学习\n\n跳转链接 跳转链接",normalizedContent:"# apache commons类库\n\n----------------------------------------\n\n\n# 官方文档\n\n访问地址\n\n# 读取 excel 数据学习\n\n跳转链接 跳转链接",charsets:{cjk:!0},lastUpdated:"2024/03/17, 02:02:47",lastUpdatedTimestamp:1710612167e3},{title:"SQL解析工具",frontmatter:{title:"SQL解析工具",date:"2022-08-20T23:00:16.000Z",permalink:"/pages/2e9bb7/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/02.%E5%B7%A5%E5%85%B7/010.SQL%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7.html",relativePath:"01.Java相关/02.工具/010.SQL解析工具.md",key:"v-4c2230e8",path:"/pages/2e9bb7/",headers:[{level:2,title:"一、SQLFlow",slug:"一、sqlflow",normalizedTitle:"一、sqlflow",charIndex:2},{level:4,title:"1. 项目简介",slug:"_1-项目简介",normalizedTitle:"1. 项目简介",charIndex:15},{level:4,title:"2. 血统分析工具",slug:"_2-血统分析工具",normalizedTitle:"2. 血统分析工具",charIndex:349}],headersStr:"一、SQLFlow 1. 项目简介 2. 血统分析工具",content:"# 一、SQLFlow\n\n# 1. 项目简介\n\n数据库中视图(View)的数据来自表(Table)或其他视图，视图中字段(Column)的数据可能来自多个表中多个字段的聚集(aggregation)。 表中的数据可能通过ETL从外部系统中导入。这种从数据的源头经过各个处理环节，到达数据终点的数据链路关系称为数据血缘关系(data lineage)。\n\nSQLFlow 通过分析各种数据库对象的定义(DDL)、DML 语句、ETL/ELT中使用的存储过程(Proceudre,Function)、 触发器(Trigger)和其他 SQL 脚本，给出完整的数据血缘关系。\n\n在大型数据仓库中，完整的数据血缘关系可以用来进行数据溯源、表和字段变更的影响分析、数据合规性的证明、数据质量的检查等。\n\n# 2. 血统分析工具\n\n参数\n\n参数                     描述\n/f                     SQL文件的完整路径\n/d                     目录的完整路径包括SQL文件\n/j                     返回包含连接关系的结果\n/s                     简单输出，忽略中间结果\n/topselectlist         带有顶部select结果的简单输出\n/i                     与/s参数类似,但将保留SQL函数生成的结果集\n/if                    保留所有中间结果集，但删除SQL函数生成的结果集\n/ic                    忽略输出中的坐标\n/lof                   将孤儿列（没有指定表的列）链接到第一个表\n/traceView             只输出源表和视图的名称，忽略所有中间数据\n/text                  此选项仅使用 /s，在文本模式下输出列依赖关系\n/json                  打印JSON格式输出\n/stat                  输出分析统计信息\n/tableLineage [/csv]   输出表级别的SQL血统\n/csv                   用csv方式输出列级别血统关系\n/t                     设置数据库类型，支持\n                       access,bigquery,couchbase,dax,db2,greenplum,hana,hive,impala,informix,mdx,mssql,sqlserver,mysql,netezza,odbc,openedge,oracle,postgresql,postgres,redshift,snowflake,sybase,teradata,soql,vertica等，默认值为oracle\n/o                     将输出流写入指定的文件\n/log                   生成dataflow.log文件以记录日志信息\n/env                   指定一个元数据Json来获取数据库元数据信息\n/transform             输出关系转换代码\n/coor                  输出关系变换坐标，但不是代码\n/defaultDatabase       specify the default schema.\n/defaultSchema         specify the default schema.\n/showImplicitSchema    show implicit schema.\n\n血缘分析示例 从数据库中抽取元数据",normalizedContent:"# 一、sqlflow\n\n# 1. 项目简介\n\n数据库中视图(view)的数据来自表(table)或其他视图，视图中字段(column)的数据可能来自多个表中多个字段的聚集(aggregation)。 表中的数据可能通过etl从外部系统中导入。这种从数据的源头经过各个处理环节，到达数据终点的数据链路关系称为数据血缘关系(data lineage)。\n\nsqlflow 通过分析各种数据库对象的定义(ddl)、dml 语句、etl/elt中使用的存储过程(proceudre,function)、 触发器(trigger)和其他 sql 脚本，给出完整的数据血缘关系。\n\n在大型数据仓库中，完整的数据血缘关系可以用来进行数据溯源、表和字段变更的影响分析、数据合规性的证明、数据质量的检查等。\n\n# 2. 血统分析工具\n\n参数\n\n参数                     描述\n/f                     sql文件的完整路径\n/d                     目录的完整路径包括sql文件\n/j                     返回包含连接关系的结果\n/s                     简单输出，忽略中间结果\n/topselectlist         带有顶部select结果的简单输出\n/i                     与/s参数类似,但将保留sql函数生成的结果集\n/if                    保留所有中间结果集，但删除sql函数生成的结果集\n/ic                    忽略输出中的坐标\n/lof                   将孤儿列（没有指定表的列）链接到第一个表\n/traceview             只输出源表和视图的名称，忽略所有中间数据\n/text                  此选项仅使用 /s，在文本模式下输出列依赖关系\n/json                  打印json格式输出\n/stat                  输出分析统计信息\n/tablelineage [/csv]   输出表级别的sql血统\n/csv                   用csv方式输出列级别血统关系\n/t                     设置数据库类型，支持\n                       access,bigquery,couchbase,dax,db2,greenplum,hana,hive,impala,informix,mdx,mssql,sqlserver,mysql,netezza,odbc,openedge,oracle,postgresql,postgres,redshift,snowflake,sybase,teradata,soql,vertica等，默认值为oracle\n/o                     将输出流写入指定的文件\n/log                   生成dataflow.log文件以记录日志信息\n/env                   指定一个元数据json来获取数据库元数据信息\n/transform             输出关系转换代码\n/coor                  输出关系变换坐标，但不是代码\n/defaultdatabase       specify the default schema.\n/defaultschema         specify the default schema.\n/showimplicitschema    show implicit schema.\n\n血缘分析示例 从数据库中抽取元数据",charsets:{cjk:!0},lastUpdated:"2022/08/29, 12:56:39",lastUpdatedTimestamp:1661748999e3},{title:"Spring Boot相关",frontmatter:{title:"Spring Boot相关",date:"2022-02-28T08:54:08.000Z",permalink:"/pages/1e9420/",categories:["Java相关","框架"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/03.%E6%A1%86%E6%9E%B6/01.Spring%20Boot%E7%9B%B8%E5%85%B3.html",relativePath:"01.Java相关/03.框架/01.Spring Boot相关.md",key:"v-1a0eb102",path:"/pages/1e9420/",headers:[{level:2,title:"知识点",slug:"知识点",normalizedTitle:"知识点",charIndex:2},{level:3,title:"Spring 配置文件",slug:"spring-配置文件",normalizedTitle:"spring 配置文件",charIndex:10},{level:4,title:"Spring 配置文件优先级（从高到低）",slug:"spring-配置文件优先级-从高到低",normalizedTitle:"spring 配置文件优先级（从高到低）",charIndex:25},{level:4,title:"启动参数指定配置文件",slug:"启动参数指定配置文件",normalizedTitle:"启动参数指定配置文件",charIndex:196},{level:4,title:"Spring Boot项目中读取application配置文件中配置",slug:"spring-boot项目中读取application配置文件中配置",normalizedTitle:"spring boot项目中读取application配置文件中配置",charIndex:643},{level:3,title:"Spring Boot实体类时间格式化",slug:"spring-boot实体类时间格式化",normalizedTitle:"spring boot实体类时间格式化",charIndex:1650},{level:3,title:"事务注解",slug:"事务注解",normalizedTitle:"事务注解",charIndex:1796},{level:3,title:"国内最好的maven repository",slug:"国内最好的maven-repository",normalizedTitle:"国内最好的maven repository",charIndex:2575},{level:3,title:"有时间了解一下自动部署相关",slug:"有时间了解一下自动部署相关",normalizedTitle:"有时间了解一下自动部署相关",charIndex:3866},{level:2,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:2486},{level:4,title:"工作Spring + Strusts2 + EXTJS5",slug:"工作spring-strusts2-extjs5",normalizedTitle:"工作spring + strusts2 + extjs5",charIndex:3890}],headersStr:"知识点 Spring 配置文件 Spring 配置文件优先级（从高到低） 启动参数指定配置文件 Spring Boot项目中读取application配置文件中配置 Spring Boot实体类时间格式化 事务注解 国内最好的maven repository 有时间了解一下自动部署相关 其他 工作Spring + Strusts2 + EXTJS5",content:'# 知识点\n\n\n# Spring 配置文件\n\n# Spring 配置文件优先级（从高到低）\n\n文件优先级\n\n 1. properties配置文件\n 2. yml配置文件\n 3. yaml配置文件\n\n文件位置优先级\n\n 1. 直接子目录/config\n 2. 项目根目录/config\n 3. 项目根目录\n 4. classpath根config/\n 5. classpath根目录下的\n\n# 启动参数指定配置文件\n\n# 精确读取外部配置文件\njava  -jar -Dspring.profiles.active=test  xxx.jar\n\n# 改变主配置文件名\njava -jar foo.jar --spring.config.name=spring\n\n\n# 使用指定目录\njava  -Dspring.profiles.active=test -jar comet-service/target/xxx.jar --spring.config.location=/tmp/\n# 使用 optional，当目录路径不存在时不报错\njava  -Dspring.profiles.active=test -jar comet-service/target/xxx.jar --spring.config.location=optional:/tmp/\n\n\n# spring.config.additional-location # 不会覆盖主配置文件中的设置，而是作为补充\n\n\n# Spring Boot项目中读取application配置文件中配置\n\n * 使用@Value方式\n\n@Value("${spring.kafka.topic}")\nprivate String topic;\n\n\n * 使用Environment方式\n\n@Autowired  \nprivate Environment env;  \n      \nenv.getProperty("spring.kafka.topic");\n\n\n * @ConfigurationProperties(prefix = "") 注解\n\n1、在application.yml中添加配置\napplication:\n  serverConfig:\n    address: localhost\n    port: 22\n    username: geiri\n    password: 12345678\n    \n2.建配置类\npackage com.pn.ebs.config;\n \nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.stereotype.Component;\n \n@Component\n@ConfigurationProperties(prefix = "application")\npublic class ApplicationProperties {\n \n    private ServerConfig serverConfig = new ServerConfig();\n \n    public ServerConfig getServerConfig() {\n        return serverConfig;\n    }\n    public final class ServerConfig{\n        private String address;\n        private String port;\n        private String username;\n        private String password;\n        // geter/setter 此处略\n    }\n \n}\n\n\n\n# Spring Boot实体类时间格式化\n\n// 返回时间格式\n@JsonFormat(pattern="yyyy-MM-dd HH:mm:ss",timezone="GMT+8")\n\n// 传入时间格式\n@DateTimeFormat(pattern ="yyyy-MM-dd")\n\n\n\n# 事务注解\n\n> Spring Boot中实现事务没有额外的Jar包，还是基本的数据库访问包，比如mybatis\n\n注解事务@Transactional\n\n@Service\npublic class PersonService {\n    @Resource\n    private PersonMapper personMapper;\n\n    @Resource\n    private CompanyMapper companyMapper;\n\n    @Transactional(rollbackFor = {RuntimeException.class, Error.class})\n    public void saveOne(Person person) {\n        Company company = new Company();\n        company.setName("tenmao:" + person.getName());\n        companyMapper.insertOne(company);\n        personMapper.insertOne(person);\n    }\n}\n\n\n注解属性\n\n * rollbackFor：触发回滚的异常，默认是RuntimeException和Error\n * isolation: 事务的隔离级别，默认是Isolation.DEFAULT也就是数据库自身的默认隔离级别，比如MySQL是ISOLATION_REPEATABLE_READ可重复读\n\n> 这样就可以了，不需要其他配置。\n> ps：网络上还说要在@SpringBootApplication上添加注解@EnableTransactionManagement，已经不需要了\n\n原文\n\n\n# 国内最好的maven repository\n\n方法1：全局配置:修改maven根目录下的conf文件夹中的setting.xml文件，内容如下：\n\n<mirrors>\n    <mirror>\n      <id>alimaven</id>\n      <name>aliyun maven</name>\n      <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n      <mirrorOf>central</mirrorOf>        \n    </mirror>\n  </mirrors>\n\n\n方法2：单项目配置: pom.xml文件里添加\n\n<repositories>  \n        <repository>  \n            <id>alimaven</id>  \n            <name>aliyun maven</name>  \n            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>  \n            <releases>  \n                <enabled>true</enabled>  \n            </releases>  \n            <snapshots>  \n                <enabled>false</enabled>  \n            </snapshots>  \n        </repository>  \n</repositories> \n===========================================\n<repositories>\n        <repository>\n            <id>central</id>\n            <name>aliyun maven</name>\n            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n            <layout>default</layout>\n            \x3c!-- 是否开启发布版构件下载 --\x3e\n            <releases>\n                <enabled>true</enabled>\n            </releases>\n            \x3c!-- 是否开启快照版构件下载 --\x3e\n            <snapshots>\n                <enabled>false</enabled>\n            </snapshots>\n        </repository>\n    </repositories> \n\n\n\n# 有时间了解一下自动部署相关\n\n\n# 其他\n\n# 工作Spring + Strusts2 + EXTJS5\n\n分层\n\n * action层类似于controller\n * service相当于service层\n * BgdDataSource类似于dao层（负责与数据库交互，但是sql在service层作为参数传入）\n\n配置文件\n\n * Struts-Spring集成web.xml（未详细了解）\n\n> Spring监听器加载spring上下文文件\n\n * Spring的配置文件applicationContext.xml\n\n> 注册实体类Spring beans的路径，创建action\n\n * struts.xml\n\n> 配置action路径，与spring配置对应\n\n\n\nEXT渲染流程\n\n参考链接\n\nExt.Panel为例（其他类似）：\n\n> 将一个Panel显示在浏览器中，其过程叫做render（渲染）。有这么几道工序：\n> 第一、触发”beforeRender”事件\n> 第二、得到这个Panel的父节点（针对DOM来说），即容器，也就是供Panel入住的那个容器\n> 第三、设置rendered=true\n> 第四、调用onRender方法，这步是最重要的，也就是如何将组件显示在浏览器上，涉及到很多流程，一会详解\n> 第五、设置这个panel的css\n> 第六、触发”render”事件，指的是当render完成后，触发的事件\n> 第七、调用aferRender，这步和第四步一样，是很重要的流程之一\n> 第八、看看要不要将这个panel隐藏或者失效，如果用户设置了hidden或者disable\n> 第九、设置这个panel的位置，也就是doLayout，布局\n\nEXT函数及选择器\n\n// 1. $.post()方法\n$.post("/xx/xx/xx.action", {\n    para: $.trim(code)\n}, function (jsondata) {\n    if(jsondata.success){\n\n    }else{\n\n    }\n}, "json")\n\n// 2. 自加载函数\nExt.onReady(function () {});\n\n// 3. EXT选择器 根据组件类型(xtype属性)获取组件\nExt.ComponentQuery.query();\n// 实例\nrender : function (self){\n    Ext.query(\'textarea[name="ALARM_DESC"]\')[0].outerHTML = "<div name = \'ALARM_DESC\' style = \'background:#E6E6E6; width: 100%; height: 120px; padding: 4px 6px 3px 6px\'>" + self.value + "</div>";\n    // document.getElementsByName("ALARM_DESC")[0].outerHTML = "<div name = \'ALARM_DESC\' style = \'background:#E6E6E6; width: 100%; height: 120px; padding: 4px 6px 3px 6px\'>" + self.value + "</div>";\n    Ext.get(Ext.query(\'div[name="ALARM_DESC"] a\')).applyStyles(\'color:#0000FF\');\n    // $(\'div[name="ALARM_DESC"] a\').css("color", "#0000FF")\n\n    // a标签禁用\n    // Ext.get(Ext.query(\'div[name="ALARM_DESC"] a\')).applyStyles(\'color: red; pointer-events: none;\');\n}\n\n// 4. 获取表格选中行\n[Grid].getSelectionModel().getSelection();  // 多行\n[getGrid].getCurrentRecord();               // 单行\n\n\n问题\n\n 1. spring和struts2整合时：spring接管了action对象的创建，所以一定要在spring配置文件中配置action，这里需要注意的是配置中的id时，要与struts.xml配置action中的class一致\n 2. EXT框架：后台返回时, "success"一定要返回true, 否则store不会刷新, 还是缓存的内容\n 3. 要根据数据库里的字段生成a标签：ext尝试无果后, 选择在render事件中用document.xxx.outerHTML直接修改dom元素, 暂时未发现bug',normalizedContent:'# 知识点\n\n\n# spring 配置文件\n\n# spring 配置文件优先级（从高到低）\n\n文件优先级\n\n 1. properties配置文件\n 2. yml配置文件\n 3. yaml配置文件\n\n文件位置优先级\n\n 1. 直接子目录/config\n 2. 项目根目录/config\n 3. 项目根目录\n 4. classpath根config/\n 5. classpath根目录下的\n\n# 启动参数指定配置文件\n\n# 精确读取外部配置文件\njava  -jar -dspring.profiles.active=test  xxx.jar\n\n# 改变主配置文件名\njava -jar foo.jar --spring.config.name=spring\n\n\n# 使用指定目录\njava  -dspring.profiles.active=test -jar comet-service/target/xxx.jar --spring.config.location=/tmp/\n# 使用 optional，当目录路径不存在时不报错\njava  -dspring.profiles.active=test -jar comet-service/target/xxx.jar --spring.config.location=optional:/tmp/\n\n\n# spring.config.additional-location # 不会覆盖主配置文件中的设置，而是作为补充\n\n\n# spring boot项目中读取application配置文件中配置\n\n * 使用@value方式\n\n@value("${spring.kafka.topic}")\nprivate string topic;\n\n\n * 使用environment方式\n\n@autowired  \nprivate environment env;  \n      \nenv.getproperty("spring.kafka.topic");\n\n\n * @configurationproperties(prefix = "") 注解\n\n1、在application.yml中添加配置\napplication:\n  serverconfig:\n    address: localhost\n    port: 22\n    username: geiri\n    password: 12345678\n    \n2.建配置类\npackage com.pn.ebs.config;\n \nimport org.springframework.boot.context.properties.configurationproperties;\nimport org.springframework.stereotype.component;\n \n@component\n@configurationproperties(prefix = "application")\npublic class applicationproperties {\n \n    private serverconfig serverconfig = new serverconfig();\n \n    public serverconfig getserverconfig() {\n        return serverconfig;\n    }\n    public final class serverconfig{\n        private string address;\n        private string port;\n        private string username;\n        private string password;\n        // geter/setter 此处略\n    }\n \n}\n\n\n\n# spring boot实体类时间格式化\n\n// 返回时间格式\n@jsonformat(pattern="yyyy-mm-dd hh:mm:ss",timezone="gmt+8")\n\n// 传入时间格式\n@datetimeformat(pattern ="yyyy-mm-dd")\n\n\n\n# 事务注解\n\n> spring boot中实现事务没有额外的jar包，还是基本的数据库访问包，比如mybatis\n\n注解事务@transactional\n\n@service\npublic class personservice {\n    @resource\n    private personmapper personmapper;\n\n    @resource\n    private companymapper companymapper;\n\n    @transactional(rollbackfor = {runtimeexception.class, error.class})\n    public void saveone(person person) {\n        company company = new company();\n        company.setname("tenmao:" + person.getname());\n        companymapper.insertone(company);\n        personmapper.insertone(person);\n    }\n}\n\n\n注解属性\n\n * rollbackfor：触发回滚的异常，默认是runtimeexception和error\n * isolation: 事务的隔离级别，默认是isolation.default也就是数据库自身的默认隔离级别，比如mysql是isolation_repeatable_read可重复读\n\n> 这样就可以了，不需要其他配置。\n> ps：网络上还说要在@springbootapplication上添加注解@enabletransactionmanagement，已经不需要了\n\n原文\n\n\n# 国内最好的maven repository\n\n方法1：全局配置:修改maven根目录下的conf文件夹中的setting.xml文件，内容如下：\n\n<mirrors>\n    <mirror>\n      <id>alimaven</id>\n      <name>aliyun maven</name>\n      <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n      <mirrorof>central</mirrorof>        \n    </mirror>\n  </mirrors>\n\n\n方法2：单项目配置: pom.xml文件里添加\n\n<repositories>  \n        <repository>  \n            <id>alimaven</id>  \n            <name>aliyun maven</name>  \n            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>  \n            <releases>  \n                <enabled>true</enabled>  \n            </releases>  \n            <snapshots>  \n                <enabled>false</enabled>  \n            </snapshots>  \n        </repository>  \n</repositories> \n===========================================\n<repositories>\n        <repository>\n            <id>central</id>\n            <name>aliyun maven</name>\n            <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n            <layout>default</layout>\n            \x3c!-- 是否开启发布版构件下载 --\x3e\n            <releases>\n                <enabled>true</enabled>\n            </releases>\n            \x3c!-- 是否开启快照版构件下载 --\x3e\n            <snapshots>\n                <enabled>false</enabled>\n            </snapshots>\n        </repository>\n    </repositories> \n\n\n\n# 有时间了解一下自动部署相关\n\n\n# 其他\n\n# 工作spring + strusts2 + extjs5\n\n分层\n\n * action层类似于controller\n * service相当于service层\n * bgddatasource类似于dao层（负责与数据库交互，但是sql在service层作为参数传入）\n\n配置文件\n\n * struts-spring集成web.xml（未详细了解）\n\n> spring监听器加载spring上下文文件\n\n * spring的配置文件applicationcontext.xml\n\n> 注册实体类spring beans的路径，创建action\n\n * struts.xml\n\n> 配置action路径，与spring配置对应\n\n\n\next渲染流程\n\n参考链接\n\next.panel为例（其他类似）：\n\n> 将一个panel显示在浏览器中，其过程叫做render（渲染）。有这么几道工序：\n> 第一、触发”beforerender”事件\n> 第二、得到这个panel的父节点（针对dom来说），即容器，也就是供panel入住的那个容器\n> 第三、设置rendered=true\n> 第四、调用onrender方法，这步是最重要的，也就是如何将组件显示在浏览器上，涉及到很多流程，一会详解\n> 第五、设置这个panel的css\n> 第六、触发”render”事件，指的是当render完成后，触发的事件\n> 第七、调用aferrender，这步和第四步一样，是很重要的流程之一\n> 第八、看看要不要将这个panel隐藏或者失效，如果用户设置了hidden或者disable\n> 第九、设置这个panel的位置，也就是dolayout，布局\n\next函数及选择器\n\n// 1. $.post()方法\n$.post("/xx/xx/xx.action", {\n    para: $.trim(code)\n}, function (jsondata) {\n    if(jsondata.success){\n\n    }else{\n\n    }\n}, "json")\n\n// 2. 自加载函数\next.onready(function () {});\n\n// 3. ext选择器 根据组件类型(xtype属性)获取组件\next.componentquery.query();\n// 实例\nrender : function (self){\n    ext.query(\'textarea[name="alarm_desc"]\')[0].outerhtml = "<div name = \'alarm_desc\' style = \'background:#e6e6e6; width: 100%; height: 120px; padding: 4px 6px 3px 6px\'>" + self.value + "</div>";\n    // document.getelementsbyname("alarm_desc")[0].outerhtml = "<div name = \'alarm_desc\' style = \'background:#e6e6e6; width: 100%; height: 120px; padding: 4px 6px 3px 6px\'>" + self.value + "</div>";\n    ext.get(ext.query(\'div[name="alarm_desc"] a\')).applystyles(\'color:#0000ff\');\n    // $(\'div[name="alarm_desc"] a\').css("color", "#0000ff")\n\n    // a标签禁用\n    // ext.get(ext.query(\'div[name="alarm_desc"] a\')).applystyles(\'color: red; pointer-events: none;\');\n}\n\n// 4. 获取表格选中行\n[grid].getselectionmodel().getselection();  // 多行\n[getgrid].getcurrentrecord();               // 单行\n\n\n问题\n\n 1. spring和struts2整合时：spring接管了action对象的创建，所以一定要在spring配置文件中配置action，这里需要注意的是配置中的id时，要与struts.xml配置action中的class一致\n 2. ext框架：后台返回时, "success"一定要返回true, 否则store不会刷新, 还是缓存的内容\n 3. 要根据数据库里的字段生成a标签：ext尝试无果后, 选择在render事件中用document.xxx.outerhtml直接修改dom元素, 暂时未发现bug',charsets:{cjk:!0},lastUpdated:"2024/09/10, 20:38:55",lastUpdatedTimestamp:1725971935e3},{title:"设计模式入门",frontmatter:{title:"设计模式入门",date:"2022-07-10T16:30:55.000Z",permalink:"/pages/bdceb5/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/006.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%85%A5%E9%97%A8.html",relativePath:"01.Java相关/04.设计模式/006.设计模式入门.md",key:"v-2c168266",path:"/pages/bdceb5/",headers:[{level:2,title:"类间关系",slug:"类间关系",normalizedTitle:"类间关系",charIndex:2},{level:4,title:"1、依赖（Dependence）",slug:"_1、依赖-dependence",normalizedTitle:"1、依赖（dependence）",charIndex:61},{level:4,title:"2、关联（Association）",slug:"_2、关联-association",normalizedTitle:"2、关联（association）",charIndex:187},{level:4,title:"3、聚合（Aggregation）",slug:"_3、聚合-aggregation",normalizedTitle:"3、聚合（aggregation）",charIndex:406},{level:4,title:"4、组合（Composition）",slug:"_4、组合-composition",normalizedTitle:"4、组合（composition）",charIndex:579},{level:4,title:"5、泛化（Generalization）",slug:"_5、泛化-generalization",normalizedTitle:"5、泛化（generalization）",charIndex:769},{level:4,title:"6、实现（Realization）",slug:"_6、实现-realization",normalizedTitle:"6、实现（realization）",charIndex:920},{level:2,title:"六(七)大设计原则",slug:"六-七-大设计原则",normalizedTitle:"六(七)大设计原则",charIndex:1036},{level:4,title:"一、单一职责原则",slug:"一、单一职责原则",normalizedTitle:"一、单一职责原则",charIndex:1091},{level:4,title:"二、接口隔离原则",slug:"二、接口隔离原则",normalizedTitle:"二、接口隔离原则",charIndex:1241},{level:4,title:"三、依赖倒转原则",slug:"三、依赖倒转原则",normalizedTitle:"三、依赖倒转原则",charIndex:1414},{level:4,title:"四、里式替换原则",slug:"四、里式替换原则",normalizedTitle:"四、里式替换原则",charIndex:2419},{level:4,title:"五、开闭原则ocp",slug:"五、开闭原则ocp",normalizedTitle:"五、开闭原则ocp",charIndex:2777},{level:4,title:"六、迪米特法则(最少知道原则)",slug:"六、迪米特法则-最少知道原则",normalizedTitle:"六、迪米特法则(最少知道原则)",charIndex:3088},{level:4,title:"七？合成复用原则",slug:"七-合成复用原则",normalizedTitle:"七？合成复用原则",charIndex:3582},{level:2,title:"设计模式入门",slug:"设计模式入门",normalizedTitle:"设计模式入门",charIndex:3626},{level:4,title:"设计原则",slug:"设计原则",normalizedTitle:"设计原则",charIndex:1041},{level:4,title:"元认知",slug:"元认知",normalizedTitle:"元认知",charIndex:3917},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:3926},{level:2,title:"mermaid 语法",slug:"mermaid-语法",normalizedTitle:"mermaid 语法",charIndex:4210},{level:4,title:"Github官网",slug:"github官网",normalizedTitle:"github官网",charIndex:4266}],headersStr:"类间关系 1、依赖（Dependence） 2、关联（Association） 3、聚合（Aggregation） 4、组合（Composition） 5、泛化（Generalization） 6、实现（Realization） 六(七)大设计原则 一、单一职责原则 二、接口隔离原则 三、依赖倒转原则 四、里式替换原则 五、开闭原则ocp 六、迪米特法则(最少知道原则) 七？合成复用原则 设计模式入门 设计原则 元认知 要点 mermaid 语法 Github官网",content:"# 类间关系\n\n----------------------------------------\n\n耦合度从弱到强\n\n# 1、依赖（Dependence）\n\n含义：体现了类之间的弱作用关系，是一种临时性的使用关系，通常用虚线+箭头表示。\n\n举例：依赖关系是类之间最弱的关系，比如，类A的一些方法参数中使用了类B的实例；类A的一些方法逻辑中调用了类B的方法或变量等等。\n\n# 2、关联（Association）\n\n含义：体现了类之间的强作用关系，通常用实线或实线+箭头表示，这里的关联关系指的是一般关联关系，后面的聚合和组合也属于关联关系。\n\n举例：关联关系是类之间的引用关系，生活中的常见，比如有：手机和充电线，老师和学生，生产者和消费者等。可以通过成员变量来实现关联关系，比如类A中使用了类B的对象引用，A和B之间就是一种关联关系。\n\n类型：一般关联关系又可以分为单向关联、双向关联、自关联，画图表示。\n\n# 3、聚合（Aggregation）\n\n含义：体现了类之间的强作用关系，也属于关联关系的一种，是整体和局部之间的关系，是 has-a 的关系，通常用实线+虚心菱形箭头表示。\n\n举例：聚合关系强调了整体和局部的关系，比如学校和教师，工厂和工人等，注意的是局部可以独立于整体而存在，比如工厂没了但工人还是可以存在的！通过成员属性来实现聚合关系。\n\n# 4、组合（Composition）\n\n含义：体现了类之间的强作用关系，也属于关联关系的一种，也是整体和局部之间的关系，是 cxmtains-a 的关系，通常用实线+实心菱形箭头表示。\n\n举例：组合关系是一种耦合度更高的聚合关系，整体对象可以控制部分对象的生命周期，部分对象不能脱离整体对象而存在，比如电脑和CPU，如果CPU没了，电脑就失去了基本的运算能力等同于电脑报废。\n\n# 5、泛化（Generalization）\n\n含义：体现了类之间的继承关系，是一种耦合度最高的关系，是 is-a 的关系，通常用实线+空心三角箭头表示。\n\n举例：泛化关系强调了一般与特殊的关系，通过Java的类继承机制实现类之间的泛化关系，比如：手机工厂，与华为手机工厂，小米手机工厂之间的关系。\n\n# 6、实现（Realization）\n\n含义：体现了接口和类之间的关系，通常用虚线+空心三角箭头表示。\n\n举例：实现关系，通过Java的实现机制实现的，比如：手机工厂接口，与华为手机工厂实现类，小米手机工厂实现类之间的关系。\n\n\n# 六(七)大设计原则\n\n----------------------------------------\n\n# 一、单一职责原则\n\n注意事项和细节\n\n 1. 降低类的复杂度，一个类只负责一个职责\n 2. 提高类的可读性，可维护性\n 3. 降低变更引起的风险\n 4. 通常情况下，我们应当遵守单一职责原则 ，只有逻辑足够简单，才能在代码级违反单一职责原则；只有类中方法足够少，可以在方法级别保持单一职责原则\n\n# 二、接口隔离原则\n\n客户端不应该依赖它不需要的接口， 即一个类对另一个类的依赖应该建立在最小的接口上\n\n问题： 类 A 通过接口依赖类 B， 类 C 通过接口依赖类 D， 如果接口对于类 A 和类 C 来说不是最小接口， 那么类 B 和类 D 必须去实现他们不需要的方法\n\n解决： 将接口拆分为独立的几个接口(这里我们拆分成 3 个接口)\n\n# 三、依赖倒转原则\n\n依赖倒转原则(Dependence Inversion Principle)是指:\n\n 1. 高层模块不应该依赖低层模块， 二者都应该依赖其抽象\n 2. 抽象不应该依赖细节， 细节应该依赖抽象\n 3. 依赖倒转(倒置)的中心思想是面向接口编程\n 4. 依赖倒转原则是基于这样的设计理念： 相对于细节的多变性， 抽象的东西要稳定的多。 以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。 在 java 中， 抽象指的是接口或抽象类， 细节就是具体的实现类\n 5. 使用接口或抽象类的目的是制定好规范， 而不涉及任何具体的操作， 把展现细节的任务交给他的实现类去完成\n\n问题(不知道图画的对不对)：如果获取的对象是微信，就要新增类，Persion也要新增相应接收方法\n\n解决思路: 引入一个抽象的接口 IReceiver\n\n依赖关系传递的三种方式\n\n 1. 接口传递\n\nChangHong changHong = new ChangHong();  //实现ITV接口\nOpenAndClose openAndClose = new OpenAndClose();  //实现IOpenAndClose接口\nopenAndClose.open(changHong);  //IOpenAndClose方法参数为ITV\n\n\n 2. 构造方法传递\n\nOpenAndClose openAndClose = new OpenAndClose(changHong);  //实现IOpenAndClose接口 且 构造参数为ITV\nopenAndClose.open();  //调用ITV的play方法\n\n\n 3. setter 方式传递\n\nOpenAndClose openAndClose = new OpenAndClose();  //实现IOpenAndClose接口\nopenAndClose.setTv(changHong);  //set方法参数为ITV\nopenAndClose.open();  //调用ITV的play方法\n\n\n注意事项:\n\n 1. 低层模块尽量都要有抽象类或接口， 或者两者都有， 程序稳定性更好.\n 2. 变量的声明类型尽量是抽象类或接口, 这样我们的变量引用和实际对象间， 就存在一个缓冲层， 利于程序扩展和优化\n 3. 继承时遵循里氏替换原则\n\n# 四、里式替换原则\n\nOO 中的继承性的思考和说明:\n\n 1. 继承包含这样一层含义： 父类中凡是已经实现好的方法， 实际上是在设定规范和契约子类如果对这些方法任意修改, 就会对继承体系造成破坏\n 2. 继承在给程序设计带来便利的同时， 也带来了弊端。会给程序带来侵入性， 程序的可移植性降低，增加对象间的耦合性(修改父类, 子类可能出现故障)\n 3. 问题提出： 在编程中， 如何正确的使用继承? => 里氏替换原则\n\n基本介绍:\n\n 1. 1988 年， 由麻省理工学院的以为姓里的女士提出\n 2. 理想状态: 所有引用基类的地方必须能透明地使用其子类的对象\n 3. 使用继承时: 子类中尽量不要重写父类的方法\n 4. 继承实际上让两个类耦合性增强了，适当的情况下: 可以通过聚合， 组合， 依赖来解决问题\n\n# 五、开闭原则ocp\n\n基本介绍:\n\n 1. 开闭原则（Open Closed Principle） 是编程中最基础、 最重要的设计原则\n 2. 一个软件实体如类， 模块和函数应该对扩展开放(对提供方)， 对修改关闭(对使用方)。 用抽象构建框架， 用实现扩展细节\n 3. 当软件需要变化时， 尽量通过扩展软件实体的行为来实现变化， 而不是通过修改已有的代码来实现变化。\n 4. 编程中遵循其它原则， 以及使用设计模式的目的就是遵循开闭原则\n\n优缺点：好理解易操作；违反了开闭原则；新增加一个三角形类，要修改很多地方（如：新加Trlangle类 GraphicEditor类增加方法 drawShape方法增加分支）\n\n# 六、迪米特法则(最少知道原则)\n\n基本原则:\n\n 1. 一个对象应该对其他对象保持最少的了解\n 2. 类与类关系越密切， 耦合度越大\n 3. 迪米特法则(Demeter Principle)又叫最少知道原则， 即一个类对自己依赖的类知道的越少越好。 也就是说， 对于被依赖的类不管多么复杂， 都尽量将逻辑封装在类的内部。 对外除了提供的 public 方法， 不对外泄露任何信息\n 4. 迪米特法则还有个更简单的定义： 只与直接的朋友通信\n 5. 直接的朋友： 每个对象都会与其他对象有耦合关系， 只要两个对象之间有耦合关系， 我们就说这两个对象之间是朋友关系。 耦合的方式很多， 依赖， 关联， 组合， 聚合等。 其中， 我们称出现成员变量， 方法参数， 方法返回值中的类为直接的朋友， 而出现在局部变量中的类不是直接的朋友。 也就是说， 陌生的类最好不要以局部变量的形式出现在类的内部\n\n注意事项\n\n 1. 迪米特法则的核心是降低类之间的耦合\n 2. 但是注意： 由于每个类都减少了不必要的依赖， 因此迪米特法则只是要求降低类间(对象间)耦合关系， 并不是要求完全没有依赖关系\n\n# 七？合成复用原则\n\n基本介绍：原则是尽量使用合成/聚合的方式， 而不是使用继承\n\n\n# 设计模式入门\n\n----------------------------------------\n\n# 设计原则\n\n 1. 找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。\n 2. 针对接口编程，而不是针对实现编程。\n 3. 多用组合，少用继承\n 4. 为了交互对象之间的松耦合设计而努力\n 5. 类应该对扩展开放，对修改关闭。（开闭原则）\n 6. 要依赖抽象，不要依赖具体类。（依赖倒置原则）\n 7. 最少知识原则：只和你的密友谈话。\n 8. 别调用我们，我们会调用你（好莱坞原则）\n 9. 一个类应该只有一个引起变化的原因（单一职责原则）\n\n# 元认知\n\n\n\n# 要点\n\n * 知道OO基础，并不足以让你设计出良好的OO系统。\n * 良好的OO设计必须具备可复用、可扩充、可维护三个特性。\n * 模式可以让我们建造出具有良好OO设计质量的系统。\n * 模式被认为是历经验证的OO设计经验。\n * 模式不是代码，而是针对设计问题的通用解决方案。你可把它们应用到特定的应用中。\n * 模式不是被发明，而是被发现。\n * 大多数的模式和原则，都着眼于软件变化的主题。\n * 大多数的模式都允许系统局部改变独立于其他部分。\n * 我们常把系统中会变化的部分抽出来封装。\n * 模式让开发人员之间有共享的语言，能够最大化沟通的价值。\n\n\n# mermaid 语法\n\n----------------------------------------\n\n# Github官网\n\nMermaid 是一个基于 JavaScript 的图表和图表工具，通过解析 Markdown 的文本定义，以动态创建和修改图表。\n\n可使之创建流程图、时序图、UML类图、状态图、实体关系图、用户体验旅程图、甘特图、饼图、需求图、Git分支图、软件架构（C4）图等\n\n官网语法",normalizedContent:"# 类间关系\n\n----------------------------------------\n\n耦合度从弱到强\n\n# 1、依赖（dependence）\n\n含义：体现了类之间的弱作用关系，是一种临时性的使用关系，通常用虚线+箭头表示。\n\n举例：依赖关系是类之间最弱的关系，比如，类a的一些方法参数中使用了类b的实例；类a的一些方法逻辑中调用了类b的方法或变量等等。\n\n# 2、关联（association）\n\n含义：体现了类之间的强作用关系，通常用实线或实线+箭头表示，这里的关联关系指的是一般关联关系，后面的聚合和组合也属于关联关系。\n\n举例：关联关系是类之间的引用关系，生活中的常见，比如有：手机和充电线，老师和学生，生产者和消费者等。可以通过成员变量来实现关联关系，比如类a中使用了类b的对象引用，a和b之间就是一种关联关系。\n\n类型：一般关联关系又可以分为单向关联、双向关联、自关联，画图表示。\n\n# 3、聚合（aggregation）\n\n含义：体现了类之间的强作用关系，也属于关联关系的一种，是整体和局部之间的关系，是 has-a 的关系，通常用实线+虚心菱形箭头表示。\n\n举例：聚合关系强调了整体和局部的关系，比如学校和教师，工厂和工人等，注意的是局部可以独立于整体而存在，比如工厂没了但工人还是可以存在的！通过成员属性来实现聚合关系。\n\n# 4、组合（composition）\n\n含义：体现了类之间的强作用关系，也属于关联关系的一种，也是整体和局部之间的关系，是 cxmtains-a 的关系，通常用实线+实心菱形箭头表示。\n\n举例：组合关系是一种耦合度更高的聚合关系，整体对象可以控制部分对象的生命周期，部分对象不能脱离整体对象而存在，比如电脑和cpu，如果cpu没了，电脑就失去了基本的运算能力等同于电脑报废。\n\n# 5、泛化（generalization）\n\n含义：体现了类之间的继承关系，是一种耦合度最高的关系，是 is-a 的关系，通常用实线+空心三角箭头表示。\n\n举例：泛化关系强调了一般与特殊的关系，通过java的类继承机制实现类之间的泛化关系，比如：手机工厂，与华为手机工厂，小米手机工厂之间的关系。\n\n# 6、实现（realization）\n\n含义：体现了接口和类之间的关系，通常用虚线+空心三角箭头表示。\n\n举例：实现关系，通过java的实现机制实现的，比如：手机工厂接口，与华为手机工厂实现类，小米手机工厂实现类之间的关系。\n\n\n# 六(七)大设计原则\n\n----------------------------------------\n\n# 一、单一职责原则\n\n注意事项和细节\n\n 1. 降低类的复杂度，一个类只负责一个职责\n 2. 提高类的可读性，可维护性\n 3. 降低变更引起的风险\n 4. 通常情况下，我们应当遵守单一职责原则 ，只有逻辑足够简单，才能在代码级违反单一职责原则；只有类中方法足够少，可以在方法级别保持单一职责原则\n\n# 二、接口隔离原则\n\n客户端不应该依赖它不需要的接口， 即一个类对另一个类的依赖应该建立在最小的接口上\n\n问题： 类 a 通过接口依赖类 b， 类 c 通过接口依赖类 d， 如果接口对于类 a 和类 c 来说不是最小接口， 那么类 b 和类 d 必须去实现他们不需要的方法\n\n解决： 将接口拆分为独立的几个接口(这里我们拆分成 3 个接口)\n\n# 三、依赖倒转原则\n\n依赖倒转原则(dependence inversion principle)是指:\n\n 1. 高层模块不应该依赖低层模块， 二者都应该依赖其抽象\n 2. 抽象不应该依赖细节， 细节应该依赖抽象\n 3. 依赖倒转(倒置)的中心思想是面向接口编程\n 4. 依赖倒转原则是基于这样的设计理念： 相对于细节的多变性， 抽象的东西要稳定的多。 以抽象为基础搭建的架构比以细节为基础的架构要稳定的多。 在 java 中， 抽象指的是接口或抽象类， 细节就是具体的实现类\n 5. 使用接口或抽象类的目的是制定好规范， 而不涉及任何具体的操作， 把展现细节的任务交给他的实现类去完成\n\n问题(不知道图画的对不对)：如果获取的对象是微信，就要新增类，persion也要新增相应接收方法\n\n解决思路: 引入一个抽象的接口 ireceiver\n\n依赖关系传递的三种方式\n\n 1. 接口传递\n\nchanghong changhong = new changhong();  //实现itv接口\nopenandclose openandclose = new openandclose();  //实现iopenandclose接口\nopenandclose.open(changhong);  //iopenandclose方法参数为itv\n\n\n 2. 构造方法传递\n\nopenandclose openandclose = new openandclose(changhong);  //实现iopenandclose接口 且 构造参数为itv\nopenandclose.open();  //调用itv的play方法\n\n\n 3. setter 方式传递\n\nopenandclose openandclose = new openandclose();  //实现iopenandclose接口\nopenandclose.settv(changhong);  //set方法参数为itv\nopenandclose.open();  //调用itv的play方法\n\n\n注意事项:\n\n 1. 低层模块尽量都要有抽象类或接口， 或者两者都有， 程序稳定性更好.\n 2. 变量的声明类型尽量是抽象类或接口, 这样我们的变量引用和实际对象间， 就存在一个缓冲层， 利于程序扩展和优化\n 3. 继承时遵循里氏替换原则\n\n# 四、里式替换原则\n\noo 中的继承性的思考和说明:\n\n 1. 继承包含这样一层含义： 父类中凡是已经实现好的方法， 实际上是在设定规范和契约子类如果对这些方法任意修改, 就会对继承体系造成破坏\n 2. 继承在给程序设计带来便利的同时， 也带来了弊端。会给程序带来侵入性， 程序的可移植性降低，增加对象间的耦合性(修改父类, 子类可能出现故障)\n 3. 问题提出： 在编程中， 如何正确的使用继承? => 里氏替换原则\n\n基本介绍:\n\n 1. 1988 年， 由麻省理工学院的以为姓里的女士提出\n 2. 理想状态: 所有引用基类的地方必须能透明地使用其子类的对象\n 3. 使用继承时: 子类中尽量不要重写父类的方法\n 4. 继承实际上让两个类耦合性增强了，适当的情况下: 可以通过聚合， 组合， 依赖来解决问题\n\n# 五、开闭原则ocp\n\n基本介绍:\n\n 1. 开闭原则（open closed principle） 是编程中最基础、 最重要的设计原则\n 2. 一个软件实体如类， 模块和函数应该对扩展开放(对提供方)， 对修改关闭(对使用方)。 用抽象构建框架， 用实现扩展细节\n 3. 当软件需要变化时， 尽量通过扩展软件实体的行为来实现变化， 而不是通过修改已有的代码来实现变化。\n 4. 编程中遵循其它原则， 以及使用设计模式的目的就是遵循开闭原则\n\n优缺点：好理解易操作；违反了开闭原则；新增加一个三角形类，要修改很多地方（如：新加trlangle类 graphiceditor类增加方法 drawshape方法增加分支）\n\n# 六、迪米特法则(最少知道原则)\n\n基本原则:\n\n 1. 一个对象应该对其他对象保持最少的了解\n 2. 类与类关系越密切， 耦合度越大\n 3. 迪米特法则(demeter principle)又叫最少知道原则， 即一个类对自己依赖的类知道的越少越好。 也就是说， 对于被依赖的类不管多么复杂， 都尽量将逻辑封装在类的内部。 对外除了提供的 public 方法， 不对外泄露任何信息\n 4. 迪米特法则还有个更简单的定义： 只与直接的朋友通信\n 5. 直接的朋友： 每个对象都会与其他对象有耦合关系， 只要两个对象之间有耦合关系， 我们就说这两个对象之间是朋友关系。 耦合的方式很多， 依赖， 关联， 组合， 聚合等。 其中， 我们称出现成员变量， 方法参数， 方法返回值中的类为直接的朋友， 而出现在局部变量中的类不是直接的朋友。 也就是说， 陌生的类最好不要以局部变量的形式出现在类的内部\n\n注意事项\n\n 1. 迪米特法则的核心是降低类之间的耦合\n 2. 但是注意： 由于每个类都减少了不必要的依赖， 因此迪米特法则只是要求降低类间(对象间)耦合关系， 并不是要求完全没有依赖关系\n\n# 七？合成复用原则\n\n基本介绍：原则是尽量使用合成/聚合的方式， 而不是使用继承\n\n\n# 设计模式入门\n\n----------------------------------------\n\n# 设计原则\n\n 1. 找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。\n 2. 针对接口编程，而不是针对实现编程。\n 3. 多用组合，少用继承\n 4. 为了交互对象之间的松耦合设计而努力\n 5. 类应该对扩展开放，对修改关闭。（开闭原则）\n 6. 要依赖抽象，不要依赖具体类。（依赖倒置原则）\n 7. 最少知识原则：只和你的密友谈话。\n 8. 别调用我们，我们会调用你（好莱坞原则）\n 9. 一个类应该只有一个引起变化的原因（单一职责原则）\n\n# 元认知\n\n\n\n# 要点\n\n * 知道oo基础，并不足以让你设计出良好的oo系统。\n * 良好的oo设计必须具备可复用、可扩充、可维护三个特性。\n * 模式可以让我们建造出具有良好oo设计质量的系统。\n * 模式被认为是历经验证的oo设计经验。\n * 模式不是代码，而是针对设计问题的通用解决方案。你可把它们应用到特定的应用中。\n * 模式不是被发明，而是被发现。\n * 大多数的模式和原则，都着眼于软件变化的主题。\n * 大多数的模式都允许系统局部改变独立于其他部分。\n * 我们常把系统中会变化的部分抽出来封装。\n * 模式让开发人员之间有共享的语言，能够最大化沟通的价值。\n\n\n# mermaid 语法\n\n----------------------------------------\n\n# github官网\n\nmermaid 是一个基于 javascript 的图表和图表工具，通过解析 markdown 的文本定义，以动态创建和修改图表。\n\n可使之创建流程图、时序图、uml类图、状态图、实体关系图、用户体验旅程图、甘特图、饼图、需求图、git分支图、软件架构（c4）图等\n\n官网语法",charsets:{cjk:!0},lastUpdated:"2022/08/11, 00:48:36",lastUpdatedTimestamp:1660150116e3},{title:"策略模式",frontmatter:{title:"策略模式",date:"2022-07-15T08:46:45.000Z",permalink:"/pages/676d02/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/011.%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/011.策略模式.md",key:"v-c32a4ba6",path:"/pages/676d02/",headers:[{level:2,title:"策略模式（Strategy Pattern）",slug:"策略模式-strategy-pattern",normalizedTitle:"策略模式（strategy pattern）",charIndex:2},{level:4,title:"鸭子飞和叫",slug:"鸭子飞和叫",normalizedTitle:"鸭子飞和叫",charIndex:80},{level:4,title:"小游戏：动作冒险游戏",slug:"小游戏-动作冒险游戏",normalizedTitle:"小游戏：动作冒险游戏",charIndex:491}],headersStr:"策略模式（Strategy Pattern） 鸭子飞和叫 小游戏：动作冒险游戏",content:"# 策略模式（Strategy Pattern）\n\n策略模式定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。\n\n# 鸭子飞和叫\n\n为了给鸭子增加飞行能力\n\n> 问题：在超类增加方法导致橡皮鸭也会飞了 解决方案：在子类中覆盖掉父类方法，又会导致其他问题（一旦创建新的鸭子类，就必须检查飞行和叫的方法）\n\n> 使用接口呢，会导致\n> \n>  1. 代码不能复用\n>  2. 飞行动作有区别，就要每个类的方法都有不同的实现\n\n> 针对接口编程 真正含义为针对超类编程。即Animal animal = new Dog()的形式 优点：\n> \n>  1. 飞行和叫的动作可以被其他对象复用\n>  2. 可以新增行为，不会影响到行为类，也不会影响到鸭子类\n> \n> 缺点：构造器实例化对象，是对具体实现编程，有待改进\n\n改进： 创建 FlyBehavior、QuackBehavior 的 get、set 方法，使运行时可以动态的设定其行为，即在创建鸭子对象时传入行为对象来设置其行为。（有点类似于函数编程通过参数传入一段逻辑的感觉？？？）\n\n# 小游戏：动作冒险游戏\n\n有游戏角色和使用武器行为的类，每个角色一次只能使用一种武器，但是可以在游戏过程中换武器。",normalizedContent:"# 策略模式（strategy pattern）\n\n策略模式定义了算法族，分别封装起来，让它们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。\n\n# 鸭子飞和叫\n\n为了给鸭子增加飞行能力\n\n> 问题：在超类增加方法导致橡皮鸭也会飞了 解决方案：在子类中覆盖掉父类方法，又会导致其他问题（一旦创建新的鸭子类，就必须检查飞行和叫的方法）\n\n> 使用接口呢，会导致\n> \n>  1. 代码不能复用\n>  2. 飞行动作有区别，就要每个类的方法都有不同的实现\n\n> 针对接口编程 真正含义为针对超类编程。即animal animal = new dog()的形式 优点：\n> \n>  1. 飞行和叫的动作可以被其他对象复用\n>  2. 可以新增行为，不会影响到行为类，也不会影响到鸭子类\n> \n> 缺点：构造器实例化对象，是对具体实现编程，有待改进\n\n改进： 创建 flybehavior、quackbehavior 的 get、set 方法，使运行时可以动态的设定其行为，即在创建鸭子对象时传入行为对象来设置其行为。（有点类似于函数编程通过参数传入一段逻辑的感觉？？？）\n\n# 小游戏：动作冒险游戏\n\n有游戏角色和使用武器行为的类，每个角色一次只能使用一种武器，但是可以在游戏过程中换武器。",charsets:{cjk:!0},lastUpdated:"2022/07/15, 18:03:14",lastUpdatedTimestamp:1657879394e3},{title:"Java基础",frontmatter:{title:"Java基础",date:"2022-03-02T11:35:41.000Z",permalink:"/pages/768c32/",categories:["Java相关","基础"],tags:[null]},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/01.%E5%9F%BA%E7%A1%80/01.Java%E5%9F%BA%E7%A1%80.html",relativePath:"01.Java相关/01.基础/01.Java基础.md",key:"v-1d12c416",path:"/pages/768c32/",headers:[{level:2,title:"基础语法",slug:"基础语法",normalizedTitle:"基础语法",charIndex:2},{level:4,title:"8种基本数据类型",slug:"_8种基本数据类型",normalizedTitle:"8种基本数据类型",charIndex:10},{level:4,title:"流程控制",slug:"流程控制",normalizedTitle:"流程控制",charIndex:3020},{level:4,title:"函数（方法）",slug:"函数-方法",normalizedTitle:"函数（方法）",charIndex:8317},{level:4,title:"类和对象",slug:"类和对象",normalizedTitle:"类和对象",charIndex:10417},{level:4,title:"类的继承与抽象类的实现",slug:"类的继承与抽象类的实现",normalizedTitle:"类的继承与抽象类的实现",charIndex:12295},{level:4,title:"接口实现及深浅拷贝",slug:"接口实现及深浅拷贝",normalizedTitle:"接口实现及深浅拷贝",charIndex:16358},{level:4,title:"类间关系",slug:"类间关系",normalizedTitle:"类间关系",charIndex:19786},{level:4,title:"简单设计模式",slug:"简单设计模式",normalizedTitle:"简单设计模式",charIndex:24794},{level:4,title:"常见异常类与捕获异常",slug:"常见异常类与捕获异常",normalizedTitle:"常见异常类与捕获异常",charIndex:27676},{level:4,title:"线程",slug:"线程",normalizedTitle:"线程",charIndex:30336},{level:5,title:"多线程",slug:"多线程",normalizedTitle:"多线程",charIndex:30342},{level:5,title:"多线程锁",slug:"多线程锁",normalizedTitle:"多线程锁",charIndex:35318},{level:4,title:"常用工具类",slug:"常用工具类",normalizedTitle:"常用工具类",charIndex:40018},{level:4,title:"Java Stream",slug:"java-stream",normalizedTitle:"java stream",charIndex:57642},{level:4,title:"文件操作",slug:"文件操作",normalizedTitle:"文件操作",charIndex:60627},{level:4,title:"javax.swing（略，已经很少使用）",slug:"javax-swing-略-已经很少使用",normalizedTitle:"javax.swing（略，已经很少使用）",charIndex:80798},{level:4,title:"网络编程（略，java.net包）",slug:"网络编程-略-java-net包",normalizedTitle:"网络编程（略，java.net包）",charIndex:80823},{level:2,title:"注解",slug:"注解",normalizedTitle:"注解",charIndex:80845},{level:4,title:"定义",slug:"定义",normalizedTitle:"定义",charIndex:7229},{level:4,title:"JDK基本注解",slug:"jdk基本注解",normalizedTitle:"jdk基本注解",charIndex:80948},{level:4,title:"JDK元注解",slug:"jdk元注解",normalizedTitle:"jdk元注解",charIndex:81048},{level:4,title:"自定义注解",slug:"自定义注解",normalizedTitle:"自定义注解",charIndex:81905},{level:4,title:"通过反射获取注解信息",slug:"通过反射获取注解信息",normalizedTitle:"通过反射获取注解信息",charIndex:82268}],headersStr:"基础语法 8种基本数据类型 流程控制 函数（方法） 类和对象 类的继承与抽象类的实现 接口实现及深浅拷贝 类间关系 简单设计模式 常见异常类与捕获异常 线程 多线程 多线程锁 常用工具类 Java Stream 文件操作 javax.swing（略，已经很少使用） 网络编程（略，java.net包） 注解 定义 JDK基本注解 JDK元注解 自定义注解 通过反射获取注解信息",content:'# 基础语法\n\n# 8种基本数据类型\n\npublic class Data {\n\tpublic static void main(String[] args) {\n\t    // byte  \n        System.out.println("基本类型：byte 二进制位数：" + Byte.SIZE);  \n        System.out.println("包装类：java.lang.Byte");  \n        System.out.println("最小值：Byte.MIN_VALUE=" + Byte.MIN_VALUE);  \n        System.out.println("最大值：Byte.MAX_VALUE=" + Byte.MAX_VALUE);  \n        System.out.println();  \n  \n        // short  \n        System.out.println("基本类型：short 二进制位数：" + Short.SIZE);  \n        System.out.println("包装类：java.lang.Short");  \n        System.out.println("最小值：Short.MIN_VALUE=" + Short.MIN_VALUE);  \n        System.out.println("最大值：Short.MAX_VALUE=" + Short.MAX_VALUE);  \n        System.out.println();  \n  \n        // int  \n        System.out.println("基本类型：int 二进制位数：" + Integer.SIZE);  \n        System.out.println("包装类：java.lang.Integer");  \n        System.out.println("最小值：Integer.MIN_VALUE=" + Integer.MIN_VALUE);  \n        System.out.println("最大值：Integer.MAX_VALUE=" + Integer.MAX_VALUE);  \n        System.out.println();  \n  \n        // long  \n        System.out.println("基本类型：long 二进制位数：" + Long.SIZE);  \n        System.out.println("包装类：java.lang.Long");  \n        System.out.println("最小值：Long.MIN_VALUE=" + Long.MIN_VALUE);  \n        System.out.println("最大值：Long.MAX_VALUE=" + Long.MAX_VALUE);  \n        System.out.println();  \n  \n        // float  \n        System.out.println("基本类型：float 二进制位数：" + Float.SIZE);  \n        System.out.println("包装类：java.lang.Float");  \n        System.out.println("最小值：Float.MIN_VALUE=" + Float.MIN_VALUE);  \n        System.out.println("最大值：Float.MAX_VALUE=" + Float.MAX_VALUE);  \n        System.out.println();  \n  \n        // double  \n        System.out.println("基本类型：double 二进制位数：" + Double.SIZE);  \n        System.out.println("包装类：java.lang.Double");  \n        System.out.println("最小值：Double.MIN_VALUE=" + Double.MIN_VALUE);  \n        System.out.println("最大值：Double.MAX_VALUE=" + Double.MAX_VALUE);  \n        System.out.println();  \n  \n        // char  \n        System.out.println("基本类型：char 二进制位数：" + Character.SIZE);  \n        System.out.println("包装类：java.lang.Character");  \n        // 以数值形式而不是字符形式将Character.MIN_VALUE输出到控制台  \n        System.out.println("最小值：Character.MIN_VALUE="  + (int) Character.MIN_VALUE);  \n        // 以数值形式而不是字符形式将Character.MAX_VALUE输出到控制台  \n        System.out.println("最大值：Character.MAX_VALUE="  + (int) Character.MAX_VALUE); \n        \n        // 布尔\n        boolean bool1=false;\n        byte b =15;\n        short s = (short)3556;\n        int i = 150;\n        long l = 31356L;\n        float f = 12.345f;\n        double d = 20.1236467892;\n        char c = \'B\';\n        System.out.println("\\n" + "bool1=" + bool1 +" b="+b + " s="+s +" i="+i +" l="+l +" f="+f +" d="+d + " c=" +c +"\\n");\n        \n        System.out.println("i++=" + (i++) +"\\n");\n        i=150;\n        System.out.println("++i=" + (++i) +"\\n");\n        \n        i=150;\n        System.out.println("i--=" + (i--) +"\\n");\n        i=150;\n        System.out.println("--i=" + (--i) +"\\n");\n    }\n}\n\n\n# 流程控制\n\n\npublic static void main(String[] args) {\n    here: while (true) {\n        System.out.println("请输入成绩：（0-100）");\n        Scanner scan = new Scanner(System.in);\n        int score = scan.nextInt();\n        if (score > 100) {\n            System.out.println("输入错误！");\n        } else {\n            switch (score / 10) {\n            case 10:\n            case 9:\n                System.out.println("优秀");\n                break;\n            case 8:\n                System.out.println("良好");\n                break;\n            case 7:\n                System.out.println("中等");\n                break;\n            case 6:\n                System.out.println("及格");\n                break;\n            case 5:\n            case 4:\n            case 3:\n            case 2:\n            case 1:\n            case 0:\n                System.out.println("不及格");\n                break;\n            default:\n                System.out.println("输入错误！请输入0-100的数。");\n                break here;\n            }\n        }\n    }\n}\n\n\npublic static void main(String[] args) {\n    while (true) {\n        System.out.println("请输入年份：");\n        Scanner scan = new Scanner(System.in);\n        int year = scan.nextInt();\n        if (year % 400 == 0 || year % 4 == 0 && year % 100 != 0) {\n            System.out.println(year + "是闰年");\n            System.exit(0);\n        } else {\n            System.out.println(year + "不是闰年");\n        }\n    }\n}\n\n\npublic static void main(String[] args) {\n    System.out.println("请输入一个数：");\n    Scanner scan = new Scanner(System.in);\n    int num = scan.nextInt();\n    boolean flag = true;\n    for(int i=2;i<num;i++)\n    {\n        if(num%i == 0){\n            flag = false;\n        }\n        else{\n        }\n    }\n    if(flag==true){\n        System.out.println(num + "是质数");\n    }\n    else{\n        System.out.println(num + "不是质数");\n    }\n}\n// ------------------------------------------\npublic static void main(String[] args) {\n    for (int i = 2; i <= 1000; i++) {\n        boolean flag = true;\n        int n = i;\n        for (int j = 2; j < Math.sqrt(i) + 1; j++) {\n            if (n % j == 0) {\n                flag = false;\n            }\n        }\n        if (flag == true) {\n            System.out.println(n + "是质数");\n        } else {\n            System.out.println(n + "不是质数");\n        }\n    }\n}\n\n\npublic static void main(String[] args) {\n    // TODO Auto-generated method stub\n    int a[]=new int[] {\n            45, 52, 23, 63, 25,\n            13, 22, 42, 32, 20,\n            46, 55, 35, 32, 66\n    };\n    \n    System.out.println("输出原数组：");\n    for (int i:a) {\n        System.out.print(i + " ");\n    }\n    \n    System.out.println();\n    int sum = 0;\n    int average = 0;\n    int max = a[0];\n    for (int i = 0; i < a.length; i++) {        \n        sum += a[i];\n        if(max<a[i]){\n            max = a[i];\n        }\n    }\n    System.out.println("max = " + max);\n    average = sum / a.length;\n    System.out.println("average = " + average);\n    \n    int len = a.length;\n    boolean flag = true;\n    while (flag) {\n        flag = false;\n        for (int i = 1; i < a.length; i++) {\n            if (a[i - 1] > a[i]) {\n                int temp = a[i];\n                a[i] = a[i-1];\n                a[i-1] = temp;\n                flag = true;\n            }\n        }\n        len -- ;\n    }\n    System.out.println("排序后数组：");\n    for (int i:a) {\n        System.out.print(i + " ");\n    }\n}\n\n\npublic class Method2 {\n    public static long fib(int n){\n        if(n==1||n==2) {\n            return 1;\n        } else {\n            return fib(n-1)+fib(n-2);\n        }\n    }\n    \n    public static long fib1(int n){\n        long f[] = new long[n]; \n        f[0]=1;\n        f[1]=1;\n        for (int i = 2; i < f.length; i++) {\n            f[i]=f[i-1]+f[i-2];\n        }\n        return f[n-1];\n    }\n    //公式：fib(n) = pow(((1 + sqrt(5)) / 2.0),n) / sqrt(5) - pow(((1 - sqrt(5)) / 2.0),n) / sqrt(5));\n    public static long fib2(int n) {\n        int f[] = new int[n+1];\n        f[n] = (int) (Math.pow(((1 + Math.sqrt(5)) / 2.0),n) / Math.sqrt(5) - Math.pow(((1 - Math.sqrt(5)) / 2.0),n) / Math.sqrt(5));\n        return f[n];\n    }\n    \n    public static long[][] fib3(int n) {\n        long a[][] = { { 1, 1 }, { 1, 0 } }; // 定义基矩阵\n        long b[][]; // 存储子方法的结果\n        long c[][] = new long[2][2]; // 存储最后计算结果\n        long d[][] = new long[2][2]; // 存储中间计算结果\n        if ((n) <= 1)\n            return a; // 如果次方小等于1直接返回\n        else if ((n) % 2 == 1) {\n            b = fib3((n - 1) / 2);\n\n            d[0][0] = b[0][0] * b[0][0] + b[0][1] * b[1][0];\n            d[0][1] = b[0][0] * b[0][1] + b[0][1] * b[1][1];\n            d[1][0] = b[1][0] * b[0][0] + b[1][1] * b[1][0];\n            d[1][1] = b[1][0] * b[0][1] + b[1][1] * b[1][1];\n\n            c[0][0] = d[0][0] * a[0][0] + d[0][1] * a[1][0];\n            c[0][1] = d[0][0] * a[0][1] + d[0][1] * a[1][1];\n            c[1][0] = d[1][0] * a[0][0] + d[1][1] * a[1][0];\n            c[1][1] = d[1][0] * a[0][1] + d[1][1] * a[1][1];\n\n        } else {\n            b = fib3((n) / 2);\n\n            c[0][0] = b[0][0] * b[0][0] + b[0][1] * b[1][0];\n            c[0][1] = b[0][0] * b[0][1] + b[0][1] * b[1][1];\n            c[1][0] = b[1][0] * b[0][0] + b[1][1] * b[1][0];\n            c[1][1] = b[1][0] * b[0][1] + b[1][1] * b[1][1];\n        }\n        return c;\n    }\n}\n\n\n# 函数（方法）\n\n\n  public class Method1 {\n      public static void showArr(int a1[]) {\n          for (int i = 0; i < a1.length; i++) {\n              System.out.print(a1[i] + "  ");\n          }\n          System.out.println();\n      }\n      //showArr方法重载\n      public static void showArr(double b1[]) {\n          for (int i = 0; i < b1.length; i++) {\n              System.out.print(b1[i] + "  ");\n          }\n          System.out.println();\n      }\n      \n      public static void findArr(int a1[],int n){\n          boolean flag=true;\n          for (int i = 0; i < a1.length; i++) {\n              if(a1[i]==n){\n                  flag=false;\n                  System.out.println(a1[i] + "下标为"+i);\n              }\n          }\n          if(flag==true){\n                  System.out.println("没有找到符合条件的数");\n          }\n      }\n      //findArr方法重载\n      public static void findArr(double b1[],double m){\n          boolean flag=true;\n          for (int i = 0; i < b1.length; i++) {\n              if(b1[i]==m){\n                  flag=false;\n                  System.out.println(b1[i] + "下标为"+i);\n              }\n          }\n          if(flag==true){\n                  System.out.println("没有找到符合条件的数");\n          }\n      }\n      \n      \n      public static int[] sortArr(int a1[]) {\n          for (int i = 0; i < a1.length - 1; i++) {\n              for (int j = 0; j < a1.length - i - 1; j++) {\n                  if (a1[j] > a1[j + 1]) {\n                      int temp = a1[j];\n                      a1[j] = a1[j + 1];\n                      a1[j + 1] = temp;\n                  }\n              }\n          }\n          return a1;\n      }\n      \n      public static double[] sortArr(double a1[]) {\n          //需要比较a1.length-1轮\n          for (int i = 0; i < a1.length - 1; i++) {\n              //第i轮需要比较的两个数\n              for (int j = 0; j < a1.length - i - 1; j++) {\n                  if (a1[j] > a1[j + 1]) {\n                      double temp = a1[j];\n                      a1[j] = a1[j + 1];\n                      a1[j + 1] = temp;\n                  }\n              }\n          }\n          return a1;\n      }\n  \n  }\n\n\n# 类和对象\n\n\npublic class Method3 {\n\tprotected String name;\n\tprotected int age;\n\tprotected String sex;\n\tprotected String num;\n\tpublic Method3(){\n\t\t\n\t}\n\t\n\tpublic Method3(String name, int age, String sex, String num) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.sex = sex;\n\t\tthis.num = num;\n\t}\n\tpublic void setname(){\n\t\tthis.name = name;\n\t}\n\tpublic String getname(){\n\t\treturn name;\n\t}\n\tpublic void setage(){\n\t\tthis.age = age;\n\t}\n\tpublic int getage(){\n\t\treturn age;\n\t}\n\tpublic void setsex(){\n\t\tthis.sex = sex;\n\t}\n\tpublic String getsex(){\n\t\treturn sex;\n\t}\n\tpublic void setnum(){\n\t\tthis.num = num;\n\t}\n\tpublic String getnum(){\n\t\treturn num;\n\t}\n\t\n\t@Override\n    public String toString() {\n        return "student [name=" + name + ", age=" + age + ", sex=" + sex + ", num=" + num + "]";\n    }\n\t\n  /* public static void sortNum(Method3 []s){\n\t\tfor (int i = 0; i < s.length-1; i++) {\n\t\t\tfor (int j = 0; j < s.length-i-1; j++) {\n\t\t\t\tif(s[j].age>s[j+1].age){\n\t\t\t\t\tMethod3 a;\n\t\t\t\t\ta=s[j];\n\t\t\t\t\ts[j]=s[j+1];\n\t\t\t\t\ts[j+1]=a;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}*/\n}\n// ------------------------\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t    Method3 student[] = new Method3[3];\n\t   \tstudent[0]=new Method3("bbb",24,"男","17044003");\n\t   \tstudent[1]=new Method3("ccc",23,"女","17044002");\n\t   \tstudent[2]=new Method3("aaa",25,"男","17044001");\n\t   \t\n\t   \tList<Method3> list = new ArrayList<Method3>();\n\t   \tlist.add(student[0]);\n\t   \tlist.add(student[1]);\n\t   \tlist.add(student[2]);\n\t   \t\n\t   \tSystem.out.println("排序前：");\n        //排序前\n\t   \tfor (Method3 method3 : list) {\n\t   \t\tSystem.out.println(method3);\n\t\t}\n      ComparatorConsunInfo comparatorConsunInfo = new ComparatorConsunInfo();//比较器\n      Collections.sort(list,comparatorConsunInfo);//排序\n      \n      System.out.println("按年龄排序后：");\n      //排序后\n      for (Method3 method3 : list) {\n        \tSystem.out.println(method3);\n\t\t}\n       \n\t}\n}\n\n\n# 类的继承与抽象类的实现\n\n\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\t// TODO Auto-generated method stub\n\t\tPerson p0 = new Person();\n\t\tSystem.out.println(p0);\n\t\t\n\t\tPerson p1 = new Person("aaa");\n\t\tSystem.out.println(p1);\n\t\tp1.say();\n\t\tPerson.speak();\n\t\tSystem.out.println();\n\t\t\n\t\tPerson p2 = new Student();\n\t\tSystem.out.println(p2);\n\t\t\n\t\tPerson p3 = new Student("哈尔滨学院");\n\t\tSystem.out.println(p3);\n\t\t\n\t\tPerson p4 = new Student("bbb","XXX学校");\n\t\tSystem.out.println(p4);\n\t\tp4.say();\n\t\tp4.display();\n\t\tStudent.speak();\n\t\tSystem.out.println();\n\t\t\n\t\tPerson p5 = new Middlestudent();\n\t\tSystem.out.println(p5);\n\t\t\n\t\tPerson p6 = new Middlestudent("一高");\n\t\tSystem.out.println(p6);\n\t\t\n\t\tPerson p7 = new Middlestudent("ddd","二高");\n\t\tSystem.out.println(p7);\n\t\tp7.say();\n\t\tMiddlestudent.speak();\n\t\tSystem.out.println();\n\t\t\n\t\tPerson p8 = new Smallstudent();\n\t\tp8.display();\n\t\tp8.say();\n\t\tSmallstudent p9 = new Smallstudent();\n\t\tp9.display1();\n\n\t\tVirtualTree tree = new Tree("雪松");\n\t\ttree.act();\n\t}\n}\n\n\npublic class Person {\n\tprotected String name;\n\tpublic Person(){\n\t\t\n\t}\n\tpublic Person(String name){\n\t\tthis.name=name;\n\t}\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tprivate void setName(String name) {\n\t\tthis.name = name;\n\t}\n\t\n\t\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "我的名字:"+ this.name ;\n\t}\n\tpublic void say(){\n\t\tSystem.out.println("我是一个人。。。");\n\t}\n\t\n\tpublic static void speak(){\n\t\tSystem.out.println("吃饭");\n\t}\n\t\n\tpublic final void display(){\n\t\tSystem.out.println("我是final方法\\t不能被重写");\n\t}\n}\n\n\npublic class Student extends Person {\n\tprivate String school;\n\t\n\tpublic Student(){\n\t\t\n\t}\n\tpublic Student(String school){\n\t\tsuper(" ");\n\t\tthis.school=school;\n\t}\n\tpublic Student(String name,String school){\n\t\tsuper(name);\n\t\tthis.school=school;\n\t}\n\t\n\tpublic String getSchool() {\n\t\treturn school;\n\t}\n\tpublic void setSchool(String school) {\n\t\tthis.school = school;\n\t}\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "我的名字:"+ super.name +"\\t我的学校:" + this.school;\n\t}\n\t@Override\n\tpublic void say() {\n\t\t// TODO Auto-generated method stub\n\t\tsuper.say();\n\t\tSystem.out.println("我是一个学生。。。");\n\t}\n\tpublic static void speak(){\n\t\tSystem.out.println("学习");\n\t}\n}\n\n\nfinal public class Smallstudent extends Student  {\n\tpublic void say(){\n\t\tSystem.out.println("我是一只小学生");\n\t}\n\tpublic void display1(){\n\t\tSystem.out.println("我是final类\\t不可被继承\\n");\n\t}\n}\n\n\npublic class Middlestudent extends Student {\n\n\tpublic Middlestudent(){\n\t\tsuper("","");\n\t}\n\tpublic Middlestudent(String school){\n\t\tsuper(" ",school);\n\t}\n\tpublic Middlestudent(String name,String school){\n\t\tsuper(name,school);\n\t}\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "我的名字:"+ super.getName() +"\\t我的学校:" + super.getSchool();\n\t}\n\t@Override\n\tpublic void say() {\n\t\t// TODO Auto-generated method stub\n\t\tsuper.say();\n\t\tSystem.out.println("我是一个高中生。。。");\n\t}\n\t\n\tpublic static void speak(){\n\t\tSystem.out.println("睡觉");\n\t}\n}\n\n\npublic abstract class VirtualTree {\n\tprivate String tree="柳树";\n\tpublic VirtualTree(){\n\t\t\n\t}\n\tpublic VirtualTree(String tree){\n\t\tthis.tree=tree;\n\t}\n\t\n\tpublic String getTree() {\n\t\treturn tree;\n\t}\n\tpublic void setTree(String tree) {\n\t\tthis.tree = tree;\n\t}\n\tpublic abstract void wave(); \n\tpublic abstract void grow();\n\tpublic abstract void dieAway();\n\tpublic abstract void fellDown();\n\tpublic void act(){\n\t\t\tthis.wave();\n\t\t\tthis.grow();\n\t\t\tthis.dieAway();\n\t\t\tthis.fellDown();\n\t}\n}\n\n\npublic class Tree extends VirtualTree {\n\t\n\tpublic Tree(){\n\t\t\n\t}\n\tpublic Tree(String tree){\n\t\tsuper(tree);\n\t}\n\t\n\t@Override\n\tpublic void wave() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.println("风吹过，" + super.getTree() + "树枝摇动。");\n\t}\n\n\t@Override\n\tpublic void grow() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.println(super.getTree() + "生长中······");\n\t}\n\n\t@Override\n\tpublic void dieAway() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.println(super.getTree() + "枯萎凋零");\n\t}\n\n\t@Override\n\tpublic void fellDown() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.println(super.getTree() + "被砍伐");\n\t}\n}\n\n\n# 接口实现及深浅拷贝\n\n\npublic class Main {\n\tpublic static void main(String[] args) throws CloneNotSupportedException{\n\t\tHero hero1 = new Hero("德鲁伊");\n\t\tPets pet1 = new Pets("龙狼");\n\t\thero1.setPet(pet1);\n\t\thero1.displayMes();\n\t\t//System.out.println(hero1);\n\n\t\t/*Hero hero2 = hero1;\t\t\t//引用拷贝\n\t\t//hero2.displayMes();\n\t\tSystem.out.println(hero2);\n\t\tSystem.out.println(hero1.equals(hero3));*/\n\t\t\n\t\t/*Hero hero3 = (Hero) hero1.clone();\t\t//浅拷贝\t第一个clone()重写\n\t\tSystem.out.println(hero3.equals(hero1));\n\t\thero3.displayMes();\n\t\tSystem.out.println(hero3.pet.equals(hero1.pet));\n\t\tSystem.out.println("hero1的pet地址：" + hero1.pet);\n\t\tSystem.out.println("hero4的pet地址：" + hero3.pet);*/\n\n\t\t//深拷贝的两种方法\n\t\t//1.深复制条件 ---父类和子类都要实现Cloneable（）接口\n\t\t//2.父类重写Clone接口的时候，要把子类带上？\n\t\tHero hero4 = (Hero) hero1.clone();\t\t//深拷贝\t第二个clone()重写\n\t\t\n\t\tSystem.out.println(hero4.equals(hero1));\n\t\thero4.displayMes();\n\t\tSystem.out.println(hero4.pet==hero1.pet);\n\t\tSystem.out.println("hero1的pet" + hero1.pet.petname);\n\t\tSystem.out.println("hero4的pet" + hero4.pet.petname);\n\t\tSystem.out.println(hero1.pet.equals(hero4.pet));\n\t}\n}\n\n\npublic interface Flyable {\n\tString fly="挥动翅膀";\t//全局变量 默认为public static String\n\tpublic void able1();\t\t\t\t//接口方法默认为抽象\n\tpublic static void fly(String f){\t\t//接口静态方法\n\t\t//fly = f;\n\t\tSystem.out.print("\\t" + Flyable.fly);\n\t}\n}\n\n\npublic class Pets implements Flyable,Cloneable{\n\t String petname;\n\t\t\n\tpublic Pets() {\n\t}\n\n\tpublic Pets(String petname) {\n\t\tthis.petname = petname;\n\t}\n\n\tpublic String getPet() {\n\t\treturn petname;\n\t}\n\n\tpublic void setPet(String petname) {\n\t\tthis.petname = petname;\n\t}\n\t\n\t//接口方法的实例化\n\tpublic void able1(){\n\t\tSystem.out.print(" and fly");\n\t}\n\n\t@Override\n\tpublic Object clone() throws CloneNotSupportedException {\n\t\t// TODO Auto-generated method stub\n\t\treturn super.clone();\n\t}\n\n\t// 注：（此处为反面示例）重写equals方法时一定要重写hashCode()方法\n\t/*@Override\n\tpublic boolean equals(Object temp) {\n\t\t// TODO Auto-generated method stub\n\t\tif(this==temp){\n\t\t\treturn true;\n\t\t}\n\t\tif(temp instanceof Pets){\n\t\t\tPets pet=(Pets)temp;\n\t\t\t\n\t\t\tif(this.petname.equals(((Pets) temp).petname)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\telse{\n\t\t\treturn false;\t\t\t\n\t\t}\n\t}*/\n}\n\n\n// 克隆：实现Cloneable接口，重写clone()方法，权限为public\npublic class Hero implements Cloneable {\n\tprivate String name;\n\tPets pet;\n\t\n\tpublic Hero(){\n\t\t\n\t}\n\tpublic Hero(String name){\n\t\tthis.name = name;\n\t}\n\t\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\t\n\tpublic Pets getPet() {\n\t\treturn pet;\n\t}\n\tpublic void setPet(Pets pet) {\n\t\tthis.pet = pet;\n\t}\n\t/*@Override //浅拷贝\n\tprotected Object clone() throws CloneNotSupportedException {\n\t\t// TODO Auto-generated method stub\n\t\treturn super.clone();\n\t}*/\n\t@Override\t//深拷贝\n\tpublic Object clone() throws CloneNotSupportedException {\n\t\tHero hero = (Hero)super.clone();\n\t\thero.pet = (Pets)pet.clone();\n\t\treturn hero;\n\t}\n\t\n\t\n\t// 注：（此处为反面示例）重写equals方法时一定要重写hashCode()方法\n\t/*@Override\n\tpublic boolean equals(Object temp) {\n\t\t// TODO Auto-generated method stub\n\t\tif(this==temp){\n\t\t\treturn true;\n\t\t}\n\t\tif(temp instanceof Hero){\n\t\t\tHero hero=(Hero) temp;\n\t\t\tPets pet=(Pets)hero.pet;\n\t\t\t\n\t\t\tif(this.pet==hero.pet && this.pet.petname.equals(hero.pet.petname)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\telse{\n\t\t\treturn false;\n\t\t}\t\t\n\t}*/\n\t\n\tpublic void displayMes(){\n\t\tSystem.out.println("Hero name:" + name);\n\t\tSystem.out.print("Pet name:" + pet.getPet());\n\t\tFlyable.fly(" ");\n\t\tpet.able1();\n\t\tSystem.out.println();\n\t}\n}\n\n\n# 类间关系\n\n\npublic class Main {\n\t//体会类和类之间的关系\n\tpublic static void main(String[] args) {\n\t\t\n\t\tbyte f[]={9,11,13,12,10};\n\n\t\tStudent s[]=new Student[2];\n\t\ts[0]=new Student("雪域雷鸣",(byte)127,"男","14000000",true);\n\t\tPhone phone = new Phone();\n\t\tphone=new Phone("WAL-000",2000,20);\n\t\ts[0].finger(f);\n\t\ts[0].toString();//System.out.println(s);\n\t\ts[0].playPhone(phone);\n\t\ts[0].buyPhone(phone);\n\t\ts[0].breath();\n\t\t\n\t\ts[1]=new Student();\n\t\ts[1].toString();\n\t\ts[1].breath();\n\t\t\n\t\t\n\t\t/*s=null;\n\t\tSystem.gc();*/\n\t}\n\n}\n\n\n  public class Student {\n      private String name=" ";\n      private byte age;\n      private String sex;\n      private String num;\n      private boolean graduate;\n      Phone phone=new Phone();\n      Hands hand = new Hands();\n      \n      public Student(){\n          hand = new Hands();\n      }\n      public Student(String name){\n          this.name=name;\n      }\n      public Student(String name,byte age){\n          this(name);\n          this.age=age;\n      }\n      public Student(String name,byte age,String sex){\n          this(name,age);\n          this.sex=sex;\n      }\n      public Student(String name,byte age,String sex,String num){\n          this(name,age,sex);\n          this.num=num;\n      }\n      public Student(String name,byte age,String sex,String num ,boolean graduate){\n          this(name,age,sex,num);\n          this.graduate=graduate;\n      }\n  \n      \n      public String getName(){\n          return name;\n      }\n      public void setName(String name){\n          this.name=name;\n      }\n      public short getAge() {\n          return age;\n      }\n      public void setAge(byte age) {\n          this.age = age;\n      }\n      public String getSex() {\n          return sex;\n      }\n      public void setSex(String sex) {\n          this.sex = sex;\n      }\n      public String getNum() {\n          return num;\n      }\n      public void setNum(String num) {\n          this.num = num;\n      }\n      public boolean isGraduate() {\n          return graduate;\n      }\n      public void setGraduate(boolean graduate) {\n          this.graduate = graduate;\n      }\n      \n      public Hands getHand() {\n          return hand;\n      }\n      public void setHand(Hands hand) {\n          this.hand = hand;\n      }\n      \n      public void finger(byte a[]){       //与Hands有组合关系\n          hand = new Hands(a);\n      }\n      \n      @Override\n      public String toString() {\n          // TODO Auto-generated method stub\n          System.out.println("姓名：" + this.name +"\\t年龄：" + age + "\\t性别：" + sex + "\\t学号：" + num + "\\t是否毕业：" + graduate);\n          System.out.println(this.getHand());\n          return super.toString();\n      }\n      \n      /*@Override\n      protected void finalize() throws Throwable {\n          // TODO Auto-generated method stub\n          System.out.println("回收垃圾...");\n          super.finalize();\n      }*/\n      public void breath(){       //与Air类有依赖关系\n          Air freshair = new Air();\n          freshair.air();\n      }\n      \n      public void playPhone(Phone phone){     //与Phone有聚合关系\n          System.out.println(this.getName()+"同学的手机  型号："+phone.getModel()+ "\\t价格：" +phone.getPrice() + "\\t尺寸：" + phone.getSize());\n      }\n      \n      public Phone buyPhone(Phone phone){\n          System.out.println("购买手机 型号："+phone.getModel()+ "  价格：" +phone.getPrice() + "  尺寸：" + phone.getSize());\n          return this.phone;\n      }\n  }\n\n\n  public class Air {\n      //依赖\n      public void air(){\n          System.out.println("吸气" + "\\t呼" +" 气" + "\\n");\n      }\n  }\n\n\npublic class Hands {\n\t//组合\n\tprivate byte[] finger=new byte[5];\n\tpublic Hands(){\n\t\tfinger[0]=(byte)7;\n\t\tfinger[1]=(byte)8.2;\n\t\tfinger[2]=(byte)10;\t\t\n\t\tfinger[3]=(byte)9.3;\n\t\tfinger[4]=(byte)7.5;\n\t}\n\tpublic Hands(byte[] finger){\n\t\tthis.finger=finger;\n\t}\n\t\n\tpublic byte[] getFinger() {\n\t\treturn finger;\n\t}\n\n\tpublic void setFinger(byte[] finger) {\n\t\tthis.finger = finger;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.println("拇指长为："+finger[0]+"\\t食指长为："+finger[1]+"\\t中指长为："+finger[2]+"\\t无名指长为："+finger[3]+"\\t小指长为："+finger[4]);\n\t\treturn super.toString();\n\t}\n}\n\n\n  public class Phone {\n      //聚合\n      private String model;\n      private int price;\n      private int size;\n  \n      public Phone() {\n  \n      }\n  \n      public Phone(String model) {\n          this();\n          this.model=model;\n      }\n  \n      public Phone(String model, int price) {\n          this(model);\n          this.price=price;\n      }\n  \n      public Phone(String model, int price, int size) {\n          this(model,price);\n          this.size=size;\n      }\n  \n      public String getModel() {\n          return model;\n      }\n  \n      public void setModel(String model) {\n          this.model = model;\n      }\n  \n      public int getPrice() {\n          return price;\n      }\n  \n      public void setPrice(int price) {\n          this.price = price;\n      }\n  \n      public int getSize() {\n          return size;\n      }\n  \n      public void setSize(int size) {\n          this.size = size;\n      }\n  }\n\n\n# 简单设计模式\n\n\n  public class Main {\n      static{\n          System.out.println("测试类的静态代码块");\n      }\n      public static void mothod(int n){\n          \n          System.out.println("我是" + n + "句无聊的话。。。");\n      }\n      public static void main(String[] args) {\n          // TODO Auto-generated method stub\n          /*Student.setSchool("XX学院");\n          Student s1 = new Student();\n          s1.setName("aaa");\n          System.out.println(s1.getName() + " " + Student.getSchool());*/\n          \n          Test.mothod(3);\n          \n          Student s0 = new Student();\n          System.out.println(s0);\n          \n          Student s2 = new Student("aaa");\n          s2.schoolName("XX学院");\n          s2.showMessage();\n          \n          Singleton s3 = Singleton.getInstane();\n          System.out.println(s3);\n          Singleton s4 = Singleton.getInstane();\n          System.out.println(s4);\n          System.out.println("（单例饿汉式）对象数：" + Singleton.num + "\\n");\n          \n          Singleton1 s5 = Singleton1.getInstane();\n          System.out.println(s5);\n          Singleton1 s6 = Singleton1.getInstane();\n          System.out.println(s6);\n          System.out.println("（单例懒汉式）对象数：" + Singleton1.num + "\\n");\n          \n          Multiton s7 = Multiton.getInstane("恒星1");\n          System.out.println(s7.getStar());\n          Multiton s8 = Multiton.getInstane("恒星2");\n          System.out.println(s8.getStar());\n          Multiton s9 = Multiton.getInstane("恒星3");\n          System.out.println(s9.getStar());\n          System.out.println("（多例）对象数：" + Multiton.num);\n      }\n  }\n\n\n// 多例\npublic class Multiton {\n\tprivate String star;\n\tpublic static int num=0;\n\tprivate static Multiton[] s = new Multiton[3];\n\tstatic{\n\t\tfor (int i = 0; i < s.length; i++) {\n\t\t\ts[i] = new Multiton("恒星" + (i+1));\n\t\t}\n\t}\n\t\n\tpublic String getStar() {\n\t\treturn star;\n\t}\n\tpublic void setStar(String star) {\n\t\tthis.star = star;\n\t}\n\t\n\tprivate Multiton(){\n\t\tnum++;\n\t}\n\tprivate Multiton(String star){\n\t\tthis.star=star;\n\t\tnum++;\n\t}\n\t\n\tpublic static Multiton getInstane(String star)\n\t{\n\t\tif(s[0].getStar().equals(star)){\n\t\t\treturn s[0];\n\t\t}\n\t\telse if(s[1].getStar().equals(star))\n\t\t{\n\t\t\treturn s[1];\n\t\t}\n\t\telse{\n\t\t\treturn s[2];\n\t\t}\n\t}\n}\n\n\n//单例   饿汉式\npublic class Singleton {\n\tprivate String school;\n\tpublic static int num=0;\n\tprivate static final Singleton s = new Singleton("XX学院");\n\t\n\tprivate Singleton(){\n\t\tnum++;\n\t}\n\tprivate Singleton(String school){\n\t\tthis.school=school;\n\t\tnum++;\n\t}\n\t\n\tpublic static Singleton getInstane()\n\t{\n\t\treturn s;\n\t}\n}\n\n\n//单例  懒汉式\npublic class Singleton1 {\n\tprivate String school;\n\tpublic static int num=0;\n\tprivate static Singleton1 s = null;\n\t\n\tprivate Singleton1() {\n\t\tnum++;\n\t}\n\tprivate Singleton1(String school) {\n\t\tthis.school=school;\n\t\tnum++;\n\t}\n\t\n\tpublic static Singleton1 getInstane() {\n\t\tif(s==null){\n\t\t\ts=new Singleton1();\n\t\t} else {\n\t\t\treturn s;\n\t\t}\n\t\treturn s;\n\t}\n}\n\n\n# 常见异常类与捕获异常\n\n\npublic class ArrException {\n\tpublic static void main(String[] args){\n\t\tint a[]={21,32,52};\n\t\t\n\t\ttry{\n\t\t\tSystem.out.println(a[3]);\n\t\t}catch(ArrayIndexOutOfBoundsException e){\n\t\t\tSystem.out.println("异常信息为：" + e.getMessage());\n\t\t}\n\t}\t\n}\n\n\npublic class ClasEpt {\n\tprivate String name;\n\n\tprotected ClasEpt() {\n\t\tsuper();\n\t}\n\n\tprotected ClasEpt(String name) {\n\t\tsuper();\n\t\tthis.name = name;\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "姓名："+name;\n\t}\n\t\n\t\n\tpublic static void main(String[] args) {\n\t\t// TODO Auto-generated method stub\n\t\tClasEpt c=new ClasEpt("name");\n\t\tc=null;\n\t\t\n\t\tassert (c!=null):"对象c指向null";\n\t\t\n\t\tSystem.out.println(c);\n\t\ttry{\n\t\t\tSystem.out.println(c.toString());\n\t\t}catch(NullPointerException e){\n\t\t\tSystem.out.println("异常信息：" + e.getMessage());\n\t\t\t//e.printStackTrace();\n\t\t}\n\t}\n}\n\n\npublic class DivEpt {\n\tpublic static void main(String[] args) {\n\t\tint a=100;\n\t\tint b=0;\n\t\t\n\t\ttry{\n\t\t\tSystem.out.println(div(a,b));\n\t\t}catch(Exception e){\n\t\t\tSystem.out.println("异常信息为：" + e.getMessage());\n\t\t}finally{\n\t\t\tSystem.out.println("请重新操作");\n\t\t}\n\t}\n\t\n\tpublic static int div(int a,int b) {\n\t\treturn a/b;\n\t}\n}\n\n\npublic class DivEpt1 {\n\tpublic static void main(String[] args) {\n\t\tint a=100;\n\t\tint b=0;\n\t\t\n\t\ttry{\n\t\t\tSystem.out.println(div(a,b));\n\t\t}catch(Exception e){\n\t\t\tSystem.out.println(e.getMessage());\n\t\t}\n\t}\n\t\n\tpublic static int div(int a,int b) throws Exception {\n\t\tif(b==0){\n\t\t\tthrow new Exception("除数为零");\n\t\t}\n\t\treturn a/b;\n\t}\n}\n\n\n/**\n * 自定义异常\n * 继承Exception\n * @author Lenovo\n */\npublic class MyException extends Exception{\n\t\n\t/**\n\t * 序列化ID\n\t */\n\tprivate static final long serialVersionUID = 1L;\n\tpublic MyException(){\n\t\tsuper();\n\t}\n\tpublic MyException(String msg){\n\t\tsuper(msg);\n\t}\n\tpublic String getMessage(String s) {\n\t\t\n\t\treturn "得到异常信息：" + super.getMessage();\n\t}\n\t@Override\n\tpublic void printStackTrace() {\n\t\t// TODO Auto-generated method stub\n\t\tSystem.out.print("打印堆栈信息：");\n\t\tsuper.printStackTrace();\n\t}\n}\n\n// ----------------------------\n\npublic class MyTest {\n\tpublic static void main(String[] args) throws MyException{\n\t\tint x=5;\n\t\twhile(x--\x3e1){\n\t\t\tScanner cin = new Scanner(System.in);\n\t\ttry{\n\t\t\t\tint a = cin.nextInt();\n\t\t\t\tint b = cin.nextInt();\n\t\t\t\tif(b==0){\n\t\t\t\t\tthrow new MyException("除数不能为0");\t\t//自定义异常类对象\n\t\t\t\t}\n\t\t\t\tSystem.out.println(a/b);\n\t\t\t}catch(InputMismatchException e){\n\t\t\t\t//e.printStackTrace();\n\t\t\t\tSystem.out.println(e.getMessage());\n\t\t\t}catch(ArithmeticException e){\n\t\t\t\tSystem.out.println(e.getMessage());\n\t\t\t}catch(RuntimeErrorException e){\n\t\t\t\tSystem.out.println(e.getMessage());\n\t\t\t}catch(Exception e){\n\t\t\t\tSystem.out.println(e.getMessage());\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n# 线程\n\n# 多线程\n\n\npublic class MyThread extends Thread{\n\tprivate static int tickets = 50;\n\t//private volatile int tickets = 50;\n\t//private int tickets = 50;\n\tprivate int time ;\t\n\tpublic MyThread(String name,int time){\n\t\tsuper(name);\n\t\tthis.time = time;\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\t\n\t\twhile(tickets--\x3e0){\n\t\t\ttry {\n\t\t\t\tThread.sleep(this.time);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第" + tickets + "张票");\n\t\t}\n\t}\n}\n// ------------------------------------------------------\npublic static void main(String[] args) {\n\t// TODO Auto-generated method stub\n\tMyThread t1=new MyThread("窗口1",200);\n\tMyThread t2=new MyThread("窗口2",100);\n\tMyThread t3=new MyThread("窗口3",50);\n\tMyThread t4=new MyThread("窗口4",10);\n\t\n\tt1.start();\n\tt2.start();\n\tt3.start();\n\tt4.start();\n}\n\n\npublic class TRunnable implements Runnable{\n\tprivate int tickets = 50;\n\tprivate int time;\n\tprotected TRunnable(int time) {\n\t\tsuper();\n\t\tthis.time = time;\n\t}\n\n\t@Override\n\tpublic void run() {\n\t\t// TODO Auto-generated method stub\n\t\twhile(tickets--\x3e0){\n\t\t\ttry {\n\t\t\t\tThread.sleep(this.time);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第" + tickets + "张票");\n\t\t}\n\t}\n}\n\n// ----------------------------------\npublic static void main(String[] args) {\n\t\t//Runnable接口实现类的对象\n\t\tTRunnable tr1=new TRunnable(100);\t\t//参数为睡眠时间\n\t\t\n\t\tThread t1 = new Thread(tr1,"窗口1");\n\t\tThread t2 = new Thread(tr1,"窗口2");\n\t\tThread t3 = new Thread(tr1,"窗口3");\n\t\tThread t4 = new Thread(tr1,"窗口4");\n\t\t\n\t\tt1.start();\n\t\tt2.start();\n\t\tt3.start();\n\t\tt4.start();\n\t}\n}\n\n\n// 可带返回值的多线程\npublic class TCallable implements Callable{\n \tprivate int tickets = 50;\n \t@Override\n \tpublic Object call() throws Exception {\n \t\twhile(true){\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets==39){\n \t\t\t\t\tSystem.out.println("程序让步...");\n \t\t\t\t\tThread.yield();\n \t\t\t\t}\n \t\t\t}\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets==6){\n \t\t\t\t\tSystem.out.println("程序让步...");\n \t\t\t\t\tThread.yield();\n \t\t\t\t}\n \t\t\t}\n \t\t\t\n \t\t\ttry {\n \t\t\t\tThread.sleep(2);\n \t\t\t} catch (InterruptedException e) {\n \t\t\t\t// TODO Auto-generated catch block\n \t\t\t\te.printStackTrace();\n \t\t\t}\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets>0){\n \t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第" + tickets + "张票");\t\n \t\t\t\t\ttickets--;\n \t\t\t\t}else{\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n \t\t}\n \t\treturn tickets;\n \t}\n}\n// ----------------------------\npublic class TestTC {\n\tpublic static void main(String[] args) throws InterruptedException, ExecutionException  {\n\t\tTCallable tc = new TCallable();\n\t\t\n\t\tFutureTask ft1 = new FutureTask(tc);\n\t\tThread t1 = new Thread(ft1,"窗口1");\n\t\t\n\t\tFutureTask ft2 = new FutureTask(tc);\n\t\tThread t2 = new Thread(ft2,"窗口2");\n\t\t\n\t\tFutureTask ft3 = new FutureTask(tc);\n\t\tThread t3 = new Thread(ft3,"窗口3");\n\t\t\n\t\tFutureTask ft4 = new FutureTask(tc);\n\t\tThread t4 = new Thread(ft4,"窗口4");\n\t\t\n\t\tFutureTask ft5 = new FutureTask(tc);\n\t\tThread t5 = new Thread(ft5,"窗口5");\n\t\t\n\t\tFutureTask ft6 = new FutureTask(tc);\n\t\tThread t6 = new Thread(ft6,"窗口6");\n\t\t\n\t\tDamonThread d2 = new DamonThread();\n\t\tThread t9 = new Thread(d2,"守护线程");\n\t\tt9.setDaemon(true);\n\t\tSystem.out.println("线程t9是否是守护线程:" + t9.isDaemon());\n\t\tt9.start();\n\t\t\n\t\tt1.setPriority(1);\n\t\tt1.start();\n\t\tt2.setPriority(1);\n\t\tt2.start();\n\t\tt3.setPriority(9);\n\t\tt3.start();\n\t\tt4.setPriority(3);\n\t\tt4.start();\n\t\tt5.setPriority(3);\n\t\tt5.start();\n\t\tt5.join();\t\t//join(）后面的线程在此线程结束后才会运行\n\t\tt6.setPriority(9);\n\t\tt6.start();\n\t\t\n\t\tSystem.out.println("t1\\tID:" + t1.getId() + "\\t返回结果：" + ft1.get() + "\\t任务是否完成：" + ft1.isDone());\n\t\tSystem.out.println("t2\\tID:" + t2.getId() + "\\t返回结果：" + ft2.get() + "\\t任务是否完成：" + ft2.isDone());\n\t\tSystem.out.println("t3\\tID:" + t3.getId() + "\\t返回结果：" + ft3.get() + "\\t任务是否完成：" + ft3.isDone());\n\t\tSystem.out.println("t4\\tID:" + t4.getId() + "\\t返回结果：" + ft4.get() + "\\t任务是否完成：" + ft4.isDone());\n\t\tSystem.out.println("t5\\tID:" + t5.getId() + "\\t返回结果：" + ft5.get() + "\\t任务是否完成：" + ft5.isDone());\n\t\tSystem.out.println("t6\\tID:" + t6.getId() + "\\t返回结果：" + ft6.get() + "\\t任务是否完成：" + ft6.isDone());\n\t}\n}\n\n\npublic class DamonThread implements Runnable{\n\n\t@Override\n\tpublic void run() {\n\t\t// TODO Auto-generated method stub\n\t\twhile(true){\n\t\t\tSystem.out.println(Thread.currentThread().getName() + "运行");\n\t\t\ttry {\n\t\t\t\tThread.sleep(1);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n}\n// ----------------------------------------------\npublic class TestDT {\n\tpublic static void main(String[] args) throws InterruptedException {\n\t\tDamonThread d1 = new DamonThread();\n\t\tThread t1 = new Thread(d1,"守护线程");\n\t\tt1.setDaemon(true);\n\t\tSystem.out.println("线程t1是否是守护线程:" + t1.isDaemon());\n\t\tt1.start();\n\t\t\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tThread.sleep(3);\n\t\t\tSystem.out.println(Thread.currentThread().getName() + "运行中...");\n\t\t}\n\t\t\n\t\t/*while(true){\n\t\t\t\n\t\t}*/\n\t}\n}\n\n\n# 多线程锁\n\n\npublic class Test_Method implements Callable<Object> {\n\tprivate int tickets = 100;\n\t@Override\n\tpublic Object call() throws Exception {\n\t\t// TODO Auto-generated method stub\n\t\twhile(tickets>0){\n\t\t\tsold();\n\t\t}\n\t\treturn tickets;\n\t}\n\t\n\tpublic synchronized void sold(){\n\t\tif (tickets > 0) {\n\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第"\n\t\t\t\t\t+ tickets + "张票");\n\t\t\ttickets--;\n\t\t}\n\t}\n}\n\n\npublic class Test_synchronized implements Callable<Object> {\n\tprivate int tickets = 100;\n\n\t@Override\n\tpublic Object call() throws Exception {\n\t\twhile (true) {\n\t\t\tsynchronized (this) {\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t\tif (tickets > 0) {\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第"\n\t\t\t\t\t\t\t+ tickets + "张票");\n\t\t\t\t\ttickets--;\n\t\t\t\t} else {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn tickets;\n\t}\n}\n\n\npublic class Test_Lock implements Callable<Object> {\n\tprivate int tickets = 100;\n\tprivate final Lock lock = new ReentrantLock();\n\n\t@Override\n\tpublic Object call() throws Exception {\n\t\twhile (true) {\n\t\t\tlock.lock();\n\t\t\ttry {\n\t\t\t\tThread.sleep(30);\n\t\t\t\tif (tickets > 0) {\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + " 卖第"\n\t\t\t\t\t\t\t+ tickets + "张票");\n\t\t\t\t\ttickets--;\n\t\t\t\t} else {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}finally{\n\t\t\t\tlock.unlock();\n\t\t\t}\n\n\t\t}\n\t\treturn tickets;\n\t}\n}\n\n\npublic class DeadLockThread implements Callable<Object>{\n\tstatic Object chopsticks1 = new Object();\n\tstatic Object chopsticks2 = new Object();\n\tprivate boolean flag ;\n\tpublic DeadLockThread(boolean flag) {\n\t\tthis.flag = flag;\n\t}\n\t@Override\n\tpublic Object call() throws Exception {\n\t\tif(flag==true){\n\t\t\twhile(true){\n\t\t\t\tsynchronized(chopsticks1){\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\tget chopsticks1");\n\t\t\t\t\tsynchronized(chopsticks2){\n\t\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\tget chopsticks2");\n\t\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\teating");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}else{\n\t\t\twhile(true){\n\t\t\t\tsynchronized(chopsticks1){\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\tget chopsticks1");\n\t\t\t\t\tsynchronized(chopsticks2){\n\t\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\tget chopsticks2");\n\t\t\t\t\t\tSystem.out.println(Thread.currentThread().getName() + "\\teating");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n// ---------------\npublic class TestDLT {\n\tpublic static void main(String[] args) {\n\t\tDeadLockThread dl1 = new DeadLockThread(false);\n\t\tFutureTask ft1 = new FutureTask(dl1);\n\t\tThread t1 = new Thread(ft1,"p1");\n\t\t\n\t\tDeadLockThread dl2 = new DeadLockThread(true);\n\t\tFutureTask ft2 = new FutureTask(dl2);\n\t\tThread t2 = new Thread(ft2,"p2");\n\t\t\n\t\tt1.start();\n\t\tt2.start();\n\t}\n}\n\n\n// -------------- Storage（库存） ---------------------\npublic class Storage {\n\tprivate int data;\n\tprivate boolean b = false;\n\tint i = 0;\n\t\n\tsynchronized public void put(int num){\n\t\twhile(b == true){\n\t\t\ttry {\n\t\t\t\tthis.wait();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tdata=num;\n\t\tb=true;\n\t\ti++;\n\t\tSystem.out.println(Thread.currentThread().getName() +"在" + i + "处生产" + data);\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t} catch (InterruptedException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}finally{\n\t\t\tthis.notify();\n\t\t}\n\t}\n\t\n\tsynchronized public void get(){\n\t\t\twhile(b==false){\n\t\t\t\ttry {\n\t\t\t\t\tthis.wait();\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t\tb=false;\n\t\t\tSystem.out.println(Thread.currentThread().getName() + "消费" + data);\n\t\t\ttry {\n\t\t\t\tThread.sleep(100);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}finally{\n\t\t\t\tthis.notify();\n\t\t\t}\n\t}\n}\n\n// ----------------- Producer（生产者） -------------------\npublic class Producer implements Runnable {\n\tStorage s = new Storage();\n\tprivate int count = 0;\n\n\tpublic Producer(Storage s) {\n\t\tthis.s = s;\n\t}\n\n\t@Override\n\tpublic void run() {\n\n\t\twhile (count < 15) {\n\t\t\ts.put(count++);\n\t\t}\n\t}\n}\n\n// ----------------- Consumer（消费者） -------------------\npublic class Consumer implements Runnable {\n\tStorage s = new Storage();\n\tprivate int count = 0;\n\n\tpublic Consumer(Storage s) {\n\t\tthis.s = s;\n\t}\n\n\t@Override\n\tpublic void run() {\n\n\t\twhile (count++ < 15) {\n\t\t\ts.get();\n\t\t}\n\t}\n}\n\n// ----------------- 测试类启动类 -------------------\npublic class TestSPD {\n\tpublic static void main(String[] args) {\n\t\tStorage s = new Storage();\n\t\t\n\t\tProducer p = new Producer(s);\n\t\tConsumer c = new Consumer(s);\n\t\t\n\t\tnew Thread(p,"生产者").start();\n\t\tnew Thread(c,"消费者").start();\n\t}\n}\n\n\n# 常用工具类\n\n\npublic class T_regex {\n\tpublic static void main(String args[]){\n\t\tString s1 = "1033178928@qq.com";\n\t\tSystem.out.println("是否是一个qq邮箱:" + s1.matches("[0-9]{10,11}@(([a-zA-z0-9]-*){1,}\\\\.){1,3}[a-zA-z\\\\-]{1,}"));\n\t\t\n\t\tString s2 = "451221199705303537";\n\t\tSystem.out.println("是否是一个正确的身份证号：" + s2.matches("[0-9]{18}"));\n\t\n\t\tPattern p=Pattern.compile("[0-9]{10,11}@(([a-zA-z0-9]-*){1,}\\\\.){1,3}[a-zA-z\\\\-]{1,}"); \n\t\tMatcher m =p.matcher("1033178928@qq.com"); \n\t\tboolean b = m.matches();\n\t\tSystem.out.println(b);\n\t\tMatcher m2=p.matcher("10331789@qq.com");\n\t\tb = m2.matches();\n\t\tSystem.out.println(b);\n\t\tMatcher m3=p.matcher("4534545378@qq.com");\n\t\tb = m3.matches();\n\t\tSystem.out.println(b);\n\t\tMatcher m4=p.matcher("1033178928@.com");\n\t\tb = m4.matches();\n\t\tSystem.out.println(b);\n\t}\n}\n\n\npublic class T_Method {\n\tpublic static void main(String []args){\n\t\tString s = new String(" AbCdefgHijk_LmnopwrStuVwxyz_AbCdefgHijkL_mnopwrStuVwxyz ");\n\t\t\n\t\tSystem.out.println(s.indexOf("Stu"));\n\t\tSystem.out.println(s.lastIndexOf("Stu"));\n\t\tSystem.out.println(s.startsWith("AbCdefg"));\n\t\tSystem.out.println(s.endsWith("vwxyz"));\n\t\tSystem.out.println(s.equals(""));\n\t\tSystem.out.println(s.length());\n\t\tSystem.out.println(s.contains("mnopwrSt"));\n\t\tSystem.out.println(s.toUpperCase());\n\t\tSystem.out.println(s.toLowerCase());\n\t\tSystem.out.println(s.replace("AbCdefgHijk_LmnopwrStuVwxyz", "aaa"));\n\t\tString s_arr[] = s.split("_");\n\t\tfor (int i = 0; i < s_arr.length; i++) {\n\t\t\tif(i != s_arr.length - 1){\n\t\t\t\tSystem.out.print(s_arr[i] + "0.0\\t");\n\t\t\t}else{\n\t\t\t\tSystem.out.println(s_arr[i]);\n\t\t\t}\n\t\t}\n\t\tSystem.out.println(s.substring(18,26));\t\t//18-26的字符\n\t\tSystem.out.println(s.trim());\n\t}\n}\n\n\npublic class T_Builder {\n\tpublic static void main(String args[]){\n\t\tSystem.out.println("增=======");\n\t\tStringBuilder s1 = new StringBuilder("才知人力终有穷尽");\n\t\tString s2 = "*";\n\t\tadd(s1,s2);\n\t\tSystem.out.println("删=======");\n\t\tupdate();\n\t\tSystem.out.println("改=======");\n\t\tdelete();\n\t}\n\tpublic static void add(StringBuilder str1,String str2){\n\t\tstr1.append(str2);\n\t\tSystem.out.println("append添加结果：" + str1);\n\t\t\n\t\tstr1.insert(4, str2);\n\t\tSystem.out.println("insert添加结果：" + str1);\n\t}\n\tpublic static void update(){\n\t\tStringBuilder sb = new StringBuilder("apple");\n\t\tsb.setCharAt(3, \' \');\n\t\tSystem.out.println("修改：" + sb);\n\t\t\n\t\tsb.replace(2, 4, "===");\n\t\tSystem.out.println("替换：" + sb);\n\t\t\n\t\tStringBuilder sb1 = new StringBuilder("上海自来水来自海上");\n\t\tSystem.out.println( "sb1是否是回文:" + sb1.equals(sb1.reverse()));\n\t\tStringBuilder sb3 = new StringBuilder("玲珑骰子安红豆，入骨相思君知否");\n\t\tSystem.out.println("翻转：" + sb1.reverse() + "\\t" + sb3.reverse());\n\t}\n\tpublic static void delete(){\n\t\tStringBuilder sb = new StringBuilder("年少轻狂，总以为天下事无可不为。");\n\t\tsb.delete(2, 5);\n\t\tSystem.out.println("删除指定位置:" + sb);\n\t\tsb.deleteCharAt(2);\n\t\tSystem.out.println("删除指定位置:" + sb);\n\t\tsb.delete(0, sb.length());\n\t\tSystem.out.println("清空缓冲区:" + sb);\n\t}\n}\n\n\npublic class T_Buffer {\n\tpublic static void main(String args[]){\n\t\tSystem.out.println("增=======");\n\t\tStringBuffer s1 = new StringBuffer("才知人力终有穷尽");\n\t\tString s2 = "*";\n\t\tadd(s1,s2);\n\t\tSystem.out.println("删=======");\n\t\tupdate();\n\t\tSystem.out.println("改=======");\n\t\tdelete();\n\t}\n\tpublic static void add(StringBuffer str1,String str2){\n\t\tstr1.append(str2);\n\t\tSystem.out.println("append添加结果：" + str1);\n\t\t\n\t\tstr1.insert(4, str2);\n\t\tSystem.out.println("insert添加结果：" + str1);\n\t}\n\tpublic static void update(){\n\t\tStringBuffer sb = new StringBuffer("apple");\n\t\tsb.setCharAt(3, \' \');\n\t\tSystem.out.println("修改：" + sb);\n\t\t\n\t\tsb.replace(2, 4, "===");\n\t\tSystem.out.println("替换：" + sb);\n\t\t\n\t\tStringBuffer sb1 = new StringBuffer("上海自来水来自海上");\n\t\tSystem.out.println( "sb1是否是回文:" + sb1.equals(sb1.reverse()));\n\t\tStringBuffer sb3 = new StringBuffer("玲珑骰子安红豆，入骨相思君知否");\n\t\tSystem.out.println("翻转：" + sb1.reverse() + "\\t" + sb3.reverse());\n\t}\n\tpublic static void delete(){\n\t\tStringBuffer sb = new StringBuffer("年少轻狂，总以为天下事无可不为。");\n\t\tsb.delete(2, 5);\n\t\tSystem.out.println("删除指定位置:" + sb);\n\t\tsb.deleteCharAt(2);\n\t\tSystem.out.println("删除指定位置:" + sb);\n\t\tsb.delete(0, sb.length());\n\t\tSystem.out.println("清空缓冲区:" + sb);\n\t}\n}\n\n\npublic class Test {\n\tpublic static void main(String[] args) {\n\t\tRuntime rt = Runtime.getRuntime();\n\t\tSystem.out.println("处理机个数：" + rt.availableProcessors() + "个");\n\t\tSystem.out.println("空闲内存：" + rt.freeMemory()/1024/1024 + "M");\n\t\tSystem.out.println("最大内存：" + rt.maxMemory()/1024/1024 + "M");\n\t\t\n\t\ttry {\n\t\t\t\n\t\t\tProcess process = rt.exec("notepad.exe");\n\t\t\tThread.sleep(3000);\n\t\t\tprocess.destroy();\n\t\t\t\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n\n\n// ------------- DateFormat -----------\npublic class T_DateFormat {\n\tpublic static void main(String[] args) {\n\t\tDate d = new Date();\n\t\tDateFormat fullFormat = DateFormat.getDateInstance(DateFormat.FULL);\n\t\tDateFormat longFormat = DateFormat.getDateInstance(DateFormat.LONG);\n\t\tDateFormat mediumFormat = DateFormat.getDateTimeInstance(DateFormat.MEDIUM, DateFormat.MEDIUM);\n\t\tDateFormat shortFormat = DateFormat.getDateTimeInstance(DateFormat.SHORT, DateFormat.SHORT);\n\n\t\tSystem.out.println("当前日期的完整格式为：" + fullFormat.format(d));\n\t\tSystem.out.println("当前日期的长格式为：" + longFormat.format(d));\n\t\tSystem.out.println("当前日期的普通格式为：" + mediumFormat.format(d));\n\t\tSystem.out.println("当前日期的短格式为：" + shortFormat.format(d));\n\t\t\n\t\tSimpleDateFormat s = new SimpleDateFormat("Gyyyy年MM月dd日：今天是yyyy年第D天，E");\n\t\tSystem.out.println(s.format(new Date()));\n\t}\n}\n\n// ------------- Clock、Duration、Instant -----------\npublic class T_time {\n\tpublic static void main(String[] args) {\n\t\t//Clock\n\t\tClock c = Clock.systemUTC();\n\t\tSystem.out.println("UTC转换当前时间：" + c.instant());\n\t\tSystem.out.println("UTC转换毫秒数：" + c.millis());\n\t\t//Duration\n\t\tDuration d = Duration.ofDays(3);\n\t\tSystem.out.println("3天=" + d.toHours() + "时");\n\t\tSystem.out.println("3天=" + d.toMinutes() + "分");\n\t\tSystem.out.println("3天=" + d.toMillis() + "秒");\n\t\t//Instant\n\t\tInstant i = Instant.now();\n\t\tSystem.out.println("UTC当前时间：" + i);\n\t\tSystem.out.println("UTC当前时间+1小时：" + i.plusSeconds(3600));\n\t\tSystem.out.println("UTC当前时间-1小时：" + i.minusSeconds(3600));\t\t\n\t}\n}  \n\n// ------------- Calendar -----------\npublic class Test {\n\tpublic static void main(String[] args) {\n\t\tDate d1 = new Date();\n\t\tDate d2 = new Date(System.currentTimeMillis() + 1000);\n\t\tSystem.out.println(d1);\n\t\tSystem.out.println(d2);\n\t\t\n\t\t//得到当前年 月 日 时 分 秒\n\t\tCalendar cr = Calendar.getInstance();\n\t\tint year = cr.get(Calendar.YEAR);\n\t\tint month = cr.get(Calendar.MONTH)+ 1;\n\t\tint date = cr.get(Calendar.DATE);\n\t\tint hour = cr.get(Calendar.HOUR);\n\t\tint minute = cr.get(Calendar.MINUTE);\n\t\tint second = cr.get(Calendar.SECOND);\t\t\n\t\tSystem.out.println("当前时间" + year + "年" + month + "月" + date + "日\\t" + hour + ":" + minute + ":" + second );\n\t\n\t\t//设置日期+100天\n\t\tCalendar cr2 = Calendar.getInstance();\n\t\tcr2.set(2019, 6, 6);\n\t\tcr2.add(Calendar.DATE, 100);\n\t\tint y = cr2.get(Calendar.YEAR);\n\t\tint m = cr2.get(Calendar.MONTH);\n\t\tint d = cr2.get(Calendar.DATE);\n\t\tSystem.out.println("计划完成时间是：" + y + "年" + m + "月" + d +"日");\n\t\t\n\t\t//容错模式与非容错模式\n\t\tCalendar ca = Calendar.getInstance();\n\t\tca.set(Calendar.MONTH, 13);\n\t\tSystem.out.println(ca.getTime());\n\t\t/*ca.setLenient(false);\n\t\tca.set(Calendar.MONTH, 13);\n\t\tSystem.out.println(ca.getTime());*/\n\t}\n}\n\n\n// --------------- arraycopy ----------------------------\npublic class T_arraycopy {\n\tpublic static void main(String[] args) {\n\t\tint []srcarry = {100,101,102,103,104,105,106,107,108};\n\t\tint []desarray = {1,2,3,4,5};\n\t\tSystem.arraycopy(srcarry, 3, desarray, 0, desarray.length);\n\t\tfor (int i = 0; i < desarray.length; i++) {\n\t\t\tSystem.out.println(i + ":" + desarray[i]);\n\t\t}\n\t}\n}\n// --------------- currentTimeMillis ----------------------------\npublic class T_currentTimeMillis {\n\tpublic static void main(String[] args) {\n\t\tlong s_time = System.nanoTime();\n\t\tlong starttime = System.currentTimeMillis();\n\t\tint s = 0;\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\ts=s+1;\n\t\t}\n\t\tlong endtime = System.currentTimeMillis();\n\t\tlong e_time = System.nanoTime();\n\n\t\tSystem.out.println("运行时间：" + (endtime-starttime) + "ms");\n\t\tSystem.out.println("运行时间：" + (e_time-s_time) + "毫微秒");\n\t}\n}\n// --------------- getProperties ----------------------------\npublic class T_getproperties {\n\tpublic static void main(String[] args) {\n\t\tProperties properties = System.getProperties();\n\t\tSystem.out.println(properties);\n\t\t\n\t\tSet<String>propertyNames = properties.stringPropertyNames();\n\t\tfor (String key : propertyNames) {\n\t\t\tString value = System.getProperty(key);\n\t\t\tSystem.out.println(key + "---" + value);\n\t\t}\n\t}\n}\n\n\npublic class T_List {\n\tpublic static void main(String[] args) {\n\t\tArrayList<String> list = new ArrayList<String>();\n\t\tlist.add("Eve");\n\t\tlist.add("Mark");\n\t\tlist.add("Rose");\n\t\tlist.add("Rose");\n\t\tSystem.out.println(list);\n\n\t\tSystem.out.println("第三个元素：" + list.get(2));\n\t\tSystem.out.println("长度：" + list.size());\n\t\tSystem.out.println("删除第四个元素" + list.remove(3));\n\n\t\t//foreach遍历\n\t\tfor (String str : list) {\n\t\t\tSystem.out.print(str + " ");\n\t\t}\n\t\tSystem.out.println();\n\n\t\tLinkedList<String> ll = new LinkedList<String>();\n\t\tll.addAll(list);\t//把list集合加入ll中\n\t\tll.add("John");\n\t\tll.addFirst("John");\n\n\t\t//iterator遍历\n\t\tIterator<String> it = ll.iterator();\n\t\tSystem.out.print("iteraror遍历:");\n\t\twhile(it.hasNext()) {\n\t\t\tString str = (String)(it.next());\n\t\t\tSystem.out.print(str + " ");\n\t\t}\n\t\tSystem.out.println();\n\t\t\n\t\t//jdk8 forEach遍历迭代器对象\n\t\tll.removeFirst();\n\t\tIterator<String> it1 = ll.iterator();\n\t\tit1.forEachRemaining(obj -> System.out.print("\\t迭代集合元素：" + obj));\n\t\tSystem.out.println();\n\t\t\n\t\t//逆向迭代遍历\n\t\tSystem.out.print("逆向迭代遍历：");\n\t\tListIterator<String> li = ll.listIterator(ll.size());\n\t\twhile(li.hasPrevious()){\n\t\t\tString str = (String)li.previous();\n\t\t\tSystem.out.print(str + " ");\n\t\t}\n\t}\n}\n\n\npublic class T_Vector {\n\tpublic static void main(String[] args) {\n\t\tT_Vector t = new T_Vector();\n\t\tVector<String> v = new Vector<String>();\n\t\tv.add("10086");\n\t\tv.add("10087");\n\t\tv.add("10088");\n\t\tv.add("10089");\n\t\tt.printSet2(v);\n\t}\n\n\tpublic void printSet2(Vector<String> hs) {\n        Enumeration<String> elements = hs.elements();\n        while (elements.hasMoreElements()) {\n            System.out.println(elements.nextElement());\n        }\n    }\n}\n\n\n// -----------------------第一种：实现comparable接口 -------------------------\npublic class Student implements Comparable<Object>{\n\tprivate String name;\n\tprivate byte age;\n\tprivate String id;\n\tpublic Student(String name, byte age, String id) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.id = id;\n\t}\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "姓名：" + name + "年龄：" + age + "学号：" + id;\n\t}\n\t@Override\n\tpublic int compareTo(Object obj) {\n\t\t// TODO Auto-generated method stub\n\t\tStudent student = (Student)obj;\n\t\t/*if(this.age>student.age){\n\t\t\treturn 1;\n\t\t}else if(this.age==student.age){\n\t\t\treturn this.name.compareTo(student.name);\n\t\t}else{\n\t\t\treturn -1;\n\t\t}*/\n\t\tif(this.name.equals(student.name)){\n\t\t\treturn this.age-student.age;\n\t\t}else{\n\t\t\treturn this.name.compareTo(student.name);\n\t\t}\n\t}\n}\n\n// -----------------------第二种：Comparator（自定义比较器） -------------------------\npublic class MyComparator implements Comparator<Object>{\n\t@Override\n\tpublic int compare(Object obj1, Object obj2) {\n\t\t// TODO Auto-generated method stub\n\t\tStudents students1 = (Students)obj1;\n\t\tStudents students2 = (Students)obj2;\n\t\t/*if(students1.age>students2.age){\n\t\t\treturn 1;\n\t\t}else if(students1.age==students2.age){\n\t\t\treturn students1.name.compareTo(students2.name);\n\t\t}else{\n\t\t\treturn -1;\n\t\t}*/\n\t\tif(students1.name.equals(students2.name)){\n\t\t\treturn students2.age-students1.age;\n\t\t}else{\n\t\t\treturn students1.name.compareTo(students2.name);\n\t\t}\n\t}\n}\n\npublic class Students {\n\tString name;\n\tbyte age;\n\tString id;\n\tpublic Students(String name, byte age, String id) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.id = id;\n\t}\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn "姓名：" + name + "年龄：" + age + "学号：" + id;\n\t}\n\t@Override\n\tpublic boolean equals(Object obj) {\n\t\t// TODO Auto-generated method stub\n\t\tif(this == obj){\n\t\t\treturn true; \n\t\t}\n\t\tif(obj instanceof Students){\n\t\t\tif(this.id.equals(((Students) obj).id)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\t@Override\n\tpublic int hashCode() {\n\t\t// TODO Auto-generated method stub\n\t\treturn id.hashCode();\n\t}\n}\n\n// --------------------- 测试类 -----------------------------\npublic class Test {\n\tpublic static void main(String[] args) {\n\t\t// TODO Auto-generated method stub\n\t\tHashSet<Student> hs = new HashSet<Student>();\n\t\tStudent s1 = new Student("aaa", (byte) 20, "10086");\n\t\tStudent s2 = new Student("bbb", (byte) 23, "10087");\n\t\tStudent s3 = new Student("ccc", (byte) 21, "10088");\n\t\tStudent s4 = new Student("aaa", (byte) 19, "10089");\n\t\ths.add(s1);\n\t\ths.add(s2);\n\t\ths.add(s3);\n\t\ths.add(s4);\n\t\ths.forEach(str -> System.out.println(str));\n\t\t// System.out.println(hs);\n\t\tSystem.out.println();\n\n\t\tHashSet<Students> hst = new HashSet<Students>();\n\t\tStudents s5 = new Students("aaa", (byte) 20, "10086");\n\t\tStudents s6 = new Students("bbb", (byte) 23, "10087");\n\t\tStudents s7 = new Students("ccc", (byte) 21, "10088");\n\t\tStudents s8 = new Students("aaa", (byte) 19, "10089");\n\t\thst.add(s5);\n\t\thst.add(s6);\n\t\thst.add(s7);\n\t\thst.add(s8);\n\t\thst.forEach(str -> System.out.println(str));\n\n\t\tTreeSet<Student> ts2 = new TreeSet<Student>();\n\t\t// 不实现comparatable时不可排序 运行时错误\n\t\tts2.add(s1);\n\t\tts2.add(s2);\n\t\tts2.add(s3);\n\t\tts2.add(s4);\n\t\t//System.out.println(ts2);\n\t\tSystem.out.println("Comparable：按姓名-年龄排序");\n\t\tIterator<Student> it2 = ts2.iterator();\n\t\tit2.forEachRemaining(stu->System.out.println(stu + ""));\n\n\t\tTreeSet<Students> ts = new TreeSet<Students>(new MyComparator());\n\t\tts.add(s5);\n\t\tts.add(s6);\n\t\tts.add(s7);\n\t\tts.add(s8);\n\t\t//System.out.println(ts);\n\t\tSystem.out.println("Comparator：按姓名-年龄排序");\n\t\tIterator<Students> it = ts.iterator();\n\t\tit.forEachRemaining(stu->System.out.println(stu + " "));\n\t}\n}\n\n\npublic class T_map {\n\tpublic static void main(String[] args) {\n\t\tMap<String, String> map = new HashMap<String, String>();\n\t\tmap.put("aaa", "987654321");\n\t\tmap.put("bbb", "87654321");\n\t\tmap.put("ccc", "7654321");\n\t\tmap.put("ddd", "654321");\n\t\tmap.put("bbb", "54321");\n\t\t// 迭代器遍历\n\t\tSystem.out.println("迭代器遍历：");\n\t\tSet keySet = map.keySet();\n\t\tIterator it = keySet.iterator();\n\t\twhile (it.hasNext()) {\n\t\t\tObject key = it.next();\n\t\t\tObject value = map.get(key);\n\t\t\tSystem.out.print(key + "=" + value +"\\t");\n\t\t}\n\t\tSystem.out.println();\n\t\t// System.out.println(map);\n\n\t\tif (map.containsKey("aaa") && map.get("aaa").equals("987654321")) {\n\t\t\tSystem.out.println("用户存在且密码正确");\n\t\t}else{\n\t\t\tSystem.out.println("用户名或密码不正确");\n\t\t}\n\n\t\tSystem.out.println(map.keySet());\n\t\tSystem.out.println(map.values());\n\n\t\tmap.replace("bbb", "876543210");\n\t\t//foreach遍历\n\t\tSystem.out.println("foreach遍历：");\n\t\tmap.forEach((k,v)->System.out.println(k + "=" +v));\n\n\t\tmap.remove("aaa");\n\t\tSystem.out.println("entrySet方法：");\n\t\tSet entrySet = map.entrySet();\n\t\tIterator it2 = keySet.iterator();\n\t\twhile (it2.hasNext()) {\n\t\t\tObject key = it2.next();\n\t\t\tObject value = map.get(key);\n\t\t\tSystem.out.print(key + "=" + value +"\\t");\n\t\t}\n\t\tSystem.out.println();\n\t\tCollection<String> values = map.values();\n\t\tvalues.forEach(value->System.out.print(value + "    "));\n\t\t\n\t\tSystem.out.println();\n\t\t//按放的顺序输出\n\t\tMap map2 = new LinkedHashMap();\n\t\t//map2.putAll(map);\n\t\tmap2.put("aaa", "987654321");\n\t\tmap2.put("bbb", "87654321");\n\t\tmap2.put("ccc", "7654321");\n\t\tmap2.put("ddd", "654321");\n\t\tmap2.put("bbb", "54321");\n\t\tmap2.forEach((k,v)->System.out.println(k + ":" +v));\n\t}\n}\n\n\npublic class T_Collections {\n\tpublic static void main(String[] args) {\n\t\tStudent stu[] = new Student[3];\n\t\tstu[0] = new Student("aaa",(byte)20,"10086");\n\t\tstu[1] = new Student("bbb",(byte)19,"10087");\n\t\tstu[2] = new Student("ccc",(byte)21,"70088");\n\t\tList<Student> lt = new LinkedList<Student>();\n\t\tlt.add(stu[0]);\n\t\tlt.add(stu[1]);\n\t\tlt.add(stu[2]);\n\t\tlt.forEach(i->System.out.println(i));\n\t\t\n\t\tSystem.out.println("排序后：");\n\t\tCollections.sort(lt);\t\t\t\t\t\t\t//实现比较器（自然排序或定制排序）\n\t\tlt.forEach(i->System.out.println(i));\n\t\t\n\t\tSystem.out.println("二分查找：");\n\t\tStudent s = new Student("ccc",(byte)21,"10087");\t\t//为什么先反转有两个查不到？？？\n\t\tint index = Collections.binarySearch(lt,s,null);\n\t\tSystem.out.println(index);\n\t\t\n\t\tSystem.out.println("反转后：");\n\t\tCollections.reverse(lt);\n\t\tlt.forEach(i->System.out.println(i));\n\t\t\n\t\t//System.out.println(lt);\n\t\t/*Iterator it = lt.iterator();\n\t\twhile(it.hasNext()){\n\t\t\tObject obj = it.next();\n\t\t\tSystem.out.println(obj);\n\t\t}*/\n\t}\n}\n\n\npublic class T_Arrays {\n\tpublic static void main(String[] args) {\n\t\tString arr[] = {"h","l","a","h","b"};\n\t\t//排序\n\t\tSystem.out.println("排序：");\n\t\tArrays.sort(arr);\n\t\tSystem.out.println(Arrays.toString(arr));\n\t\t\n\t\t//二分查找\n\t\tSystem.out.println("二分查找：");\n\t\tint index = Arrays.binarySearch(arr, "l");\n\t\tSystem.out.println("l的位置：" + index);\n\t\t\n\t\t//打印\n\t\tSystem.out.println("打印数组：");\n\t\tSystem.out.println(arr);\n\t\tString str = Arrays.toString(arr);\n\t\tSystem.out.println(str);\n\t\t\n\t\t//根据数组创建ArrayList\n\t\tSystem.out.println("根据数组创建ArrayList:");\n\t\tArrayList al = new ArrayList(Arrays.asList(arr));\n\t\tSystem.out.println(al);\n\t\t\n\t\t//检查数组是否包含某个值\n\t\tSystem.out.println("检查数组是否包含某个值:");\n\t\tboolean b = al.contains("lh");\n\t\tSystem.out.println(b);\n\t}\n}\n\n\nclass CachePool2<T>{\n\t\tT temp;\n\t\tpublic T getTemp() {\n\t\t\treturn temp;\n\t\t}\n\t\tpublic void setTemp(T temp) {\n\t\t\tthis.temp = temp;\n\t\t}\n\t}\npublic class T_CachePool {\n\tpublic static void main(String[] args) {\n\t\tStudent stu = new Student("名字",(byte)20,"10086");\n\t\tCachePool2 c = new CachePool2();\n\t\tc.setTemp(stu);\n\t\tSystem.out.println(c.getTemp());\n\t\tc.setTemp("This is an apple!");\n\t\tSystem.out.println(c.getTemp());\n\t}\n}\n\n\n# Java Stream\n\n作用\n\n 1. 对数组、Collection 等集合类中的元素进行操作\n\n简单实例\n\n> 需求：从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n\n/**\n * 【常规方式】\n * 从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n *\n * @param sentence 给定的句子，约定非空，且单词之间仅由一个空格分隔\n * @return 倒序输出符合条件的单词列表\n */\npublic List<String> sortGetTop3LongWords(@NotNull String sentence) {\n    // 先切割句子，获取具体的单词信息\n    String[] words = sentence.split(" ");\n    List<String> wordList = new ArrayList<>();\n    // 循环判断单词的长度，先过滤出符合长度要求的单词\n    for (String word : words) {\n        if (word.length() > 5) {\n            wordList.add(word);\n        }\n    }\n    // 对符合条件的列表按照长度进行排序\n    wordList.sort((o1, o2) -> o2.length() - o1.length());\n    // 判断list结果长度，如果大于3则截取前三个数据的子list返回\n    if (wordList.size() > 3) {\n        wordList = wordList.subList(0, 3);\n    }\n    return wordList;\n}\n\n\n/**\n * 【Stream方式】\n * 从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n *\n * @param sentence 给定的句子，约定非空，且单词之间仅由一个空格分隔\n * @return 倒序输出符合条件的单词列表\n */\npublic List<String> sortGetTop3LongWordsByStream(@NotNull String sentence) {\n    return Arrays.stream(sentence.split(" "))\n            .filter(word -> word.length() > 5)\n            .sorted((o1, o2) -> o2.length() - o1.length())\n            .limit(3)\n            .collect(Collectors.toList());\n}\n\n\nStream 使用 与 Spark RDD 使用有些许类似？\n\n 1. 创建 Stream\n\n> 主要负责新建一个 Stream 流，或者基于现有的数组 List、Set、Map 等集合类型对象创建出新的Stream流。\n\nAPI                功能说明\nstream()           创建出一个新的stream串行流对象\nparallelStream()   创建出一个可并行执行的stream流对象\nStream.of()        通过给定的一系列元素创建一个新的Stream串行流对象\n\n 2. 转换算子\n\n> 负责对 Stream 进行处理操作，并返回一个新的 Stream 对象，中间管道操作可以进行叠加。\n> \n>  1. 无状态（Stateless）操作：指元素的处理不受之前元素的影响\n>  2. 有状态（Stateful）操作：指该操作只有拿到所有元素之后才能继续下去\n\nAPI           功能说明\nfilter()      1按照条件过滤符合要求的元素， 返回新的stream流\nmap()         1将已有元素转换为另一个对象类型，一对一逻辑，返回新的stream流\nflatMap()     将已有元素转换为另一个对象类型，一对多逻辑，即原来一个元素对象可能会转换为1个或者多个新类型的元素，返回新的stream流\nlimit()       2仅保留集合前面指定个数的元素，返回新的stream流\nskip()        2跳过集合前面指定个数的元素，返回新的stream流\nconcat()      将两个流的数据合并起来为1个新的流，返回新的stream流\ndistinct()    2对Stream中所有元素进行去重，返回新的stream流\nsorted()      2对stream中所有的元素按照指定规则进行排序，返回新的stream流\npeek()        1对stream流中的每个元素进行逐个遍历处理，返回处理后的stream流\nunordered()   1明确地对流进行去除有序约束可以改善某些有状态或终端操作的并行性能。\n\n 3. 终止Stream\n\n> 通过终止管道操作之后，Stream 流将会结束，最后可能会执行某些逻辑处理，或者是按照要求返回某些执行后的结果数据。\n> \n>  1. 短路（Short-circuiting）操作：指遇到某些符合条件的元素就可以得到最终结果\n>  2. 非短路（Unshort-circuiting）操作：指必须处理完所有元素才能得到最终结果\n\nAPI                功能说明\ncount()            2返回stream处理后最终的元素个数\nmax()              2返回stream处理后的元素最大值\nmin()              2返回stream处理后的元素最小值\nfindFirst()        1找到第一个符合条件的元素时则终止流处理\nfindAny()          1找到任何一个符合条件的元素时则退出流处理，这个对于串行流时与findFirst相同，对于并行流时比较高效，任何分片中找到都会终止后续计算逻辑\nanyMatch()         1返回一个boolean值，类似于isContains(),用于判断是否有符合条件的元素\nallMatch()         1返回一个boolean值，用于判断是否所有元素都符合条件\nnoneMatch()        1返回一个boolean值， 用于判断是否所有元素都不符合条件\ncollect()          2将流转换为指定的类型，通过Collectors进行指定\nreduce()           2合并流的元素并产生单个值。\ntoArray()          2将流转换为数组\niterator()         将流转换为Iterator对象\nforEach()          2无返回值，对元素进行逐个遍历，然后执行给定的处理逻辑\nforEachOrdered()   2对该流的每个元素执行操作，并按流的遇到顺序进行。\n\n# 文件操作\n\n\npublic class Test1 {\n\tpublic static void main(String[] args) {\n\t\t// TODO Auto-generated method stub\n\t\tFileInputStream fis=null;\n\t\tFileOutputStream fos=null;\n\t\ttry{\n\t\t\tfis = new FileInputStream("file/Hello.txt");\n\t\t\tfos = new FileOutputStream("file/Hello副本.txt",true);\n\t\t\t\n\t\t\tlong start = System.currentTimeMillis();\n\t\t\tint b;\n\t\t\twhile((b=fis.read())!=-1){\n\t\t\t\tfos.write(b);\n\t\t\t}\n\t\t\tlong end = System.currentTimeMillis();\n\t\t\tSystem.out.println(end-start + " ms");\n\n\t\t}catch(IOException e){\n\t\t\tSystem.out.println("拷贝出错");\n\t\t}finally{\n\t\t\ttry{\n\t\t\t\tif(fos!=null){\n\t\t\t\t\tfos.close();\n\t\t\t\t\tSystem.out.println("关闭输出流对象成功");\n\t\t\t\t}\n\t\t\t}catch(Exception e){\n\t\t\t\tSystem.out.println("关闭输出流对象失败");\n\t\t\t}finally{\n\t\t\t\ttry{\n\t\t\t\t\tif(fis!=null){\n\t\t\t\t\t\tfis.close();\n\t\t\t\t\t\tSystem.out.println("关闭输入流对象成功");\n\t\t\t\t\t}\n\t\t\t\t}catch(Exception e){\n\t\t\t\t\tSystem.out.println("关闭输入流对象失败");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n\npublic class Test2 {\n\tpublic static void main(String[] args) throws IOException {\n\t\t// TODO Auto-generated method stub\n\t\tFileInputStream fis = new FileInputStream("file/视频.mp4");\n\t\tFileOutputStream fos = new FileOutputStream("file/视频副本.MP4");\n\t\t\n\t\tbyte buff[] = new byte[8192];\n\t\tlong start = System.currentTimeMillis();\n\t\tint len;\n\t\twhile((len=fis.read(buff))!=-1){\n\t\t\tfos.write(buff,0,len);\n\t\t}\n\t\tlong end = System.currentTimeMillis();\n\t\tSystem.out.println(end-start + " ms");\n\t\t\n\t\tfos.close();\n\t\tfis.close();\n\t}\n}\n\n\npublic class Test3 {\n\tpublic static void main(String[] args) throws Exception {\n\t\t// TODO Auto-generated method stub\n\t\tBufferedInputStream bis = new BufferedInputStream(new FileInputStream("file/猫.jpg"));\n\t\tBufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream("file/猫副本.jpg"));\n\t\tlong start = System.currentTimeMillis();\n\t\tint len;\n\t\twhile((len=bis.read())!=-1){\n\t\t\tbos.write(len);\n\t\t}\n\t\tlong end = System.currentTimeMillis();\n\t\tSystem.out.println(end-start + " ms");\n\t\tbos.close();\n\t\tbis.close();\n\t}\n}\n\n\npublic class Test4 {\n\tpublic static void main(String[] args) throws IOException {\n\t\t// TODO Auto-generated method stub\n\t\tFileReader fr = new FileReader("file/文档.txt");\n\t\tFileWriter fw = new FileWriter("file/文档副本.txt");\n\t\tlong start = System.currentTimeMillis();\n\t\tint len;\n\t\twhile((len=fr.read())!=-1){\n\t\t\tfw.write(len);\n\t\t}\n\t\tfw.write("\\r\\n");\n\t\tfw.write("玲珑骰子");\n\t\tfw.write("安红豆，\\r\\n");\n\t\tfw.write("入骨相思");\n\t\tfw.write("君知否");\n\t\tlong end = System.currentTimeMillis();\n\t\tSystem.out.println(end-start + "ms");\n\t\tfw.close();\n\t\tfr.close();\n\t}\n}\n\n\npublic class Test5 {\n\tpublic static void main(String[] args) throws IOException {\n\t\t// TODO Auto-generated method stub\n\t\tBufferedReader br = new BufferedReader(new FileReader("file/文档.txt"));\n\n\t\tBufferedWriter bw = new BufferedWriter(new FileWriter("file/文档副本1.txt"));\n\t\tlong start = System.currentTimeMillis();\n\t\tString str = null;\n\t\twhile ((str = br.readLine()) != null) {\n\t\t\tbw.write(str);\n\t\t\tbw.newLine();\n\t\t}\n\t\tlong end = System.currentTimeMillis();\n\t\tSystem.out.println(end - start + " ms");\n\t\tbw.close();\n\t\tbr.close();\n\t}\n}\n\n\npublic class Test6 {\n\tpublic static void main(String[] args) throws IOException {\t\t\t//转换流\n\t\tFileInputStream fis = new FileInputStream("file/reader.txt");\n\t\tInputStreamReader isr = new InputStreamReader(fis);\n\t\tBufferedReader br = new BufferedReader(isr);\n\t\t\n\t\tFileOutputStream fos = new FileOutputStream("file/writer.txt");\n\t\tOutputStreamWriter osr = new OutputStreamWriter(fos);\n\t\tBufferedWriter bw = new BufferedWriter(osr);\n\n\t\tString line=null;\n\t\twhile((line=br.readLine())!=null){\n\t\t\tbw.write(line);\n\t\t\tbw.newLine();\t\t\t\t\t\t//换行\n\t\t\tbw.flush();\t\t\t\t\t\t\t//刷新缓冲\n\t\t\tif(line.equals("end")){\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t\n\t\tbw.close();\n\t\tbw.close();\n\t}\n}\n\n\npublic class Test7 {\n\tpublic static void main(String[] args) {\n\n\t\tStudent stu=new Student("学生");\n\t\tDecorator dec = new Decorator(stu);\n\t\tSystem.out.println(dec);\n\t\tdec.study();\n\t}\n}\nclass Student{\n\tprivate String name;\n\tpublic Student(){\n\t\t\n\t}\n\tpublic Student(String name) {\n\t\tsuper();\n\t\tthis.name = name;\n\t}\n\tpublic String getName(){\n\t\treturn name;\n\t}\n\tpublic void study(){\n\t\tSystem.out.println("做题");\n\t}\n}\nclass Decorator{\n\tStudent s = new Student();\n\tpublic Decorator(Student s) {\n\t\tsuper();\n\t\tthis.s = s;\n\t}\n\tpublic void study(){\n\t\ts.study();\n\t\tSystem.out.println("看书");\n\t}\n\t@Override\n\tpublic String toString() {\n\t\treturn "姓名：" + s.getName();\n\t}\n}\n\n\nclass Hero implements Serializable{\n\tprivate static final long serialVersionUID = 1L;\n\tprivate String name;\n\tprivate int hp;\n\tpublic Hero(String name, int hp) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.hp = hp;\n\t}\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\tpublic int getHp() {\n\t\treturn hp;\n\t}\n\tpublic void setHp(int hp) {\n\t\tthis.hp = hp;\n\t}\n\t@Override\n\tpublic String toString() {\n\t\t// TODO Auto-generated method stub\n\t\treturn name + "  " + hp;\n\t}\n}\n\npublic class Test8 {\n\tpublic static void main(String[] args) throws IOException, ClassNotFoundException {\n\n\t\tFileOutputStream fos = new FileOutputStream("file/hero.txt",true);\n\t\tObjectOutputStream oos = new ObjectOutputStream(fos);\n\t\t\n\t\tFileInputStream fis = new FileInputStream("file/hero.txt");\n\t\tObjectInputStream ois = new ObjectInputStream(fis);\n\t\t\n\t\tHero hero = new Hero("德鲁伊",1000);\n\t\tSystem.out.println(hero);\n\t\toos.writeObject(hero);\n\n\t\tfor (int i = 0; i < 5; i++) {\n\t\t\thero.setHp(hero.getHp()-(int)Math.floor(Math.random()*200));\n\t\t}\n\t\tSystem.out.println(hero);\n\t\t\n\t\thero = (Hero)(ois.readObject());\n\t\tSystem.out.println(hero);\n\t\t\n\t\tois.close();\n\t\tfis.close();\n\t\toos.close();\n\t\tfos.close();\n\t}\n}\n\n\n// 数据输出流允许应用程序以与机器无关方式将Java基本数据类型写到底层输出流\npublic class Test_Data_Stream {\n\n\tpublic static void main(String[] args) throws Exception {\n\t\tFileOutputStream fos = new FileOutputStream("file/文本.txt");\n\t\tDataOutputStream dos = new DataOutputStream(new BufferedOutputStream(fos));\n\n\t\tdos.writeByte(01);\n\t\tdos.writeDouble(99.999999);\n\t\tdos.writeInt(516546);\n\t\tdos.writeBoolean(false);\n\t\tdos.writeUTF("龘龘");\n\n\t\tdos.close();\n\t\tfos.close();\n\n\t\tFileInputStream fis = new FileInputStream("file/文本.txt");\n\t\tDataInputStream dis = new DataInputStream(new BufferedInputStream(fis));\n\n\t\tSystem.out.println(dis.readByte());\n\t\tSystem.out.println(dis.readDouble());\n\t\tSystem.out.println(dis.readInt());\n\t\tSystem.out.println(dis.readBoolean());\n\t\tSystem.out.println(dis.readUTF());\n\n\t\tdis.close();\n\t\tfis.close();\n\t}\n}\n\n\n// 合并流：它从输入流的有序集合开始，并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末尾为止\npublic class Test_Sequence {\n\tpublic static void main(String[] args) throws Exception {\n\t\t// 创建了两个流对象in1、in2\n\t\tFileInputStream in1 = new FileInputStream("file/stream1.txt");\n\t\tFileInputStream in2 = new FileInputStream("file/stream2.txt");\n\t\t// 创建一个序列流，合并两个字节流in1和in2\n\t\tSequenceInputStream sis = new SequenceInputStream(in1, in2);\n\t\tFileOutputStream out = new FileOutputStream("file/stream.txt");\n\t\tint len;\n\t\t// 创建一个1024个字节数组作为缓冲区\n\t\tbyte[] buf = new byte[1024];\n\t\t// 同时三个流！\n\t\twhile ((len = sis.read(buf)) != -1) {\n\t\t\tout.write(buf, 0, len); // 将缓冲区中的数据输出\n\t\t\tout.write("\\r\\n".getBytes());\n\t\t}\n\t\tsis.close();\n\t\tout.close();\n\t}\n}\n\n\n//System.in是InputStream, 标准输入流, 默认可以从键盘输入读取字节数据\n//System.out是PrintStream, 标准输出流, 默认可以向Console中输出字符和字节数据\npublic class Test_Print1 {\n\tpublic static void main(String[] args) throws IOException{\n\n\t\t// inputStream();\n\t\tSystem.setIn(new FileInputStream("file/in.txt")); // 改变标准输入流\n\t\tSystem.setOut(new PrintStream("file/out.txt")); // 改变标准输出流\n\t\tInputStream is = System.in; // 获取标准的键盘输入流，默认指向键盘，改变后指向文件\n\t\tPrintStream ps = System.out; // 获取标准的输出流，默认指向的是控制台，改变后就指向文件\n\n\t\tint b;\n\t\twhile ((b = is.read()) != -1) {\n\t\t\tps.write(b);\n\t\t}\n\t\tis.close();\n\t\tps.close();\n\t}\n}\n\n// ----------------------------------------------------------------------\n\npublic class Test_Print2 {\n\tpublic static void main(String[] args) throws Exception {\n\t\tSystem.setIn(new FileInputStream("file/in.txt"));\t\t//改变后指向文件\n\t\tInputStream is2=System.in;\n\t\tPrintStream ps2 = System.out;\n\t\tint b2;\n\t\twhile ((b2 = is2.read()) != -1) {\n\t\t\tps2.write(b2);\n\t\t}\n\t\tps2.close();\n\t\tis2.close();\n\t\t\n\t\t/*System.setOut(new PrintStream("file/out.txt"));\n\t\tInputStream is3=System.in;\n\t\tPrintStream ps3 = System.out;\n\t\tint b3;\n\t\twhile ((b3 = is3.read()) != -1) {\n\t\t\tps3.write(b3);\n\t\t}\n\t\tps3.close();\n\t\tis3.close();*/\n\t}\n}\n\n\npublic static void main(String[] args) {\n    try {\n        FileInputStream fis = new FileInputStream("D://java.txt");\n        InputStreamReader isr = new InputStreamReader(fis, "UTF-8");\n        int b = 0;\n        while ((b = isr.read()) != -1) {\n            System.out.print((char) b);    // 输出结果为“C语言中文网”\n        }\n    } catch (FileNotFoundException e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n    } catch (IOException e) {\n        // TODO Auto-generated catch block\n        e.printStackTrace();\n    }\n}\n\n\nimport java.io.*;\nimport java.net.MalformedURLException;\nimport java.net.URL;\n\n/**\n * 文件工具类\n */\npublic class FileUtil {\n    /**\n     * 读取文件内容\n     *\n     * @param is\n     * @return\n     */\n    public static String readFile(InputStream is) {\n        BufferedReader br = null;\n        StringBuffer sb = new StringBuffer();\n        try {\n            br = new BufferedReader(new InputStreamReader(is, "UTF-8"));\n            String readLine = null;\n            while ((readLine = br.readLine()) != null) {\n                sb.append(readLine+"\\r\\n");\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            try {\n                br.close();\n                is.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n        return sb.toString();\n    }\n    /**\n     * @description 写文件\n     * @param args\n     * @throws UnsupportedEncodingException\n     * @throws IOException\n     */\n    public static boolean writeTxtFile(String content, File fileName, String encoding) {\n        FileOutputStream o = null;\n        boolean result=false;\n        try {\n            o = new FileOutputStream(fileName);\n            o.write(content.getBytes(encoding));\n            result=true;\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        } catch (UnsupportedEncodingException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if (o != null) {\n                try {\n                    o.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n\n        return result;\n    }\n    public static String readFile(String path){\n        File file07 = new File(path);\n        InputStream is=null;\n        try {\n            is = new FileInputStream(file07);\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        }\n        return readFile(is);\n    }\n    \n    /**\n     * 判断指定的文件是否存在。\n     *\n     * @param fileName\n     * @return\n     */\n    public static boolean isFileExist(String fileName) {\n        return new File(fileName).isFile();\n    }\n\n    /**\n     * 创建指定的目录。 如果指定的目录的父目录不存在则创建其目录书上所有需要的父目录。\n     * 注意：可能会在返回false的时候创建部分父目录。\n     *\n     * @param file\n     * @return\n     */\n    public static boolean makeDirectory(File file) {\n        File parent = file.getParentFile();\n        if (parent != null) {\n            return parent.mkdirs();\n        }\n        return false;\n    }\n\n    /**\n     * 返回文件的URL地址。\n     *\n     * @param file\n     * @return\n     * @throws MalformedURLException\n     */\n    public static URL getURL(File file) throws MalformedURLException {\n        String fileURL = "file:/" + file.getAbsolutePath();\n        URL url = new URL(fileURL);\n        return url;\n    }\n\n    /**\n     * 从文件路径得到文件名。\n     *\n     * @param filePath\n     * @return\n     */\n    public static String getFileName(String filePath) {\n        File file = new File(filePath);\n        return file.getName();\n    }\n\n    /**\n     * 从文件名得到文件绝对路径。\n     *\n     * @param fileName\n     * @return\n     */\n    public static String getFilePath(String fileName) {\n        File file = new File(fileName);\n        return file.getAbsolutePath();\n    }\n\n    /**\n     * 将DOS/Windows格式的路径转换为UNIX/Linux格式的路径。\n     *\n     * @param filePath\n     * @return\n     */\n    public static String toUNIXpath(String filePath) {\n        return filePath.replace("", "/");\n    }\n\n    /**\n     * 从文件名得到UNIX风格的文件绝对路径。\n     *\n     * @param fileName\n     * @return\n     */\n    public static String getUNIXfilePath(String fileName) {\n        File file = new File(fileName);\n        return toUNIXpath(file.getAbsolutePath());\n    }\n\n    /**\n     * 得到文件后缀名\n     *\n     * @param fileName\n     * @return\n     */\n    public static String getFileExt(String fileName) {\n        int point = fileName.lastIndexOf(\'.\');\n        int length = fileName.length();\n        if (point == -1 || point == length - 1) {\n            return "";\n        } else {\n            return fileName.substring(point + 1, length);\n        }\n    }\n\n    /**\n     * 得到文件的名字部分。 实际上就是路径中的最后一个路径分隔符后的部分。\n     *\n     * @param fileName\n     * @return\n     */\n    public static String getNamePart(String fileName) {\n        int point = getPathLastIndex(fileName);\n        int length = fileName.length();\n        if (point == -1) {\n            return fileName;\n        } else if (point == length - 1) {\n            int secondPoint = getPathLastIndex(fileName, point - 1);\n            if (secondPoint == -1) {\n                if (length == 1) {\n                    return fileName;\n                } else {\n                    return fileName.substring(0, point);\n                }\n            } else {\n                return fileName.substring(secondPoint + 1, point);\n            }\n        } else {\n            return fileName.substring(point + 1);\n        }\n    }\n\n    /**\n     * 得到文件名中的父路径部分。 对两种路径分隔符都有效。 不存在时返回""。\n     * 如果文件名是以路径分隔符结尾的则不考虑该分隔符，例如"/path/"返回""。\n     *\n     * @param fileName\n     * @return\n     */\n    public static String getPathPart(String fileName) {\n        int point = getPathLastIndex(fileName);\n        int length = fileName.length();\n        if (point == -1) {\n            return "";\n        } else if (point == length - 1) {\n            int secondPoint = getPathLastIndex(fileName, point - 1);\n            if (secondPoint == -1) {\n                return "";\n            } else {\n                return fileName.substring(0, secondPoint);\n            }\n        } else {\n            return fileName.substring(0, point);\n        }\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中最后出现的位置。 对于DOS或者UNIX风格的分隔符都可以。\n     *\n     * @param fileName\n     * @return\n     */\n    public static int getPathLastIndex(String fileName) {\n        int point = fileName.lastIndexOf("/");\n        if (point == -1) {\n            point = fileName.lastIndexOf("");\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中指定位置前最后出现的位置。 对于DOS或者UNIX风格的分隔符都可以。\n     *\n     * @param fileName\n     * @param fromIndex\n     * @return\n     */\n    public static int getPathLastIndex(String fileName, int fromIndex) {\n        int point = fileName.lastIndexOf("/", fromIndex);\n        if (point == -1) {\n            point = fileName.lastIndexOf("", fromIndex);\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中首次出现的位置。 对于DOS或者UNIX风格的分隔符都可以。\n     *\n     * @param fileName\n     * @return\n     */\n    public static int getPathIndex(String fileName) {\n        int point = fileName.indexOf("/");\n        if (point == -1) {\n            point = fileName.indexOf("");\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中指定位置后首次出现的位置。 对于DOS或者UNIX风格的分隔符都可以。\n     *\n     * @param fileName\n     * @param fromIndex\n     * @return\n     */\n    public static int getPathIndex(String fileName, int fromIndex) {\n        int point = fileName.indexOf("/", fromIndex);\n        if (point == -1) {\n            point = fileName.indexOf("", fromIndex);\n        }\n        return point;\n    }\n\n    /**\n     * 将文件名中的类型部分去掉。\n     *\n     * @param filename\n     * @return\n     */\n    public static String removeFileExt(String filename) {\n        int index = filename.lastIndexOf(".");\n        if (index != -1) {\n            return filename.substring(0, index);\n        } else {\n            return filename;\n        }\n    }\n\n    /**\n     * 得到相对路径。 文件名不是目录名的子节点时返回文件名。\n     *\n     * @param pathName\n     * @param fileName\n     * @return\n     */\n    public static String getSubpath(String pathName, String fileName) {\n        int index = fileName.indexOf(pathName);\n        if (index != -1) {\n            return fileName.substring(index + pathName.length() + 1);\n        } else {\n            return fileName;\n        }\n    }\n\n    /**\n     * 删除一个文件。\n     *\n     * @param filename\n     * @throws IOException\n     */\n    public static void deleteFile(String filename) throws IOException {\n        File file = new File(filename);\n        if (file.isDirectory()) {\n            throw new IOException("IOException -> BadInputException: not a file.");\n        }\n        if (!file.exists()) {\n            throw new IOException("IOException -> BadInputException: file is not exist.");\n        }\n        if (!file.delete()) {\n            throw new IOException("Cannot delete file. filename = " + filename);\n        }\n    }\n\n    /**\n     * 删除文件夹及其下面的子文件夹\n     *\n     * @param dir\n     * @throws IOException\n     */\n    public static void deleteDir(File dir) throws IOException {\n        if (dir.isFile())\n            throw new IOException("IOException -> BadInputException: not a directory.");\n        File[] files = dir.listFiles();\n        if (files != null) {\n            for (int i = 0; i < files.length; i++) {\n                File file = files[i];\n                if (file.isFile()) {\n                    file.delete();\n                } else {\n                    deleteDir(file);\n                }\n            }\n        }\n        dir.delete();\n    }\n\n    /**\n     * 复制文件\n     *\n     * @param src\n     * @param dst\n     * @throws Exception\n     */\n    public static void copy(File src, File dst) throws Exception {\n        int BUFFER_SIZE = 4096;\n        InputStream in = null;\n        OutputStream out = null;\n        try {\n            in = new BufferedInputStream(new FileInputStream(src), BUFFER_SIZE);\n            out = new BufferedOutputStream(new FileOutputStream(dst), BUFFER_SIZE);\n            byte[] buffer = new byte[BUFFER_SIZE];\n            int len = 0;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } catch (Exception e) {\n            throw e;\n        } finally {\n            if (null != in) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n                in = null;\n            }\n            if (null != out) {\n                try {\n                    out.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n                out = null;\n            }\n        }\n    }\n\n    /**\n     * @复制文件，支持把源文件内容追加到目标文件末尾\n     * @param src\n     * @param dst\n     * @param append\n     * @throws Exception\n     */\n    public static void copy(File src, File dst, boolean append) throws Exception {\n        int BUFFER_SIZE = 4096;\n        InputStream in = null;\n        OutputStream out = null;\n        try {\n            in = new BufferedInputStream(new FileInputStream(src), BUFFER_SIZE);\n            out = new BufferedOutputStream(new FileOutputStream(dst, append), BUFFER_SIZE);\n            byte[] buffer = new byte[BUFFER_SIZE];\n            int len = 0;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } catch (Exception e) {\n            throw e;\n        } finally {\n            if (null != in) {\n                try {\n                    in.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n                in = null;\n            }\n            if (null != out) {\n                try {\n                    out.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n                out = null;\n            }\n        }\n    }\n}\n\n\n# javax.swing（略，已经很少使用）\n\n# 网络编程（略，java.net包）\n\n\n# 注解\n\n# 定义\n\n> Java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。\n> 注解相关类都包含在java.lang.annotation包中。\n\n# JDK基本注解\n\n 1. @Override 重写\n 2. @Deprecated 已过时\n 3. @SuppressWarnings(value = "unchecked") 压制编辑器警告\n\n# JDK元注解\n\n> 元注解用于修饰其他的注解\n\n/* 定义注解的保留策略 */\n@Retention(RetentionPolicy.SOURCE)             // 注解仅存在于源码中，在class字节码文件中不包含\n@Retention(RetentionPolicy.CLASS)              // 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得，\n@Retention(RetentionPolicy.RUNTIME)            // 注解会在class字节码文件中存在，在运行时可以通过反射获取到\n\n\n/* 指定被修饰的Annotation可以放置的位置(被修饰的目标) */\n@Target(ElementType.TYPE)                      // 类、接口（包括注解类型）或 enum 声明\n@Target(ElementType.FIELD)                     // 用于成员变量（包括枚举常量）\n@Target(ElementType.METHOD)                    // 方法\n@Target(ElementType.PARAMETER)                 // 方法参数\n@Target(ElementType.CONSTRUCTOR)               // 构造函数\n@Target(ElementType.LOCAL_VARIABLE)            // 局部变量\n@Target(ElementType.ANNOTATION_TYPE)           // 注解\n@Target(ElementType.PACKAGE)                   // 包 \n\n\n// 指定被修饰的Annotation将具有继承性\n\n\n// 指定被修饰的该Annotation可以被javadoc工具提取成文档\n\n\n# 自定义注解\n\n 1. 标记注解：没有定义成员变量的注解类型被称为标记注解。这种注解仅利用自身的存在与否来提供信息，如 @Override。\n    \n    // 定义一个简单的注解类型\n    public @interface Test {\n    \n    }\n    \n\n 2. 元数据注解：包含成员变量的注解，因为它们可以接受更多的元数据，所以也被称为元数据注解。\n    \n    public @interface MyTag {\n        // 定义了两个成员变量的注解\n        // 使用default为两个成员变量指定初始值\n        String name() default "C语言中文网";\n        int age() default 7;\n    }\n    \n\n# 通过反射获取注解信息\n\n@XmlRootElement(name="user")\n@XmlAccessorType(XmlAccessType.FIELD)\npublic class User {\n \n  private String pwd;\n \n  @XmlElement(name = "ID")\n  private int id;\n  \n  @XmlAttribute\n  @XmlElement\n  private String name;\n  \n  /***\n   *  1、获取属性上的指定类型的注释\n   *  2、获取属性上的指定类型的注释的指定方法\n   *  3、获取属性上的所有注释\n   *  4、获取类上的所有注释\n   *  5、获取方法上的所有注释\n   */\n  @SuppressWarnings("rawtypes")\n  public static void main(String[] args) {\n    \n    Field[] fields =  User.class.getDeclaredFields();\n    \n    for(Field f : fields){\n      String filedName = f.getName();\n      System.out.println("属性名称:【"+filedName+"】");\n \n      //1、获取属性上的指定类型的注释\n      Annotation annotation = f.getAnnotation(XmlElement.class);\n      \n      //有该类型的注释存在\n      if (annotation!=null) {\n        //强制转化为相应的注释\t\n        XmlElement xmlElement = (XmlElement)annotation;\n        //3、获取属性上的指定类型的注释的指定方法\n        //具体是不是默认值可以去查看源代码\n        if (xmlElement.name().equals("##default")) {\n          System.out.println("属性【"+filedName+"】注释使用的name是默认值: "+xmlElement.name());\n        }else {\n          System.out.println("属性【"+filedName+"】注释使用的name是自定义的值: "+xmlElement.name());\n        }\n      }\n \n      //2、获取属性上的所有注释\n      Annotation[] allAnnotations = f.getAnnotations();\n      \n      for(Annotation an : allAnnotations){\n        \n        Class annotationType = an.annotationType();\n        \n        System.out.println("属性【"+filedName+"】的注释类型有: " + annotationType);\n      }\n      System.out.println("----------华丽的分割线--------------");\n    }\n    \n    //4、获取类上的所有注释\n    Annotation[] classAnnotation = User.class.getAnnotations();\n    \n    for(Annotation cAnnotation : classAnnotation){\n      Class annotationType =  cAnnotation.annotationType();\n      System.out.println("User类上的注释有: " +annotationType);\n    }\n    \n    System.out.println("----------华丽的分割线--------------");\n    \n    // 5、获取方法上的所有注释\n    Method method;\n    try {\n      method = User.class.getMethod("setPwd",String.class);\n      \n      Annotation[] methodAnnotations = method.getAnnotations();\n \n      for(Annotation me : methodAnnotations){\n        Class annotationType =  me.annotationType();\n        System.out.println("setPwd方法上的注释有: " + annotationType);\n      }\n    } catch (SecurityException e) {\n      e.printStackTrace();\n    } catch (NoSuchMethodException e) {\n      e.printStackTrace();\n    }\n  }\n \n  @XmlElement\n  public void setPwd(String pwd) {\n    this.pwd = pwd;\n  }\n \n  public String getPwd() {\n    return pwd;\n  }\n}\n',normalizedContent:'# 基础语法\n\n# 8种基本数据类型\n\npublic class data {\n\tpublic static void main(string[] args) {\n\t    // byte  \n        system.out.println("基本类型：byte 二进制位数：" + byte.size);  \n        system.out.println("包装类：java.lang.byte");  \n        system.out.println("最小值：byte.min_value=" + byte.min_value);  \n        system.out.println("最大值：byte.max_value=" + byte.max_value);  \n        system.out.println();  \n  \n        // short  \n        system.out.println("基本类型：short 二进制位数：" + short.size);  \n        system.out.println("包装类：java.lang.short");  \n        system.out.println("最小值：short.min_value=" + short.min_value);  \n        system.out.println("最大值：short.max_value=" + short.max_value);  \n        system.out.println();  \n  \n        // int  \n        system.out.println("基本类型：int 二进制位数：" + integer.size);  \n        system.out.println("包装类：java.lang.integer");  \n        system.out.println("最小值：integer.min_value=" + integer.min_value);  \n        system.out.println("最大值：integer.max_value=" + integer.max_value);  \n        system.out.println();  \n  \n        // long  \n        system.out.println("基本类型：long 二进制位数：" + long.size);  \n        system.out.println("包装类：java.lang.long");  \n        system.out.println("最小值：long.min_value=" + long.min_value);  \n        system.out.println("最大值：long.max_value=" + long.max_value);  \n        system.out.println();  \n  \n        // float  \n        system.out.println("基本类型：float 二进制位数：" + float.size);  \n        system.out.println("包装类：java.lang.float");  \n        system.out.println("最小值：float.min_value=" + float.min_value);  \n        system.out.println("最大值：float.max_value=" + float.max_value);  \n        system.out.println();  \n  \n        // double  \n        system.out.println("基本类型：double 二进制位数：" + double.size);  \n        system.out.println("包装类：java.lang.double");  \n        system.out.println("最小值：double.min_value=" + double.min_value);  \n        system.out.println("最大值：double.max_value=" + double.max_value);  \n        system.out.println();  \n  \n        // char  \n        system.out.println("基本类型：char 二进制位数：" + character.size);  \n        system.out.println("包装类：java.lang.character");  \n        // 以数值形式而不是字符形式将character.min_value输出到控制台  \n        system.out.println("最小值：character.min_value="  + (int) character.min_value);  \n        // 以数值形式而不是字符形式将character.max_value输出到控制台  \n        system.out.println("最大值：character.max_value="  + (int) character.max_value); \n        \n        // 布尔\n        boolean bool1=false;\n        byte b =15;\n        short s = (short)3556;\n        int i = 150;\n        long l = 31356l;\n        float f = 12.345f;\n        double d = 20.1236467892;\n        char c = \'b\';\n        system.out.println("\\n" + "bool1=" + bool1 +" b="+b + " s="+s +" i="+i +" l="+l +" f="+f +" d="+d + " c=" +c +"\\n");\n        \n        system.out.println("i++=" + (i++) +"\\n");\n        i=150;\n        system.out.println("++i=" + (++i) +"\\n");\n        \n        i=150;\n        system.out.println("i--=" + (i--) +"\\n");\n        i=150;\n        system.out.println("--i=" + (--i) +"\\n");\n    }\n}\n\n\n# 流程控制\n\n\npublic static void main(string[] args) {\n    here: while (true) {\n        system.out.println("请输入成绩：（0-100）");\n        scanner scan = new scanner(system.in);\n        int score = scan.nextint();\n        if (score > 100) {\n            system.out.println("输入错误！");\n        } else {\n            switch (score / 10) {\n            case 10:\n            case 9:\n                system.out.println("优秀");\n                break;\n            case 8:\n                system.out.println("良好");\n                break;\n            case 7:\n                system.out.println("中等");\n                break;\n            case 6:\n                system.out.println("及格");\n                break;\n            case 5:\n            case 4:\n            case 3:\n            case 2:\n            case 1:\n            case 0:\n                system.out.println("不及格");\n                break;\n            default:\n                system.out.println("输入错误！请输入0-100的数。");\n                break here;\n            }\n        }\n    }\n}\n\n\npublic static void main(string[] args) {\n    while (true) {\n        system.out.println("请输入年份：");\n        scanner scan = new scanner(system.in);\n        int year = scan.nextint();\n        if (year % 400 == 0 || year % 4 == 0 && year % 100 != 0) {\n            system.out.println(year + "是闰年");\n            system.exit(0);\n        } else {\n            system.out.println(year + "不是闰年");\n        }\n    }\n}\n\n\npublic static void main(string[] args) {\n    system.out.println("请输入一个数：");\n    scanner scan = new scanner(system.in);\n    int num = scan.nextint();\n    boolean flag = true;\n    for(int i=2;i<num;i++)\n    {\n        if(num%i == 0){\n            flag = false;\n        }\n        else{\n        }\n    }\n    if(flag==true){\n        system.out.println(num + "是质数");\n    }\n    else{\n        system.out.println(num + "不是质数");\n    }\n}\n// ------------------------------------------\npublic static void main(string[] args) {\n    for (int i = 2; i <= 1000; i++) {\n        boolean flag = true;\n        int n = i;\n        for (int j = 2; j < math.sqrt(i) + 1; j++) {\n            if (n % j == 0) {\n                flag = false;\n            }\n        }\n        if (flag == true) {\n            system.out.println(n + "是质数");\n        } else {\n            system.out.println(n + "不是质数");\n        }\n    }\n}\n\n\npublic static void main(string[] args) {\n    // todo auto-generated method stub\n    int a[]=new int[] {\n            45, 52, 23, 63, 25,\n            13, 22, 42, 32, 20,\n            46, 55, 35, 32, 66\n    };\n    \n    system.out.println("输出原数组：");\n    for (int i:a) {\n        system.out.print(i + " ");\n    }\n    \n    system.out.println();\n    int sum = 0;\n    int average = 0;\n    int max = a[0];\n    for (int i = 0; i < a.length; i++) {        \n        sum += a[i];\n        if(max<a[i]){\n            max = a[i];\n        }\n    }\n    system.out.println("max = " + max);\n    average = sum / a.length;\n    system.out.println("average = " + average);\n    \n    int len = a.length;\n    boolean flag = true;\n    while (flag) {\n        flag = false;\n        for (int i = 1; i < a.length; i++) {\n            if (a[i - 1] > a[i]) {\n                int temp = a[i];\n                a[i] = a[i-1];\n                a[i-1] = temp;\n                flag = true;\n            }\n        }\n        len -- ;\n    }\n    system.out.println("排序后数组：");\n    for (int i:a) {\n        system.out.print(i + " ");\n    }\n}\n\n\npublic class method2 {\n    public static long fib(int n){\n        if(n==1||n==2) {\n            return 1;\n        } else {\n            return fib(n-1)+fib(n-2);\n        }\n    }\n    \n    public static long fib1(int n){\n        long f[] = new long[n]; \n        f[0]=1;\n        f[1]=1;\n        for (int i = 2; i < f.length; i++) {\n            f[i]=f[i-1]+f[i-2];\n        }\n        return f[n-1];\n    }\n    //公式：fib(n) = pow(((1 + sqrt(5)) / 2.0),n) / sqrt(5) - pow(((1 - sqrt(5)) / 2.0),n) / sqrt(5));\n    public static long fib2(int n) {\n        int f[] = new int[n+1];\n        f[n] = (int) (math.pow(((1 + math.sqrt(5)) / 2.0),n) / math.sqrt(5) - math.pow(((1 - math.sqrt(5)) / 2.0),n) / math.sqrt(5));\n        return f[n];\n    }\n    \n    public static long[][] fib3(int n) {\n        long a[][] = { { 1, 1 }, { 1, 0 } }; // 定义基矩阵\n        long b[][]; // 存储子方法的结果\n        long c[][] = new long[2][2]; // 存储最后计算结果\n        long d[][] = new long[2][2]; // 存储中间计算结果\n        if ((n) <= 1)\n            return a; // 如果次方小等于1直接返回\n        else if ((n) % 2 == 1) {\n            b = fib3((n - 1) / 2);\n\n            d[0][0] = b[0][0] * b[0][0] + b[0][1] * b[1][0];\n            d[0][1] = b[0][0] * b[0][1] + b[0][1] * b[1][1];\n            d[1][0] = b[1][0] * b[0][0] + b[1][1] * b[1][0];\n            d[1][1] = b[1][0] * b[0][1] + b[1][1] * b[1][1];\n\n            c[0][0] = d[0][0] * a[0][0] + d[0][1] * a[1][0];\n            c[0][1] = d[0][0] * a[0][1] + d[0][1] * a[1][1];\n            c[1][0] = d[1][0] * a[0][0] + d[1][1] * a[1][0];\n            c[1][1] = d[1][0] * a[0][1] + d[1][1] * a[1][1];\n\n        } else {\n            b = fib3((n) / 2);\n\n            c[0][0] = b[0][0] * b[0][0] + b[0][1] * b[1][0];\n            c[0][1] = b[0][0] * b[0][1] + b[0][1] * b[1][1];\n            c[1][0] = b[1][0] * b[0][0] + b[1][1] * b[1][0];\n            c[1][1] = b[1][0] * b[0][1] + b[1][1] * b[1][1];\n        }\n        return c;\n    }\n}\n\n\n# 函数（方法）\n\n\n  public class method1 {\n      public static void showarr(int a1[]) {\n          for (int i = 0; i < a1.length; i++) {\n              system.out.print(a1[i] + "  ");\n          }\n          system.out.println();\n      }\n      //showarr方法重载\n      public static void showarr(double b1[]) {\n          for (int i = 0; i < b1.length; i++) {\n              system.out.print(b1[i] + "  ");\n          }\n          system.out.println();\n      }\n      \n      public static void findarr(int a1[],int n){\n          boolean flag=true;\n          for (int i = 0; i < a1.length; i++) {\n              if(a1[i]==n){\n                  flag=false;\n                  system.out.println(a1[i] + "下标为"+i);\n              }\n          }\n          if(flag==true){\n                  system.out.println("没有找到符合条件的数");\n          }\n      }\n      //findarr方法重载\n      public static void findarr(double b1[],double m){\n          boolean flag=true;\n          for (int i = 0; i < b1.length; i++) {\n              if(b1[i]==m){\n                  flag=false;\n                  system.out.println(b1[i] + "下标为"+i);\n              }\n          }\n          if(flag==true){\n                  system.out.println("没有找到符合条件的数");\n          }\n      }\n      \n      \n      public static int[] sortarr(int a1[]) {\n          for (int i = 0; i < a1.length - 1; i++) {\n              for (int j = 0; j < a1.length - i - 1; j++) {\n                  if (a1[j] > a1[j + 1]) {\n                      int temp = a1[j];\n                      a1[j] = a1[j + 1];\n                      a1[j + 1] = temp;\n                  }\n              }\n          }\n          return a1;\n      }\n      \n      public static double[] sortarr(double a1[]) {\n          //需要比较a1.length-1轮\n          for (int i = 0; i < a1.length - 1; i++) {\n              //第i轮需要比较的两个数\n              for (int j = 0; j < a1.length - i - 1; j++) {\n                  if (a1[j] > a1[j + 1]) {\n                      double temp = a1[j];\n                      a1[j] = a1[j + 1];\n                      a1[j + 1] = temp;\n                  }\n              }\n          }\n          return a1;\n      }\n  \n  }\n\n\n# 类和对象\n\n\npublic class method3 {\n\tprotected string name;\n\tprotected int age;\n\tprotected string sex;\n\tprotected string num;\n\tpublic method3(){\n\t\t\n\t}\n\t\n\tpublic method3(string name, int age, string sex, string num) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.sex = sex;\n\t\tthis.num = num;\n\t}\n\tpublic void setname(){\n\t\tthis.name = name;\n\t}\n\tpublic string getname(){\n\t\treturn name;\n\t}\n\tpublic void setage(){\n\t\tthis.age = age;\n\t}\n\tpublic int getage(){\n\t\treturn age;\n\t}\n\tpublic void setsex(){\n\t\tthis.sex = sex;\n\t}\n\tpublic string getsex(){\n\t\treturn sex;\n\t}\n\tpublic void setnum(){\n\t\tthis.num = num;\n\t}\n\tpublic string getnum(){\n\t\treturn num;\n\t}\n\t\n\t@override\n    public string tostring() {\n        return "student [name=" + name + ", age=" + age + ", sex=" + sex + ", num=" + num + "]";\n    }\n\t\n  /* public static void sortnum(method3 []s){\n\t\tfor (int i = 0; i < s.length-1; i++) {\n\t\t\tfor (int j = 0; j < s.length-i-1; j++) {\n\t\t\t\tif(s[j].age>s[j+1].age){\n\t\t\t\t\tmethod3 a;\n\t\t\t\t\ta=s[j];\n\t\t\t\t\ts[j]=s[j+1];\n\t\t\t\t\ts[j+1]=a;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}*/\n}\n// ------------------------\npublic class main {\n\n\tpublic static void main(string[] args) {\n\t    method3 student[] = new method3[3];\n\t   \tstudent[0]=new method3("bbb",24,"男","17044003");\n\t   \tstudent[1]=new method3("ccc",23,"女","17044002");\n\t   \tstudent[2]=new method3("aaa",25,"男","17044001");\n\t   \t\n\t   \tlist<method3> list = new arraylist<method3>();\n\t   \tlist.add(student[0]);\n\t   \tlist.add(student[1]);\n\t   \tlist.add(student[2]);\n\t   \t\n\t   \tsystem.out.println("排序前：");\n        //排序前\n\t   \tfor (method3 method3 : list) {\n\t   \t\tsystem.out.println(method3);\n\t\t}\n      comparatorconsuninfo comparatorconsuninfo = new comparatorconsuninfo();//比较器\n      collections.sort(list,comparatorconsuninfo);//排序\n      \n      system.out.println("按年龄排序后：");\n      //排序后\n      for (method3 method3 : list) {\n        \tsystem.out.println(method3);\n\t\t}\n       \n\t}\n}\n\n\n# 类的继承与抽象类的实现\n\n\npublic class main {\n\tpublic static void main(string[] args) {\n\t\t// todo auto-generated method stub\n\t\tperson p0 = new person();\n\t\tsystem.out.println(p0);\n\t\t\n\t\tperson p1 = new person("aaa");\n\t\tsystem.out.println(p1);\n\t\tp1.say();\n\t\tperson.speak();\n\t\tsystem.out.println();\n\t\t\n\t\tperson p2 = new student();\n\t\tsystem.out.println(p2);\n\t\t\n\t\tperson p3 = new student("哈尔滨学院");\n\t\tsystem.out.println(p3);\n\t\t\n\t\tperson p4 = new student("bbb","xxx学校");\n\t\tsystem.out.println(p4);\n\t\tp4.say();\n\t\tp4.display();\n\t\tstudent.speak();\n\t\tsystem.out.println();\n\t\t\n\t\tperson p5 = new middlestudent();\n\t\tsystem.out.println(p5);\n\t\t\n\t\tperson p6 = new middlestudent("一高");\n\t\tsystem.out.println(p6);\n\t\t\n\t\tperson p7 = new middlestudent("ddd","二高");\n\t\tsystem.out.println(p7);\n\t\tp7.say();\n\t\tmiddlestudent.speak();\n\t\tsystem.out.println();\n\t\t\n\t\tperson p8 = new smallstudent();\n\t\tp8.display();\n\t\tp8.say();\n\t\tsmallstudent p9 = new smallstudent();\n\t\tp9.display1();\n\n\t\tvirtualtree tree = new tree("雪松");\n\t\ttree.act();\n\t}\n}\n\n\npublic class person {\n\tprotected string name;\n\tpublic person(){\n\t\t\n\t}\n\tpublic person(string name){\n\t\tthis.name=name;\n\t}\n\tpublic string getname() {\n\t\treturn name;\n\t}\n\tprivate void setname(string name) {\n\t\tthis.name = name;\n\t}\n\t\n\t\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "我的名字:"+ this.name ;\n\t}\n\tpublic void say(){\n\t\tsystem.out.println("我是一个人。。。");\n\t}\n\t\n\tpublic static void speak(){\n\t\tsystem.out.println("吃饭");\n\t}\n\t\n\tpublic final void display(){\n\t\tsystem.out.println("我是final方法\\t不能被重写");\n\t}\n}\n\n\npublic class student extends person {\n\tprivate string school;\n\t\n\tpublic student(){\n\t\t\n\t}\n\tpublic student(string school){\n\t\tsuper(" ");\n\t\tthis.school=school;\n\t}\n\tpublic student(string name,string school){\n\t\tsuper(name);\n\t\tthis.school=school;\n\t}\n\t\n\tpublic string getschool() {\n\t\treturn school;\n\t}\n\tpublic void setschool(string school) {\n\t\tthis.school = school;\n\t}\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "我的名字:"+ super.name +"\\t我的学校:" + this.school;\n\t}\n\t@override\n\tpublic void say() {\n\t\t// todo auto-generated method stub\n\t\tsuper.say();\n\t\tsystem.out.println("我是一个学生。。。");\n\t}\n\tpublic static void speak(){\n\t\tsystem.out.println("学习");\n\t}\n}\n\n\nfinal public class smallstudent extends student  {\n\tpublic void say(){\n\t\tsystem.out.println("我是一只小学生");\n\t}\n\tpublic void display1(){\n\t\tsystem.out.println("我是final类\\t不可被继承\\n");\n\t}\n}\n\n\npublic class middlestudent extends student {\n\n\tpublic middlestudent(){\n\t\tsuper("","");\n\t}\n\tpublic middlestudent(string school){\n\t\tsuper(" ",school);\n\t}\n\tpublic middlestudent(string name,string school){\n\t\tsuper(name,school);\n\t}\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "我的名字:"+ super.getname() +"\\t我的学校:" + super.getschool();\n\t}\n\t@override\n\tpublic void say() {\n\t\t// todo auto-generated method stub\n\t\tsuper.say();\n\t\tsystem.out.println("我是一个高中生。。。");\n\t}\n\t\n\tpublic static void speak(){\n\t\tsystem.out.println("睡觉");\n\t}\n}\n\n\npublic abstract class virtualtree {\n\tprivate string tree="柳树";\n\tpublic virtualtree(){\n\t\t\n\t}\n\tpublic virtualtree(string tree){\n\t\tthis.tree=tree;\n\t}\n\t\n\tpublic string gettree() {\n\t\treturn tree;\n\t}\n\tpublic void settree(string tree) {\n\t\tthis.tree = tree;\n\t}\n\tpublic abstract void wave(); \n\tpublic abstract void grow();\n\tpublic abstract void dieaway();\n\tpublic abstract void felldown();\n\tpublic void act(){\n\t\t\tthis.wave();\n\t\t\tthis.grow();\n\t\t\tthis.dieaway();\n\t\t\tthis.felldown();\n\t}\n}\n\n\npublic class tree extends virtualtree {\n\t\n\tpublic tree(){\n\t\t\n\t}\n\tpublic tree(string tree){\n\t\tsuper(tree);\n\t}\n\t\n\t@override\n\tpublic void wave() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.println("风吹过，" + super.gettree() + "树枝摇动。");\n\t}\n\n\t@override\n\tpublic void grow() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.println(super.gettree() + "生长中······");\n\t}\n\n\t@override\n\tpublic void dieaway() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.println(super.gettree() + "枯萎凋零");\n\t}\n\n\t@override\n\tpublic void felldown() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.println(super.gettree() + "被砍伐");\n\t}\n}\n\n\n# 接口实现及深浅拷贝\n\n\npublic class main {\n\tpublic static void main(string[] args) throws clonenotsupportedexception{\n\t\thero hero1 = new hero("德鲁伊");\n\t\tpets pet1 = new pets("龙狼");\n\t\thero1.setpet(pet1);\n\t\thero1.displaymes();\n\t\t//system.out.println(hero1);\n\n\t\t/*hero hero2 = hero1;\t\t\t//引用拷贝\n\t\t//hero2.displaymes();\n\t\tsystem.out.println(hero2);\n\t\tsystem.out.println(hero1.equals(hero3));*/\n\t\t\n\t\t/*hero hero3 = (hero) hero1.clone();\t\t//浅拷贝\t第一个clone()重写\n\t\tsystem.out.println(hero3.equals(hero1));\n\t\thero3.displaymes();\n\t\tsystem.out.println(hero3.pet.equals(hero1.pet));\n\t\tsystem.out.println("hero1的pet地址：" + hero1.pet);\n\t\tsystem.out.println("hero4的pet地址：" + hero3.pet);*/\n\n\t\t//深拷贝的两种方法\n\t\t//1.深复制条件 ---父类和子类都要实现cloneable（）接口\n\t\t//2.父类重写clone接口的时候，要把子类带上？\n\t\thero hero4 = (hero) hero1.clone();\t\t//深拷贝\t第二个clone()重写\n\t\t\n\t\tsystem.out.println(hero4.equals(hero1));\n\t\thero4.displaymes();\n\t\tsystem.out.println(hero4.pet==hero1.pet);\n\t\tsystem.out.println("hero1的pet" + hero1.pet.petname);\n\t\tsystem.out.println("hero4的pet" + hero4.pet.petname);\n\t\tsystem.out.println(hero1.pet.equals(hero4.pet));\n\t}\n}\n\n\npublic interface flyable {\n\tstring fly="挥动翅膀";\t//全局变量 默认为public static string\n\tpublic void able1();\t\t\t\t//接口方法默认为抽象\n\tpublic static void fly(string f){\t\t//接口静态方法\n\t\t//fly = f;\n\t\tsystem.out.print("\\t" + flyable.fly);\n\t}\n}\n\n\npublic class pets implements flyable,cloneable{\n\t string petname;\n\t\t\n\tpublic pets() {\n\t}\n\n\tpublic pets(string petname) {\n\t\tthis.petname = petname;\n\t}\n\n\tpublic string getpet() {\n\t\treturn petname;\n\t}\n\n\tpublic void setpet(string petname) {\n\t\tthis.petname = petname;\n\t}\n\t\n\t//接口方法的实例化\n\tpublic void able1(){\n\t\tsystem.out.print(" and fly");\n\t}\n\n\t@override\n\tpublic object clone() throws clonenotsupportedexception {\n\t\t// todo auto-generated method stub\n\t\treturn super.clone();\n\t}\n\n\t// 注：（此处为反面示例）重写equals方法时一定要重写hashcode()方法\n\t/*@override\n\tpublic boolean equals(object temp) {\n\t\t// todo auto-generated method stub\n\t\tif(this==temp){\n\t\t\treturn true;\n\t\t}\n\t\tif(temp instanceof pets){\n\t\t\tpets pet=(pets)temp;\n\t\t\t\n\t\t\tif(this.petname.equals(((pets) temp).petname)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\telse{\n\t\t\treturn false;\t\t\t\n\t\t}\n\t}*/\n}\n\n\n// 克隆：实现cloneable接口，重写clone()方法，权限为public\npublic class hero implements cloneable {\n\tprivate string name;\n\tpets pet;\n\t\n\tpublic hero(){\n\t\t\n\t}\n\tpublic hero(string name){\n\t\tthis.name = name;\n\t}\n\t\n\tpublic string getname() {\n\t\treturn name;\n\t}\n\n\tpublic void setname(string name) {\n\t\tthis.name = name;\n\t}\n\t\n\tpublic pets getpet() {\n\t\treturn pet;\n\t}\n\tpublic void setpet(pets pet) {\n\t\tthis.pet = pet;\n\t}\n\t/*@override //浅拷贝\n\tprotected object clone() throws clonenotsupportedexception {\n\t\t// todo auto-generated method stub\n\t\treturn super.clone();\n\t}*/\n\t@override\t//深拷贝\n\tpublic object clone() throws clonenotsupportedexception {\n\t\thero hero = (hero)super.clone();\n\t\thero.pet = (pets)pet.clone();\n\t\treturn hero;\n\t}\n\t\n\t\n\t// 注：（此处为反面示例）重写equals方法时一定要重写hashcode()方法\n\t/*@override\n\tpublic boolean equals(object temp) {\n\t\t// todo auto-generated method stub\n\t\tif(this==temp){\n\t\t\treturn true;\n\t\t}\n\t\tif(temp instanceof hero){\n\t\t\thero hero=(hero) temp;\n\t\t\tpets pet=(pets)hero.pet;\n\t\t\t\n\t\t\tif(this.pet==hero.pet && this.pet.petname.equals(hero.pet.petname)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t\telse{\n\t\t\treturn false;\n\t\t}\t\t\n\t}*/\n\t\n\tpublic void displaymes(){\n\t\tsystem.out.println("hero name:" + name);\n\t\tsystem.out.print("pet name:" + pet.getpet());\n\t\tflyable.fly(" ");\n\t\tpet.able1();\n\t\tsystem.out.println();\n\t}\n}\n\n\n# 类间关系\n\n\npublic class main {\n\t//体会类和类之间的关系\n\tpublic static void main(string[] args) {\n\t\t\n\t\tbyte f[]={9,11,13,12,10};\n\n\t\tstudent s[]=new student[2];\n\t\ts[0]=new student("雪域雷鸣",(byte)127,"男","14000000",true);\n\t\tphone phone = new phone();\n\t\tphone=new phone("wal-000",2000,20);\n\t\ts[0].finger(f);\n\t\ts[0].tostring();//system.out.println(s);\n\t\ts[0].playphone(phone);\n\t\ts[0].buyphone(phone);\n\t\ts[0].breath();\n\t\t\n\t\ts[1]=new student();\n\t\ts[1].tostring();\n\t\ts[1].breath();\n\t\t\n\t\t\n\t\t/*s=null;\n\t\tsystem.gc();*/\n\t}\n\n}\n\n\n  public class student {\n      private string name=" ";\n      private byte age;\n      private string sex;\n      private string num;\n      private boolean graduate;\n      phone phone=new phone();\n      hands hand = new hands();\n      \n      public student(){\n          hand = new hands();\n      }\n      public student(string name){\n          this.name=name;\n      }\n      public student(string name,byte age){\n          this(name);\n          this.age=age;\n      }\n      public student(string name,byte age,string sex){\n          this(name,age);\n          this.sex=sex;\n      }\n      public student(string name,byte age,string sex,string num){\n          this(name,age,sex);\n          this.num=num;\n      }\n      public student(string name,byte age,string sex,string num ,boolean graduate){\n          this(name,age,sex,num);\n          this.graduate=graduate;\n      }\n  \n      \n      public string getname(){\n          return name;\n      }\n      public void setname(string name){\n          this.name=name;\n      }\n      public short getage() {\n          return age;\n      }\n      public void setage(byte age) {\n          this.age = age;\n      }\n      public string getsex() {\n          return sex;\n      }\n      public void setsex(string sex) {\n          this.sex = sex;\n      }\n      public string getnum() {\n          return num;\n      }\n      public void setnum(string num) {\n          this.num = num;\n      }\n      public boolean isgraduate() {\n          return graduate;\n      }\n      public void setgraduate(boolean graduate) {\n          this.graduate = graduate;\n      }\n      \n      public hands gethand() {\n          return hand;\n      }\n      public void sethand(hands hand) {\n          this.hand = hand;\n      }\n      \n      public void finger(byte a[]){       //与hands有组合关系\n          hand = new hands(a);\n      }\n      \n      @override\n      public string tostring() {\n          // todo auto-generated method stub\n          system.out.println("姓名：" + this.name +"\\t年龄：" + age + "\\t性别：" + sex + "\\t学号：" + num + "\\t是否毕业：" + graduate);\n          system.out.println(this.gethand());\n          return super.tostring();\n      }\n      \n      /*@override\n      protected void finalize() throws throwable {\n          // todo auto-generated method stub\n          system.out.println("回收垃圾...");\n          super.finalize();\n      }*/\n      public void breath(){       //与air类有依赖关系\n          air freshair = new air();\n          freshair.air();\n      }\n      \n      public void playphone(phone phone){     //与phone有聚合关系\n          system.out.println(this.getname()+"同学的手机  型号："+phone.getmodel()+ "\\t价格：" +phone.getprice() + "\\t尺寸：" + phone.getsize());\n      }\n      \n      public phone buyphone(phone phone){\n          system.out.println("购买手机 型号："+phone.getmodel()+ "  价格：" +phone.getprice() + "  尺寸：" + phone.getsize());\n          return this.phone;\n      }\n  }\n\n\n  public class air {\n      //依赖\n      public void air(){\n          system.out.println("吸气" + "\\t呼" +" 气" + "\\n");\n      }\n  }\n\n\npublic class hands {\n\t//组合\n\tprivate byte[] finger=new byte[5];\n\tpublic hands(){\n\t\tfinger[0]=(byte)7;\n\t\tfinger[1]=(byte)8.2;\n\t\tfinger[2]=(byte)10;\t\t\n\t\tfinger[3]=(byte)9.3;\n\t\tfinger[4]=(byte)7.5;\n\t}\n\tpublic hands(byte[] finger){\n\t\tthis.finger=finger;\n\t}\n\t\n\tpublic byte[] getfinger() {\n\t\treturn finger;\n\t}\n\n\tpublic void setfinger(byte[] finger) {\n\t\tthis.finger = finger;\n\t}\n\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.println("拇指长为："+finger[0]+"\\t食指长为："+finger[1]+"\\t中指长为："+finger[2]+"\\t无名指长为："+finger[3]+"\\t小指长为："+finger[4]);\n\t\treturn super.tostring();\n\t}\n}\n\n\n  public class phone {\n      //聚合\n      private string model;\n      private int price;\n      private int size;\n  \n      public phone() {\n  \n      }\n  \n      public phone(string model) {\n          this();\n          this.model=model;\n      }\n  \n      public phone(string model, int price) {\n          this(model);\n          this.price=price;\n      }\n  \n      public phone(string model, int price, int size) {\n          this(model,price);\n          this.size=size;\n      }\n  \n      public string getmodel() {\n          return model;\n      }\n  \n      public void setmodel(string model) {\n          this.model = model;\n      }\n  \n      public int getprice() {\n          return price;\n      }\n  \n      public void setprice(int price) {\n          this.price = price;\n      }\n  \n      public int getsize() {\n          return size;\n      }\n  \n      public void setsize(int size) {\n          this.size = size;\n      }\n  }\n\n\n# 简单设计模式\n\n\n  public class main {\n      static{\n          system.out.println("测试类的静态代码块");\n      }\n      public static void mothod(int n){\n          \n          system.out.println("我是" + n + "句无聊的话。。。");\n      }\n      public static void main(string[] args) {\n          // todo auto-generated method stub\n          /*student.setschool("xx学院");\n          student s1 = new student();\n          s1.setname("aaa");\n          system.out.println(s1.getname() + " " + student.getschool());*/\n          \n          test.mothod(3);\n          \n          student s0 = new student();\n          system.out.println(s0);\n          \n          student s2 = new student("aaa");\n          s2.schoolname("xx学院");\n          s2.showmessage();\n          \n          singleton s3 = singleton.getinstane();\n          system.out.println(s3);\n          singleton s4 = singleton.getinstane();\n          system.out.println(s4);\n          system.out.println("（单例饿汉式）对象数：" + singleton.num + "\\n");\n          \n          singleton1 s5 = singleton1.getinstane();\n          system.out.println(s5);\n          singleton1 s6 = singleton1.getinstane();\n          system.out.println(s6);\n          system.out.println("（单例懒汉式）对象数：" + singleton1.num + "\\n");\n          \n          multiton s7 = multiton.getinstane("恒星1");\n          system.out.println(s7.getstar());\n          multiton s8 = multiton.getinstane("恒星2");\n          system.out.println(s8.getstar());\n          multiton s9 = multiton.getinstane("恒星3");\n          system.out.println(s9.getstar());\n          system.out.println("（多例）对象数：" + multiton.num);\n      }\n  }\n\n\n// 多例\npublic class multiton {\n\tprivate string star;\n\tpublic static int num=0;\n\tprivate static multiton[] s = new multiton[3];\n\tstatic{\n\t\tfor (int i = 0; i < s.length; i++) {\n\t\t\ts[i] = new multiton("恒星" + (i+1));\n\t\t}\n\t}\n\t\n\tpublic string getstar() {\n\t\treturn star;\n\t}\n\tpublic void setstar(string star) {\n\t\tthis.star = star;\n\t}\n\t\n\tprivate multiton(){\n\t\tnum++;\n\t}\n\tprivate multiton(string star){\n\t\tthis.star=star;\n\t\tnum++;\n\t}\n\t\n\tpublic static multiton getinstane(string star)\n\t{\n\t\tif(s[0].getstar().equals(star)){\n\t\t\treturn s[0];\n\t\t}\n\t\telse if(s[1].getstar().equals(star))\n\t\t{\n\t\t\treturn s[1];\n\t\t}\n\t\telse{\n\t\t\treturn s[2];\n\t\t}\n\t}\n}\n\n\n//单例   饿汉式\npublic class singleton {\n\tprivate string school;\n\tpublic static int num=0;\n\tprivate static final singleton s = new singleton("xx学院");\n\t\n\tprivate singleton(){\n\t\tnum++;\n\t}\n\tprivate singleton(string school){\n\t\tthis.school=school;\n\t\tnum++;\n\t}\n\t\n\tpublic static singleton getinstane()\n\t{\n\t\treturn s;\n\t}\n}\n\n\n//单例  懒汉式\npublic class singleton1 {\n\tprivate string school;\n\tpublic static int num=0;\n\tprivate static singleton1 s = null;\n\t\n\tprivate singleton1() {\n\t\tnum++;\n\t}\n\tprivate singleton1(string school) {\n\t\tthis.school=school;\n\t\tnum++;\n\t}\n\t\n\tpublic static singleton1 getinstane() {\n\t\tif(s==null){\n\t\t\ts=new singleton1();\n\t\t} else {\n\t\t\treturn s;\n\t\t}\n\t\treturn s;\n\t}\n}\n\n\n# 常见异常类与捕获异常\n\n\npublic class arrexception {\n\tpublic static void main(string[] args){\n\t\tint a[]={21,32,52};\n\t\t\n\t\ttry{\n\t\t\tsystem.out.println(a[3]);\n\t\t}catch(arrayindexoutofboundsexception e){\n\t\t\tsystem.out.println("异常信息为：" + e.getmessage());\n\t\t}\n\t}\t\n}\n\n\npublic class clasept {\n\tprivate string name;\n\n\tprotected clasept() {\n\t\tsuper();\n\t}\n\n\tprotected clasept(string name) {\n\t\tsuper();\n\t\tthis.name = name;\n\t}\n\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "姓名："+name;\n\t}\n\t\n\t\n\tpublic static void main(string[] args) {\n\t\t// todo auto-generated method stub\n\t\tclasept c=new clasept("name");\n\t\tc=null;\n\t\t\n\t\tassert (c!=null):"对象c指向null";\n\t\t\n\t\tsystem.out.println(c);\n\t\ttry{\n\t\t\tsystem.out.println(c.tostring());\n\t\t}catch(nullpointerexception e){\n\t\t\tsystem.out.println("异常信息：" + e.getmessage());\n\t\t\t//e.printstacktrace();\n\t\t}\n\t}\n}\n\n\npublic class divept {\n\tpublic static void main(string[] args) {\n\t\tint a=100;\n\t\tint b=0;\n\t\t\n\t\ttry{\n\t\t\tsystem.out.println(div(a,b));\n\t\t}catch(exception e){\n\t\t\tsystem.out.println("异常信息为：" + e.getmessage());\n\t\t}finally{\n\t\t\tsystem.out.println("请重新操作");\n\t\t}\n\t}\n\t\n\tpublic static int div(int a,int b) {\n\t\treturn a/b;\n\t}\n}\n\n\npublic class divept1 {\n\tpublic static void main(string[] args) {\n\t\tint a=100;\n\t\tint b=0;\n\t\t\n\t\ttry{\n\t\t\tsystem.out.println(div(a,b));\n\t\t}catch(exception e){\n\t\t\tsystem.out.println(e.getmessage());\n\t\t}\n\t}\n\t\n\tpublic static int div(int a,int b) throws exception {\n\t\tif(b==0){\n\t\t\tthrow new exception("除数为零");\n\t\t}\n\t\treturn a/b;\n\t}\n}\n\n\n/**\n * 自定义异常\n * 继承exception\n * @author lenovo\n */\npublic class myexception extends exception{\n\t\n\t/**\n\t * 序列化id\n\t */\n\tprivate static final long serialversionuid = 1l;\n\tpublic myexception(){\n\t\tsuper();\n\t}\n\tpublic myexception(string msg){\n\t\tsuper(msg);\n\t}\n\tpublic string getmessage(string s) {\n\t\t\n\t\treturn "得到异常信息：" + super.getmessage();\n\t}\n\t@override\n\tpublic void printstacktrace() {\n\t\t// todo auto-generated method stub\n\t\tsystem.out.print("打印堆栈信息：");\n\t\tsuper.printstacktrace();\n\t}\n}\n\n// ----------------------------\n\npublic class mytest {\n\tpublic static void main(string[] args) throws myexception{\n\t\tint x=5;\n\t\twhile(x--\x3e1){\n\t\t\tscanner cin = new scanner(system.in);\n\t\ttry{\n\t\t\t\tint a = cin.nextint();\n\t\t\t\tint b = cin.nextint();\n\t\t\t\tif(b==0){\n\t\t\t\t\tthrow new myexception("除数不能为0");\t\t//自定义异常类对象\n\t\t\t\t}\n\t\t\t\tsystem.out.println(a/b);\n\t\t\t}catch(inputmismatchexception e){\n\t\t\t\t//e.printstacktrace();\n\t\t\t\tsystem.out.println(e.getmessage());\n\t\t\t}catch(arithmeticexception e){\n\t\t\t\tsystem.out.println(e.getmessage());\n\t\t\t}catch(runtimeerrorexception e){\n\t\t\t\tsystem.out.println(e.getmessage());\n\t\t\t}catch(exception e){\n\t\t\t\tsystem.out.println(e.getmessage());\n\t\t\t}\n\t\t}\n\t}\n}\n\n\n# 线程\n\n# 多线程\n\n\npublic class mythread extends thread{\n\tprivate static int tickets = 50;\n\t//private volatile int tickets = 50;\n\t//private int tickets = 50;\n\tprivate int time ;\t\n\tpublic mythread(string name,int time){\n\t\tsuper(name);\n\t\tthis.time = time;\n\t}\n\n\t@override\n\tpublic void run() {\n\t\t\n\t\twhile(tickets--\x3e0){\n\t\t\ttry {\n\t\t\t\tthread.sleep(this.time);\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第" + tickets + "张票");\n\t\t}\n\t}\n}\n// ------------------------------------------------------\npublic static void main(string[] args) {\n\t// todo auto-generated method stub\n\tmythread t1=new mythread("窗口1",200);\n\tmythread t2=new mythread("窗口2",100);\n\tmythread t3=new mythread("窗口3",50);\n\tmythread t4=new mythread("窗口4",10);\n\t\n\tt1.start();\n\tt2.start();\n\tt3.start();\n\tt4.start();\n}\n\n\npublic class trunnable implements runnable{\n\tprivate int tickets = 50;\n\tprivate int time;\n\tprotected trunnable(int time) {\n\t\tsuper();\n\t\tthis.time = time;\n\t}\n\n\t@override\n\tpublic void run() {\n\t\t// todo auto-generated method stub\n\t\twhile(tickets--\x3e0){\n\t\t\ttry {\n\t\t\t\tthread.sleep(this.time);\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第" + tickets + "张票");\n\t\t}\n\t}\n}\n\n// ----------------------------------\npublic static void main(string[] args) {\n\t\t//runnable接口实现类的对象\n\t\ttrunnable tr1=new trunnable(100);\t\t//参数为睡眠时间\n\t\t\n\t\tthread t1 = new thread(tr1,"窗口1");\n\t\tthread t2 = new thread(tr1,"窗口2");\n\t\tthread t3 = new thread(tr1,"窗口3");\n\t\tthread t4 = new thread(tr1,"窗口4");\n\t\t\n\t\tt1.start();\n\t\tt2.start();\n\t\tt3.start();\n\t\tt4.start();\n\t}\n}\n\n\n// 可带返回值的多线程\npublic class tcallable implements callable{\n \tprivate int tickets = 50;\n \t@override\n \tpublic object call() throws exception {\n \t\twhile(true){\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets==39){\n \t\t\t\t\tsystem.out.println("程序让步...");\n \t\t\t\t\tthread.yield();\n \t\t\t\t}\n \t\t\t}\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets==6){\n \t\t\t\t\tsystem.out.println("程序让步...");\n \t\t\t\t\tthread.yield();\n \t\t\t\t}\n \t\t\t}\n \t\t\t\n \t\t\ttry {\n \t\t\t\tthread.sleep(2);\n \t\t\t} catch (interruptedexception e) {\n \t\t\t\t// todo auto-generated catch block\n \t\t\t\te.printstacktrace();\n \t\t\t}\n \t\t\tsynchronized(this){\n \t\t\t\tif(tickets>0){\n \t\t\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第" + tickets + "张票");\t\n \t\t\t\t\ttickets--;\n \t\t\t\t}else{\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n \t\t}\n \t\treturn tickets;\n \t}\n}\n// ----------------------------\npublic class testtc {\n\tpublic static void main(string[] args) throws interruptedexception, executionexception  {\n\t\ttcallable tc = new tcallable();\n\t\t\n\t\tfuturetask ft1 = new futuretask(tc);\n\t\tthread t1 = new thread(ft1,"窗口1");\n\t\t\n\t\tfuturetask ft2 = new futuretask(tc);\n\t\tthread t2 = new thread(ft2,"窗口2");\n\t\t\n\t\tfuturetask ft3 = new futuretask(tc);\n\t\tthread t3 = new thread(ft3,"窗口3");\n\t\t\n\t\tfuturetask ft4 = new futuretask(tc);\n\t\tthread t4 = new thread(ft4,"窗口4");\n\t\t\n\t\tfuturetask ft5 = new futuretask(tc);\n\t\tthread t5 = new thread(ft5,"窗口5");\n\t\t\n\t\tfuturetask ft6 = new futuretask(tc);\n\t\tthread t6 = new thread(ft6,"窗口6");\n\t\t\n\t\tdamonthread d2 = new damonthread();\n\t\tthread t9 = new thread(d2,"守护线程");\n\t\tt9.setdaemon(true);\n\t\tsystem.out.println("线程t9是否是守护线程:" + t9.isdaemon());\n\t\tt9.start();\n\t\t\n\t\tt1.setpriority(1);\n\t\tt1.start();\n\t\tt2.setpriority(1);\n\t\tt2.start();\n\t\tt3.setpriority(9);\n\t\tt3.start();\n\t\tt4.setpriority(3);\n\t\tt4.start();\n\t\tt5.setpriority(3);\n\t\tt5.start();\n\t\tt5.join();\t\t//join(）后面的线程在此线程结束后才会运行\n\t\tt6.setpriority(9);\n\t\tt6.start();\n\t\t\n\t\tsystem.out.println("t1\\tid:" + t1.getid() + "\\t返回结果：" + ft1.get() + "\\t任务是否完成：" + ft1.isdone());\n\t\tsystem.out.println("t2\\tid:" + t2.getid() + "\\t返回结果：" + ft2.get() + "\\t任务是否完成：" + ft2.isdone());\n\t\tsystem.out.println("t3\\tid:" + t3.getid() + "\\t返回结果：" + ft3.get() + "\\t任务是否完成：" + ft3.isdone());\n\t\tsystem.out.println("t4\\tid:" + t4.getid() + "\\t返回结果：" + ft4.get() + "\\t任务是否完成：" + ft4.isdone());\n\t\tsystem.out.println("t5\\tid:" + t5.getid() + "\\t返回结果：" + ft5.get() + "\\t任务是否完成：" + ft5.isdone());\n\t\tsystem.out.println("t6\\tid:" + t6.getid() + "\\t返回结果：" + ft6.get() + "\\t任务是否完成：" + ft6.isdone());\n\t}\n}\n\n\npublic class damonthread implements runnable{\n\n\t@override\n\tpublic void run() {\n\t\t// todo auto-generated method stub\n\t\twhile(true){\n\t\t\tsystem.out.println(thread.currentthread().getname() + "运行");\n\t\t\ttry {\n\t\t\t\tthread.sleep(1);\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t}\n}\n// ----------------------------------------------\npublic class testdt {\n\tpublic static void main(string[] args) throws interruptedexception {\n\t\tdamonthread d1 = new damonthread();\n\t\tthread t1 = new thread(d1,"守护线程");\n\t\tt1.setdaemon(true);\n\t\tsystem.out.println("线程t1是否是守护线程:" + t1.isdaemon());\n\t\tt1.start();\n\t\t\n\t\tfor (int i = 0; i < 10; i++) {\n\t\t\tthread.sleep(3);\n\t\t\tsystem.out.println(thread.currentthread().getname() + "运行中...");\n\t\t}\n\t\t\n\t\t/*while(true){\n\t\t\t\n\t\t}*/\n\t}\n}\n\n\n# 多线程锁\n\n\npublic class test_method implements callable<object> {\n\tprivate int tickets = 100;\n\t@override\n\tpublic object call() throws exception {\n\t\t// todo auto-generated method stub\n\t\twhile(tickets>0){\n\t\t\tsold();\n\t\t}\n\t\treturn tickets;\n\t}\n\t\n\tpublic synchronized void sold(){\n\t\tif (tickets > 0) {\n\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第"\n\t\t\t\t\t+ tickets + "张票");\n\t\t\ttickets--;\n\t\t}\n\t}\n}\n\n\npublic class test_synchronized implements callable<object> {\n\tprivate int tickets = 100;\n\n\t@override\n\tpublic object call() throws exception {\n\t\twhile (true) {\n\t\t\tsynchronized (this) {\n\t\t\t\ttry {\n\t\t\t\t\tthread.sleep(1000);\n\t\t\t\t} catch (interruptedexception e) {\n\t\t\t\t\te.printstacktrace();\n\t\t\t\t}\n\t\t\t\tif (tickets > 0) {\n\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第"\n\t\t\t\t\t\t\t+ tickets + "张票");\n\t\t\t\t\ttickets--;\n\t\t\t\t} else {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn tickets;\n\t}\n}\n\n\npublic class test_lock implements callable<object> {\n\tprivate int tickets = 100;\n\tprivate final lock lock = new reentrantlock();\n\n\t@override\n\tpublic object call() throws exception {\n\t\twhile (true) {\n\t\t\tlock.lock();\n\t\t\ttry {\n\t\t\t\tthread.sleep(30);\n\t\t\t\tif (tickets > 0) {\n\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + " 卖第"\n\t\t\t\t\t\t\t+ tickets + "张票");\n\t\t\t\t\ttickets--;\n\t\t\t\t} else {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}finally{\n\t\t\t\tlock.unlock();\n\t\t\t}\n\n\t\t}\n\t\treturn tickets;\n\t}\n}\n\n\npublic class deadlockthread implements callable<object>{\n\tstatic object chopsticks1 = new object();\n\tstatic object chopsticks2 = new object();\n\tprivate boolean flag ;\n\tpublic deadlockthread(boolean flag) {\n\t\tthis.flag = flag;\n\t}\n\t@override\n\tpublic object call() throws exception {\n\t\tif(flag==true){\n\t\t\twhile(true){\n\t\t\t\tsynchronized(chopsticks1){\n\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\tget chopsticks1");\n\t\t\t\t\tsynchronized(chopsticks2){\n\t\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\tget chopsticks2");\n\t\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\teating");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}else{\n\t\t\twhile(true){\n\t\t\t\tsynchronized(chopsticks1){\n\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\tget chopsticks1");\n\t\t\t\t\tsynchronized(chopsticks2){\n\t\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\tget chopsticks2");\n\t\t\t\t\t\tsystem.out.println(thread.currentthread().getname() + "\\teating");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n// ---------------\npublic class testdlt {\n\tpublic static void main(string[] args) {\n\t\tdeadlockthread dl1 = new deadlockthread(false);\n\t\tfuturetask ft1 = new futuretask(dl1);\n\t\tthread t1 = new thread(ft1,"p1");\n\t\t\n\t\tdeadlockthread dl2 = new deadlockthread(true);\n\t\tfuturetask ft2 = new futuretask(dl2);\n\t\tthread t2 = new thread(ft2,"p2");\n\t\t\n\t\tt1.start();\n\t\tt2.start();\n\t}\n}\n\n\n// -------------- storage（库存） ---------------------\npublic class storage {\n\tprivate int data;\n\tprivate boolean b = false;\n\tint i = 0;\n\t\n\tsynchronized public void put(int num){\n\t\twhile(b == true){\n\t\t\ttry {\n\t\t\t\tthis.wait();\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t\tdata=num;\n\t\tb=true;\n\t\ti++;\n\t\tsystem.out.println(thread.currentthread().getname() +"在" + i + "处生产" + data);\n\t\ttry {\n\t\t\tthread.sleep(100);\n\t\t} catch (interruptedexception e) {\n\t\t\t// todo auto-generated catch block\n\t\t\te.printstacktrace();\n\t\t}finally{\n\t\t\tthis.notify();\n\t\t}\n\t}\n\t\n\tsynchronized public void get(){\n\t\t\twhile(b==false){\n\t\t\t\ttry {\n\t\t\t\t\tthis.wait();\n\t\t\t\t} catch (interruptedexception e) {\n\t\t\t\t\t// todo auto-generated catch block\n\t\t\t\t\te.printstacktrace();\n\t\t\t\t}\n\t\t\t}\n\t\t\tb=false;\n\t\t\tsystem.out.println(thread.currentthread().getname() + "消费" + data);\n\t\t\ttry {\n\t\t\t\tthread.sleep(100);\n\t\t\t} catch (interruptedexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}finally{\n\t\t\t\tthis.notify();\n\t\t\t}\n\t}\n}\n\n// ----------------- producer（生产者） -------------------\npublic class producer implements runnable {\n\tstorage s = new storage();\n\tprivate int count = 0;\n\n\tpublic producer(storage s) {\n\t\tthis.s = s;\n\t}\n\n\t@override\n\tpublic void run() {\n\n\t\twhile (count < 15) {\n\t\t\ts.put(count++);\n\t\t}\n\t}\n}\n\n// ----------------- consumer（消费者） -------------------\npublic class consumer implements runnable {\n\tstorage s = new storage();\n\tprivate int count = 0;\n\n\tpublic consumer(storage s) {\n\t\tthis.s = s;\n\t}\n\n\t@override\n\tpublic void run() {\n\n\t\twhile (count++ < 15) {\n\t\t\ts.get();\n\t\t}\n\t}\n}\n\n// ----------------- 测试类启动类 -------------------\npublic class testspd {\n\tpublic static void main(string[] args) {\n\t\tstorage s = new storage();\n\t\t\n\t\tproducer p = new producer(s);\n\t\tconsumer c = new consumer(s);\n\t\t\n\t\tnew thread(p,"生产者").start();\n\t\tnew thread(c,"消费者").start();\n\t}\n}\n\n\n# 常用工具类\n\n\npublic class t_regex {\n\tpublic static void main(string args[]){\n\t\tstring s1 = "1033178928@qq.com";\n\t\tsystem.out.println("是否是一个qq邮箱:" + s1.matches("[0-9]{10,11}@(([a-za-z0-9]-*){1,}\\\\.){1,3}[a-za-z\\\\-]{1,}"));\n\t\t\n\t\tstring s2 = "451221199705303537";\n\t\tsystem.out.println("是否是一个正确的身份证号：" + s2.matches("[0-9]{18}"));\n\t\n\t\tpattern p=pattern.compile("[0-9]{10,11}@(([a-za-z0-9]-*){1,}\\\\.){1,3}[a-za-z\\\\-]{1,}"); \n\t\tmatcher m =p.matcher("1033178928@qq.com"); \n\t\tboolean b = m.matches();\n\t\tsystem.out.println(b);\n\t\tmatcher m2=p.matcher("10331789@qq.com");\n\t\tb = m2.matches();\n\t\tsystem.out.println(b);\n\t\tmatcher m3=p.matcher("4534545378@qq.com");\n\t\tb = m3.matches();\n\t\tsystem.out.println(b);\n\t\tmatcher m4=p.matcher("1033178928@.com");\n\t\tb = m4.matches();\n\t\tsystem.out.println(b);\n\t}\n}\n\n\npublic class t_method {\n\tpublic static void main(string []args){\n\t\tstring s = new string(" abcdefghijk_lmnopwrstuvwxyz_abcdefghijkl_mnopwrstuvwxyz ");\n\t\t\n\t\tsystem.out.println(s.indexof("stu"));\n\t\tsystem.out.println(s.lastindexof("stu"));\n\t\tsystem.out.println(s.startswith("abcdefg"));\n\t\tsystem.out.println(s.endswith("vwxyz"));\n\t\tsystem.out.println(s.equals(""));\n\t\tsystem.out.println(s.length());\n\t\tsystem.out.println(s.contains("mnopwrst"));\n\t\tsystem.out.println(s.touppercase());\n\t\tsystem.out.println(s.tolowercase());\n\t\tsystem.out.println(s.replace("abcdefghijk_lmnopwrstuvwxyz", "aaa"));\n\t\tstring s_arr[] = s.split("_");\n\t\tfor (int i = 0; i < s_arr.length; i++) {\n\t\t\tif(i != s_arr.length - 1){\n\t\t\t\tsystem.out.print(s_arr[i] + "0.0\\t");\n\t\t\t}else{\n\t\t\t\tsystem.out.println(s_arr[i]);\n\t\t\t}\n\t\t}\n\t\tsystem.out.println(s.substring(18,26));\t\t//18-26的字符\n\t\tsystem.out.println(s.trim());\n\t}\n}\n\n\npublic class t_builder {\n\tpublic static void main(string args[]){\n\t\tsystem.out.println("增=======");\n\t\tstringbuilder s1 = new stringbuilder("才知人力终有穷尽");\n\t\tstring s2 = "*";\n\t\tadd(s1,s2);\n\t\tsystem.out.println("删=======");\n\t\tupdate();\n\t\tsystem.out.println("改=======");\n\t\tdelete();\n\t}\n\tpublic static void add(stringbuilder str1,string str2){\n\t\tstr1.append(str2);\n\t\tsystem.out.println("append添加结果：" + str1);\n\t\t\n\t\tstr1.insert(4, str2);\n\t\tsystem.out.println("insert添加结果：" + str1);\n\t}\n\tpublic static void update(){\n\t\tstringbuilder sb = new stringbuilder("apple");\n\t\tsb.setcharat(3, \' \');\n\t\tsystem.out.println("修改：" + sb);\n\t\t\n\t\tsb.replace(2, 4, "===");\n\t\tsystem.out.println("替换：" + sb);\n\t\t\n\t\tstringbuilder sb1 = new stringbuilder("上海自来水来自海上");\n\t\tsystem.out.println( "sb1是否是回文:" + sb1.equals(sb1.reverse()));\n\t\tstringbuilder sb3 = new stringbuilder("玲珑骰子安红豆，入骨相思君知否");\n\t\tsystem.out.println("翻转：" + sb1.reverse() + "\\t" + sb3.reverse());\n\t}\n\tpublic static void delete(){\n\t\tstringbuilder sb = new stringbuilder("年少轻狂，总以为天下事无可不为。");\n\t\tsb.delete(2, 5);\n\t\tsystem.out.println("删除指定位置:" + sb);\n\t\tsb.deletecharat(2);\n\t\tsystem.out.println("删除指定位置:" + sb);\n\t\tsb.delete(0, sb.length());\n\t\tsystem.out.println("清空缓冲区:" + sb);\n\t}\n}\n\n\npublic class t_buffer {\n\tpublic static void main(string args[]){\n\t\tsystem.out.println("增=======");\n\t\tstringbuffer s1 = new stringbuffer("才知人力终有穷尽");\n\t\tstring s2 = "*";\n\t\tadd(s1,s2);\n\t\tsystem.out.println("删=======");\n\t\tupdate();\n\t\tsystem.out.println("改=======");\n\t\tdelete();\n\t}\n\tpublic static void add(stringbuffer str1,string str2){\n\t\tstr1.append(str2);\n\t\tsystem.out.println("append添加结果：" + str1);\n\t\t\n\t\tstr1.insert(4, str2);\n\t\tsystem.out.println("insert添加结果：" + str1);\n\t}\n\tpublic static void update(){\n\t\tstringbuffer sb = new stringbuffer("apple");\n\t\tsb.setcharat(3, \' \');\n\t\tsystem.out.println("修改：" + sb);\n\t\t\n\t\tsb.replace(2, 4, "===");\n\t\tsystem.out.println("替换：" + sb);\n\t\t\n\t\tstringbuffer sb1 = new stringbuffer("上海自来水来自海上");\n\t\tsystem.out.println( "sb1是否是回文:" + sb1.equals(sb1.reverse()));\n\t\tstringbuffer sb3 = new stringbuffer("玲珑骰子安红豆，入骨相思君知否");\n\t\tsystem.out.println("翻转：" + sb1.reverse() + "\\t" + sb3.reverse());\n\t}\n\tpublic static void delete(){\n\t\tstringbuffer sb = new stringbuffer("年少轻狂，总以为天下事无可不为。");\n\t\tsb.delete(2, 5);\n\t\tsystem.out.println("删除指定位置:" + sb);\n\t\tsb.deletecharat(2);\n\t\tsystem.out.println("删除指定位置:" + sb);\n\t\tsb.delete(0, sb.length());\n\t\tsystem.out.println("清空缓冲区:" + sb);\n\t}\n}\n\n\npublic class test {\n\tpublic static void main(string[] args) {\n\t\truntime rt = runtime.getruntime();\n\t\tsystem.out.println("处理机个数：" + rt.availableprocessors() + "个");\n\t\tsystem.out.println("空闲内存：" + rt.freememory()/1024/1024 + "m");\n\t\tsystem.out.println("最大内存：" + rt.maxmemory()/1024/1024 + "m");\n\t\t\n\t\ttry {\n\t\t\t\n\t\t\tprocess process = rt.exec("notepad.exe");\n\t\t\tthread.sleep(3000);\n\t\t\tprocess.destroy();\n\t\t\t\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t} catch (interruptedexception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t}\n}\n\n\n// ------------- dateformat -----------\npublic class t_dateformat {\n\tpublic static void main(string[] args) {\n\t\tdate d = new date();\n\t\tdateformat fullformat = dateformat.getdateinstance(dateformat.full);\n\t\tdateformat longformat = dateformat.getdateinstance(dateformat.long);\n\t\tdateformat mediumformat = dateformat.getdatetimeinstance(dateformat.medium, dateformat.medium);\n\t\tdateformat shortformat = dateformat.getdatetimeinstance(dateformat.short, dateformat.short);\n\n\t\tsystem.out.println("当前日期的完整格式为：" + fullformat.format(d));\n\t\tsystem.out.println("当前日期的长格式为：" + longformat.format(d));\n\t\tsystem.out.println("当前日期的普通格式为：" + mediumformat.format(d));\n\t\tsystem.out.println("当前日期的短格式为：" + shortformat.format(d));\n\t\t\n\t\tsimpledateformat s = new simpledateformat("gyyyy年mm月dd日：今天是yyyy年第d天，e");\n\t\tsystem.out.println(s.format(new date()));\n\t}\n}\n\n// ------------- clock、duration、instant -----------\npublic class t_time {\n\tpublic static void main(string[] args) {\n\t\t//clock\n\t\tclock c = clock.systemutc();\n\t\tsystem.out.println("utc转换当前时间：" + c.instant());\n\t\tsystem.out.println("utc转换毫秒数：" + c.millis());\n\t\t//duration\n\t\tduration d = duration.ofdays(3);\n\t\tsystem.out.println("3天=" + d.tohours() + "时");\n\t\tsystem.out.println("3天=" + d.tominutes() + "分");\n\t\tsystem.out.println("3天=" + d.tomillis() + "秒");\n\t\t//instant\n\t\tinstant i = instant.now();\n\t\tsystem.out.println("utc当前时间：" + i);\n\t\tsystem.out.println("utc当前时间+1小时：" + i.plusseconds(3600));\n\t\tsystem.out.println("utc当前时间-1小时：" + i.minusseconds(3600));\t\t\n\t}\n}  \n\n// ------------- calendar -----------\npublic class test {\n\tpublic static void main(string[] args) {\n\t\tdate d1 = new date();\n\t\tdate d2 = new date(system.currenttimemillis() + 1000);\n\t\tsystem.out.println(d1);\n\t\tsystem.out.println(d2);\n\t\t\n\t\t//得到当前年 月 日 时 分 秒\n\t\tcalendar cr = calendar.getinstance();\n\t\tint year = cr.get(calendar.year);\n\t\tint month = cr.get(calendar.month)+ 1;\n\t\tint date = cr.get(calendar.date);\n\t\tint hour = cr.get(calendar.hour);\n\t\tint minute = cr.get(calendar.minute);\n\t\tint second = cr.get(calendar.second);\t\t\n\t\tsystem.out.println("当前时间" + year + "年" + month + "月" + date + "日\\t" + hour + ":" + minute + ":" + second );\n\t\n\t\t//设置日期+100天\n\t\tcalendar cr2 = calendar.getinstance();\n\t\tcr2.set(2019, 6, 6);\n\t\tcr2.add(calendar.date, 100);\n\t\tint y = cr2.get(calendar.year);\n\t\tint m = cr2.get(calendar.month);\n\t\tint d = cr2.get(calendar.date);\n\t\tsystem.out.println("计划完成时间是：" + y + "年" + m + "月" + d +"日");\n\t\t\n\t\t//容错模式与非容错模式\n\t\tcalendar ca = calendar.getinstance();\n\t\tca.set(calendar.month, 13);\n\t\tsystem.out.println(ca.gettime());\n\t\t/*ca.setlenient(false);\n\t\tca.set(calendar.month, 13);\n\t\tsystem.out.println(ca.gettime());*/\n\t}\n}\n\n\n// --------------- arraycopy ----------------------------\npublic class t_arraycopy {\n\tpublic static void main(string[] args) {\n\t\tint []srcarry = {100,101,102,103,104,105,106,107,108};\n\t\tint []desarray = {1,2,3,4,5};\n\t\tsystem.arraycopy(srcarry, 3, desarray, 0, desarray.length);\n\t\tfor (int i = 0; i < desarray.length; i++) {\n\t\t\tsystem.out.println(i + ":" + desarray[i]);\n\t\t}\n\t}\n}\n// --------------- currenttimemillis ----------------------------\npublic class t_currenttimemillis {\n\tpublic static void main(string[] args) {\n\t\tlong s_time = system.nanotime();\n\t\tlong starttime = system.currenttimemillis();\n\t\tint s = 0;\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\ts=s+1;\n\t\t}\n\t\tlong endtime = system.currenttimemillis();\n\t\tlong e_time = system.nanotime();\n\n\t\tsystem.out.println("运行时间：" + (endtime-starttime) + "ms");\n\t\tsystem.out.println("运行时间：" + (e_time-s_time) + "毫微秒");\n\t}\n}\n// --------------- getproperties ----------------------------\npublic class t_getproperties {\n\tpublic static void main(string[] args) {\n\t\tproperties properties = system.getproperties();\n\t\tsystem.out.println(properties);\n\t\t\n\t\tset<string>propertynames = properties.stringpropertynames();\n\t\tfor (string key : propertynames) {\n\t\t\tstring value = system.getproperty(key);\n\t\t\tsystem.out.println(key + "---" + value);\n\t\t}\n\t}\n}\n\n\npublic class t_list {\n\tpublic static void main(string[] args) {\n\t\tarraylist<string> list = new arraylist<string>();\n\t\tlist.add("eve");\n\t\tlist.add("mark");\n\t\tlist.add("rose");\n\t\tlist.add("rose");\n\t\tsystem.out.println(list);\n\n\t\tsystem.out.println("第三个元素：" + list.get(2));\n\t\tsystem.out.println("长度：" + list.size());\n\t\tsystem.out.println("删除第四个元素" + list.remove(3));\n\n\t\t//foreach遍历\n\t\tfor (string str : list) {\n\t\t\tsystem.out.print(str + " ");\n\t\t}\n\t\tsystem.out.println();\n\n\t\tlinkedlist<string> ll = new linkedlist<string>();\n\t\tll.addall(list);\t//把list集合加入ll中\n\t\tll.add("john");\n\t\tll.addfirst("john");\n\n\t\t//iterator遍历\n\t\titerator<string> it = ll.iterator();\n\t\tsystem.out.print("iteraror遍历:");\n\t\twhile(it.hasnext()) {\n\t\t\tstring str = (string)(it.next());\n\t\t\tsystem.out.print(str + " ");\n\t\t}\n\t\tsystem.out.println();\n\t\t\n\t\t//jdk8 foreach遍历迭代器对象\n\t\tll.removefirst();\n\t\titerator<string> it1 = ll.iterator();\n\t\tit1.foreachremaining(obj -> system.out.print("\\t迭代集合元素：" + obj));\n\t\tsystem.out.println();\n\t\t\n\t\t//逆向迭代遍历\n\t\tsystem.out.print("逆向迭代遍历：");\n\t\tlistiterator<string> li = ll.listiterator(ll.size());\n\t\twhile(li.hasprevious()){\n\t\t\tstring str = (string)li.previous();\n\t\t\tsystem.out.print(str + " ");\n\t\t}\n\t}\n}\n\n\npublic class t_vector {\n\tpublic static void main(string[] args) {\n\t\tt_vector t = new t_vector();\n\t\tvector<string> v = new vector<string>();\n\t\tv.add("10086");\n\t\tv.add("10087");\n\t\tv.add("10088");\n\t\tv.add("10089");\n\t\tt.printset2(v);\n\t}\n\n\tpublic void printset2(vector<string> hs) {\n        enumeration<string> elements = hs.elements();\n        while (elements.hasmoreelements()) {\n            system.out.println(elements.nextelement());\n        }\n    }\n}\n\n\n// -----------------------第一种：实现comparable接口 -------------------------\npublic class student implements comparable<object>{\n\tprivate string name;\n\tprivate byte age;\n\tprivate string id;\n\tpublic student(string name, byte age, string id) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.id = id;\n\t}\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "姓名：" + name + "年龄：" + age + "学号：" + id;\n\t}\n\t@override\n\tpublic int compareto(object obj) {\n\t\t// todo auto-generated method stub\n\t\tstudent student = (student)obj;\n\t\t/*if(this.age>student.age){\n\t\t\treturn 1;\n\t\t}else if(this.age==student.age){\n\t\t\treturn this.name.compareto(student.name);\n\t\t}else{\n\t\t\treturn -1;\n\t\t}*/\n\t\tif(this.name.equals(student.name)){\n\t\t\treturn this.age-student.age;\n\t\t}else{\n\t\t\treturn this.name.compareto(student.name);\n\t\t}\n\t}\n}\n\n// -----------------------第二种：comparator（自定义比较器） -------------------------\npublic class mycomparator implements comparator<object>{\n\t@override\n\tpublic int compare(object obj1, object obj2) {\n\t\t// todo auto-generated method stub\n\t\tstudents students1 = (students)obj1;\n\t\tstudents students2 = (students)obj2;\n\t\t/*if(students1.age>students2.age){\n\t\t\treturn 1;\n\t\t}else if(students1.age==students2.age){\n\t\t\treturn students1.name.compareto(students2.name);\n\t\t}else{\n\t\t\treturn -1;\n\t\t}*/\n\t\tif(students1.name.equals(students2.name)){\n\t\t\treturn students2.age-students1.age;\n\t\t}else{\n\t\t\treturn students1.name.compareto(students2.name);\n\t\t}\n\t}\n}\n\npublic class students {\n\tstring name;\n\tbyte age;\n\tstring id;\n\tpublic students(string name, byte age, string id) {\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t\tthis.id = id;\n\t}\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn "姓名：" + name + "年龄：" + age + "学号：" + id;\n\t}\n\t@override\n\tpublic boolean equals(object obj) {\n\t\t// todo auto-generated method stub\n\t\tif(this == obj){\n\t\t\treturn true; \n\t\t}\n\t\tif(obj instanceof students){\n\t\t\tif(this.id.equals(((students) obj).id)){\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\t@override\n\tpublic int hashcode() {\n\t\t// todo auto-generated method stub\n\t\treturn id.hashcode();\n\t}\n}\n\n// --------------------- 测试类 -----------------------------\npublic class test {\n\tpublic static void main(string[] args) {\n\t\t// todo auto-generated method stub\n\t\thashset<student> hs = new hashset<student>();\n\t\tstudent s1 = new student("aaa", (byte) 20, "10086");\n\t\tstudent s2 = new student("bbb", (byte) 23, "10087");\n\t\tstudent s3 = new student("ccc", (byte) 21, "10088");\n\t\tstudent s4 = new student("aaa", (byte) 19, "10089");\n\t\ths.add(s1);\n\t\ths.add(s2);\n\t\ths.add(s3);\n\t\ths.add(s4);\n\t\ths.foreach(str -> system.out.println(str));\n\t\t// system.out.println(hs);\n\t\tsystem.out.println();\n\n\t\thashset<students> hst = new hashset<students>();\n\t\tstudents s5 = new students("aaa", (byte) 20, "10086");\n\t\tstudents s6 = new students("bbb", (byte) 23, "10087");\n\t\tstudents s7 = new students("ccc", (byte) 21, "10088");\n\t\tstudents s8 = new students("aaa", (byte) 19, "10089");\n\t\thst.add(s5);\n\t\thst.add(s6);\n\t\thst.add(s7);\n\t\thst.add(s8);\n\t\thst.foreach(str -> system.out.println(str));\n\n\t\ttreeset<student> ts2 = new treeset<student>();\n\t\t// 不实现comparatable时不可排序 运行时错误\n\t\tts2.add(s1);\n\t\tts2.add(s2);\n\t\tts2.add(s3);\n\t\tts2.add(s4);\n\t\t//system.out.println(ts2);\n\t\tsystem.out.println("comparable：按姓名-年龄排序");\n\t\titerator<student> it2 = ts2.iterator();\n\t\tit2.foreachremaining(stu->system.out.println(stu + ""));\n\n\t\ttreeset<students> ts = new treeset<students>(new mycomparator());\n\t\tts.add(s5);\n\t\tts.add(s6);\n\t\tts.add(s7);\n\t\tts.add(s8);\n\t\t//system.out.println(ts);\n\t\tsystem.out.println("comparator：按姓名-年龄排序");\n\t\titerator<students> it = ts.iterator();\n\t\tit.foreachremaining(stu->system.out.println(stu + " "));\n\t}\n}\n\n\npublic class t_map {\n\tpublic static void main(string[] args) {\n\t\tmap<string, string> map = new hashmap<string, string>();\n\t\tmap.put("aaa", "987654321");\n\t\tmap.put("bbb", "87654321");\n\t\tmap.put("ccc", "7654321");\n\t\tmap.put("ddd", "654321");\n\t\tmap.put("bbb", "54321");\n\t\t// 迭代器遍历\n\t\tsystem.out.println("迭代器遍历：");\n\t\tset keyset = map.keyset();\n\t\titerator it = keyset.iterator();\n\t\twhile (it.hasnext()) {\n\t\t\tobject key = it.next();\n\t\t\tobject value = map.get(key);\n\t\t\tsystem.out.print(key + "=" + value +"\\t");\n\t\t}\n\t\tsystem.out.println();\n\t\t// system.out.println(map);\n\n\t\tif (map.containskey("aaa") && map.get("aaa").equals("987654321")) {\n\t\t\tsystem.out.println("用户存在且密码正确");\n\t\t}else{\n\t\t\tsystem.out.println("用户名或密码不正确");\n\t\t}\n\n\t\tsystem.out.println(map.keyset());\n\t\tsystem.out.println(map.values());\n\n\t\tmap.replace("bbb", "876543210");\n\t\t//foreach遍历\n\t\tsystem.out.println("foreach遍历：");\n\t\tmap.foreach((k,v)->system.out.println(k + "=" +v));\n\n\t\tmap.remove("aaa");\n\t\tsystem.out.println("entryset方法：");\n\t\tset entryset = map.entryset();\n\t\titerator it2 = keyset.iterator();\n\t\twhile (it2.hasnext()) {\n\t\t\tobject key = it2.next();\n\t\t\tobject value = map.get(key);\n\t\t\tsystem.out.print(key + "=" + value +"\\t");\n\t\t}\n\t\tsystem.out.println();\n\t\tcollection<string> values = map.values();\n\t\tvalues.foreach(value->system.out.print(value + "    "));\n\t\t\n\t\tsystem.out.println();\n\t\t//按放的顺序输出\n\t\tmap map2 = new linkedhashmap();\n\t\t//map2.putall(map);\n\t\tmap2.put("aaa", "987654321");\n\t\tmap2.put("bbb", "87654321");\n\t\tmap2.put("ccc", "7654321");\n\t\tmap2.put("ddd", "654321");\n\t\tmap2.put("bbb", "54321");\n\t\tmap2.foreach((k,v)->system.out.println(k + ":" +v));\n\t}\n}\n\n\npublic class t_collections {\n\tpublic static void main(string[] args) {\n\t\tstudent stu[] = new student[3];\n\t\tstu[0] = new student("aaa",(byte)20,"10086");\n\t\tstu[1] = new student("bbb",(byte)19,"10087");\n\t\tstu[2] = new student("ccc",(byte)21,"70088");\n\t\tlist<student> lt = new linkedlist<student>();\n\t\tlt.add(stu[0]);\n\t\tlt.add(stu[1]);\n\t\tlt.add(stu[2]);\n\t\tlt.foreach(i->system.out.println(i));\n\t\t\n\t\tsystem.out.println("排序后：");\n\t\tcollections.sort(lt);\t\t\t\t\t\t\t//实现比较器（自然排序或定制排序）\n\t\tlt.foreach(i->system.out.println(i));\n\t\t\n\t\tsystem.out.println("二分查找：");\n\t\tstudent s = new student("ccc",(byte)21,"10087");\t\t//为什么先反转有两个查不到？？？\n\t\tint index = collections.binarysearch(lt,s,null);\n\t\tsystem.out.println(index);\n\t\t\n\t\tsystem.out.println("反转后：");\n\t\tcollections.reverse(lt);\n\t\tlt.foreach(i->system.out.println(i));\n\t\t\n\t\t//system.out.println(lt);\n\t\t/*iterator it = lt.iterator();\n\t\twhile(it.hasnext()){\n\t\t\tobject obj = it.next();\n\t\t\tsystem.out.println(obj);\n\t\t}*/\n\t}\n}\n\n\npublic class t_arrays {\n\tpublic static void main(string[] args) {\n\t\tstring arr[] = {"h","l","a","h","b"};\n\t\t//排序\n\t\tsystem.out.println("排序：");\n\t\tarrays.sort(arr);\n\t\tsystem.out.println(arrays.tostring(arr));\n\t\t\n\t\t//二分查找\n\t\tsystem.out.println("二分查找：");\n\t\tint index = arrays.binarysearch(arr, "l");\n\t\tsystem.out.println("l的位置：" + index);\n\t\t\n\t\t//打印\n\t\tsystem.out.println("打印数组：");\n\t\tsystem.out.println(arr);\n\t\tstring str = arrays.tostring(arr);\n\t\tsystem.out.println(str);\n\t\t\n\t\t//根据数组创建arraylist\n\t\tsystem.out.println("根据数组创建arraylist:");\n\t\tarraylist al = new arraylist(arrays.aslist(arr));\n\t\tsystem.out.println(al);\n\t\t\n\t\t//检查数组是否包含某个值\n\t\tsystem.out.println("检查数组是否包含某个值:");\n\t\tboolean b = al.contains("lh");\n\t\tsystem.out.println(b);\n\t}\n}\n\n\nclass cachepool2<t>{\n\t\tt temp;\n\t\tpublic t gettemp() {\n\t\t\treturn temp;\n\t\t}\n\t\tpublic void settemp(t temp) {\n\t\t\tthis.temp = temp;\n\t\t}\n\t}\npublic class t_cachepool {\n\tpublic static void main(string[] args) {\n\t\tstudent stu = new student("名字",(byte)20,"10086");\n\t\tcachepool2 c = new cachepool2();\n\t\tc.settemp(stu);\n\t\tsystem.out.println(c.gettemp());\n\t\tc.settemp("this is an apple!");\n\t\tsystem.out.println(c.gettemp());\n\t}\n}\n\n\n# java stream\n\n作用\n\n 1. 对数组、collection 等集合类中的元素进行操作\n\n简单实例\n\n> 需求：从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n\n/**\n * 【常规方式】\n * 从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n *\n * @param sentence 给定的句子，约定非空，且单词之间仅由一个空格分隔\n * @return 倒序输出符合条件的单词列表\n */\npublic list<string> sortgettop3longwords(@notnull string sentence) {\n    // 先切割句子，获取具体的单词信息\n    string[] words = sentence.split(" ");\n    list<string> wordlist = new arraylist<>();\n    // 循环判断单词的长度，先过滤出符合长度要求的单词\n    for (string word : words) {\n        if (word.length() > 5) {\n            wordlist.add(word);\n        }\n    }\n    // 对符合条件的列表按照长度进行排序\n    wordlist.sort((o1, o2) -> o2.length() - o1.length());\n    // 判断list结果长度，如果大于3则截取前三个数据的子list返回\n    if (wordlist.size() > 3) {\n        wordlist = wordlist.sublist(0, 3);\n    }\n    return wordlist;\n}\n\n\n/**\n * 【stream方式】\n * 从给定句子中返回单词长度大于5的单词列表，按长度倒序输出，最多返回3个\n *\n * @param sentence 给定的句子，约定非空，且单词之间仅由一个空格分隔\n * @return 倒序输出符合条件的单词列表\n */\npublic list<string> sortgettop3longwordsbystream(@notnull string sentence) {\n    return arrays.stream(sentence.split(" "))\n            .filter(word -> word.length() > 5)\n            .sorted((o1, o2) -> o2.length() - o1.length())\n            .limit(3)\n            .collect(collectors.tolist());\n}\n\n\nstream 使用 与 spark rdd 使用有些许类似？\n\n 1. 创建 stream\n\n> 主要负责新建一个 stream 流，或者基于现有的数组 list、set、map 等集合类型对象创建出新的stream流。\n\napi                功能说明\nstream()           创建出一个新的stream串行流对象\nparallelstream()   创建出一个可并行执行的stream流对象\nstream.of()        通过给定的一系列元素创建一个新的stream串行流对象\n\n 2. 转换算子\n\n> 负责对 stream 进行处理操作，并返回一个新的 stream 对象，中间管道操作可以进行叠加。\n> \n>  1. 无状态（stateless）操作：指元素的处理不受之前元素的影响\n>  2. 有状态（stateful）操作：指该操作只有拿到所有元素之后才能继续下去\n\napi           功能说明\nfilter()      1按照条件过滤符合要求的元素， 返回新的stream流\nmap()         1将已有元素转换为另一个对象类型，一对一逻辑，返回新的stream流\nflatmap()     将已有元素转换为另一个对象类型，一对多逻辑，即原来一个元素对象可能会转换为1个或者多个新类型的元素，返回新的stream流\nlimit()       2仅保留集合前面指定个数的元素，返回新的stream流\nskip()        2跳过集合前面指定个数的元素，返回新的stream流\nconcat()      将两个流的数据合并起来为1个新的流，返回新的stream流\ndistinct()    2对stream中所有元素进行去重，返回新的stream流\nsorted()      2对stream中所有的元素按照指定规则进行排序，返回新的stream流\npeek()        1对stream流中的每个元素进行逐个遍历处理，返回处理后的stream流\nunordered()   1明确地对流进行去除有序约束可以改善某些有状态或终端操作的并行性能。\n\n 3. 终止stream\n\n> 通过终止管道操作之后，stream 流将会结束，最后可能会执行某些逻辑处理，或者是按照要求返回某些执行后的结果数据。\n> \n>  1. 短路（short-circuiting）操作：指遇到某些符合条件的元素就可以得到最终结果\n>  2. 非短路（unshort-circuiting）操作：指必须处理完所有元素才能得到最终结果\n\napi                功能说明\ncount()            2返回stream处理后最终的元素个数\nmax()              2返回stream处理后的元素最大值\nmin()              2返回stream处理后的元素最小值\nfindfirst()        1找到第一个符合条件的元素时则终止流处理\nfindany()          1找到任何一个符合条件的元素时则退出流处理，这个对于串行流时与findfirst相同，对于并行流时比较高效，任何分片中找到都会终止后续计算逻辑\nanymatch()         1返回一个boolean值，类似于iscontains(),用于判断是否有符合条件的元素\nallmatch()         1返回一个boolean值，用于判断是否所有元素都符合条件\nnonematch()        1返回一个boolean值， 用于判断是否所有元素都不符合条件\ncollect()          2将流转换为指定的类型，通过collectors进行指定\nreduce()           2合并流的元素并产生单个值。\ntoarray()          2将流转换为数组\niterator()         将流转换为iterator对象\nforeach()          2无返回值，对元素进行逐个遍历，然后执行给定的处理逻辑\nforeachordered()   2对该流的每个元素执行操作，并按流的遇到顺序进行。\n\n# 文件操作\n\n\npublic class test1 {\n\tpublic static void main(string[] args) {\n\t\t// todo auto-generated method stub\n\t\tfileinputstream fis=null;\n\t\tfileoutputstream fos=null;\n\t\ttry{\n\t\t\tfis = new fileinputstream("file/hello.txt");\n\t\t\tfos = new fileoutputstream("file/hello副本.txt",true);\n\t\t\t\n\t\t\tlong start = system.currenttimemillis();\n\t\t\tint b;\n\t\t\twhile((b=fis.read())!=-1){\n\t\t\t\tfos.write(b);\n\t\t\t}\n\t\t\tlong end = system.currenttimemillis();\n\t\t\tsystem.out.println(end-start + " ms");\n\n\t\t}catch(ioexception e){\n\t\t\tsystem.out.println("拷贝出错");\n\t\t}finally{\n\t\t\ttry{\n\t\t\t\tif(fos!=null){\n\t\t\t\t\tfos.close();\n\t\t\t\t\tsystem.out.println("关闭输出流对象成功");\n\t\t\t\t}\n\t\t\t}catch(exception e){\n\t\t\t\tsystem.out.println("关闭输出流对象失败");\n\t\t\t}finally{\n\t\t\t\ttry{\n\t\t\t\t\tif(fis!=null){\n\t\t\t\t\t\tfis.close();\n\t\t\t\t\t\tsystem.out.println("关闭输入流对象成功");\n\t\t\t\t\t}\n\t\t\t\t}catch(exception e){\n\t\t\t\t\tsystem.out.println("关闭输入流对象失败");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n\npublic class test2 {\n\tpublic static void main(string[] args) throws ioexception {\n\t\t// todo auto-generated method stub\n\t\tfileinputstream fis = new fileinputstream("file/视频.mp4");\n\t\tfileoutputstream fos = new fileoutputstream("file/视频副本.mp4");\n\t\t\n\t\tbyte buff[] = new byte[8192];\n\t\tlong start = system.currenttimemillis();\n\t\tint len;\n\t\twhile((len=fis.read(buff))!=-1){\n\t\t\tfos.write(buff,0,len);\n\t\t}\n\t\tlong end = system.currenttimemillis();\n\t\tsystem.out.println(end-start + " ms");\n\t\t\n\t\tfos.close();\n\t\tfis.close();\n\t}\n}\n\n\npublic class test3 {\n\tpublic static void main(string[] args) throws exception {\n\t\t// todo auto-generated method stub\n\t\tbufferedinputstream bis = new bufferedinputstream(new fileinputstream("file/猫.jpg"));\n\t\tbufferedoutputstream bos = new bufferedoutputstream(new fileoutputstream("file/猫副本.jpg"));\n\t\tlong start = system.currenttimemillis();\n\t\tint len;\n\t\twhile((len=bis.read())!=-1){\n\t\t\tbos.write(len);\n\t\t}\n\t\tlong end = system.currenttimemillis();\n\t\tsystem.out.println(end-start + " ms");\n\t\tbos.close();\n\t\tbis.close();\n\t}\n}\n\n\npublic class test4 {\n\tpublic static void main(string[] args) throws ioexception {\n\t\t// todo auto-generated method stub\n\t\tfilereader fr = new filereader("file/文档.txt");\n\t\tfilewriter fw = new filewriter("file/文档副本.txt");\n\t\tlong start = system.currenttimemillis();\n\t\tint len;\n\t\twhile((len=fr.read())!=-1){\n\t\t\tfw.write(len);\n\t\t}\n\t\tfw.write("\\r\\n");\n\t\tfw.write("玲珑骰子");\n\t\tfw.write("安红豆，\\r\\n");\n\t\tfw.write("入骨相思");\n\t\tfw.write("君知否");\n\t\tlong end = system.currenttimemillis();\n\t\tsystem.out.println(end-start + "ms");\n\t\tfw.close();\n\t\tfr.close();\n\t}\n}\n\n\npublic class test5 {\n\tpublic static void main(string[] args) throws ioexception {\n\t\t// todo auto-generated method stub\n\t\tbufferedreader br = new bufferedreader(new filereader("file/文档.txt"));\n\n\t\tbufferedwriter bw = new bufferedwriter(new filewriter("file/文档副本1.txt"));\n\t\tlong start = system.currenttimemillis();\n\t\tstring str = null;\n\t\twhile ((str = br.readline()) != null) {\n\t\t\tbw.write(str);\n\t\t\tbw.newline();\n\t\t}\n\t\tlong end = system.currenttimemillis();\n\t\tsystem.out.println(end - start + " ms");\n\t\tbw.close();\n\t\tbr.close();\n\t}\n}\n\n\npublic class test6 {\n\tpublic static void main(string[] args) throws ioexception {\t\t\t//转换流\n\t\tfileinputstream fis = new fileinputstream("file/reader.txt");\n\t\tinputstreamreader isr = new inputstreamreader(fis);\n\t\tbufferedreader br = new bufferedreader(isr);\n\t\t\n\t\tfileoutputstream fos = new fileoutputstream("file/writer.txt");\n\t\toutputstreamwriter osr = new outputstreamwriter(fos);\n\t\tbufferedwriter bw = new bufferedwriter(osr);\n\n\t\tstring line=null;\n\t\twhile((line=br.readline())!=null){\n\t\t\tbw.write(line);\n\t\t\tbw.newline();\t\t\t\t\t\t//换行\n\t\t\tbw.flush();\t\t\t\t\t\t\t//刷新缓冲\n\t\t\tif(line.equals("end")){\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t\n\t\tbw.close();\n\t\tbw.close();\n\t}\n}\n\n\npublic class test7 {\n\tpublic static void main(string[] args) {\n\n\t\tstudent stu=new student("学生");\n\t\tdecorator dec = new decorator(stu);\n\t\tsystem.out.println(dec);\n\t\tdec.study();\n\t}\n}\nclass student{\n\tprivate string name;\n\tpublic student(){\n\t\t\n\t}\n\tpublic student(string name) {\n\t\tsuper();\n\t\tthis.name = name;\n\t}\n\tpublic string getname(){\n\t\treturn name;\n\t}\n\tpublic void study(){\n\t\tsystem.out.println("做题");\n\t}\n}\nclass decorator{\n\tstudent s = new student();\n\tpublic decorator(student s) {\n\t\tsuper();\n\t\tthis.s = s;\n\t}\n\tpublic void study(){\n\t\ts.study();\n\t\tsystem.out.println("看书");\n\t}\n\t@override\n\tpublic string tostring() {\n\t\treturn "姓名：" + s.getname();\n\t}\n}\n\n\nclass hero implements serializable{\n\tprivate static final long serialversionuid = 1l;\n\tprivate string name;\n\tprivate int hp;\n\tpublic hero(string name, int hp) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.hp = hp;\n\t}\n\tpublic string getname() {\n\t\treturn name;\n\t}\n\tpublic void setname(string name) {\n\t\tthis.name = name;\n\t}\n\tpublic int gethp() {\n\t\treturn hp;\n\t}\n\tpublic void sethp(int hp) {\n\t\tthis.hp = hp;\n\t}\n\t@override\n\tpublic string tostring() {\n\t\t// todo auto-generated method stub\n\t\treturn name + "  " + hp;\n\t}\n}\n\npublic class test8 {\n\tpublic static void main(string[] args) throws ioexception, classnotfoundexception {\n\n\t\tfileoutputstream fos = new fileoutputstream("file/hero.txt",true);\n\t\tobjectoutputstream oos = new objectoutputstream(fos);\n\t\t\n\t\tfileinputstream fis = new fileinputstream("file/hero.txt");\n\t\tobjectinputstream ois = new objectinputstream(fis);\n\t\t\n\t\thero hero = new hero("德鲁伊",1000);\n\t\tsystem.out.println(hero);\n\t\toos.writeobject(hero);\n\n\t\tfor (int i = 0; i < 5; i++) {\n\t\t\thero.sethp(hero.gethp()-(int)math.floor(math.random()*200));\n\t\t}\n\t\tsystem.out.println(hero);\n\t\t\n\t\thero = (hero)(ois.readobject());\n\t\tsystem.out.println(hero);\n\t\t\n\t\tois.close();\n\t\tfis.close();\n\t\toos.close();\n\t\tfos.close();\n\t}\n}\n\n\n// 数据输出流允许应用程序以与机器无关方式将java基本数据类型写到底层输出流\npublic class test_data_stream {\n\n\tpublic static void main(string[] args) throws exception {\n\t\tfileoutputstream fos = new fileoutputstream("file/文本.txt");\n\t\tdataoutputstream dos = new dataoutputstream(new bufferedoutputstream(fos));\n\n\t\tdos.writebyte(01);\n\t\tdos.writedouble(99.999999);\n\t\tdos.writeint(516546);\n\t\tdos.writeboolean(false);\n\t\tdos.writeutf("龘龘");\n\n\t\tdos.close();\n\t\tfos.close();\n\n\t\tfileinputstream fis = new fileinputstream("file/文本.txt");\n\t\tdatainputstream dis = new datainputstream(new bufferedinputstream(fis));\n\n\t\tsystem.out.println(dis.readbyte());\n\t\tsystem.out.println(dis.readdouble());\n\t\tsystem.out.println(dis.readint());\n\t\tsystem.out.println(dis.readboolean());\n\t\tsystem.out.println(dis.readutf());\n\n\t\tdis.close();\n\t\tfis.close();\n\t}\n}\n\n\n// 合并流：它从输入流的有序集合开始，并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末尾为止\npublic class test_sequence {\n\tpublic static void main(string[] args) throws exception {\n\t\t// 创建了两个流对象in1、in2\n\t\tfileinputstream in1 = new fileinputstream("file/stream1.txt");\n\t\tfileinputstream in2 = new fileinputstream("file/stream2.txt");\n\t\t// 创建一个序列流，合并两个字节流in1和in2\n\t\tsequenceinputstream sis = new sequenceinputstream(in1, in2);\n\t\tfileoutputstream out = new fileoutputstream("file/stream.txt");\n\t\tint len;\n\t\t// 创建一个1024个字节数组作为缓冲区\n\t\tbyte[] buf = new byte[1024];\n\t\t// 同时三个流！\n\t\twhile ((len = sis.read(buf)) != -1) {\n\t\t\tout.write(buf, 0, len); // 将缓冲区中的数据输出\n\t\t\tout.write("\\r\\n".getbytes());\n\t\t}\n\t\tsis.close();\n\t\tout.close();\n\t}\n}\n\n\n//system.in是inputstream, 标准输入流, 默认可以从键盘输入读取字节数据\n//system.out是printstream, 标准输出流, 默认可以向console中输出字符和字节数据\npublic class test_print1 {\n\tpublic static void main(string[] args) throws ioexception{\n\n\t\t// inputstream();\n\t\tsystem.setin(new fileinputstream("file/in.txt")); // 改变标准输入流\n\t\tsystem.setout(new printstream("file/out.txt")); // 改变标准输出流\n\t\tinputstream is = system.in; // 获取标准的键盘输入流，默认指向键盘，改变后指向文件\n\t\tprintstream ps = system.out; // 获取标准的输出流，默认指向的是控制台，改变后就指向文件\n\n\t\tint b;\n\t\twhile ((b = is.read()) != -1) {\n\t\t\tps.write(b);\n\t\t}\n\t\tis.close();\n\t\tps.close();\n\t}\n}\n\n// ----------------------------------------------------------------------\n\npublic class test_print2 {\n\tpublic static void main(string[] args) throws exception {\n\t\tsystem.setin(new fileinputstream("file/in.txt"));\t\t//改变后指向文件\n\t\tinputstream is2=system.in;\n\t\tprintstream ps2 = system.out;\n\t\tint b2;\n\t\twhile ((b2 = is2.read()) != -1) {\n\t\t\tps2.write(b2);\n\t\t}\n\t\tps2.close();\n\t\tis2.close();\n\t\t\n\t\t/*system.setout(new printstream("file/out.txt"));\n\t\tinputstream is3=system.in;\n\t\tprintstream ps3 = system.out;\n\t\tint b3;\n\t\twhile ((b3 = is3.read()) != -1) {\n\t\t\tps3.write(b3);\n\t\t}\n\t\tps3.close();\n\t\tis3.close();*/\n\t}\n}\n\n\npublic static void main(string[] args) {\n    try {\n        fileinputstream fis = new fileinputstream("d://java.txt");\n        inputstreamreader isr = new inputstreamreader(fis, "utf-8");\n        int b = 0;\n        while ((b = isr.read()) != -1) {\n            system.out.print((char) b);    // 输出结果为“c语言中文网”\n        }\n    } catch (filenotfoundexception e) {\n        // todo auto-generated catch block\n        e.printstacktrace();\n    } catch (ioexception e) {\n        // todo auto-generated catch block\n        e.printstacktrace();\n    }\n}\n\n\nimport java.io.*;\nimport java.net.malformedurlexception;\nimport java.net.url;\n\n/**\n * 文件工具类\n */\npublic class fileutil {\n    /**\n     * 读取文件内容\n     *\n     * @param is\n     * @return\n     */\n    public static string readfile(inputstream is) {\n        bufferedreader br = null;\n        stringbuffer sb = new stringbuffer();\n        try {\n            br = new bufferedreader(new inputstreamreader(is, "utf-8"));\n            string readline = null;\n            while ((readline = br.readline()) != null) {\n                sb.append(readline+"\\r\\n");\n            }\n        } catch (exception e) {\n            e.printstacktrace();\n        } finally {\n            try {\n                br.close();\n                is.close();\n            } catch (ioexception e) {\n                e.printstacktrace();\n            }\n        }\n        return sb.tostring();\n    }\n    /**\n     * @description 写文件\n     * @param args\n     * @throws unsupportedencodingexception\n     * @throws ioexception\n     */\n    public static boolean writetxtfile(string content, file filename, string encoding) {\n        fileoutputstream o = null;\n        boolean result=false;\n        try {\n            o = new fileoutputstream(filename);\n            o.write(content.getbytes(encoding));\n            result=true;\n        } catch (filenotfoundexception e) {\n            e.printstacktrace();\n        } catch (unsupportedencodingexception e) {\n            e.printstacktrace();\n        } catch (ioexception e) {\n            e.printstacktrace();\n        } finally {\n            if (o != null) {\n                try {\n                    o.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n            }\n        }\n\n        return result;\n    }\n    public static string readfile(string path){\n        file file07 = new file(path);\n        inputstream is=null;\n        try {\n            is = new fileinputstream(file07);\n        } catch (filenotfoundexception e) {\n            e.printstacktrace();\n        }\n        return readfile(is);\n    }\n    \n    /**\n     * 判断指定的文件是否存在。\n     *\n     * @param filename\n     * @return\n     */\n    public static boolean isfileexist(string filename) {\n        return new file(filename).isfile();\n    }\n\n    /**\n     * 创建指定的目录。 如果指定的目录的父目录不存在则创建其目录书上所有需要的父目录。\n     * 注意：可能会在返回false的时候创建部分父目录。\n     *\n     * @param file\n     * @return\n     */\n    public static boolean makedirectory(file file) {\n        file parent = file.getparentfile();\n        if (parent != null) {\n            return parent.mkdirs();\n        }\n        return false;\n    }\n\n    /**\n     * 返回文件的url地址。\n     *\n     * @param file\n     * @return\n     * @throws malformedurlexception\n     */\n    public static url geturl(file file) throws malformedurlexception {\n        string fileurl = "file:/" + file.getabsolutepath();\n        url url = new url(fileurl);\n        return url;\n    }\n\n    /**\n     * 从文件路径得到文件名。\n     *\n     * @param filepath\n     * @return\n     */\n    public static string getfilename(string filepath) {\n        file file = new file(filepath);\n        return file.getname();\n    }\n\n    /**\n     * 从文件名得到文件绝对路径。\n     *\n     * @param filename\n     * @return\n     */\n    public static string getfilepath(string filename) {\n        file file = new file(filename);\n        return file.getabsolutepath();\n    }\n\n    /**\n     * 将dos/windows格式的路径转换为unix/linux格式的路径。\n     *\n     * @param filepath\n     * @return\n     */\n    public static string tounixpath(string filepath) {\n        return filepath.replace("", "/");\n    }\n\n    /**\n     * 从文件名得到unix风格的文件绝对路径。\n     *\n     * @param filename\n     * @return\n     */\n    public static string getunixfilepath(string filename) {\n        file file = new file(filename);\n        return tounixpath(file.getabsolutepath());\n    }\n\n    /**\n     * 得到文件后缀名\n     *\n     * @param filename\n     * @return\n     */\n    public static string getfileext(string filename) {\n        int point = filename.lastindexof(\'.\');\n        int length = filename.length();\n        if (point == -1 || point == length - 1) {\n            return "";\n        } else {\n            return filename.substring(point + 1, length);\n        }\n    }\n\n    /**\n     * 得到文件的名字部分。 实际上就是路径中的最后一个路径分隔符后的部分。\n     *\n     * @param filename\n     * @return\n     */\n    public static string getnamepart(string filename) {\n        int point = getpathlastindex(filename);\n        int length = filename.length();\n        if (point == -1) {\n            return filename;\n        } else if (point == length - 1) {\n            int secondpoint = getpathlastindex(filename, point - 1);\n            if (secondpoint == -1) {\n                if (length == 1) {\n                    return filename;\n                } else {\n                    return filename.substring(0, point);\n                }\n            } else {\n                return filename.substring(secondpoint + 1, point);\n            }\n        } else {\n            return filename.substring(point + 1);\n        }\n    }\n\n    /**\n     * 得到文件名中的父路径部分。 对两种路径分隔符都有效。 不存在时返回""。\n     * 如果文件名是以路径分隔符结尾的则不考虑该分隔符，例如"/path/"返回""。\n     *\n     * @param filename\n     * @return\n     */\n    public static string getpathpart(string filename) {\n        int point = getpathlastindex(filename);\n        int length = filename.length();\n        if (point == -1) {\n            return "";\n        } else if (point == length - 1) {\n            int secondpoint = getpathlastindex(filename, point - 1);\n            if (secondpoint == -1) {\n                return "";\n            } else {\n                return filename.substring(0, secondpoint);\n            }\n        } else {\n            return filename.substring(0, point);\n        }\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中最后出现的位置。 对于dos或者unix风格的分隔符都可以。\n     *\n     * @param filename\n     * @return\n     */\n    public static int getpathlastindex(string filename) {\n        int point = filename.lastindexof("/");\n        if (point == -1) {\n            point = filename.lastindexof("");\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中指定位置前最后出现的位置。 对于dos或者unix风格的分隔符都可以。\n     *\n     * @param filename\n     * @param fromindex\n     * @return\n     */\n    public static int getpathlastindex(string filename, int fromindex) {\n        int point = filename.lastindexof("/", fromindex);\n        if (point == -1) {\n            point = filename.lastindexof("", fromindex);\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中首次出现的位置。 对于dos或者unix风格的分隔符都可以。\n     *\n     * @param filename\n     * @return\n     */\n    public static int getpathindex(string filename) {\n        int point = filename.indexof("/");\n        if (point == -1) {\n            point = filename.indexof("");\n        }\n        return point;\n    }\n\n    /**\n     * 得到路径分隔符在文件路径中指定位置后首次出现的位置。 对于dos或者unix风格的分隔符都可以。\n     *\n     * @param filename\n     * @param fromindex\n     * @return\n     */\n    public static int getpathindex(string filename, int fromindex) {\n        int point = filename.indexof("/", fromindex);\n        if (point == -1) {\n            point = filename.indexof("", fromindex);\n        }\n        return point;\n    }\n\n    /**\n     * 将文件名中的类型部分去掉。\n     *\n     * @param filename\n     * @return\n     */\n    public static string removefileext(string filename) {\n        int index = filename.lastindexof(".");\n        if (index != -1) {\n            return filename.substring(0, index);\n        } else {\n            return filename;\n        }\n    }\n\n    /**\n     * 得到相对路径。 文件名不是目录名的子节点时返回文件名。\n     *\n     * @param pathname\n     * @param filename\n     * @return\n     */\n    public static string getsubpath(string pathname, string filename) {\n        int index = filename.indexof(pathname);\n        if (index != -1) {\n            return filename.substring(index + pathname.length() + 1);\n        } else {\n            return filename;\n        }\n    }\n\n    /**\n     * 删除一个文件。\n     *\n     * @param filename\n     * @throws ioexception\n     */\n    public static void deletefile(string filename) throws ioexception {\n        file file = new file(filename);\n        if (file.isdirectory()) {\n            throw new ioexception("ioexception -> badinputexception: not a file.");\n        }\n        if (!file.exists()) {\n            throw new ioexception("ioexception -> badinputexception: file is not exist.");\n        }\n        if (!file.delete()) {\n            throw new ioexception("cannot delete file. filename = " + filename);\n        }\n    }\n\n    /**\n     * 删除文件夹及其下面的子文件夹\n     *\n     * @param dir\n     * @throws ioexception\n     */\n    public static void deletedir(file dir) throws ioexception {\n        if (dir.isfile())\n            throw new ioexception("ioexception -> badinputexception: not a directory.");\n        file[] files = dir.listfiles();\n        if (files != null) {\n            for (int i = 0; i < files.length; i++) {\n                file file = files[i];\n                if (file.isfile()) {\n                    file.delete();\n                } else {\n                    deletedir(file);\n                }\n            }\n        }\n        dir.delete();\n    }\n\n    /**\n     * 复制文件\n     *\n     * @param src\n     * @param dst\n     * @throws exception\n     */\n    public static void copy(file src, file dst) throws exception {\n        int buffer_size = 4096;\n        inputstream in = null;\n        outputstream out = null;\n        try {\n            in = new bufferedinputstream(new fileinputstream(src), buffer_size);\n            out = new bufferedoutputstream(new fileoutputstream(dst), buffer_size);\n            byte[] buffer = new byte[buffer_size];\n            int len = 0;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } catch (exception e) {\n            throw e;\n        } finally {\n            if (null != in) {\n                try {\n                    in.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n                in = null;\n            }\n            if (null != out) {\n                try {\n                    out.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n                out = null;\n            }\n        }\n    }\n\n    /**\n     * @复制文件，支持把源文件内容追加到目标文件末尾\n     * @param src\n     * @param dst\n     * @param append\n     * @throws exception\n     */\n    public static void copy(file src, file dst, boolean append) throws exception {\n        int buffer_size = 4096;\n        inputstream in = null;\n        outputstream out = null;\n        try {\n            in = new bufferedinputstream(new fileinputstream(src), buffer_size);\n            out = new bufferedoutputstream(new fileoutputstream(dst, append), buffer_size);\n            byte[] buffer = new byte[buffer_size];\n            int len = 0;\n            while ((len = in.read(buffer)) > 0) {\n                out.write(buffer, 0, len);\n            }\n        } catch (exception e) {\n            throw e;\n        } finally {\n            if (null != in) {\n                try {\n                    in.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n                in = null;\n            }\n            if (null != out) {\n                try {\n                    out.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n                out = null;\n            }\n        }\n    }\n}\n\n\n# javax.swing（略，已经很少使用）\n\n# 网络编程（略，java.net包）\n\n\n# 注解\n\n# 定义\n\n> java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。\n> 注解相关类都包含在java.lang.annotation包中。\n\n# jdk基本注解\n\n 1. @override 重写\n 2. @deprecated 已过时\n 3. @suppresswarnings(value = "unchecked") 压制编辑器警告\n\n# jdk元注解\n\n> 元注解用于修饰其他的注解\n\n/* 定义注解的保留策略 */\n@retention(retentionpolicy.source)             // 注解仅存在于源码中，在class字节码文件中不包含\n@retention(retentionpolicy.class)              // 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得，\n@retention(retentionpolicy.runtime)            // 注解会在class字节码文件中存在，在运行时可以通过反射获取到\n\n\n/* 指定被修饰的annotation可以放置的位置(被修饰的目标) */\n@target(elementtype.type)                      // 类、接口（包括注解类型）或 enum 声明\n@target(elementtype.field)                     // 用于成员变量（包括枚举常量）\n@target(elementtype.method)                    // 方法\n@target(elementtype.parameter)                 // 方法参数\n@target(elementtype.constructor)               // 构造函数\n@target(elementtype.local_variable)            // 局部变量\n@target(elementtype.annotation_type)           // 注解\n@target(elementtype.package)                   // 包 \n\n\n// 指定被修饰的annotation将具有继承性\n\n\n// 指定被修饰的该annotation可以被javadoc工具提取成文档\n\n\n# 自定义注解\n\n 1. 标记注解：没有定义成员变量的注解类型被称为标记注解。这种注解仅利用自身的存在与否来提供信息，如 @override。\n    \n    // 定义一个简单的注解类型\n    public @interface test {\n    \n    }\n    \n\n 2. 元数据注解：包含成员变量的注解，因为它们可以接受更多的元数据，所以也被称为元数据注解。\n    \n    public @interface mytag {\n        // 定义了两个成员变量的注解\n        // 使用default为两个成员变量指定初始值\n        string name() default "c语言中文网";\n        int age() default 7;\n    }\n    \n\n# 通过反射获取注解信息\n\n@xmlrootelement(name="user")\n@xmlaccessortype(xmlaccesstype.field)\npublic class user {\n \n  private string pwd;\n \n  @xmlelement(name = "id")\n  private int id;\n  \n  @xmlattribute\n  @xmlelement\n  private string name;\n  \n  /***\n   *  1、获取属性上的指定类型的注释\n   *  2、获取属性上的指定类型的注释的指定方法\n   *  3、获取属性上的所有注释\n   *  4、获取类上的所有注释\n   *  5、获取方法上的所有注释\n   */\n  @suppresswarnings("rawtypes")\n  public static void main(string[] args) {\n    \n    field[] fields =  user.class.getdeclaredfields();\n    \n    for(field f : fields){\n      string filedname = f.getname();\n      system.out.println("属性名称:【"+filedname+"】");\n \n      //1、获取属性上的指定类型的注释\n      annotation annotation = f.getannotation(xmlelement.class);\n      \n      //有该类型的注释存在\n      if (annotation!=null) {\n        //强制转化为相应的注释\t\n        xmlelement xmlelement = (xmlelement)annotation;\n        //3、获取属性上的指定类型的注释的指定方法\n        //具体是不是默认值可以去查看源代码\n        if (xmlelement.name().equals("##default")) {\n          system.out.println("属性【"+filedname+"】注释使用的name是默认值: "+xmlelement.name());\n        }else {\n          system.out.println("属性【"+filedname+"】注释使用的name是自定义的值: "+xmlelement.name());\n        }\n      }\n \n      //2、获取属性上的所有注释\n      annotation[] allannotations = f.getannotations();\n      \n      for(annotation an : allannotations){\n        \n        class annotationtype = an.annotationtype();\n        \n        system.out.println("属性【"+filedname+"】的注释类型有: " + annotationtype);\n      }\n      system.out.println("----------华丽的分割线--------------");\n    }\n    \n    //4、获取类上的所有注释\n    annotation[] classannotation = user.class.getannotations();\n    \n    for(annotation cannotation : classannotation){\n      class annotationtype =  cannotation.annotationtype();\n      system.out.println("user类上的注释有: " +annotationtype);\n    }\n    \n    system.out.println("----------华丽的分割线--------------");\n    \n    // 5、获取方法上的所有注释\n    method method;\n    try {\n      method = user.class.getmethod("setpwd",string.class);\n      \n      annotation[] methodannotations = method.getannotations();\n \n      for(annotation me : methodannotations){\n        class annotationtype =  me.annotationtype();\n        system.out.println("setpwd方法上的注释有: " + annotationtype);\n      }\n    } catch (securityexception e) {\n      e.printstacktrace();\n    } catch (nosuchmethodexception e) {\n      e.printstacktrace();\n    }\n  }\n \n  @xmlelement\n  public void setpwd(string pwd) {\n    this.pwd = pwd;\n  }\n \n  public string getpwd() {\n    return pwd;\n  }\n}\n',charsets:{cjk:!0},lastUpdated:"2022/11/08, 23:40:21",lastUpdatedTimestamp:1667922021e3},{title:"装饰者模式",frontmatter:{title:"装饰者模式",date:"2022-07-15T08:46:45.000Z",permalink:"/pages/116f8a/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/030.%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/030.装饰者模式.md",key:"v-8aa2b0da",path:"/pages/116f8a/",headers:[{level:2,title:"装饰者模式（Decorator Pattern）",slug:"装饰者模式-decorator-pattern",normalizedTitle:"装饰者模式（decorator pattern）",charIndex:2},{level:4,title:"咖啡订单系统",slug:"咖啡订单系统",normalizedTitle:"咖啡订单系统",charIndex:77},{level:5,title:"第一次尝试",slug:"第一次尝试",normalizedTitle:"第一次尝试",charIndex:87},{level:5,title:"设计",slug:"设计",normalizedTitle:"设计",charIndex:200},{level:5,title:"关键点",slug:"关键点",normalizedTitle:"关键点",charIndex:206},{level:5,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:406},{level:4,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:412},{level:4,title:"Java API中的装饰者模式（IO流）",slug:"java-api中的装饰者模式-io流",normalizedTitle:"java api中的装饰者模式（io流）",charIndex:3841},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:3865}],headersStr:"装饰者模式（Decorator Pattern） 咖啡订单系统 第一次尝试 设计 关键点 类图 代码实现 Java API中的装饰者模式（IO流） 要点",content:'# 装饰者模式（Decorator Pattern）\n\n装饰者模式 动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。\n\n# 咖啡订单系统\n\n# 第一次尝试\n\nBeverage（饮料）类作为抽象类，每个子类都实现 Beverage 类中的 cost方法。但由于购买咖啡时，可以再其中加入蒸奶、豆浆等调料，所以订单系统需要考虑加入不同调料的价格，导致类呈爆炸性增长。\n\n# 设计\n\n# 关键点\n\n * 装饰者和被装饰对象有相同的父类。\n * 你可以用一个或多个装饰者包装一个对象。\n * 既然装饰者和被装饰对象有相同的父类，所以在任何需要原始对象（被包装的）的场合，可以用装饰过的对象代替它。\n * 装饰者可以在所委托被装饰者的行为之前与（或）之后，加上自己的行为，以达到特定的目的。\n * 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。\n\n# 类图\n\n# 代码实现\n\npublic abstract class Beverage {\n    String description = "未知的饮料";\n\n    public String getDescription() {\n        return description;\n    }\n\n    public abstract double cost();\n}\n-------------------------------------------------------\npublic class HouseBlend extends Beverage {\n    public HouseBlend() {\n        description = "HouseBlend";\n    }\n\n    @Override\n    public double cost() {\n        return 1;\n    }\n}\n-------------------------------------------------------\npublic class DarkRoast extends Beverage {\n\n    public DarkRoast() {\n        description = "DarkRoast";\n    }\n\n    @Override\n    public double cost() {\n        return 2;\n    }\n}\n-------------------------------------------------------\npublic class Espresso extends Beverage {\n    public Espresso() {\n        description = "Espresso";\n    }\n\n    @Override\n    public double cost() {\n        return 3;\n    }\n}\n-------------------------------------------------------\npublic class Decaf extends Beverage {\n    public Decaf() {\n        description = "Decaf";\n    }\n\n    @Override\n    public double cost() {\n        return 4;\n    }\n}\n\n\npublic abstract class CondimentDecorator extends Beverage {\n    @Override\n    public String getDescription() {\n        return super.getDescription();\n    }\n}\n-------------------------------------------------------\npublic class Milk extends CondimentDecorator {\n\n    Beverage beverage;\n\n    public Milk(Beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @Override\n    public double cost() {\n        return beverage.cost() + 0.1;\n    }\n\n    @Override\n    public String getDescription() {\n        return beverage.getDescription() + "，Milk";\n    }\n}\n-------------------------------------------------------\npublic class Mocha extends CondimentDecorator {\n\n    Beverage beverage;\n\n    public Mocha(Beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @Override\n    public double cost() {\n        return beverage.cost() + 0.2;\n    }\n\n    @Override\n    public String getDescription() {\n        return beverage.getDescription() + "，Mocha";\n    }\n}\n-------------------------------------------------------\npublic class Soy extends CondimentDecorator {\n\n    Beverage beverage;\n\n    public Soy(Beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @Override\n    public double cost() {\n        return beverage.cost() + 0.3;\n    }\n\n    @Override\n    public String getDescription() {\n        return beverage.getDescription() + "，Soy";\n    }\n}\n-------------------------------------------------------\npublic class Whip extends CondimentDecorator {\n\n    Beverage beverage;\n\n    public Whip(Beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @Override\n    public double cost() {\n        return beverage.cost() + 0.4;\n    }\n\n    @Override\n    public String getDescription() {\n        return beverage.getDescription() + "，Whip";\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        Beverage darkRoast = new DarkRoast();\n        darkRoast = new Milk(darkRoast);\n        darkRoast = new Mocha(darkRoast);\n        darkRoast = new Soy(darkRoast);\n\n        System.out.println("商品：" + darkRoast.getDescription() + "\\n价格：" + darkRoast.cost());\n\n        Beverage espresso = new Espresso();\n        espresso = new Milk(espresso);\n        espresso = new Whip(espresso);\n\n        System.out.println("商品：" + espresso.getDescription() + "\\n价格：" + espresso.cost());\n    }\n}\n\n\n# Java API中的装饰者模式（IO流）\n\n# 要点\n\n * 继承属于扩展形式之一，但不见得是达到弹性设计的最佳方式。\n * 在我们的设计中，应该允许行为可以被扩展，而无须修改现有的代码。\n * 组合和委托可用于在运行时动态地加上新的行为。\n * 除了继承，装饰者模式也可以让我们扩展行为。\n * 装饰者模式意味着一群装饰者类，这些类用来包装具体组件。\n * 装饰者类反映出被装饰的组件类型（事实上，他们具有相同的类型，都经过接口或继承实现）。\n * 装饰者可以在被装饰者的行为前面与（或）后面加上自己的行为，甚至将被装饰者的行为整个取代掉，而达到特的目的。\n * 你可以用无数个装饰者包装一个组件。\n * 装饰者一般对组件的客户是透明的，除非客户程序依赖于组件的具体类型。\n * 装饰者会导致设计中出现许多小对象，如果过度使用，会让程序变得很复杂。',normalizedContent:'# 装饰者模式（decorator pattern）\n\n装饰者模式 动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。\n\n# 咖啡订单系统\n\n# 第一次尝试\n\nbeverage（饮料）类作为抽象类，每个子类都实现 beverage 类中的 cost方法。但由于购买咖啡时，可以再其中加入蒸奶、豆浆等调料，所以订单系统需要考虑加入不同调料的价格，导致类呈爆炸性增长。\n\n# 设计\n\n# 关键点\n\n * 装饰者和被装饰对象有相同的父类。\n * 你可以用一个或多个装饰者包装一个对象。\n * 既然装饰者和被装饰对象有相同的父类，所以在任何需要原始对象（被包装的）的场合，可以用装饰过的对象代替它。\n * 装饰者可以在所委托被装饰者的行为之前与（或）之后，加上自己的行为，以达到特定的目的。\n * 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。\n\n# 类图\n\n# 代码实现\n\npublic abstract class beverage {\n    string description = "未知的饮料";\n\n    public string getdescription() {\n        return description;\n    }\n\n    public abstract double cost();\n}\n-------------------------------------------------------\npublic class houseblend extends beverage {\n    public houseblend() {\n        description = "houseblend";\n    }\n\n    @override\n    public double cost() {\n        return 1;\n    }\n}\n-------------------------------------------------------\npublic class darkroast extends beverage {\n\n    public darkroast() {\n        description = "darkroast";\n    }\n\n    @override\n    public double cost() {\n        return 2;\n    }\n}\n-------------------------------------------------------\npublic class espresso extends beverage {\n    public espresso() {\n        description = "espresso";\n    }\n\n    @override\n    public double cost() {\n        return 3;\n    }\n}\n-------------------------------------------------------\npublic class decaf extends beverage {\n    public decaf() {\n        description = "decaf";\n    }\n\n    @override\n    public double cost() {\n        return 4;\n    }\n}\n\n\npublic abstract class condimentdecorator extends beverage {\n    @override\n    public string getdescription() {\n        return super.getdescription();\n    }\n}\n-------------------------------------------------------\npublic class milk extends condimentdecorator {\n\n    beverage beverage;\n\n    public milk(beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @override\n    public double cost() {\n        return beverage.cost() + 0.1;\n    }\n\n    @override\n    public string getdescription() {\n        return beverage.getdescription() + "，milk";\n    }\n}\n-------------------------------------------------------\npublic class mocha extends condimentdecorator {\n\n    beverage beverage;\n\n    public mocha(beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @override\n    public double cost() {\n        return beverage.cost() + 0.2;\n    }\n\n    @override\n    public string getdescription() {\n        return beverage.getdescription() + "，mocha";\n    }\n}\n-------------------------------------------------------\npublic class soy extends condimentdecorator {\n\n    beverage beverage;\n\n    public soy(beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @override\n    public double cost() {\n        return beverage.cost() + 0.3;\n    }\n\n    @override\n    public string getdescription() {\n        return beverage.getdescription() + "，soy";\n    }\n}\n-------------------------------------------------------\npublic class whip extends condimentdecorator {\n\n    beverage beverage;\n\n    public whip(beverage beverage) {\n        this.beverage = beverage;\n    }\n\n    @override\n    public double cost() {\n        return beverage.cost() + 0.4;\n    }\n\n    @override\n    public string getdescription() {\n        return beverage.getdescription() + "，whip";\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        beverage darkroast = new darkroast();\n        darkroast = new milk(darkroast);\n        darkroast = new mocha(darkroast);\n        darkroast = new soy(darkroast);\n\n        system.out.println("商品：" + darkroast.getdescription() + "\\n价格：" + darkroast.cost());\n\n        beverage espresso = new espresso();\n        espresso = new milk(espresso);\n        espresso = new whip(espresso);\n\n        system.out.println("商品：" + espresso.getdescription() + "\\n价格：" + espresso.cost());\n    }\n}\n\n\n# java api中的装饰者模式（io流）\n\n# 要点\n\n * 继承属于扩展形式之一，但不见得是达到弹性设计的最佳方式。\n * 在我们的设计中，应该允许行为可以被扩展，而无须修改现有的代码。\n * 组合和委托可用于在运行时动态地加上新的行为。\n * 除了继承，装饰者模式也可以让我们扩展行为。\n * 装饰者模式意味着一群装饰者类，这些类用来包装具体组件。\n * 装饰者类反映出被装饰的组件类型（事实上，他们具有相同的类型，都经过接口或继承实现）。\n * 装饰者可以在被装饰者的行为前面与（或）后面加上自己的行为，甚至将被装饰者的行为整个取代掉，而达到特的目的。\n * 你可以用无数个装饰者包装一个组件。\n * 装饰者一般对组件的客户是透明的，除非客户程序依赖于组件的具体类型。\n * 装饰者会导致设计中出现许多小对象，如果过度使用，会让程序变得很复杂。',charsets:{cjk:!0},lastUpdated:"2022/07/15, 18:03:14",lastUpdatedTimestamp:1657879394e3},{title:"观察者模式",frontmatter:{title:"观察者模式",date:"2022-07-15T08:46:45.000Z",permalink:"/pages/d0e23d/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/020.%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/020.观察者模式.md",key:"v-81b6555c",path:"/pages/d0e23d/",headers:[{level:2,title:"观察者模式（Observer）",slug:"观察者模式-observer",normalizedTitle:"观察者模式（observer）",charIndex:2},{level:4,title:"气象监测应用",slug:"气象监测应用",normalizedTitle:"气象监测应用",charIndex:128},{level:5,title:"1. 问题描述",slug:"_1-问题描述",normalizedTitle:"1. 问题描述",charIndex:138},{level:5,title:"2. 错误示范",slug:"_2-错误示范",normalizedTitle:"2. 错误示范",charIndex:232},{level:5,title:"3. 松耦合",slug:"_3-松耦合",normalizedTitle:"3. 松耦合",charIndex:810},{level:5,title:"4. 类图设计",slug:"_4-类图设计",normalizedTitle:"4. 类图设计",charIndex:942},{level:4,title:"实现观察者模式（主题推送信息）",slug:"实现观察者模式-主题推送信息",normalizedTitle:"实现观察者模式（主题推送信息）",charIndex:953},{level:4,title:"使用内置观察者模式实现主题推送数据",slug:"使用内置观察者模式实现主题推送数据",normalizedTitle:"使用内置观察者模式实现主题推送数据",charIndex:4278},{level:4,title:"使用内置观察者模式实现观察者拉取数据",slug:"使用内置观察者模式实现观察者拉取数据",normalizedTitle:"使用内置观察者模式实现观察者拉取数据",charIndex:6125},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:8445},{level:4,title:"观察者模式对设计原则的应用",slug:"观察者模式对设计原则的应用",normalizedTitle:"观察者模式对设计原则的应用",charIndex:8842}],headersStr:"观察者模式（Observer） 气象监测应用 1. 问题描述 2. 错误示范 3. 松耦合 4. 类图设计 实现观察者模式（主题推送信息） 使用内置观察者模式实现主题推送数据 使用内置观察者模式实现观察者拉取数据 要点 观察者模式对设计原则的应用",content:'# 观察者模式（Observer）\n\n观察者模式 定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。\n\n简单来说：观察者模式 = 出版者（主题 Subject） + 订阅者（观察者 Observer）\n\n# 气象监测应用\n\n# 1. 问题描述\n\n> 此系统中的三个部分是气象站（获取实际气象数据的物理装置）、WeatherData对象(追踪来自气象站的数据，并更新布告板)和布告板（显示目前天气状况给用户看）\n\n# 2. 错误示范\n\n> 错误示范：实现 measurementsChanged 方法\n> \n>  1. 这里针对具体实现编程，而非针对接口\n>  2. 对于每个新的布告板，我们都得修改代码\n>  3. 无法在运行时动态增加或删除布告板\n>  4. 没有封装改变的部分\n\npublic class WeatherData{\n    public void measurementsChanged() {\n        // 通过getter方法获取值\n        float temp = getTempreature();\n        float humidity = getHumidity();\n        float pressure = getPressure();\n\n        // 更新3个布告板\n        currentConditionsDisplay.update(temp, humidity, pressure);\n        statisticsDisplay.update(temp, humidity, pressure);\n        forecastDisplay.update(temp, humidity, pressure);\n\n        // 其他方法\n    }\n}\n\n\n# 3. 松耦合\n\n * 当两个对象之间松耦合，它们依然可以交互，但是不太清楚彼此的细节。\n * 观察者模式提供了一种对象设计，让主题和观察者之间松耦合。\n * 松耦合的设计之所以能让我们建立有弹性的OO系统，能够应对变化，是因为对象之间的互相依赖降到了最低。\n\n# 4. 类图设计\n\n# 实现观察者模式（主题推送信息）\n\n\nimport java.util.ArrayList;\nimport java.util.List;\n\ninterface Subject{\n    void registerObserver(Observer observer);\n    void removeObserver(Observer observer);\n    void notifyObservers();\n}\n\npublic class WeatherData implements Subject {\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private List<Observer> listObject;\n\n    public WeatherData() {\n        // 创建主题对象时，实例化存储观察者的集合\n        listObject = new ArrayList<>();\n    }\n\n    public float getTempreature() {\n        return tempreature;\n    }\n\n    public float getHumidity() {\n        return humidity;\n    }\n\n    public float getPressure() {\n        return pressure;\n    }\n\n    @Override\n    public void registerObserver(Observer observer) {\n        // 观察者注册，将其加入通知队列中\n        listObject.add(observer);\n    }\n\n    @Override\n    public void removeObserver(Observer observer) {\n        // 观察者取消，将其从通知队列中删除\n        listObject.remove(observer);\n    }\n\n    @Override\n    public void notifyObservers() {\n        System.out.println("观察者数量：" + listObject.size());\n        // 遍历观察者集合，发送最新观测值\n        for (Observer observer : listObject) {\n            observer.update(getTempreature(), getHumidity(), getPressure());\n        }\n    }\n\n    public void measurementsChanged() {\n        // 当从气象站获取更新观测值时，通知观察者\n        notifyObservers();\n    }\n\n    public void setMeasurements(float tempreature, float humidity, float pressure) {\n        this.tempreature = tempreature;\n        this.humidity = humidity;\n        this.pressure = pressure;\n        measurementsChanged();\n    }\n}\n\n\npublic interface Observer {\n    void update(float tempreature, float humidity, float pressure);\n}\npublic interface DisplayElement {\n    void display();\n}\npublic class CurrentConditionsDisplay implements DisplayElement, Observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private Subject subject;\n\n    public CurrentConditionsDisplay(Subject s) {\n        this.subject = s;\n        subject.registerObserver(this);\n    }\n\n    @Override\n    public String toString() {\n        return "CurrentConditionsDisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @Override\n    public void update(float tempreature, float humidity, float pressure) {\n        this.tempreature = tempreature;\n        this.humidity = humidity;\n        this.pressure = pressure;\n        display();\n    }\n\n    @Override\n    public void display() {\n        System.out.println(toString());\n    }\n}\n// 其他观察者类似\n\n\npublic class Main {\n    public static void main(String[] args) {\n        WeatherData weatherData = new WeatherData();\n\n        Observer currentConditionsDisplay = new CurrentConditionsDisplay(weatherData);\n        Observer statisticsDisplay = new StatisticsDisplay(weatherData);\n        Observer thirdPartyDisplay = new ThirdPartyDisplay(weatherData);\n        Observer forecastDisplay = new ForecastDisplay(weatherData);\n        weatherData.registerObserver(forecastDisplay);\n        // weatherData.removeObserver(currentConditionsDisplay);\n\n        weatherData.setMeasurements(22, 22, 22);\n        weatherData.setMeasurements(25, 25, 25);\n        weatherData.setMeasurements(30, 30, 30);\n    }\n}\n\n\n# 使用内置观察者模式实现主题推送数据\n\n// 1. 导入java内置包\nimport java.util.Observable;\n\n// 2.继承主题类\npublic class Weather extends Observable {\n\n    // 3. 不需要追踪观察者，父类已经实现\n    // 4. 不需要构造器初始化观察者集合\n    public Weather() {}\n\n    public void setMeasurements(Object arg) {\n        // 5. 调用 notifyObservers() 之前，调用 setChanged() 设置状态（这一步必须做，因为 changed 默认为 false ）\n        setChanged();\n        // 注意：传入数据参数，观察模式为主题推送；若没有传送数据对象，则为观察者拉取？\n        notifyObservers(arg);\n    }\n}\n\n\nimport java.util.List;\nimport java.util.Observable;\nimport java.util.Observer;\n\npublic class ThirdPartyDisplay implements DisplayElement, Observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private Observable observable;\n\n    public ThirdPartyDisplay(Observable weather) {\n        this.observable = weather;\n        this.observable.addObserver(this);\n    }\n\n    @Override\n    public String toString() {\n        return "ThirdPartyDisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @Override\n    public void display() {\n        System.out.println(toString());\n    }\n\n    @Override\n    public void update(Observable o, Object arg) {\n        List list = (List) arg;\n        this.tempreature = (float) list.get(0);\n        this.humidity = (float) list.get(1);\n        this.pressure = (float) list.get(2);\n        display();\n    }\n}\n\n\nimport java.util.Arrays;\nimport java.util.Observer;\n\npublic class Main {\n    public static void main(String[] args) {\n        // 使用内置观察者模式实现 推送数据\n        Weather weather = new Weather();\n        Observer thirdPartyDisplay = new ThirdPartyDisplay(weather);\n        Observer thirdPartyDisplay2 = new ThirdPartyDisplay(weather);\n        weather.setMeasurements(Arrays.asList(25f, 25f, 25f));\n    }\n}\n\n\n# 使用内置观察者模式实现观察者拉取数据\n\n\n// 1. 导入java内置包\nimport java.util.Observable;\n\n// 2.继承主题类\npublic class Weather extends Observable {\n\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n\n    public float getTempreature() {\n        return tempreature;\n    }\n\n    public float getHumidity() {\n        return humidity;\n    }\n\n    public float getPressure() {\n        return pressure;\n    }\n\n    // 3. 不需要追踪观察者，父类已经实现\n    // 4. 不需要构造器初始化观察者集合\n    public Weather() {}\n\n    public void setMeasurements(float v, float v1, float v2) {\n        this.tempreature = v;\n        this.humidity = v1;\n        this.pressure = v2;\n        measurementsChanged();\n    }\n    public void measurementsChanged() {\n        // 5. 调用 notifyObservers() 之前，调用 setChanged() 设置状态（这一步必须做，因为 changed 默认为 false ）\n        setChanged();\n        // 注意：没有传送数据对象，则为观察者拉取\n        notifyObservers();\n    }\n\n}\n\n\nimport java.util.Observable;\nimport java.util.Observer;\n\npublic class ThirdPartyDisplay implements DisplayElement, Observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private Observable observable;\n\n    public ThirdPartyDisplay(Observable weather) {\n        this.observable = weather;\n        this.observable.addObserver(this);\n    }\n\n    @Override\n    public String toString() {\n        return "ThirdPartyDisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @Override\n    public void display() {\n        System.out.println(toString());\n    }\n\n    @Override\n    public void update(Observable o, Object arg) {\n        if (o instanceof Weather) {\n            Weather weather = (Weather) o;\n            this.tempreature = weather.getTempreature();\n            this.humidity = weather.getHumidity();\n            this.pressure = weather.getPressure();\n            display();\n        }\n    }\n}\n\n\n\nimport java.util.Observer;\n\npublic class Main {\n    public static void main(String[] args) {\n        // 使用内置观察者模式实现观察者拉取数据\n        Weather weather = new Weather();\n        Observer thirdPartyDisplay1 = new ThirdPartyDisplay(weather);\n        Observer thirdPartyDisplay2 = new ThirdPartyDisplay(weather);\n        weather.setMeasurements(25f, 25f, 25f);\n    }\n}\n\n\n# 要点\n\n * 观察者模式定义了对象之间一对多的关系。\n * 主题（也就是可观察者）用一个共同的接口来更新观察者\n * 观察者和可观察者之间用松耦合方式结合（loosecoupling),可观察者不知道观察者的细节，只知道观察者实现了观察者接口。\n * 使用此模式时，你可从被观察者处推(push)或拉(pull)数据（然而，推的方式被认为更“正确”）。\n * 有多个观察者时，不可以依赖特定的通知次序。\n * Java有多种观察者模式的实现，包括了通用的java.util.Observable\n * 要注意 java.util.Observable 实现上所带来的一些问题。\n * 如果有必要的话，可以实现自己的Observable，这并不难，不要害怕。\n * Swing大量使用观察者模式，许多GUI框架也是如此。\n * 此模式也被应用在许多地方，例如：JavaBeans、RMI。\n\n# 观察者模式对设计原则的应用\n\n 1. 找出程序中会变化的方面，然后将其和固定不变的方面相分离。\n\n> 在观察者模式中，会改变的是主题的状态，以及观察者的数目和类型。用这个模式，你可以改变依赖于主题状态的对象，却不必改变主题。这就叫提前规划！\n\n 2. 针对接口编程，不针对实现编程。\n\n> 主题与观察者都使用接口：观察者利用主题的接口向主题注册，而主题利用观察者接口通知观察者。这样可以让两者之间运作正常，又同时具有松耦合的优点。\n\n 3. 多用组合，少用继承。\n\n> 观察者模式利用“组合”，将许多观察者组合进主题中。对象之间的这种关系不是通过继承产生的，而是在运行时利用组合的方式而产生的。',normalizedContent:'# 观察者模式（observer）\n\n观察者模式 定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。\n\n简单来说：观察者模式 = 出版者（主题 subject） + 订阅者（观察者 observer）\n\n# 气象监测应用\n\n# 1. 问题描述\n\n> 此系统中的三个部分是气象站（获取实际气象数据的物理装置）、weatherdata对象(追踪来自气象站的数据，并更新布告板)和布告板（显示目前天气状况给用户看）\n\n# 2. 错误示范\n\n> 错误示范：实现 measurementschanged 方法\n> \n>  1. 这里针对具体实现编程，而非针对接口\n>  2. 对于每个新的布告板，我们都得修改代码\n>  3. 无法在运行时动态增加或删除布告板\n>  4. 没有封装改变的部分\n\npublic class weatherdata{\n    public void measurementschanged() {\n        // 通过getter方法获取值\n        float temp = gettempreature();\n        float humidity = gethumidity();\n        float pressure = getpressure();\n\n        // 更新3个布告板\n        currentconditionsdisplay.update(temp, humidity, pressure);\n        statisticsdisplay.update(temp, humidity, pressure);\n        forecastdisplay.update(temp, humidity, pressure);\n\n        // 其他方法\n    }\n}\n\n\n# 3. 松耦合\n\n * 当两个对象之间松耦合，它们依然可以交互，但是不太清楚彼此的细节。\n * 观察者模式提供了一种对象设计，让主题和观察者之间松耦合。\n * 松耦合的设计之所以能让我们建立有弹性的oo系统，能够应对变化，是因为对象之间的互相依赖降到了最低。\n\n# 4. 类图设计\n\n# 实现观察者模式（主题推送信息）\n\n\nimport java.util.arraylist;\nimport java.util.list;\n\ninterface subject{\n    void registerobserver(observer observer);\n    void removeobserver(observer observer);\n    void notifyobservers();\n}\n\npublic class weatherdata implements subject {\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private list<observer> listobject;\n\n    public weatherdata() {\n        // 创建主题对象时，实例化存储观察者的集合\n        listobject = new arraylist<>();\n    }\n\n    public float gettempreature() {\n        return tempreature;\n    }\n\n    public float gethumidity() {\n        return humidity;\n    }\n\n    public float getpressure() {\n        return pressure;\n    }\n\n    @override\n    public void registerobserver(observer observer) {\n        // 观察者注册，将其加入通知队列中\n        listobject.add(observer);\n    }\n\n    @override\n    public void removeobserver(observer observer) {\n        // 观察者取消，将其从通知队列中删除\n        listobject.remove(observer);\n    }\n\n    @override\n    public void notifyobservers() {\n        system.out.println("观察者数量：" + listobject.size());\n        // 遍历观察者集合，发送最新观测值\n        for (observer observer : listobject) {\n            observer.update(gettempreature(), gethumidity(), getpressure());\n        }\n    }\n\n    public void measurementschanged() {\n        // 当从气象站获取更新观测值时，通知观察者\n        notifyobservers();\n    }\n\n    public void setmeasurements(float tempreature, float humidity, float pressure) {\n        this.tempreature = tempreature;\n        this.humidity = humidity;\n        this.pressure = pressure;\n        measurementschanged();\n    }\n}\n\n\npublic interface observer {\n    void update(float tempreature, float humidity, float pressure);\n}\npublic interface displayelement {\n    void display();\n}\npublic class currentconditionsdisplay implements displayelement, observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private subject subject;\n\n    public currentconditionsdisplay(subject s) {\n        this.subject = s;\n        subject.registerobserver(this);\n    }\n\n    @override\n    public string tostring() {\n        return "currentconditionsdisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @override\n    public void update(float tempreature, float humidity, float pressure) {\n        this.tempreature = tempreature;\n        this.humidity = humidity;\n        this.pressure = pressure;\n        display();\n    }\n\n    @override\n    public void display() {\n        system.out.println(tostring());\n    }\n}\n// 其他观察者类似\n\n\npublic class main {\n    public static void main(string[] args) {\n        weatherdata weatherdata = new weatherdata();\n\n        observer currentconditionsdisplay = new currentconditionsdisplay(weatherdata);\n        observer statisticsdisplay = new statisticsdisplay(weatherdata);\n        observer thirdpartydisplay = new thirdpartydisplay(weatherdata);\n        observer forecastdisplay = new forecastdisplay(weatherdata);\n        weatherdata.registerobserver(forecastdisplay);\n        // weatherdata.removeobserver(currentconditionsdisplay);\n\n        weatherdata.setmeasurements(22, 22, 22);\n        weatherdata.setmeasurements(25, 25, 25);\n        weatherdata.setmeasurements(30, 30, 30);\n    }\n}\n\n\n# 使用内置观察者模式实现主题推送数据\n\n// 1. 导入java内置包\nimport java.util.observable;\n\n// 2.继承主题类\npublic class weather extends observable {\n\n    // 3. 不需要追踪观察者，父类已经实现\n    // 4. 不需要构造器初始化观察者集合\n    public weather() {}\n\n    public void setmeasurements(object arg) {\n        // 5. 调用 notifyobservers() 之前，调用 setchanged() 设置状态（这一步必须做，因为 changed 默认为 false ）\n        setchanged();\n        // 注意：传入数据参数，观察模式为主题推送；若没有传送数据对象，则为观察者拉取？\n        notifyobservers(arg);\n    }\n}\n\n\nimport java.util.list;\nimport java.util.observable;\nimport java.util.observer;\n\npublic class thirdpartydisplay implements displayelement, observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private observable observable;\n\n    public thirdpartydisplay(observable weather) {\n        this.observable = weather;\n        this.observable.addobserver(this);\n    }\n\n    @override\n    public string tostring() {\n        return "thirdpartydisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @override\n    public void display() {\n        system.out.println(tostring());\n    }\n\n    @override\n    public void update(observable o, object arg) {\n        list list = (list) arg;\n        this.tempreature = (float) list.get(0);\n        this.humidity = (float) list.get(1);\n        this.pressure = (float) list.get(2);\n        display();\n    }\n}\n\n\nimport java.util.arrays;\nimport java.util.observer;\n\npublic class main {\n    public static void main(string[] args) {\n        // 使用内置观察者模式实现 推送数据\n        weather weather = new weather();\n        observer thirdpartydisplay = new thirdpartydisplay(weather);\n        observer thirdpartydisplay2 = new thirdpartydisplay(weather);\n        weather.setmeasurements(arrays.aslist(25f, 25f, 25f));\n    }\n}\n\n\n# 使用内置观察者模式实现观察者拉取数据\n\n\n// 1. 导入java内置包\nimport java.util.observable;\n\n// 2.继承主题类\npublic class weather extends observable {\n\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n\n    public float gettempreature() {\n        return tempreature;\n    }\n\n    public float gethumidity() {\n        return humidity;\n    }\n\n    public float getpressure() {\n        return pressure;\n    }\n\n    // 3. 不需要追踪观察者，父类已经实现\n    // 4. 不需要构造器初始化观察者集合\n    public weather() {}\n\n    public void setmeasurements(float v, float v1, float v2) {\n        this.tempreature = v;\n        this.humidity = v1;\n        this.pressure = v2;\n        measurementschanged();\n    }\n    public void measurementschanged() {\n        // 5. 调用 notifyobservers() 之前，调用 setchanged() 设置状态（这一步必须做，因为 changed 默认为 false ）\n        setchanged();\n        // 注意：没有传送数据对象，则为观察者拉取\n        notifyobservers();\n    }\n\n}\n\n\nimport java.util.observable;\nimport java.util.observer;\n\npublic class thirdpartydisplay implements displayelement, observer{\n    private float tempreature;\n    private float humidity;\n    private float pressure;\n    private observable observable;\n\n    public thirdpartydisplay(observable weather) {\n        this.observable = weather;\n        this.observable.addobserver(this);\n    }\n\n    @override\n    public string tostring() {\n        return "thirdpartydisplay{" +\n                "tempreature=" + tempreature +\n                ", humidity=" + humidity +\n                ", pressure=" + pressure +\n                \'}\';\n    }\n\n    @override\n    public void display() {\n        system.out.println(tostring());\n    }\n\n    @override\n    public void update(observable o, object arg) {\n        if (o instanceof weather) {\n            weather weather = (weather) o;\n            this.tempreature = weather.gettempreature();\n            this.humidity = weather.gethumidity();\n            this.pressure = weather.getpressure();\n            display();\n        }\n    }\n}\n\n\n\nimport java.util.observer;\n\npublic class main {\n    public static void main(string[] args) {\n        // 使用内置观察者模式实现观察者拉取数据\n        weather weather = new weather();\n        observer thirdpartydisplay1 = new thirdpartydisplay(weather);\n        observer thirdpartydisplay2 = new thirdpartydisplay(weather);\n        weather.setmeasurements(25f, 25f, 25f);\n    }\n}\n\n\n# 要点\n\n * 观察者模式定义了对象之间一对多的关系。\n * 主题（也就是可观察者）用一个共同的接口来更新观察者\n * 观察者和可观察者之间用松耦合方式结合（loosecoupling),可观察者不知道观察者的细节，只知道观察者实现了观察者接口。\n * 使用此模式时，你可从被观察者处推(push)或拉(pull)数据（然而，推的方式被认为更“正确”）。\n * 有多个观察者时，不可以依赖特定的通知次序。\n * java有多种观察者模式的实现，包括了通用的java.util.observable\n * 要注意 java.util.observable 实现上所带来的一些问题。\n * 如果有必要的话，可以实现自己的observable，这并不难，不要害怕。\n * swing大量使用观察者模式，许多gui框架也是如此。\n * 此模式也被应用在许多地方，例如：javabeans、rmi。\n\n# 观察者模式对设计原则的应用\n\n 1. 找出程序中会变化的方面，然后将其和固定不变的方面相分离。\n\n> 在观察者模式中，会改变的是主题的状态，以及观察者的数目和类型。用这个模式，你可以改变依赖于主题状态的对象，却不必改变主题。这就叫提前规划！\n\n 2. 针对接口编程，不针对实现编程。\n\n> 主题与观察者都使用接口：观察者利用主题的接口向主题注册，而主题利用观察者接口通知观察者。这样可以让两者之间运作正常，又同时具有松耦合的优点。\n\n 3. 多用组合，少用继承。\n\n> 观察者模式利用“组合”，将许多观察者组合进主题中。对象之间的这种关系不是通过继承产生的，而是在运行时利用组合的方式而产生的。',charsets:{cjk:!0},lastUpdated:"2022/07/15, 18:03:14",lastUpdatedTimestamp:1657879394e3},{title:"单例模式",frontmatter:{title:"单例模式",date:"2022-07-17T23:15:31.000Z",permalink:"/pages/4e0678/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/050.%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/050.单例模式.md",key:"v-830992f8",path:"/pages/4e0678/",headers:[{level:2,title:"单例模式（Singleton）",slug:"单例模式-singleton",normalizedTitle:"单例模式（singleton）",charIndex:2},{level:4,title:"问题提出",slug:"问题提出",normalizedTitle:"问题提出",charIndex:51},{level:4,title:"经典单例模式",slug:"经典单例模式",normalizedTitle:"经典单例模式",charIndex:188},{level:5,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:198},{level:5,title:"代码",slug:"代码",normalizedTitle:"代码",charIndex:204},{level:4,title:"解决多线程问题",slug:"解决多线程问题",normalizedTitle:"解决多线程问题",charIndex:886},{level:5,title:"1. 加 synchronized 锁",slug:"_1-加-synchronized-锁",normalizedTitle:"1. 加 synchronized 锁",charIndex:897},{level:5,title:"2. 饿汉式单例",slug:"_2-饿汉式单例",normalizedTitle:"2. 饿汉式单例",charIndex:966},{level:5,title:"3. 懒汉式单例（双重检查加锁）",slug:"_3-懒汉式单例-双重检查加锁",normalizedTitle:"3. 懒汉式单例（双重检查加锁）",charIndex:1222},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:1805}],headersStr:"单例模式（Singleton） 问题提出 经典单例模式 类图 代码 解决多线程问题 1. 加 synchronized 锁 2. 饿汉式单例 3. 懒汉式单例（双重检查加锁） 要点",content:"# 单例模式（Singleton）\n\n单例模式 确保一个类只有一个实例，并提供一个全局访问点。\n\n# 问题提出\n\n问题：有些对象我们只需要一个。比如线程池（threadpool）、缓存（cache）、对话框、处理偏好设置和注册表（registry）的对象、日志对象、驱动程序对象等。\n\nJava 静态变量可以保证全局只有一个实例，但是会有缺点：必须一开始就创建好对象，\n\n# 经典单例模式\n\n# 类图\n\n# 代码\n\n问题：在多线程的情况下会出现问题\n\npublic class ChocolateBoiler {\n    private boolean empty;   // 锅炉是否是空的\n    private boolean boiled;  // 是否煮沸过\n    private static ChocolateBoiler chocolateBoiler;\n\n    private ChocolateBoiler() {\n        empty = true;\n        boiled = false;\n    }\n\n    public static ChocolateBoiler getInstance() {\n        if (null == chocolateBoiler) {\n            chocolateBoiler =  new ChocolateBoiler();\n        }\n        return chocolateBoiler;\n    }\n\n    public void  fill() {\n        if (isEmpty()) {\n            empty = false;\n            boiled = false;\n            // 在锅炉里填充巧克力和牛奶的混合物\n        }\n    }\n\n    private boolean isEmpty() {\n        return empty;\n    }\n}\n\n\n# 解决多线程问题\n\n# 1. 加 synchronized 锁\n\n给 getInstance() 方法加 synchronized 锁，缺点是会降低性能。\n\n# 2. 饿汉式单例\n\n在JVM加载类时立刻实例化对象，后面调用 getInstance() 方法时直接返回实例就可以。\n\npublic class Singleton() {\n  private static Singleton uniqueSingleton = new Singleton();\n\n  private Singleton() {}\n\n  public static Singleton getInstance() {\n    return uniqueSingleton;\n  }\n}\n\n\n# 3. 懒汉式单例（双重检查加锁）\n\n利用双重检查加锁（double-checked locking），首先检查是否实例已经创建了，如果尚未创建，“才”进行同步。这样一来，只有第一次会同步，这正是我们想要的。\n\n> volatile关键字是java提供的一种稍弱的同步机制。用来将变量的更新操作同步到其他线程，保证可见性，保证线程等到的变量值是最新的\n> 注：JDK1.4 及更早版本的 volatile 会导致双重检查锁失效\n\npublic class Singleton() {\n  private volatile static Singleton uniqueSingleton;\n\n  private Singleton() {}\n\n  public static Singleton getInstance() {\n    if (uniqueSingleton == null) {\n      synchronized (Singleton.class) {\n        if (uniqueSingleton == null) {\n          uniqueSingleton = new Singleton();\n        }\n      }\n    }\n    return uniqueSingleton;\n  }\n}\n\n\n# 要点\n\n * 单例模式确保程序中一个类最多只有一个实例。\n * 单例模式也提供访问这个实例的全局点。\n * 在Java中实现单例模式需要私有的构造器、一个静态方法和一个静态变量。\n * 确定在性能和资源上的限制，然后小心地选择适当的方案来实现单例，以解决多线程的问题（我们必须认定所有的程序都是多线程的）。\n * 如果不是采用JDK1.5以上，双重检查加锁实现会失效。\n * 小心，你如果使用多个类加载器，可能导致单例失效而产生多个实例。\n   \n   > 由于每个类加载器都定义了一个命名空间，如果有多个类加载器，会导致同一个类被加载多次，造成多个单例模式并存的现象。解决办法是：执行指定类加载器，并指定同一个类加载器。\n\n * 如果使用JVM1.2或之前的版本，你必须建立单例注册表，以免垃圾收集器将单例回收。\n   \n   > 谣言：垃圾收集器会吃掉单例。Java1.2之前，垃圾收集器有个bug，单例没有全局引用（只有单例类引用自身）的时候会被当做垃圾清除。1.2 以后已修复。",normalizedContent:"# 单例模式（singleton）\n\n单例模式 确保一个类只有一个实例，并提供一个全局访问点。\n\n# 问题提出\n\n问题：有些对象我们只需要一个。比如线程池（threadpool）、缓存（cache）、对话框、处理偏好设置和注册表（registry）的对象、日志对象、驱动程序对象等。\n\njava 静态变量可以保证全局只有一个实例，但是会有缺点：必须一开始就创建好对象，\n\n# 经典单例模式\n\n# 类图\n\n# 代码\n\n问题：在多线程的情况下会出现问题\n\npublic class chocolateboiler {\n    private boolean empty;   // 锅炉是否是空的\n    private boolean boiled;  // 是否煮沸过\n    private static chocolateboiler chocolateboiler;\n\n    private chocolateboiler() {\n        empty = true;\n        boiled = false;\n    }\n\n    public static chocolateboiler getinstance() {\n        if (null == chocolateboiler) {\n            chocolateboiler =  new chocolateboiler();\n        }\n        return chocolateboiler;\n    }\n\n    public void  fill() {\n        if (isempty()) {\n            empty = false;\n            boiled = false;\n            // 在锅炉里填充巧克力和牛奶的混合物\n        }\n    }\n\n    private boolean isempty() {\n        return empty;\n    }\n}\n\n\n# 解决多线程问题\n\n# 1. 加 synchronized 锁\n\n给 getinstance() 方法加 synchronized 锁，缺点是会降低性能。\n\n# 2. 饿汉式单例\n\n在jvm加载类时立刻实例化对象，后面调用 getinstance() 方法时直接返回实例就可以。\n\npublic class singleton() {\n  private static singleton uniquesingleton = new singleton();\n\n  private singleton() {}\n\n  public static singleton getinstance() {\n    return uniquesingleton;\n  }\n}\n\n\n# 3. 懒汉式单例（双重检查加锁）\n\n利用双重检查加锁（double-checked locking），首先检查是否实例已经创建了，如果尚未创建，“才”进行同步。这样一来，只有第一次会同步，这正是我们想要的。\n\n> volatile关键字是java提供的一种稍弱的同步机制。用来将变量的更新操作同步到其他线程，保证可见性，保证线程等到的变量值是最新的\n> 注：jdk1.4 及更早版本的 volatile 会导致双重检查锁失效\n\npublic class singleton() {\n  private volatile static singleton uniquesingleton;\n\n  private singleton() {}\n\n  public static singleton getinstance() {\n    if (uniquesingleton == null) {\n      synchronized (singleton.class) {\n        if (uniquesingleton == null) {\n          uniquesingleton = new singleton();\n        }\n      }\n    }\n    return uniquesingleton;\n  }\n}\n\n\n# 要点\n\n * 单例模式确保程序中一个类最多只有一个实例。\n * 单例模式也提供访问这个实例的全局点。\n * 在java中实现单例模式需要私有的构造器、一个静态方法和一个静态变量。\n * 确定在性能和资源上的限制，然后小心地选择适当的方案来实现单例，以解决多线程的问题（我们必须认定所有的程序都是多线程的）。\n * 如果不是采用jdk1.5以上，双重检查加锁实现会失效。\n * 小心，你如果使用多个类加载器，可能导致单例失效而产生多个实例。\n   \n   > 由于每个类加载器都定义了一个命名空间，如果有多个类加载器，会导致同一个类被加载多次，造成多个单例模式并存的现象。解决办法是：执行指定类加载器，并指定同一个类加载器。\n\n * 如果使用jvm1.2或之前的版本，你必须建立单例注册表，以免垃圾收集器将单例回收。\n   \n   > 谣言：垃圾收集器会吃掉单例。java1.2之前，垃圾收集器有个bug，单例没有全局引用（只有单例类引用自身）的时候会被当做垃圾清除。1.2 以后已修复。",charsets:{cjk:!0},lastUpdated:"2022/08/11, 00:48:36",lastUpdatedTimestamp:1660150116e3},{title:"工厂模式",frontmatter:{title:"工厂模式",date:"2022-07-16T17:42:58.000Z",permalink:"/pages/668a2b/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/040.%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/040.工厂模式.md",key:"v-f5852fb2",path:"/pages/668a2b/",headers:[{level:3,title:"三、工厂模式（Factory Pattern）",slug:"三、工厂模式-factory-pattern",normalizedTitle:"三、工厂模式（factory pattern）",charIndex:2},{level:4,title:"问题提出",slug:"问题提出",normalizedTitle:"问题提出",charIndex:29},{level:4,title:"简单工厂",slug:"简单工厂",normalizedTitle:"简单工厂",charIndex:470},{level:5,title:"抽取变化的地方",slug:"抽取变化的地方",normalizedTitle:"抽取变化的地方",charIndex:508},{level:5,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:961},{level:4,title:"工厂方法模式",slug:"工厂方法模式",normalizedTitle:"工厂方法模式",charIndex:967},{level:5,title:"开加盟店",slug:"开加盟店",normalizedTitle:"开加盟店",charIndex:1032},{level:6,title:"类图",slug:"类图-2",normalizedTitle:"类图",charIndex:961},{level:6,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:1046},{level:5,title:"依赖倒置原则",slug:"依赖倒置原则",normalizedTitle:"依赖倒置原则",charIndex:4075},{level:6,title:"描述",slug:"描述",normalizedTitle:"描述",charIndex:4085},{level:6,title:"如何遵循此原则",slug:"如何遵循此原则",normalizedTitle:"如何遵循此原则",charIndex:4241},{level:4,title:"抽象工厂模式",slug:"抽象工厂模式",normalizedTitle:"抽象工厂模式",charIndex:4306},{level:5,title:"原料工厂",slug:"原料工厂",normalizedTitle:"原料工厂",charIndex:4359},{level:6,title:"问题提出",slug:"问题提出-2",normalizedTitle:"问题提出",charIndex:29},{level:6,title:"类图",slug:"类图-3",normalizedTitle:"类图",charIndex:961},{level:6,title:"代码实现",slug:"代码实现-2",normalizedTitle:"代码实现",charIndex:1046},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:11097}],headersStr:"三、工厂模式（Factory Pattern） 问题提出 简单工厂 抽取变化的地方 类图 工厂方法模式 开加盟店 类图 代码实现 依赖倒置原则 描述 如何遵循此原则 抽象工厂模式 原料工厂 问题提出 类图 代码实现 要点",content:'# 三、工厂模式（Factory Pattern）\n\n# 问题提出\n\n当我们使用 "new" 来实例化对象时，也是在对具体实现编程。 比如我们根据条件的不同来实例化鸭子，需要编写以下代码\n\nPizza orderPizza(String type) {\n  Pizza pizza;\n\n  if (type.equals("cheese")) {\n    pizza = new CheesePizza();\n  } else if (type.equals("clam")) {\n    pizza = new ClamPizza();\n  } else if (type.equals("veggie")) {\n    pizza = new VeggiePizza();\n  }\n\n  pizza.perpare();\n  pizza.bake();\n  pizza.cut();\n  pizza.box();\n  return pizza;\n}\n\n\n一旦发生修改或扩展，我们就必须去维护这段代码，容易出现问题（违反开闭原则）\n\n# 简单工厂\n\n简单工厂其实不是一个设计模式，反而比较像是一种编程习惯。\n\n# 抽取变化的地方\n\n把创建不同对象这个 “变” 的地方抽取出来，不变的地方（其他方法）不做变动。\n\npublic class SimplePizzaFactory {\n  public Pizza createPizza(String type) {\n    Pizza pizza;\n\n    if (type.equals("cheese")) {\n      pizza = new CheesePizza();\n    } else if (type.equals("clam")) {\n      pizza = new ClamPizza();\n    } else if (type.equals("veggie")) {\n      pizza = new VeggiePizza();\n    }\n\n    return pizza;\n  }\n}\n\n\n附：\n\n> 静态工厂：使用静态方法来定义简单工厂，可以不使用创建对象的方法来实例化对象。缺点是不能通过继承来修改创建方法内的行为。\n\n# 类图\n\n# 工厂方法模式\n\n工厂方法模式 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。\n\n# 开加盟店\n\n# 类图\n\n# 代码实现\n\n\nimport java.util.ArrayList;\n\npublic abstract class Pizza {\n    protected String name;            // 披萨名字\n    protected String dough;           // 面团类型\n    protected String sauce;           // 酱料类型\n    protected ArrayList topping= new ArrayList();     // 一套佐料\n\n    public String getName() {\n        return name;\n    }\n\n    public void perpare(){\n        System.out.println("准备原料");\n    }\n    public void bake(){\n        System.out.println("炙烤披萨");\n    }\n    public void cut(){\n        System.out.println("披萨切片");\n    }\n    public void box(){\n        System.out.println("披萨装盒");\n    }\n}\n\n\nclass ClamPizza extends Pizza {\n    public ClamPizza() {\n        name = "ClamPizza";\n        System.out.println("初始化" + name);\n    }\n}\nclass VeggiePizza extends Pizza {\n    public VeggiePizza() {\n        name = "VeggiePizza";\n        System.out.println("初始化" + name);\n    }\n}\nclass NYStyleCheesePizza extends Pizza {\n    public NYStyleCheesePizza() {\n        name = "NYStyleCheesePizza";\n        System.out.println("初始化" + name);\n    }\n}\nclass ChicagoStyleCheesePizza extends Pizza {\n    public ChicagoStyleCheesePizza() {\n        name = "ChicagoStyleCheesePizza";\n        System.out.println("初始化" + name);\n    }\n\n    @Override\n    public void cut() {\n        System.out.println("披萨切为方块");\n    }\n}\n\n\npublic abstract class PizzaStore {\n    Pizza pizza = null;\n\n    public Pizza orderPizza(String type) {\n        return createPizza(type);\n    }\n\n    public void makePizza() {\n        if (null != this.pizza) {\n            pizza.perpare();\n            pizza.bake();\n            pizza.cut();\n            pizza.box();\n        }\n    }\n\n    protected abstract Pizza createPizza(String type);\n}\n\nclass NYStylePizzaStore extends PizzaStore {\n\n    @Override\n    protected Pizza createPizza(String type) {\n        if ("clam".equalsIgnoreCase(type)) {\n            pizza = new ClamPizza();\n        } else if ("veggie".equalsIgnoreCase(type)) {\n            pizza = new VeggiePizza();\n        } else if ("cheese".equalsIgnoreCase(type)) {\n            pizza = new NYStyleCheesePizza();\n        }\n        makePizza();\n        return pizza;\n    }\n}\n\nclass ChicagoStylePizzaStore extends PizzaStore {\n\n    @Override\n    protected Pizza createPizza(String type) {\n        if ("clam".equalsIgnoreCase(type)) {\n            pizza = new ClamPizza();\n        } else if ("veggie".equalsIgnoreCase(type)) {\n            pizza = new VeggiePizza();\n        } else if ("cheese".equalsIgnoreCase(type)) {\n            pizza = new ChicagoStyleCheesePizza();\n        }\n        makePizza();\n        return pizza;\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        PizzaStore nyStylePizzaStore = new NYStylePizzaStore();\n        PizzaStore chicagoStylePizzaStore = new ChicagoStylePizzaStore();\n\n        Pizza nyCheese = nyStylePizzaStore.orderPizza("CHEESE");\n        System.out.println(nyCheese.getName());\n\n        Pizza chCheese = chicagoStylePizzaStore.orderPizza("CHEESE");\n        System.out.println(chCheese.getName());\n    }\n}\n\n\n# 依赖倒置原则\n\n# 描述\n\n不能让高层组件依赖低层组件。而且，不管高层组件还是低层组件，都应该依赖于抽象。\n\n在应用工厂方法之后，你将注意到，高层组件（也就是PizzaStore）和低层组件（也就是这些比萨）都依赖了Pizz抽象。想要遵循依赖倒置原则，工厂方法并非是唯一的技巧，但却是最有威力的技巧之一。\n\n所谓倒置体现在：\n\n# 如何遵循此原则\n\n 1. 变量不可以持有具体类的引用。\n 2. 不要让类派生自具体类。\n 3. 不要覆盖基类中已实现的方法\n\n# 抽象工厂模式\n\n抽象工厂模式 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。\n\n# 原料工厂\n\n# 问题提出\n\n如何确保原料的一致？由于地域差别，每家店的披萨所使用的原材料并不完全一致。我们需要建造一个工厂生产原料，并处理各个区域的差异。\n\n# 类图\n\n抽象工厂允许客户使用抽象的接口来创建一组相关的产品，而不需要知道（或关心）实际产出的具体产品是什么。这样一来，客户就从具体的产品中被解耦。让我们看看类图来了解其中的关系：\n\n# 代码实现\n\n\npublic interface Ingredient {}\n\nclass Dough implements Ingredient {\n    String name = "Dough";\n    public Dough() {\n        System.out.println("配料: " + name);\n    }\n}\nclass Sauce implements Ingredient {\n    String name = "Sauce";\n    public Sauce() {\n    }\n}\nclass Cheese implements Ingredient {\n    String name = "Cheese";\n    public Cheese() {\n        System.out.println("配料: " + name);\n    }\n}\nclass Veggies implements Ingredient {\n    String name = "Veggies";\n}\nclass Carrot extends Veggies {\n    public Carrot() {\n        name = "胡萝卜";\n        System.out.println("配料: " + name);\n    }\n}\nclass Lettuce extends Veggies {\n    public Lettuce() {\n        name = "生菜";\n        System.out.println("配料: " + name);\n    }\n}\nclass Pepperoni implements Ingredient {\n    String name = "Pepperoni";\n    public Pepperoni() {\n        System.out.println("配料: " + name);\n    }\n}\n\ninterface Clams extends Ingredient {}\n\nclass FreshClams implements Clams {\n    String name = "新鲜蛤蜊";\n    public FreshClams() {\n        System.out.println("配料: " + name);\n    }\n}\nclass FrozenClams implements Clams {\n    String name = "冰冻蛤蜊";\n    public FrozenClams() {\n        System.out.println("配料: " + name);\n    }\n}\n\n\npublic interface PizzaIngredientFactory {\n    Dough createDough();\n    Sauce createSauce();\n    Cheese createCheese();\n    Veggies[] createVeggies();\n    Pepperoni createPepperoni();\n    Clams createClam();\n}\n\n\nclass ChicagoPizzaIngredientFactory implements PizzaIngredientFactory {\n\n    @Override\n    public Dough createDough() {\n        return new Dough();\n    }\n\n    @Override\n    public Sauce createSauce() {\n        return new Sauce();\n    }\n\n    @Override\n    public Cheese createCheese() {\n        return new Cheese();\n    }\n\n    @Override\n    public Veggies[] createVeggies() {\n        return new Veggies[]{new Carrot(), new Lettuce()};\n    }\n\n    @Override\n    public Pepperoni createPepperoni() {\n        return new Pepperoni();\n    }\n\n    @Override\n    public Clams createClam() {\n        return new FreshClams();\n    }\n}\n\nclass NYPizzaIngredientFactory implements PizzaIngredientFactory {\n\n    @Override\n    public Dough createDough() {\n        return new Dough();\n    }\n\n    @Override\n    public Sauce createSauce() {\n        return new Sauce();\n    }\n\n    @Override\n    public Cheese createCheese() {\n        return new Cheese();\n    }\n\n    @Override\n    public Veggies[] createVeggies() {\n        return new Veggies[]{new Lettuce()};\n    }\n\n    @Override\n    public Pepperoni createPepperoni() {\n        return new Pepperoni();\n    }\n\n    @Override\n    public Clams createClam() {\n        return new FrozenClams();\n    }\n}\n\n\npublic abstract class Pizza {\n    protected String name;            // 披萨名字\n    protected Dough dough;           // 面团类型\n    protected Sauce sauce;           // 酱料类型\n    protected List<Ingredient> topping= new ArrayList();     // 一套佐料\n    protected Clams clams;\n\n    public String getName() {\n        return name;\n    }\n\n    public void perpare(){\n        System.out.println("准备原料");\n    }\n    public void bake(){\n        System.out.println("炙烤披萨");\n    }\n    public void cut(){\n        System.out.println("披萨切片");\n    }\n    public void box(){\n        System.out.println("披萨装盒");\n    }\n}\n\n\nclass ClamPizza extends Pizza {\n    PizzaIngredientFactory pizzaIngredientFactory;   // 新增原料工厂\n\n    public ClamPizza(PizzaIngredientFactory pizzaIngredientFactory) {\n        name = "ClamPizza";\n        this.pizzaIngredientFactory = pizzaIngredientFactory;\n    }\n\n    @Override\n    public void perpare() {\n        super.perpare();\n        dough = pizzaIngredientFactory.createDough();\n        sauce = pizzaIngredientFactory.createSauce();\n        topping = Arrays.asList(pizzaIngredientFactory.createVeggies());\n        clams = pizzaIngredientFactory.createClam();\n    }\n}\nclass VeggiePizza extends Pizza {\n    public VeggiePizza() {\n        name = "VeggiePizza";\n        System.out.println("初始化" + name);\n    }\n}\nclass NYStyleCheesePizza extends Pizza {\n    public NYStyleCheesePizza() {\n        name = "NYStyleCheesePizza";\n        System.out.println("初始化" + name);\n    }\n}\nclass ChicagoStyleCheesePizza extends Pizza {\n    public ChicagoStyleCheesePizza() {\n        name = "ChicagoStyleCheesePizza";\n        System.out.println("初始化" + name);\n    }\n\n    @Override\n    public void cut() {\n        System.out.println("披萨切为方块");\n    }\n}\n\n\npublic abstract class PizzaStore {\n    Pizza pizza = null;\n    PizzaIngredientFactory pizzaIngredientFactory;   // 新增原料工厂\n\n    public Pizza orderPizza(String type) {\n        return createPizza(type);\n    }\n\n    public void makePizza() {\n        if (null != this.pizza) {\n            pizza.perpare();\n            pizza.bake();\n            pizza.cut();\n            pizza.box();\n        }\n    }\n\n    protected abstract Pizza createPizza(String type);\n}\n\nclass NYStylePizzaStore extends PizzaStore {\n    public NYStylePizzaStore(PizzaIngredientFactory pizzaIngredientFactory) {\n        super.pizzaIngredientFactory = pizzaIngredientFactory;\n    }\n\n    @Override\n    protected Pizza createPizza(String type) {\n        if ("clam".equalsIgnoreCase(type)) {\n            pizza = new ClamPizza(pizzaIngredientFactory);\n        } else if ("veggie".equalsIgnoreCase(type)) {\n            pizza = new VeggiePizza();\n        } else if ("cheese".equalsIgnoreCase(type)) {\n            pizza = new NYStyleCheesePizza();\n        }\n        makePizza();\n        return pizza;\n    }\n}\n\nclass ChicagoStylePizzaStore extends PizzaStore {\n    public ChicagoStylePizzaStore(PizzaIngredientFactory pizzaIngredientFactory) {\n        super.pizzaIngredientFactory = pizzaIngredientFactory;\n    }\n\n    @Override\n    protected Pizza createPizza(String type) {\n        if ("clam".equalsIgnoreCase(type)) {\n            pizza = new ClamPizza(pizzaIngredientFactory);\n        } else if ("veggie".equalsIgnoreCase(type)) {\n            pizza = new VeggiePizza();\n        } else if ("cheese".equalsIgnoreCase(type)) {\n            pizza = new ChicagoStyleCheesePizza();\n        }\n        makePizza();\n        return pizza;\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        PizzaStore nyStylePizzaStore = new NYStylePizzaStore(new NYPizzaIngredientFactory());\n        PizzaStore chicagoStylePizzaStore = new ChicagoStylePizzaStore(new ChicagoPizzaIngredientFactory());\n\n        Pizza nyCheese = nyStylePizzaStore.orderPizza("Clam");\n        System.out.println(nyCheese.getName());\n\n        Pizza chCheese = chicagoStylePizzaStore.orderPizza("Clam");\n        System.out.println(chCheese.getName());\n    }\n}\n\n\n# 要点\n\n> 抽象工厂的任务是定义创建一组产品的接口，这个接口里的每个方法都负责创建一个具体产品，同时我们通过实现抽象工厂子类来具体实现这些方法（工厂方法）。即，抽象工厂的方法通常是以工厂方法的方式实现的。\n\n * 所有的工厂都是用来封装对象的创建\n * 简单工厂，虽然不是真正的设计模式，但仍不失为一个简单的方法，可以将客户程序从具体类解稠。\n * 工厂方法使用继承：把对象的创建委托给子类，子类实现工厂方法来创建对象。\n * 抽象工厂使用对象组合：对象的创建被实现在工厂接口所暴露出来的方法中。\n * 所有工厂模式都通过减少应用程序和具体类之间的依赖促进松耦合。\n * 工厂方法允许类将实例化延迟到子类进行。\n * 抽象工厂创建相关的对象家族，而不需要依赖它们的具体类。\n * 依赖倒置原则，指导我们避免依赖具体类型，而要尽量依赖抽象。\n * 工厂是很有威力的技巧，帮助我们针对抽象编程，而不要针对具体类编程。',normalizedContent:'# 三、工厂模式（factory pattern）\n\n# 问题提出\n\n当我们使用 "new" 来实例化对象时，也是在对具体实现编程。 比如我们根据条件的不同来实例化鸭子，需要编写以下代码\n\npizza orderpizza(string type) {\n  pizza pizza;\n\n  if (type.equals("cheese")) {\n    pizza = new cheesepizza();\n  } else if (type.equals("clam")) {\n    pizza = new clampizza();\n  } else if (type.equals("veggie")) {\n    pizza = new veggiepizza();\n  }\n\n  pizza.perpare();\n  pizza.bake();\n  pizza.cut();\n  pizza.box();\n  return pizza;\n}\n\n\n一旦发生修改或扩展，我们就必须去维护这段代码，容易出现问题（违反开闭原则）\n\n# 简单工厂\n\n简单工厂其实不是一个设计模式，反而比较像是一种编程习惯。\n\n# 抽取变化的地方\n\n把创建不同对象这个 “变” 的地方抽取出来，不变的地方（其他方法）不做变动。\n\npublic class simplepizzafactory {\n  public pizza createpizza(string type) {\n    pizza pizza;\n\n    if (type.equals("cheese")) {\n      pizza = new cheesepizza();\n    } else if (type.equals("clam")) {\n      pizza = new clampizza();\n    } else if (type.equals("veggie")) {\n      pizza = new veggiepizza();\n    }\n\n    return pizza;\n  }\n}\n\n\n附：\n\n> 静态工厂：使用静态方法来定义简单工厂，可以不使用创建对象的方法来实例化对象。缺点是不能通过继承来修改创建方法内的行为。\n\n# 类图\n\n# 工厂方法模式\n\n工厂方法模式 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类把实例化推迟到子类。\n\n# 开加盟店\n\n# 类图\n\n# 代码实现\n\n\nimport java.util.arraylist;\n\npublic abstract class pizza {\n    protected string name;            // 披萨名字\n    protected string dough;           // 面团类型\n    protected string sauce;           // 酱料类型\n    protected arraylist topping= new arraylist();     // 一套佐料\n\n    public string getname() {\n        return name;\n    }\n\n    public void perpare(){\n        system.out.println("准备原料");\n    }\n    public void bake(){\n        system.out.println("炙烤披萨");\n    }\n    public void cut(){\n        system.out.println("披萨切片");\n    }\n    public void box(){\n        system.out.println("披萨装盒");\n    }\n}\n\n\nclass clampizza extends pizza {\n    public clampizza() {\n        name = "clampizza";\n        system.out.println("初始化" + name);\n    }\n}\nclass veggiepizza extends pizza {\n    public veggiepizza() {\n        name = "veggiepizza";\n        system.out.println("初始化" + name);\n    }\n}\nclass nystylecheesepizza extends pizza {\n    public nystylecheesepizza() {\n        name = "nystylecheesepizza";\n        system.out.println("初始化" + name);\n    }\n}\nclass chicagostylecheesepizza extends pizza {\n    public chicagostylecheesepizza() {\n        name = "chicagostylecheesepizza";\n        system.out.println("初始化" + name);\n    }\n\n    @override\n    public void cut() {\n        system.out.println("披萨切为方块");\n    }\n}\n\n\npublic abstract class pizzastore {\n    pizza pizza = null;\n\n    public pizza orderpizza(string type) {\n        return createpizza(type);\n    }\n\n    public void makepizza() {\n        if (null != this.pizza) {\n            pizza.perpare();\n            pizza.bake();\n            pizza.cut();\n            pizza.box();\n        }\n    }\n\n    protected abstract pizza createpizza(string type);\n}\n\nclass nystylepizzastore extends pizzastore {\n\n    @override\n    protected pizza createpizza(string type) {\n        if ("clam".equalsignorecase(type)) {\n            pizza = new clampizza();\n        } else if ("veggie".equalsignorecase(type)) {\n            pizza = new veggiepizza();\n        } else if ("cheese".equalsignorecase(type)) {\n            pizza = new nystylecheesepizza();\n        }\n        makepizza();\n        return pizza;\n    }\n}\n\nclass chicagostylepizzastore extends pizzastore {\n\n    @override\n    protected pizza createpizza(string type) {\n        if ("clam".equalsignorecase(type)) {\n            pizza = new clampizza();\n        } else if ("veggie".equalsignorecase(type)) {\n            pizza = new veggiepizza();\n        } else if ("cheese".equalsignorecase(type)) {\n            pizza = new chicagostylecheesepizza();\n        }\n        makepizza();\n        return pizza;\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        pizzastore nystylepizzastore = new nystylepizzastore();\n        pizzastore chicagostylepizzastore = new chicagostylepizzastore();\n\n        pizza nycheese = nystylepizzastore.orderpizza("cheese");\n        system.out.println(nycheese.getname());\n\n        pizza chcheese = chicagostylepizzastore.orderpizza("cheese");\n        system.out.println(chcheese.getname());\n    }\n}\n\n\n# 依赖倒置原则\n\n# 描述\n\n不能让高层组件依赖低层组件。而且，不管高层组件还是低层组件，都应该依赖于抽象。\n\n在应用工厂方法之后，你将注意到，高层组件（也就是pizzastore）和低层组件（也就是这些比萨）都依赖了pizz抽象。想要遵循依赖倒置原则，工厂方法并非是唯一的技巧，但却是最有威力的技巧之一。\n\n所谓倒置体现在：\n\n# 如何遵循此原则\n\n 1. 变量不可以持有具体类的引用。\n 2. 不要让类派生自具体类。\n 3. 不要覆盖基类中已实现的方法\n\n# 抽象工厂模式\n\n抽象工厂模式 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。\n\n# 原料工厂\n\n# 问题提出\n\n如何确保原料的一致？由于地域差别，每家店的披萨所使用的原材料并不完全一致。我们需要建造一个工厂生产原料，并处理各个区域的差异。\n\n# 类图\n\n抽象工厂允许客户使用抽象的接口来创建一组相关的产品，而不需要知道（或关心）实际产出的具体产品是什么。这样一来，客户就从具体的产品中被解耦。让我们看看类图来了解其中的关系：\n\n# 代码实现\n\n\npublic interface ingredient {}\n\nclass dough implements ingredient {\n    string name = "dough";\n    public dough() {\n        system.out.println("配料: " + name);\n    }\n}\nclass sauce implements ingredient {\n    string name = "sauce";\n    public sauce() {\n    }\n}\nclass cheese implements ingredient {\n    string name = "cheese";\n    public cheese() {\n        system.out.println("配料: " + name);\n    }\n}\nclass veggies implements ingredient {\n    string name = "veggies";\n}\nclass carrot extends veggies {\n    public carrot() {\n        name = "胡萝卜";\n        system.out.println("配料: " + name);\n    }\n}\nclass lettuce extends veggies {\n    public lettuce() {\n        name = "生菜";\n        system.out.println("配料: " + name);\n    }\n}\nclass pepperoni implements ingredient {\n    string name = "pepperoni";\n    public pepperoni() {\n        system.out.println("配料: " + name);\n    }\n}\n\ninterface clams extends ingredient {}\n\nclass freshclams implements clams {\n    string name = "新鲜蛤蜊";\n    public freshclams() {\n        system.out.println("配料: " + name);\n    }\n}\nclass frozenclams implements clams {\n    string name = "冰冻蛤蜊";\n    public frozenclams() {\n        system.out.println("配料: " + name);\n    }\n}\n\n\npublic interface pizzaingredientfactory {\n    dough createdough();\n    sauce createsauce();\n    cheese createcheese();\n    veggies[] createveggies();\n    pepperoni createpepperoni();\n    clams createclam();\n}\n\n\nclass chicagopizzaingredientfactory implements pizzaingredientfactory {\n\n    @override\n    public dough createdough() {\n        return new dough();\n    }\n\n    @override\n    public sauce createsauce() {\n        return new sauce();\n    }\n\n    @override\n    public cheese createcheese() {\n        return new cheese();\n    }\n\n    @override\n    public veggies[] createveggies() {\n        return new veggies[]{new carrot(), new lettuce()};\n    }\n\n    @override\n    public pepperoni createpepperoni() {\n        return new pepperoni();\n    }\n\n    @override\n    public clams createclam() {\n        return new freshclams();\n    }\n}\n\nclass nypizzaingredientfactory implements pizzaingredientfactory {\n\n    @override\n    public dough createdough() {\n        return new dough();\n    }\n\n    @override\n    public sauce createsauce() {\n        return new sauce();\n    }\n\n    @override\n    public cheese createcheese() {\n        return new cheese();\n    }\n\n    @override\n    public veggies[] createveggies() {\n        return new veggies[]{new lettuce()};\n    }\n\n    @override\n    public pepperoni createpepperoni() {\n        return new pepperoni();\n    }\n\n    @override\n    public clams createclam() {\n        return new frozenclams();\n    }\n}\n\n\npublic abstract class pizza {\n    protected string name;            // 披萨名字\n    protected dough dough;           // 面团类型\n    protected sauce sauce;           // 酱料类型\n    protected list<ingredient> topping= new arraylist();     // 一套佐料\n    protected clams clams;\n\n    public string getname() {\n        return name;\n    }\n\n    public void perpare(){\n        system.out.println("准备原料");\n    }\n    public void bake(){\n        system.out.println("炙烤披萨");\n    }\n    public void cut(){\n        system.out.println("披萨切片");\n    }\n    public void box(){\n        system.out.println("披萨装盒");\n    }\n}\n\n\nclass clampizza extends pizza {\n    pizzaingredientfactory pizzaingredientfactory;   // 新增原料工厂\n\n    public clampizza(pizzaingredientfactory pizzaingredientfactory) {\n        name = "clampizza";\n        this.pizzaingredientfactory = pizzaingredientfactory;\n    }\n\n    @override\n    public void perpare() {\n        super.perpare();\n        dough = pizzaingredientfactory.createdough();\n        sauce = pizzaingredientfactory.createsauce();\n        topping = arrays.aslist(pizzaingredientfactory.createveggies());\n        clams = pizzaingredientfactory.createclam();\n    }\n}\nclass veggiepizza extends pizza {\n    public veggiepizza() {\n        name = "veggiepizza";\n        system.out.println("初始化" + name);\n    }\n}\nclass nystylecheesepizza extends pizza {\n    public nystylecheesepizza() {\n        name = "nystylecheesepizza";\n        system.out.println("初始化" + name);\n    }\n}\nclass chicagostylecheesepizza extends pizza {\n    public chicagostylecheesepizza() {\n        name = "chicagostylecheesepizza";\n        system.out.println("初始化" + name);\n    }\n\n    @override\n    public void cut() {\n        system.out.println("披萨切为方块");\n    }\n}\n\n\npublic abstract class pizzastore {\n    pizza pizza = null;\n    pizzaingredientfactory pizzaingredientfactory;   // 新增原料工厂\n\n    public pizza orderpizza(string type) {\n        return createpizza(type);\n    }\n\n    public void makepizza() {\n        if (null != this.pizza) {\n            pizza.perpare();\n            pizza.bake();\n            pizza.cut();\n            pizza.box();\n        }\n    }\n\n    protected abstract pizza createpizza(string type);\n}\n\nclass nystylepizzastore extends pizzastore {\n    public nystylepizzastore(pizzaingredientfactory pizzaingredientfactory) {\n        super.pizzaingredientfactory = pizzaingredientfactory;\n    }\n\n    @override\n    protected pizza createpizza(string type) {\n        if ("clam".equalsignorecase(type)) {\n            pizza = new clampizza(pizzaingredientfactory);\n        } else if ("veggie".equalsignorecase(type)) {\n            pizza = new veggiepizza();\n        } else if ("cheese".equalsignorecase(type)) {\n            pizza = new nystylecheesepizza();\n        }\n        makepizza();\n        return pizza;\n    }\n}\n\nclass chicagostylepizzastore extends pizzastore {\n    public chicagostylepizzastore(pizzaingredientfactory pizzaingredientfactory) {\n        super.pizzaingredientfactory = pizzaingredientfactory;\n    }\n\n    @override\n    protected pizza createpizza(string type) {\n        if ("clam".equalsignorecase(type)) {\n            pizza = new clampizza(pizzaingredientfactory);\n        } else if ("veggie".equalsignorecase(type)) {\n            pizza = new veggiepizza();\n        } else if ("cheese".equalsignorecase(type)) {\n            pizza = new chicagostylecheesepizza();\n        }\n        makepizza();\n        return pizza;\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        pizzastore nystylepizzastore = new nystylepizzastore(new nypizzaingredientfactory());\n        pizzastore chicagostylepizzastore = new chicagostylepizzastore(new chicagopizzaingredientfactory());\n\n        pizza nycheese = nystylepizzastore.orderpizza("clam");\n        system.out.println(nycheese.getname());\n\n        pizza chcheese = chicagostylepizzastore.orderpizza("clam");\n        system.out.println(chcheese.getname());\n    }\n}\n\n\n# 要点\n\n> 抽象工厂的任务是定义创建一组产品的接口，这个接口里的每个方法都负责创建一个具体产品，同时我们通过实现抽象工厂子类来具体实现这些方法（工厂方法）。即，抽象工厂的方法通常是以工厂方法的方式实现的。\n\n * 所有的工厂都是用来封装对象的创建\n * 简单工厂，虽然不是真正的设计模式，但仍不失为一个简单的方法，可以将客户程序从具体类解稠。\n * 工厂方法使用继承：把对象的创建委托给子类，子类实现工厂方法来创建对象。\n * 抽象工厂使用对象组合：对象的创建被实现在工厂接口所暴露出来的方法中。\n * 所有工厂模式都通过减少应用程序和具体类之间的依赖促进松耦合。\n * 工厂方法允许类将实例化延迟到子类进行。\n * 抽象工厂创建相关的对象家族，而不需要依赖它们的具体类。\n * 依赖倒置原则，指导我们避免依赖具体类型，而要尽量依赖抽象。\n * 工厂是很有威力的技巧，帮助我们针对抽象编程，而不要针对具体类编程。',charsets:{cjk:!0},lastUpdated:"2022/07/17, 00:24:40",lastUpdatedTimestamp:165798868e4},{title:"命令模式",frontmatter:{title:"命令模式",date:"2022-07-18T00:13:17.000Z",permalink:"/pages/5d365c/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/060.%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/060.命令模式.md",key:"v-11fe809f",path:"/pages/5d365c/",headers:[{level:2,title:"命令模式（Command Pattern）",slug:"命令模式-command-pattern",normalizedTitle:"命令模式（command pattern）",charIndex:2},{level:4,title:"问题提出",slug:"问题提出",normalizedTitle:"问题提出",charIndex:84},{level:4,title:"思考如何实现",slug:"思考如何实现",normalizedTitle:"思考如何实现",charIndex:155},{level:4,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:279},{level:4,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:285},{level:4,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:61},{level:5,title:"实现命令撤销（待完善）",slug:"实现命令撤销-待完善",normalizedTitle:"实现命令撤销（待完善）",charIndex:4824},{level:5,title:"使用宏命令及宏撤销（待完善）",slug:"使用宏命令及宏撤销-待完善",normalizedTitle:"使用宏命令及宏撤销（待完善）",charIndex:4839},{level:5,title:"命令模式更多用途：队列请求（待完善）",slug:"命令模式更多用途-队列请求-待完善",normalizedTitle:"命令模式更多用途：队列请求（待完善）",charIndex:4857},{level:5,title:"命令模式更多用途：日志请求（待完善）",slug:"命令模式更多用途-日志请求-待完善",normalizedTitle:"命令模式更多用途：日志请求（待完善）",charIndex:4879},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:4901}],headersStr:"命令模式（Command Pattern） 问题提出 思考如何实现 类图 代码实现 其他 实现命令撤销（待完善） 使用宏命令及宏撤销（待完善） 命令模式更多用途：队列请求（待完善） 命令模式更多用途：日志请求（待完善） 要点",content:'# 命令模式（Command Pattern）\n\n命令模式 将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持可撤销的操作。\n\n# 问题提出\n\n创建一组控制遥控器的API，让遥控器每个插槽都能控制一个或一组装置。注意：要求能够控制目前的装置和任何未来可能出现的装置。\n\n# 思考如何实现\n\n 1. 客户创建一个命令对象\n 2. 客户利用 setCommand() 将命令对象存储在调用者中\n 3. 客户要求调用者执行命令\n\n> 注意：一旦命令被加载到调用者，该命令可以被使用或丢弃，或者可以被保留下来并使用许多次。\n\n# 类图\n\n# 代码实现\n\n\n// 电灯类\nclass Light {\n    String name;\n    public Light(String name) {\n        this.name = name;\n    }\n\n    public void on() {\n        System.out.println(name + "被打开");\n    }\n    public void off() {\n        System.out.println(name + "被关闭");\n    }\n}\n\n/**\n * 音响类\n */\nclass Stereo {\n    public void on() {\n        System.out.println("打开音响");\n    }\n\n    public void setCD() {\n        System.out.println("播放CD");\n    }\n\n    public void setVolume(int val) {\n        System.out.println("设置音量" + val);\n    }\n\n    public void off() {\n        System.out.println("关闭音响");\n    }\n}\n\n\npublic interface Command {\n    public void execute();\n}\n\nclass NoCommand implements Command {\n\n    @Override\n    public void execute() {\n        // System.out.println("什么也不做");\n    }\n}\n\n// 打开电灯\nclass LightOnCommand implements Command {\n    Light light;\n\n    public LightOnCommand(Light light) {\n        this.light = light;\n    }\n\n    @Override\n    public void execute() {\n        light.on();\n    }\n}\n\n// 关闭电灯\nclass LightOffCommand implements Command {\n    Light light;\n\n    public LightOffCommand(Light light) {\n        this.light = light;\n    }\n\n    @Override\n    public void execute() {\n        light.off();\n    }\n}\n\n/**\n * 打开音响命令\n */\nclass StereoOnWithCDCommand implements Command {\n    Stereo stereo;\n\n    public StereoOnWithCDCommand(Stereo stereo) {\n        this.stereo = stereo;\n    }\n\n    @Override\n    public void execute() {\n        stereo.on();\n        stereo.setCD();\n        stereo.setVolume(11);\n    }\n}\n\n/**\n * 关闭音响命令\n */\nclass StereoOffCommand implements Command {\n    Stereo stereo;\n\n    public StereoOffCommand(Stereo stereo) {\n        this.stereo = stereo;\n    }\n\n    @Override\n    public void execute() {\n        stereo.off();\n    }\n}\n\n\n/**\n * 遥控器类\n */\npublic class SimpleRemoteController {\n    // 插槽持有命令，控制着一个装置\n    // 用来记录 7 个接口的命令\n    Command[] onCommands;\n    Command[] offCommands;\n\n    public SimpleRemoteController() {\n        // 实例化并初始化两个开关数组\n        this.onCommands = new Command[7];\n        this.offCommands = new Command[7];\n\n        NoCommand noCommand = new NoCommand();\n        for (int i = 0; i < 7; i++) {\n            onCommands[i] = noCommand;\n            offCommands[i] = noCommand;\n        }\n    }\n\n    /**\n     * @param slot   插槽位置\n     * @param onCommand   开命令\n     * @param offCommand  关命令\n     * 用来设置插槽控制命令，可以通过多次调用改变行为\n     */\n    public void setCommand(int slot, Command onCommand, Command offCommand) {\n        onCommands[slot] = onCommand;\n        offCommands[slot] = offCommand;\n    }\n\n    /**\n     * 按下开启按钮，命令衔接插槽，调用 execute() 方法\n     */\n    public void onButtonWasPressed(int slot) {\n        onCommands[slot].execute();\n    }\n\n    public void offButtonWasPressed(int slot) {\n        offCommands[slot].execute();\n    }\n\n    @Override\n    public String toString() {\n        StringBuffer stringBuffer = new StringBuffer();\n\n        for (int i = 0; i < 7; i++) {\n            stringBuffer.append("装置：")\n                    .append(i)\n                    .append("\\t开启类：")\n                    .append(onCommands[i].getClass().getName())\n                    .append("\\t关闭类：")\n                    .append(offCommands.getClass().getName())\n                    .append("\\n");\n        }\n\n        return stringBuffer.toString();\n    }\n}\n\n\n/**\n * 命令模式的客户\n */\npublic class Main {\n    public static void main(String[] args) {\n        Light light1 = new Light("厨房灯");\n        Light light2 = new Light("卧室灯");\n        Stereo stereo = new Stereo();\n        LightOnCommand light1OnCommand = new LightOnCommand(light1);\n        LightOnCommand light2OnCommand = new LightOnCommand(light2);\n        LightOffCommand light1OffCommand = new LightOffCommand(light1);\n        LightOffCommand light2OffCommand = new LightOffCommand(light2);\n        StereoOnWithCDCommand stereoOnWithCDCommand = new StereoOnWithCDCommand(stereo);\n        StereoOffCommand stereoOffCommand = new StereoOffCommand(stereo);\n\n        SimpleRemoteController simpleRemoteController = new SimpleRemoteController();\n        simpleRemoteController.setCommand(1, light1OnCommand, light1OffCommand);\n        simpleRemoteController.setCommand(2, light2OnCommand, light2OffCommand);\n        simpleRemoteController.setCommand(3, stereoOnWithCDCommand, stereoOffCommand);\n\n        System.out.println(simpleRemoteController.toString());\n\n        simpleRemoteController.onButtonWasPressed(1);\n        simpleRemoteController.onButtonWasPressed(2);\n        simpleRemoteController.onButtonWasPressed(3);\n        simpleRemoteController.offButtonWasPressed(3);\n    }\n}\n\n\n# 其他\n\n# 实现命令撤销（待完善）\n\n# 使用宏命令及宏撤销（待完善）\n\n# 命令模式更多用途：队列请求（待完善）\n\n# 命令模式更多用途：日志请求（待完善）\n\n# 要点\n\n * 命令模式将发出请求的对象和执行请求的对象解耦。\n * 在被解耦的两者之间是通过命令对象进行沟通的。命令对象封装了接收者和一个或一组动作。\n * 调用者通过调用命令对象的execute()发出请求，这会使得接收者的动作被调用。\n * 调用者可以接受命令当做参数，甚至在运行时动态地进行。\n * 命令可以支特撒销，做法是实现一个undo()方法来回到execute()被执行前的状态。\n * 宏命令是命令的一种简单的延伸，允许调用多个命令。宏方法也可以支持撤销。\n * 实际操作时，很常见使用“聪明”命令对象，也就是直接实现了请求，而不是将工作委托给接收者。\n * 命令也可以用来实现日志和事务系统。',normalizedContent:'# 命令模式（command pattern）\n\n命令模式 将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持可撤销的操作。\n\n# 问题提出\n\n创建一组控制遥控器的api，让遥控器每个插槽都能控制一个或一组装置。注意：要求能够控制目前的装置和任何未来可能出现的装置。\n\n# 思考如何实现\n\n 1. 客户创建一个命令对象\n 2. 客户利用 setcommand() 将命令对象存储在调用者中\n 3. 客户要求调用者执行命令\n\n> 注意：一旦命令被加载到调用者，该命令可以被使用或丢弃，或者可以被保留下来并使用许多次。\n\n# 类图\n\n# 代码实现\n\n\n// 电灯类\nclass light {\n    string name;\n    public light(string name) {\n        this.name = name;\n    }\n\n    public void on() {\n        system.out.println(name + "被打开");\n    }\n    public void off() {\n        system.out.println(name + "被关闭");\n    }\n}\n\n/**\n * 音响类\n */\nclass stereo {\n    public void on() {\n        system.out.println("打开音响");\n    }\n\n    public void setcd() {\n        system.out.println("播放cd");\n    }\n\n    public void setvolume(int val) {\n        system.out.println("设置音量" + val);\n    }\n\n    public void off() {\n        system.out.println("关闭音响");\n    }\n}\n\n\npublic interface command {\n    public void execute();\n}\n\nclass nocommand implements command {\n\n    @override\n    public void execute() {\n        // system.out.println("什么也不做");\n    }\n}\n\n// 打开电灯\nclass lightoncommand implements command {\n    light light;\n\n    public lightoncommand(light light) {\n        this.light = light;\n    }\n\n    @override\n    public void execute() {\n        light.on();\n    }\n}\n\n// 关闭电灯\nclass lightoffcommand implements command {\n    light light;\n\n    public lightoffcommand(light light) {\n        this.light = light;\n    }\n\n    @override\n    public void execute() {\n        light.off();\n    }\n}\n\n/**\n * 打开音响命令\n */\nclass stereoonwithcdcommand implements command {\n    stereo stereo;\n\n    public stereoonwithcdcommand(stereo stereo) {\n        this.stereo = stereo;\n    }\n\n    @override\n    public void execute() {\n        stereo.on();\n        stereo.setcd();\n        stereo.setvolume(11);\n    }\n}\n\n/**\n * 关闭音响命令\n */\nclass stereooffcommand implements command {\n    stereo stereo;\n\n    public stereooffcommand(stereo stereo) {\n        this.stereo = stereo;\n    }\n\n    @override\n    public void execute() {\n        stereo.off();\n    }\n}\n\n\n/**\n * 遥控器类\n */\npublic class simpleremotecontroller {\n    // 插槽持有命令，控制着一个装置\n    // 用来记录 7 个接口的命令\n    command[] oncommands;\n    command[] offcommands;\n\n    public simpleremotecontroller() {\n        // 实例化并初始化两个开关数组\n        this.oncommands = new command[7];\n        this.offcommands = new command[7];\n\n        nocommand nocommand = new nocommand();\n        for (int i = 0; i < 7; i++) {\n            oncommands[i] = nocommand;\n            offcommands[i] = nocommand;\n        }\n    }\n\n    /**\n     * @param slot   插槽位置\n     * @param oncommand   开命令\n     * @param offcommand  关命令\n     * 用来设置插槽控制命令，可以通过多次调用改变行为\n     */\n    public void setcommand(int slot, command oncommand, command offcommand) {\n        oncommands[slot] = oncommand;\n        offcommands[slot] = offcommand;\n    }\n\n    /**\n     * 按下开启按钮，命令衔接插槽，调用 execute() 方法\n     */\n    public void onbuttonwaspressed(int slot) {\n        oncommands[slot].execute();\n    }\n\n    public void offbuttonwaspressed(int slot) {\n        offcommands[slot].execute();\n    }\n\n    @override\n    public string tostring() {\n        stringbuffer stringbuffer = new stringbuffer();\n\n        for (int i = 0; i < 7; i++) {\n            stringbuffer.append("装置：")\n                    .append(i)\n                    .append("\\t开启类：")\n                    .append(oncommands[i].getclass().getname())\n                    .append("\\t关闭类：")\n                    .append(offcommands.getclass().getname())\n                    .append("\\n");\n        }\n\n        return stringbuffer.tostring();\n    }\n}\n\n\n/**\n * 命令模式的客户\n */\npublic class main {\n    public static void main(string[] args) {\n        light light1 = new light("厨房灯");\n        light light2 = new light("卧室灯");\n        stereo stereo = new stereo();\n        lightoncommand light1oncommand = new lightoncommand(light1);\n        lightoncommand light2oncommand = new lightoncommand(light2);\n        lightoffcommand light1offcommand = new lightoffcommand(light1);\n        lightoffcommand light2offcommand = new lightoffcommand(light2);\n        stereoonwithcdcommand stereoonwithcdcommand = new stereoonwithcdcommand(stereo);\n        stereooffcommand stereooffcommand = new stereooffcommand(stereo);\n\n        simpleremotecontroller simpleremotecontroller = new simpleremotecontroller();\n        simpleremotecontroller.setcommand(1, light1oncommand, light1offcommand);\n        simpleremotecontroller.setcommand(2, light2oncommand, light2offcommand);\n        simpleremotecontroller.setcommand(3, stereoonwithcdcommand, stereooffcommand);\n\n        system.out.println(simpleremotecontroller.tostring());\n\n        simpleremotecontroller.onbuttonwaspressed(1);\n        simpleremotecontroller.onbuttonwaspressed(2);\n        simpleremotecontroller.onbuttonwaspressed(3);\n        simpleremotecontroller.offbuttonwaspressed(3);\n    }\n}\n\n\n# 其他\n\n# 实现命令撤销（待完善）\n\n# 使用宏命令及宏撤销（待完善）\n\n# 命令模式更多用途：队列请求（待完善）\n\n# 命令模式更多用途：日志请求（待完善）\n\n# 要点\n\n * 命令模式将发出请求的对象和执行请求的对象解耦。\n * 在被解耦的两者之间是通过命令对象进行沟通的。命令对象封装了接收者和一个或一组动作。\n * 调用者通过调用命令对象的execute()发出请求，这会使得接收者的动作被调用。\n * 调用者可以接受命令当做参数，甚至在运行时动态地进行。\n * 命令可以支特撒销，做法是实现一个undo()方法来回到execute()被执行前的状态。\n * 宏命令是命令的一种简单的延伸，允许调用多个命令。宏方法也可以支持撤销。\n * 实际操作时，很常见使用“聪明”命令对象，也就是直接实现了请求，而不是将工作委托给接收者。\n * 命令也可以用来实现日志和事务系统。',charsets:{cjk:!0},lastUpdated:"2022/07/19, 00:02:31",lastUpdatedTimestamp:1658160151e3},{title:"适配器模式与外观模式",frontmatter:{title:"适配器模式与外观模式",date:"2022-07-18T23:40:41.000Z",permalink:"/pages/c7cf8b/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/070.%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%E4%B8%8E%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/070.适配器模式与外观模式.md",key:"v-74435332",path:"/pages/c7cf8b/",headers:[{level:2,title:"适配器模式（Adaptor Pattern）",slug:"适配器模式-adaptor-pattern",normalizedTitle:"适配器模式（adaptor pattern）",charIndex:2},{level:4,title:"问题提出：火鸡转换器",slug:"问题提出-火鸡转换器",normalizedTitle:"问题提出：火鸡转换器",charIndex:78},{level:4,title:"类图（对象适配器）",slug:"类图-对象适配器",normalizedTitle:"类图（对象适配器）",charIndex:160},{level:4,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:183},{level:4,title:"多继承时类适配器（Java无法实现）",slug:"多继承时类适配器-java无法实现",normalizedTitle:"多继承时类适配器（java无法实现）",charIndex:1626},{level:4,title:"真实世界（Java）的适配器",slug:"真实世界-java-的适配器",normalizedTitle:"真实世界（java）的适配器",charIndex:1658},{level:5,title:"问题提出",slug:"问题提出",normalizedTitle:"问题提出",charIndex:78},{level:5,title:"将枚举适配到迭代器",slug:"将枚举适配到迭代器",normalizedTitle:"将枚举适配到迭代器",charIndex:2030},{level:2,title:"外观模式（Facade Pattern）",slug:"外观模式-facade-pattern",normalizedTitle:"外观模式（facade pattern）",charIndex:2119},{level:4,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:160},{level:4,title:"最少知道原则",slug:"最少知道原则",normalizedTitle:"最少知道原则",charIndex:2203},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:2510}],headersStr:"适配器模式（Adaptor Pattern） 问题提出：火鸡转换器 类图（对象适配器） 代码实现 多继承时类适配器（Java无法实现） 真实世界（Java）的适配器 问题提出 将枚举适配到迭代器 外观模式（Facade Pattern） 类图 最少知道原则 要点",content:'# 适配器模式（Adaptor Pattern）\n\n适配器模式 将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。\n\n# 问题提出：火鸡转换器\n\n假如我们在路上遇见一个NPC，必须给他一只鸭子才能完成任务。但是我们只有一只火鸡，这时，我们就需要适配器模式来适配他的需求。😕🤣\n\n# 类图（对象适配器）\n\n\n采用组合的方式\n\n# 代码实现\n\n/ 鸭子接口\npublic interface Duck {\n    public void quack();\n    public void fly();\n}\n\nclass MallardDuck implements Duck{\n\n    @Override\n    public void quack() {\n        System.out.println("绿头鸭叫");\n    }\n\n    @Override\n    public void fly() {\n        System.out.println("绿头鸭飞");\n    }\n}\n\n\n/**\n * 火鸡接口\n */\npublic interface Turkey {\n    public void gobble();   // 火鸡咯咯叫\n    public void fly();      // 火鸡飞\n}\n\n/**\n * 火鸡实现\n */\nclass WildTurkey implements Turkey {\n\n    @Override\n    public void gobble() {\n        System.out.println("火鸡咯咯叫");\n    }\n\n    @Override\n    public void fly() {\n        System.out.println("火鸡飞行");\n    }\n}\n\n\npublic class TurkeyAdaptor implements Duck {\n    Turkey turkey;\n\n    public TurkeyAdaptor(Turkey turkey) {\n        this.turkey = turkey;\n    }\n\n    @Override\n    public void quack() {\n        turkey.gobble();\n    }\n\n    @Override\n    public void fly() {\n        turkey.fly();\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        MallardDuck duck = new MallardDuck();   // 创建一只鸭子\n        WildTurkey turkey = new WildTurkey();   // 创建一只火鸡\n\n        Main main = new Main();\n        main.testDuck(duck);\n//        main.testDuck(turkey);\n        TurkeyAdaptor turkeyAdaptor = new TurkeyAdaptor(turkey);\n        main.testDuck(turkeyAdaptor);\n    }\n\n    /**\n     * 鸭子测试类\n     * @param duck\n     */\n    public void testDuck(Duck duck) {\n        duck.quack();\n        duck.fly();\n    }\n}\n\n\n# 多继承时类适配器（Java无法实现）\n\n采用继承的形式\n\n\n# 真实世界（Java）的适配器\n\n# 问题提出\n\n 1. 旧世界的枚举器\n    \n    > 如果你已经使用过Java，可能记得早期的集合(collection)类型（例如：Vector、Stack、Hashtable)都实现了一个名为elements（）的方法。该方法会返回一个Enumeration（举）。这个Enumeration接口可以逐一走过此集合内的每个元素，而无需知道它们在集合内是如何被管理的。\n\n 2. 新世界的迭代器\n    \n    > 当Sun推出更新后的集合类时，开始使用了Iterator（迭代器）接口，这个接口和枚举接口很像，都可以让你遍历此集合类型内的每个元素，但不同的是，迭代器还提供了删除元素的能力。\n\n 3. 遗留代码暴露了枚举器接口，但是新代码只希望用迭代器。想解决这个问题，需要构造一个适配器。\n\n# 将枚举适配到迭代器\n\n由于 Enumeration 为“只读”接口，无法实现 remove() 的效果，只能先在 remove 中抛出异常。（可以使用装饰者模式实现？）\n\n\n# 外观模式（Facade Pattern）\n\n外观模式 提供了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。\n\n# 类图\n\n# 最少知道原则\n\n最少知识原则：只和你的密友谈话。\n\n> 最少知识（Least Knowledge）原则告诉我们要减少对象之间的交互，只留下几个“密友”。\n> 这个原则希望我们在设计中，不要让太多的类耦合在一起，免得修改系统中一部分，会影响到其他部分。如果许多类之间相互依赖，那么这个系统就会变成一个易碎的系统，它需要花许多成本维护，也会因为太复杂而不容易被其他人了解。\n\n该原则提供一些方针：就任何对象而言，在该对线的方法内，我们只应该调用属于以下范围的方法：\n\n 1. 该对象本身\n 2. 被当作方法的参数而传递进来的对象\n 3. 此方法所创建或实例化的任何对象\n 4. 对象的任何组件（HAS-A关系）\n\n# 要点\n\n * 当需要使用一个现有的类而其接口并不符合你的需要时，就使用适配器。\n * 当需要简化并统一一个很大的接口或者一群复杂的接口时，使用外观。\n * 适配器改变接口以符合客户的期望。\n * 外观将客户从一个复杂的子系统中解耦。\n * 实现一个适配器可能需要一番功夫，也可能不费功夫，视目标接口的大小与复杂度而定。\n * 实现一个外观，需要将子系统组合进外观中，然后将工作委托给子系统执行。\n * 适配器模式有两种形式：对象适配器和类适配器。类适配器需要用到多重继承。\n * 你可以为一个子系统实现一个以上的外观。\n * 适配器将一个对象包装起来以改变其接口，装饰者将一个对象包装起来以增加新的行为和责任，而外观将一群对象“包装”起来以简化其接口。',normalizedContent:'# 适配器模式（adaptor pattern）\n\n适配器模式 将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。\n\n# 问题提出：火鸡转换器\n\n假如我们在路上遇见一个npc，必须给他一只鸭子才能完成任务。但是我们只有一只火鸡，这时，我们就需要适配器模式来适配他的需求。😕🤣\n\n# 类图（对象适配器）\n\n\n采用组合的方式\n\n# 代码实现\n\n/ 鸭子接口\npublic interface duck {\n    public void quack();\n    public void fly();\n}\n\nclass mallardduck implements duck{\n\n    @override\n    public void quack() {\n        system.out.println("绿头鸭叫");\n    }\n\n    @override\n    public void fly() {\n        system.out.println("绿头鸭飞");\n    }\n}\n\n\n/**\n * 火鸡接口\n */\npublic interface turkey {\n    public void gobble();   // 火鸡咯咯叫\n    public void fly();      // 火鸡飞\n}\n\n/**\n * 火鸡实现\n */\nclass wildturkey implements turkey {\n\n    @override\n    public void gobble() {\n        system.out.println("火鸡咯咯叫");\n    }\n\n    @override\n    public void fly() {\n        system.out.println("火鸡飞行");\n    }\n}\n\n\npublic class turkeyadaptor implements duck {\n    turkey turkey;\n\n    public turkeyadaptor(turkey turkey) {\n        this.turkey = turkey;\n    }\n\n    @override\n    public void quack() {\n        turkey.gobble();\n    }\n\n    @override\n    public void fly() {\n        turkey.fly();\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        mallardduck duck = new mallardduck();   // 创建一只鸭子\n        wildturkey turkey = new wildturkey();   // 创建一只火鸡\n\n        main main = new main();\n        main.testduck(duck);\n//        main.testduck(turkey);\n        turkeyadaptor turkeyadaptor = new turkeyadaptor(turkey);\n        main.testduck(turkeyadaptor);\n    }\n\n    /**\n     * 鸭子测试类\n     * @param duck\n     */\n    public void testduck(duck duck) {\n        duck.quack();\n        duck.fly();\n    }\n}\n\n\n# 多继承时类适配器（java无法实现）\n\n采用继承的形式\n\n\n# 真实世界（java）的适配器\n\n# 问题提出\n\n 1. 旧世界的枚举器\n    \n    > 如果你已经使用过java，可能记得早期的集合(collection)类型（例如：vector、stack、hashtable)都实现了一个名为elements（）的方法。该方法会返回一个enumeration（举）。这个enumeration接口可以逐一走过此集合内的每个元素，而无需知道它们在集合内是如何被管理的。\n\n 2. 新世界的迭代器\n    \n    > 当sun推出更新后的集合类时，开始使用了iterator（迭代器）接口，这个接口和枚举接口很像，都可以让你遍历此集合类型内的每个元素，但不同的是，迭代器还提供了删除元素的能力。\n\n 3. 遗留代码暴露了枚举器接口，但是新代码只希望用迭代器。想解决这个问题，需要构造一个适配器。\n\n# 将枚举适配到迭代器\n\n由于 enumeration 为“只读”接口，无法实现 remove() 的效果，只能先在 remove 中抛出异常。（可以使用装饰者模式实现？）\n\n\n# 外观模式（facade pattern）\n\n外观模式 提供了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。\n\n# 类图\n\n# 最少知道原则\n\n最少知识原则：只和你的密友谈话。\n\n> 最少知识（least knowledge）原则告诉我们要减少对象之间的交互，只留下几个“密友”。\n> 这个原则希望我们在设计中，不要让太多的类耦合在一起，免得修改系统中一部分，会影响到其他部分。如果许多类之间相互依赖，那么这个系统就会变成一个易碎的系统，它需要花许多成本维护，也会因为太复杂而不容易被其他人了解。\n\n该原则提供一些方针：就任何对象而言，在该对线的方法内，我们只应该调用属于以下范围的方法：\n\n 1. 该对象本身\n 2. 被当作方法的参数而传递进来的对象\n 3. 此方法所创建或实例化的任何对象\n 4. 对象的任何组件（has-a关系）\n\n# 要点\n\n * 当需要使用一个现有的类而其接口并不符合你的需要时，就使用适配器。\n * 当需要简化并统一一个很大的接口或者一群复杂的接口时，使用外观。\n * 适配器改变接口以符合客户的期望。\n * 外观将客户从一个复杂的子系统中解耦。\n * 实现一个适配器可能需要一番功夫，也可能不费功夫，视目标接口的大小与复杂度而定。\n * 实现一个外观，需要将子系统组合进外观中，然后将工作委托给子系统执行。\n * 适配器模式有两种形式：对象适配器和类适配器。类适配器需要用到多重继承。\n * 你可以为一个子系统实现一个以上的外观。\n * 适配器将一个对象包装起来以改变其接口，装饰者将一个对象包装起来以增加新的行为和责任，而外观将一群对象“包装”起来以简化其接口。',charsets:{cjk:!0},lastUpdated:"2022/08/11, 00:48:36",lastUpdatedTimestamp:1660150116e3},{title:"模板方法模式",frontmatter:{title:"模板方法模式",date:"2022-07-25T21:52:47.000Z",permalink:"/pages/93ef90/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/080.%E6%A8%A1%E6%9D%BF%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/080.模板方法模式.md",key:"v-0469e89f",path:"/pages/93ef90/",headers:[{level:2,title:"模板方法模式（Template Method Pattern）",slug:"模板方法模式-template-method-pattern",normalizedTitle:"模板方法模式（template method pattern）",charIndex:2},{level:4,title:"快速写出咖啡和茶的类",slug:"快速写出咖啡和茶的类",normalizedTitle:"快速写出咖啡和茶的类",charIndex:224},{level:4,title:"第一版设计",slug:"第一版设计",normalizedTitle:"第一版设计",charIndex:1132},{level:4,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:1277},{level:4,title:"代码实现（挂钩）",slug:"代码实现-挂钩",normalizedTitle:"代码实现（挂钩）",charIndex:1477},{level:4,title:"好莱坞原则",slug:"好莱坞原则",normalizedTitle:"好莱坞原则",charIndex:3976},{level:4,title:"Java Api 中的模板方法模式",slug:"java-api-中的模板方法模式",normalizedTitle:"java api 中的模板方法模式",charIndex:4128},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:4571}],headersStr:"模板方法模式（Template Method Pattern） 快速写出咖啡和茶的类 第一版设计 类图 代码实现（挂钩） 好莱坞原则 Java Api 中的模板方法模式 要点",content:'# 模板方法模式（Template Method Pattern）\n\n模板方法模式 在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。\n\n> 这个模式是用来创建一个算法的模板。什么是模板？如你所见的，模板就是一个方法。更具体地说，这个方法将算法定义成一组步骤，其中的任何步骤都可以是抽象的，由子类负责实现。这可以确保算法的结构保持不变，同时由子类提供部分实现。\n\n# 快速写出咖啡和茶的类\n\n\nclass Coffee {\n    void prepareRecipe() {\n        boilWater();\n        brewCoffeeGrinds();\n        pourInCup();\n        addSugerAndMilk();\n    }\n\n    public void boilWater() {\n        System.out.println("把水煮沸");\n    }\n    public void brewCoffeeGrinds() {\n        System.out.println("用沸水冲泡咖啡");\n    }\n    public void pourInCup() {\n        System.out.println("吧咖啡倒进杯子");\n    }\n    public void addSugerAndMilk() {\n        System.out.println("加糖和牛奶");\n    }\n}\n\n\npublic class Tea {\n    void prepareRecipe() {\n        boilWater();\n        steepTeaBag();\n        pourInCup();\n        addLemon();\n    }\n\n    public void boilWater() {\n        System.out.println("把水煮沸");\n    }\n    public void steepTeaBag() {\n        System.out.println("用沸水浸泡茶叶");\n    }\n    public void pourInCup() {\n        System.out.println("把茶倒进杯子");\n    }\n    public void addLemon() {\n        System.out.println("加柠檬");\n    }\n}\n\n\n# 第一版设计\n\n>  1. prepareRecipe() 方法在每个类中都不一样，所以定义为抽象方法；每个子类都覆盖 prepareRecipe()，实现自己的冲泡法\n>  2. boilWater() 和 pourInCup() 为相同的方法，所以定义在超类中；特有方法放到子类中\n\n# 类图\n\n>  1. CaffeineBeverage 是高层组件，他能控制冲泡法的算法，只有在需要子类实现某个方法时，才调用子类\n>  2. 饮料的客户代码只依赖 CaffeineBeverage 抽象，而不依赖具体的 Tea 或者 Coffee 这可以减少整个系统的依赖\n>  3. 子类只简单用来提供一些实现细节\n>  4. Tea 和 Coffee 如果没有先被调用，绝对不会调用抽象类\n\n# 代码实现（挂钩）\n\n\n/**\n * 抽象类，用来作为基类，其子类必须实现其操作\n */\nabstract class CaffeineBeverageWithHook {\n    /**\n     * 模板方法被声明为 final，以免算法顺序被改变（不能被子类覆盖）\n     * 此方法定义了一连串步骤，每个步骤为一个方法\n     */\n    final void prepareRecipe() {\n        boilWater();\n        brew();\n        pourInCup();\n        // 加上条件语句，条件成立（customerWantsCondiments() 为 true，即顾客想要调料 ）时，才调用 addCondiments() 方法\n        if (customerWantsCondiments()) {\n            addCondiments();\n        }\n    }\n\n    /**\n     * 原语操作，子类必须实现他们\n     */\n    abstract void brew();\n    abstract void addCondiments();\n\n    void boilWater() {\n        System.out.println("把水煮沸");\n    }\n    void pourInCup() {\n        System.out.println("倒进杯子中");\n    }\n\n    /**\n     * 这就是一个钩子，子类有可能覆盖此方法\n     * @return\n     */\n    boolean customerWantsCondiments () {\n        return true;\n    }\n\n}\n\n\nclass CoffeeWithHook extends CaffeineBeverageWithHook {\n\n    @Override\n    public void brew() {\n        System.out.println("用沸水冲泡咖啡");\n    }\n\n    @Override\n    public void addCondiments() {\n        System.out.println("加糖和牛奶");\n    }\n\n    /**\n     * 使用钩子：覆盖钩子，提供自己的功能\n     * @return\n     */\n    @Override\n    public boolean customerWantsCondiments() {\n        String answer = getUserInput();\n        return "y".equalsIgnoreCase(answer);\n    }\n\n    private String getUserInput () {\n        String answer = null;\n\n        System.out.println("咖啡里要加糖和牛奶吗？（y/n）");\n\n        BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(System.in));\n        try {\n            answer = bufferedReader.readLine();\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if (null != bufferedReader) {\n                try {\n                    bufferedReader.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n\n        if (null == answer) answer = "n";\n        return answer;\n    }\n}\n\npublic class TeaWithHook extends CaffeineBeverageWithHook {\n\n    @Override\n    public void brew() {\n        System.out.println("用沸水浸泡茶叶");\n    }\n\n    @Override\n    public void addCondiments() {\n        System.out.println("加柠檬");\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        TeaWithHook teaWithHook = new TeaWithHook();\n        CoffeeWithHook coffeeWithHook = new CoffeeWithHook();\n\n        System.out.println("制作茶...");\n        teaWithHook.prepareRecipe();\n\n        System.out.println("制作咖啡...");\n        coffeeWithHook.prepareRecipe();\n    }\n}\n\n\n# 好莱坞原则\n\n别调用（CALL）我们，我们会调用（CALL）你\n\n> 好菜坞原则可以给我们一种防止“依赖腐败”的方法。当高层组件依赖低层组件，而低层组件又依赖高层组件，而高层组件又依赖边侧组件，而边侧组件又依赖低层组件时，依赖腐败就发生了。在这种情况下，没有人可以轻易地搞懂系统是如何设计的。\n\n\n\n# Java Api 中的模板方法模式\n\n 1. 模板方法排序（java.util.Arrays 的 sort 方法）\n\n> 比较类实现 Comparable 接口并实现 compareTo 方法，就可以使用 Arrays.sort() 进行排序\n\n 2. Swing 的 JFrame（其中 paint() 方法是一个钩子）\n 3. Applet（具体的applet大量使用钩子来提供行为。因为这些行为是作为钩子实现的，所以Applet类就不用去实现它们。）\n    * init 钩子用来进行 applet 的初始化动作，会在 applet 一开始的时候调用一次\n    * repaint() 是一个具体方法，可让上层组件知道这个 applet 要重绘\n    * start 钩子可以在 applet 正要显示在网页上时，让 applet 做一些事情\n    * 若跳到别的网页 stop() 钩子会被调用\n    * applet 即将被销毁，destroy 钩子会被调用\n\n# 要点\n\n * “模板方法”定义了算法的步骤，把这些步骤的实现延迟到子类。\n * 模板方法模式为我们提供了一种代码复用的重要技巧。\n * 模板方法的抽象类可以定义具体方法、抽象方法和钩子。\n * 抽象方法由子类实现。\n * 钩子是一种方法，它在抽象类中不做事，或着只做默认的事情，子类可以选择要不要去覆盖它。\n * 为了防止子类改变模板方法中的算法，可以将模板方法声明为 final。\n * 好莱坞原则告诉我们，将决策权放在高层模块中，以便决定如何以及何时调用低层模块。\n * 你将在真实世界代码中看到模板方法模式的许多变体，不要期望一眼就可以认出它们。\n * 策略模式和模板方法模式都封装算法，一个用组合，一个用继承。\n * 工厂方法是模板方法的一种特殊饭本。',normalizedContent:'# 模板方法模式（template method pattern）\n\n模板方法模式 在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。\n\n> 这个模式是用来创建一个算法的模板。什么是模板？如你所见的，模板就是一个方法。更具体地说，这个方法将算法定义成一组步骤，其中的任何步骤都可以是抽象的，由子类负责实现。这可以确保算法的结构保持不变，同时由子类提供部分实现。\n\n# 快速写出咖啡和茶的类\n\n\nclass coffee {\n    void preparerecipe() {\n        boilwater();\n        brewcoffeegrinds();\n        pourincup();\n        addsugerandmilk();\n    }\n\n    public void boilwater() {\n        system.out.println("把水煮沸");\n    }\n    public void brewcoffeegrinds() {\n        system.out.println("用沸水冲泡咖啡");\n    }\n    public void pourincup() {\n        system.out.println("吧咖啡倒进杯子");\n    }\n    public void addsugerandmilk() {\n        system.out.println("加糖和牛奶");\n    }\n}\n\n\npublic class tea {\n    void preparerecipe() {\n        boilwater();\n        steepteabag();\n        pourincup();\n        addlemon();\n    }\n\n    public void boilwater() {\n        system.out.println("把水煮沸");\n    }\n    public void steepteabag() {\n        system.out.println("用沸水浸泡茶叶");\n    }\n    public void pourincup() {\n        system.out.println("把茶倒进杯子");\n    }\n    public void addlemon() {\n        system.out.println("加柠檬");\n    }\n}\n\n\n# 第一版设计\n\n>  1. preparerecipe() 方法在每个类中都不一样，所以定义为抽象方法；每个子类都覆盖 preparerecipe()，实现自己的冲泡法\n>  2. boilwater() 和 pourincup() 为相同的方法，所以定义在超类中；特有方法放到子类中\n\n# 类图\n\n>  1. caffeinebeverage 是高层组件，他能控制冲泡法的算法，只有在需要子类实现某个方法时，才调用子类\n>  2. 饮料的客户代码只依赖 caffeinebeverage 抽象，而不依赖具体的 tea 或者 coffee 这可以减少整个系统的依赖\n>  3. 子类只简单用来提供一些实现细节\n>  4. tea 和 coffee 如果没有先被调用，绝对不会调用抽象类\n\n# 代码实现（挂钩）\n\n\n/**\n * 抽象类，用来作为基类，其子类必须实现其操作\n */\nabstract class caffeinebeveragewithhook {\n    /**\n     * 模板方法被声明为 final，以免算法顺序被改变（不能被子类覆盖）\n     * 此方法定义了一连串步骤，每个步骤为一个方法\n     */\n    final void preparerecipe() {\n        boilwater();\n        brew();\n        pourincup();\n        // 加上条件语句，条件成立（customerwantscondiments() 为 true，即顾客想要调料 ）时，才调用 addcondiments() 方法\n        if (customerwantscondiments()) {\n            addcondiments();\n        }\n    }\n\n    /**\n     * 原语操作，子类必须实现他们\n     */\n    abstract void brew();\n    abstract void addcondiments();\n\n    void boilwater() {\n        system.out.println("把水煮沸");\n    }\n    void pourincup() {\n        system.out.println("倒进杯子中");\n    }\n\n    /**\n     * 这就是一个钩子，子类有可能覆盖此方法\n     * @return\n     */\n    boolean customerwantscondiments () {\n        return true;\n    }\n\n}\n\n\nclass coffeewithhook extends caffeinebeveragewithhook {\n\n    @override\n    public void brew() {\n        system.out.println("用沸水冲泡咖啡");\n    }\n\n    @override\n    public void addcondiments() {\n        system.out.println("加糖和牛奶");\n    }\n\n    /**\n     * 使用钩子：覆盖钩子，提供自己的功能\n     * @return\n     */\n    @override\n    public boolean customerwantscondiments() {\n        string answer = getuserinput();\n        return "y".equalsignorecase(answer);\n    }\n\n    private string getuserinput () {\n        string answer = null;\n\n        system.out.println("咖啡里要加糖和牛奶吗？（y/n）");\n\n        bufferedreader bufferedreader = new bufferedreader(new inputstreamreader(system.in));\n        try {\n            answer = bufferedreader.readline();\n        } catch (ioexception e) {\n            e.printstacktrace();\n        } finally {\n            if (null != bufferedreader) {\n                try {\n                    bufferedreader.close();\n                } catch (ioexception e) {\n                    e.printstacktrace();\n                }\n            }\n        }\n\n        if (null == answer) answer = "n";\n        return answer;\n    }\n}\n\npublic class teawithhook extends caffeinebeveragewithhook {\n\n    @override\n    public void brew() {\n        system.out.println("用沸水浸泡茶叶");\n    }\n\n    @override\n    public void addcondiments() {\n        system.out.println("加柠檬");\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        teawithhook teawithhook = new teawithhook();\n        coffeewithhook coffeewithhook = new coffeewithhook();\n\n        system.out.println("制作茶...");\n        teawithhook.preparerecipe();\n\n        system.out.println("制作咖啡...");\n        coffeewithhook.preparerecipe();\n    }\n}\n\n\n# 好莱坞原则\n\n别调用（call）我们，我们会调用（call）你\n\n> 好菜坞原则可以给我们一种防止“依赖腐败”的方法。当高层组件依赖低层组件，而低层组件又依赖高层组件，而高层组件又依赖边侧组件，而边侧组件又依赖低层组件时，依赖腐败就发生了。在这种情况下，没有人可以轻易地搞懂系统是如何设计的。\n\n\n\n# java api 中的模板方法模式\n\n 1. 模板方法排序（java.util.arrays 的 sort 方法）\n\n> 比较类实现 comparable 接口并实现 compareto 方法，就可以使用 arrays.sort() 进行排序\n\n 2. swing 的 jframe（其中 paint() 方法是一个钩子）\n 3. applet（具体的applet大量使用钩子来提供行为。因为这些行为是作为钩子实现的，所以applet类就不用去实现它们。）\n    * init 钩子用来进行 applet 的初始化动作，会在 applet 一开始的时候调用一次\n    * repaint() 是一个具体方法，可让上层组件知道这个 applet 要重绘\n    * start 钩子可以在 applet 正要显示在网页上时，让 applet 做一些事情\n    * 若跳到别的网页 stop() 钩子会被调用\n    * applet 即将被销毁，destroy 钩子会被调用\n\n# 要点\n\n * “模板方法”定义了算法的步骤，把这些步骤的实现延迟到子类。\n * 模板方法模式为我们提供了一种代码复用的重要技巧。\n * 模板方法的抽象类可以定义具体方法、抽象方法和钩子。\n * 抽象方法由子类实现。\n * 钩子是一种方法，它在抽象类中不做事，或着只做默认的事情，子类可以选择要不要去覆盖它。\n * 为了防止子类改变模板方法中的算法，可以将模板方法声明为 final。\n * 好莱坞原则告诉我们，将决策权放在高层模块中，以便决定如何以及何时调用低层模块。\n * 你将在真实世界代码中看到模板方法模式的许多变体，不要期望一眼就可以认出它们。\n * 策略模式和模板方法模式都封装算法，一个用组合，一个用继承。\n * 工厂方法是模板方法的一种特殊饭本。',charsets:{cjk:!0},lastUpdated:"2022/07/26, 00:03:35",lastUpdatedTimestamp:1658765015e3},{title:"迭代器与组合模式",frontmatter:{title:"迭代器与组合模式",date:"2022-08-09T22:20:38.000Z",permalink:"/pages/4372f2/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/090.%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/090.迭代器与组合模式.md",key:"v-3ed5a0cf",path:"/pages/4372f2/",headers:[{level:2,title:"迭代器模式（Iterator Pattern）",slug:"迭代器模式-iterator-pattern",normalizedTitle:"迭代器模式（iterator pattern）",charIndex:2},{level:4,title:"定义",slug:"定义",normalizedTitle:"定义",charIndex:29},{level:4,title:"问题提出",slug:"问题提出",normalizedTitle:"问题提出",charIndex:78},{level:4,title:"迭代器",slug:"迭代器",normalizedTitle:"迭代器",charIndex:2},{level:4,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:506},{level:4,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:512},{level:4,title:"改进",slug:"改进",normalizedTitle:"改进",charIndex:5242},{level:4,title:"单一职责原则",slug:"单一职责原则",normalizedTitle:"单一职责原则",charIndex:5305},{level:2,title:"组合模式（Composite Pattern）",slug:"组合模式-composite-pattern",normalizedTitle:"组合模式（composite pattern）",charIndex:5432},{level:4,title:"定义",slug:"定义-2",normalizedTitle:"定义",charIndex:29},{level:4,title:"问题提出",slug:"问题提出-2",normalizedTitle:"问题提出",charIndex:78},{level:4,title:"类图",slug:"类图-2",normalizedTitle:"类图",charIndex:506},{level:4,title:"代码实现",slug:"代码实现-2",normalizedTitle:"代码实现",charIndex:512},{level:4,title:"组合迭代器（待完善）",slug:"组合迭代器-待完善",normalizedTitle:"组合迭代器（待完善）",charIndex:9412},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:9426}],headersStr:"迭代器模式（Iterator Pattern） 定义 问题提出 迭代器 类图 代码实现 改进 单一职责原则 组合模式（Composite Pattern） 定义 问题提出 类图 代码实现 组合迭代器（待完善） 要点",content:'# 迭代器模式（Iterator Pattern）\n\n# 定义\n\n迭代器模式 提供一种方法顺序访向一个聚合对象中的各个元素，而又不暴露其内部的表示。\n\n# 问题提出\n\n现在有一个煎饼屋和餐厅需要合并，早上菜单由煎饼屋提供，午饭菜单由餐厅提供。但是两家菜单的实现方式不一样，一个是通过 ArrayList 实现，另一个通过数组实现。因此，遍历菜单的方式不一样，代码不能通用。\n\n// 集合方式遍历\nfor (int i = 0; i < breakfastItems.size(); i++) {\n    MenuItem menuItem = (MenuItem)breakfastItems.get(i);\n    System.out.println(menuItem.toString());\n}\n\n// 数组方式遍历\nfor (int i = 0; i < lunchItems.length; i++) {\n    MenuItem menuItem = lunchItems[i];\n    System.out.println(menuItem.toString());\n}\n\n\n# 迭代器\n\n# 类图\n\n# 代码实现\n\n\npublic class MenuItem {\n    String name;\n    String description;\n    boolean vegetaian;\n    double price;\n\n    public MenuItem(String name, String description, boolean vegetaian, double price) {\n        this.name = name;\n        this.description = description;\n        this.vegetaian = vegetaian;\n        this.price = price;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public String getDescription() {\n        return description;\n    }\n\n    public boolean isVegetaian() {\n        return vegetaian;\n    }\n\n    public double getPrice() {\n        return price;\n    }\n\n    @Override\n    public String toString() {\n        return "MenuItem{" +\n                "name=\'" + name + \'\\\'\' +\n                ", description=\'" + description + \'\\\'\' +\n                ", vegetaian=" + vegetaian +\n                ", price=" + price +\n                \'}\';\n    }\n}\n\n\npublic class DinerMenu {\n    static final int MAX_ITEM = 6;\n    int numOfItems = 0;\n    MenuItem[] menuItems;\n\n    public DinerMenu() {\n        menuItems = new MenuItem[MAX_ITEM];\n        addItem("11", "11", true, 1.1);\n        addItem("22", "22", true, 2.2);\n        addItem("33", "33", true, 3.3);\n        addItem("44", "44", true, 4.4);\n        addItem("55", "55", true, 5.5);\n    }\n\n    public void addItem(String name, String description, boolean vegetaian, double price) {\n        MenuItem menuItem = new MenuItem(name, description, vegetaian, price);\n\n        if (numOfItems >= MAX_ITEM) {\n            System.out.println("超过最大保存菜单数");\n        } else {\n            menuItems[numOfItems++] = new MenuItem(name, description, vegetaian, price);\n        }\n    }\n\n    /*public MenuItem[] getMenuItems() {\n        return menuItems;\n    }*/\n\n    public Iterator createIterator() {\n        return new DinerMenuIterator(menuItems);\n    }\n}\n\n\n// 迭代器接口\ninterface Iterator {\n    boolean hasNext();\n    Object next();\n}\npublic class DinerMenuIterator implements Iterator{\n    MenuItem[] items;\n    int position; // 记录当前位置\n\n    public DinerMenuIterator(MenuItem[] items) {\n        this.items = items;\n    }\n\n    @Override\n    public boolean hasNext() {\n        if (position >= items.length || null == items[position]) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    @Override\n    public Object next() {\n        return items[position++];\n    }\n}\n\n\npublic class PancakeHoseMenu {\n    ArrayList menuItems;\n\n    public PancakeHoseMenu() {\n        menuItems = new ArrayList<>();\n        addItem("111", "111", true, 1.11);\n        addItem("222", "222", true, 2.22);\n        addItem("333", "333", true, 3.33);\n        addItem("444", "444", true, 4.44);\n        addItem("555", "555", true, 5.55);\n    }\n\n    public void addItem(String name, String description, boolean vegetaian, double price) {\n        MenuItem menuItem = new MenuItem(name, description, vegetaian, price);\n        menuItems.add(menuItem);\n    }\n\n    /*public ArrayList getMenuItem() {\n        return menuItems;\n    }*/\n    public Iterator createIterator() {\n        return new PancakeHoseMenuIterator(menuItems);\n    }\n}\n\n\npublic class PancakeHoseMenuIterator implements Iterator {\n    ArrayList menuItems;\n    int position; // 记录当前位置\n\n    public PancakeHoseMenuIterator(ArrayList menuItems) {\n        this.menuItems = menuItems;\n    }\n\n    @Override\n    public boolean hasNext() {\n        if (position >= menuItems.size()) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    @Override\n    public Object next() {\n        return menuItems.get(position++);\n    }\n}\n\n\npublic class Waitress {\n    PancakeHoseMenu pancakeHoseMenu;\n    DinerMenu dinerMenu;\n\n    public Waitress(PancakeHoseMenu pancakeHoseMenu, DinerMenu dinerMenu) {\n        this.pancakeHoseMenu = pancakeHoseMenu;\n        this.dinerMenu = dinerMenu;\n    }\n\n    private void printMenu(Iterator iterator) {\n        while (iterator.hasNext()) {\n            MenuItem menuItem = (MenuItem)iterator.next();\n            System.out.println(menuItem.toString());\n        }\n    }\n\n    public void printMenu() {\n        Iterator pancakeHoseMenuIterator = pancakeHoseMenu.createIterator();\n        Iterator dinerMenuIterator = dinerMenu.createIterator();\n        System.out.println("----- pancakeHoseMenuIterator ----");\n        printMenu(pancakeHoseMenuIterator);\n        System.out.println("----- dinerMenuIterator ----");\n        printMenu(dinerMenuIterator);\n    }\n}\n\n\npublic class Main {\n    public static void main(String[] args) {\n        PancakeHoseMenu pancakeHoseMenu = new PancakeHoseMenu();\n        DinerMenu dinerMenu = new DinerMenu();\n\n        Waitress waitress = new Waitress(pancakeHoseMenu, dinerMenu);\n        waitress.printMenu();\n    }\n}\n\n\n# 改进\n\n利用接口（而不是具体类）引用菜单兑现，通过“针对接口编程，而不针对实现编程”，减少服务员和具体类之间的依赖。\n\n\n# 单一职责原则\n\n一个类应该只有一个引起变化的原因\n\n> 我们知道要避免类内的改变，因为修改代码很容易造成许多潜在的错误。如果有一个类具有两个改变的原因，那么这会使得将来该类的变化机率上升，而当它真的改变时，你的设计中同时有两个方面将会受到影响。\n\n\n# 组合模式（Composite Pattern）\n\n# 定义\n\n组合模式 允许你将对象组合成树形结构来表现“整体/部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合。\n\n# 问题提出\n\n当我们使用了迭代器模式，我们可以很轻易的加入一份菜单。但是，如果我们想要加上一份餐后甜点的菜单（菜单中的菜单），迭代器模式就有些无能为力了。\n\n因此，需要重新设计：\n\n 1. 我们需要树形结构，来容纳菜单、子菜单和菜单项。\n 2. 我们必须能够轻易遍历菜单项，至少需要和迭代器一样方便。\n 3. 也需要更有弹性的遍历菜单项，比如：可能只需要遍历甜点菜单，或者可以遍历全部菜单。\n\n# 类图\n\n设计菜单\n\n# 代码实现\n\n\npublic abstract class MenuComponent {\n  public String getName(){\n      throw new UnsupportedOperationException();\n  }\n  public String getDescription(){\n      throw new UnsupportedOperationException();\n  }\n  public double getPrice(){\n      throw new UnsupportedOperationException();\n  }\n  public boolean isVegetarian(){\n      throw new UnsupportedOperationException();\n  }\n  public void print()  {\n      throw new UnsupportedOperationException();\n  }\n  public void add(MenuComponent menuComponent){\n      throw new UnsupportedOperationException();\n  }\n  public void remove(MenuComponent menuComponent){\n      throw new UnsupportedOperationException();\n  }\n  public MenuComponent getChild(int num) {\n      throw new UnsupportedOperationException();\n  }\n}\n\n\npublic class MenuItem extends MenuComponent {\n  String name;\n  String description;\n  boolean vegetaian;\n  double price;\n\n  public MenuItem(String name, String description, boolean vegetaian, double price) {\n      this.name = name;\n      this.description = description;\n      this.vegetaian = vegetaian;\n      this.price = price;\n  }\n\n  @Override\n  public String getName() {\n      return name;\n  }\n\n  @Override\n  public String getDescription() {\n      return description;\n  }\n\n  @Override\n  public boolean isVegetarian() {\n      return vegetaian;\n  }\n\n  @Override\n  public double getPrice() {\n      return price;\n  }\n\n  @Override\n  public void print() {\n      String isV = isVegetarian() ? "(v)" : "";\n      System.out.println(" " + getName() + isV);\n      System.out.println(" " + getDescription());\n      System.out.println(" " + getPrice());\n  }\n}\n\n\npublic class Menu extends MenuComponent {\n  ArrayList menuComponents = new ArrayList<>();\n  String name;\n  String description;\n\n  public Menu(String name, String description) {\n      this.name = name;\n      this.description = description;\n  }\n\n  @Override\n  public String getName() {\n      return name;\n  }\n\n  @Override\n  public String getDescription() {\n      return description;\n  }\n\n  @Override\n  public void print() {\n      System.out.println("菜单名称：" + getName());\n      System.out.println("菜单描述：" + getDescription());\n      System.out.println("--------------------------------");\n\n      Iterator iterator = menuComponents.iterator();\n      while (iterator.hasNext()) {\n          MenuComponent menuComponent = (MenuComponent)iterator.next();\n          menuComponent.print();\n      }\n  }\n\n  @Override\n  public void add(MenuComponent menuComponent) {\n      menuComponents.add(menuComponent);\n  }\n\n  @Override\n  public void remove(MenuComponent menuComponent) {\n      menuComponents.remove(menuComponent);\n  }\n\n  @Override\n  public MenuComponent getChild(int num) {\n      return (MenuComponent)menuComponents.get(num);\n  }\n}\n\n\npublic class Waitress {\n  MenuComponent allMenus;\n\n  public Waitress(MenuComponent allMenus) {\n      this.allMenus = allMenus;\n  }\n\n  public void printMenu() {\n      allMenus.print();\n  }\n}\n\n\npublic class Main {\n  public static void main(String[] args) {\n      MenuComponent pancakeHouseMenu = new Menu("煎饼", "早餐");\n      MenuComponent dinerMenu = new Menu("餐厅", "午餐");\n      MenuComponent cafeMenu = new Menu("咖啡", "晚餐");\n      MenuComponent dessertMenu = new Menu("甜点", "");\n      dessertMenu.add(new MenuItem("蛋糕", "蛋糕", true, 0));\n      dinerMenu.add(dessertMenu);\n      dinerMenu.add(new MenuItem("炒胡萝卜", "炒胡萝卜", true, 22));\n      dinerMenu.add(new MenuItem("炒鸡蛋", "炒鸡蛋", false, 23));\n\n      MenuComponent menuRoot = new Menu("所有菜单", "根节点");\n      menuRoot.add(pancakeHouseMenu);\n      menuRoot.add(dinerMenu);\n      menuRoot.add(cafeMenu);\n\n      Waitress waitress = new Waitress(menuRoot);\n      waitress.printMenu();\n  }\n}\n\n\n# 组合迭代器（待完善）\n\n# 要点\n\n * 迭代器允许访问聚合的元素，而不需要暴露它的内部结构。\n * 迭代器将遍历聚合的工作封装进一个对象中。\n * 当使用迭代器的时候，我们依赖聚合提供遍历。\n * 迭代器提供了一个通用的接口，让我们遍历聚合的项，当我们编码使用聚合的项时，就可以使用多态机制。\n * 我们应该努力让一个类只分配一个责任。\n * 组合模式提供一个结构，可同时包容个别对象和组合对象。\n * 组合模式允许客户对个别对象以及组合对象一视同仁。\n * 组合结构内的任意对象称为组件，组件可以是组合，也可以是叶节点。\n * 在实现组合模式时，有许多设计上的折中。你要根据需要平衡透明性和安全性',normalizedContent:'# 迭代器模式（iterator pattern）\n\n# 定义\n\n迭代器模式 提供一种方法顺序访向一个聚合对象中的各个元素，而又不暴露其内部的表示。\n\n# 问题提出\n\n现在有一个煎饼屋和餐厅需要合并，早上菜单由煎饼屋提供，午饭菜单由餐厅提供。但是两家菜单的实现方式不一样，一个是通过 arraylist 实现，另一个通过数组实现。因此，遍历菜单的方式不一样，代码不能通用。\n\n// 集合方式遍历\nfor (int i = 0; i < breakfastitems.size(); i++) {\n    menuitem menuitem = (menuitem)breakfastitems.get(i);\n    system.out.println(menuitem.tostring());\n}\n\n// 数组方式遍历\nfor (int i = 0; i < lunchitems.length; i++) {\n    menuitem menuitem = lunchitems[i];\n    system.out.println(menuitem.tostring());\n}\n\n\n# 迭代器\n\n# 类图\n\n# 代码实现\n\n\npublic class menuitem {\n    string name;\n    string description;\n    boolean vegetaian;\n    double price;\n\n    public menuitem(string name, string description, boolean vegetaian, double price) {\n        this.name = name;\n        this.description = description;\n        this.vegetaian = vegetaian;\n        this.price = price;\n    }\n\n    public string getname() {\n        return name;\n    }\n\n    public string getdescription() {\n        return description;\n    }\n\n    public boolean isvegetaian() {\n        return vegetaian;\n    }\n\n    public double getprice() {\n        return price;\n    }\n\n    @override\n    public string tostring() {\n        return "menuitem{" +\n                "name=\'" + name + \'\\\'\' +\n                ", description=\'" + description + \'\\\'\' +\n                ", vegetaian=" + vegetaian +\n                ", price=" + price +\n                \'}\';\n    }\n}\n\n\npublic class dinermenu {\n    static final int max_item = 6;\n    int numofitems = 0;\n    menuitem[] menuitems;\n\n    public dinermenu() {\n        menuitems = new menuitem[max_item];\n        additem("11", "11", true, 1.1);\n        additem("22", "22", true, 2.2);\n        additem("33", "33", true, 3.3);\n        additem("44", "44", true, 4.4);\n        additem("55", "55", true, 5.5);\n    }\n\n    public void additem(string name, string description, boolean vegetaian, double price) {\n        menuitem menuitem = new menuitem(name, description, vegetaian, price);\n\n        if (numofitems >= max_item) {\n            system.out.println("超过最大保存菜单数");\n        } else {\n            menuitems[numofitems++] = new menuitem(name, description, vegetaian, price);\n        }\n    }\n\n    /*public menuitem[] getmenuitems() {\n        return menuitems;\n    }*/\n\n    public iterator createiterator() {\n        return new dinermenuiterator(menuitems);\n    }\n}\n\n\n// 迭代器接口\ninterface iterator {\n    boolean hasnext();\n    object next();\n}\npublic class dinermenuiterator implements iterator{\n    menuitem[] items;\n    int position; // 记录当前位置\n\n    public dinermenuiterator(menuitem[] items) {\n        this.items = items;\n    }\n\n    @override\n    public boolean hasnext() {\n        if (position >= items.length || null == items[position]) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    @override\n    public object next() {\n        return items[position++];\n    }\n}\n\n\npublic class pancakehosemenu {\n    arraylist menuitems;\n\n    public pancakehosemenu() {\n        menuitems = new arraylist<>();\n        additem("111", "111", true, 1.11);\n        additem("222", "222", true, 2.22);\n        additem("333", "333", true, 3.33);\n        additem("444", "444", true, 4.44);\n        additem("555", "555", true, 5.55);\n    }\n\n    public void additem(string name, string description, boolean vegetaian, double price) {\n        menuitem menuitem = new menuitem(name, description, vegetaian, price);\n        menuitems.add(menuitem);\n    }\n\n    /*public arraylist getmenuitem() {\n        return menuitems;\n    }*/\n    public iterator createiterator() {\n        return new pancakehosemenuiterator(menuitems);\n    }\n}\n\n\npublic class pancakehosemenuiterator implements iterator {\n    arraylist menuitems;\n    int position; // 记录当前位置\n\n    public pancakehosemenuiterator(arraylist menuitems) {\n        this.menuitems = menuitems;\n    }\n\n    @override\n    public boolean hasnext() {\n        if (position >= menuitems.size()) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    @override\n    public object next() {\n        return menuitems.get(position++);\n    }\n}\n\n\npublic class waitress {\n    pancakehosemenu pancakehosemenu;\n    dinermenu dinermenu;\n\n    public waitress(pancakehosemenu pancakehosemenu, dinermenu dinermenu) {\n        this.pancakehosemenu = pancakehosemenu;\n        this.dinermenu = dinermenu;\n    }\n\n    private void printmenu(iterator iterator) {\n        while (iterator.hasnext()) {\n            menuitem menuitem = (menuitem)iterator.next();\n            system.out.println(menuitem.tostring());\n        }\n    }\n\n    public void printmenu() {\n        iterator pancakehosemenuiterator = pancakehosemenu.createiterator();\n        iterator dinermenuiterator = dinermenu.createiterator();\n        system.out.println("----- pancakehosemenuiterator ----");\n        printmenu(pancakehosemenuiterator);\n        system.out.println("----- dinermenuiterator ----");\n        printmenu(dinermenuiterator);\n    }\n}\n\n\npublic class main {\n    public static void main(string[] args) {\n        pancakehosemenu pancakehosemenu = new pancakehosemenu();\n        dinermenu dinermenu = new dinermenu();\n\n        waitress waitress = new waitress(pancakehosemenu, dinermenu);\n        waitress.printmenu();\n    }\n}\n\n\n# 改进\n\n利用接口（而不是具体类）引用菜单兑现，通过“针对接口编程，而不针对实现编程”，减少服务员和具体类之间的依赖。\n\n\n# 单一职责原则\n\n一个类应该只有一个引起变化的原因\n\n> 我们知道要避免类内的改变，因为修改代码很容易造成许多潜在的错误。如果有一个类具有两个改变的原因，那么这会使得将来该类的变化机率上升，而当它真的改变时，你的设计中同时有两个方面将会受到影响。\n\n\n# 组合模式（composite pattern）\n\n# 定义\n\n组合模式 允许你将对象组合成树形结构来表现“整体/部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合。\n\n# 问题提出\n\n当我们使用了迭代器模式，我们可以很轻易的加入一份菜单。但是，如果我们想要加上一份餐后甜点的菜单（菜单中的菜单），迭代器模式就有些无能为力了。\n\n因此，需要重新设计：\n\n 1. 我们需要树形结构，来容纳菜单、子菜单和菜单项。\n 2. 我们必须能够轻易遍历菜单项，至少需要和迭代器一样方便。\n 3. 也需要更有弹性的遍历菜单项，比如：可能只需要遍历甜点菜单，或者可以遍历全部菜单。\n\n# 类图\n\n设计菜单\n\n# 代码实现\n\n\npublic abstract class menucomponent {\n  public string getname(){\n      throw new unsupportedoperationexception();\n  }\n  public string getdescription(){\n      throw new unsupportedoperationexception();\n  }\n  public double getprice(){\n      throw new unsupportedoperationexception();\n  }\n  public boolean isvegetarian(){\n      throw new unsupportedoperationexception();\n  }\n  public void print()  {\n      throw new unsupportedoperationexception();\n  }\n  public void add(menucomponent menucomponent){\n      throw new unsupportedoperationexception();\n  }\n  public void remove(menucomponent menucomponent){\n      throw new unsupportedoperationexception();\n  }\n  public menucomponent getchild(int num) {\n      throw new unsupportedoperationexception();\n  }\n}\n\n\npublic class menuitem extends menucomponent {\n  string name;\n  string description;\n  boolean vegetaian;\n  double price;\n\n  public menuitem(string name, string description, boolean vegetaian, double price) {\n      this.name = name;\n      this.description = description;\n      this.vegetaian = vegetaian;\n      this.price = price;\n  }\n\n  @override\n  public string getname() {\n      return name;\n  }\n\n  @override\n  public string getdescription() {\n      return description;\n  }\n\n  @override\n  public boolean isvegetarian() {\n      return vegetaian;\n  }\n\n  @override\n  public double getprice() {\n      return price;\n  }\n\n  @override\n  public void print() {\n      string isv = isvegetarian() ? "(v)" : "";\n      system.out.println(" " + getname() + isv);\n      system.out.println(" " + getdescription());\n      system.out.println(" " + getprice());\n  }\n}\n\n\npublic class menu extends menucomponent {\n  arraylist menucomponents = new arraylist<>();\n  string name;\n  string description;\n\n  public menu(string name, string description) {\n      this.name = name;\n      this.description = description;\n  }\n\n  @override\n  public string getname() {\n      return name;\n  }\n\n  @override\n  public string getdescription() {\n      return description;\n  }\n\n  @override\n  public void print() {\n      system.out.println("菜单名称：" + getname());\n      system.out.println("菜单描述：" + getdescription());\n      system.out.println("--------------------------------");\n\n      iterator iterator = menucomponents.iterator();\n      while (iterator.hasnext()) {\n          menucomponent menucomponent = (menucomponent)iterator.next();\n          menucomponent.print();\n      }\n  }\n\n  @override\n  public void add(menucomponent menucomponent) {\n      menucomponents.add(menucomponent);\n  }\n\n  @override\n  public void remove(menucomponent menucomponent) {\n      menucomponents.remove(menucomponent);\n  }\n\n  @override\n  public menucomponent getchild(int num) {\n      return (menucomponent)menucomponents.get(num);\n  }\n}\n\n\npublic class waitress {\n  menucomponent allmenus;\n\n  public waitress(menucomponent allmenus) {\n      this.allmenus = allmenus;\n  }\n\n  public void printmenu() {\n      allmenus.print();\n  }\n}\n\n\npublic class main {\n  public static void main(string[] args) {\n      menucomponent pancakehousemenu = new menu("煎饼", "早餐");\n      menucomponent dinermenu = new menu("餐厅", "午餐");\n      menucomponent cafemenu = new menu("咖啡", "晚餐");\n      menucomponent dessertmenu = new menu("甜点", "");\n      dessertmenu.add(new menuitem("蛋糕", "蛋糕", true, 0));\n      dinermenu.add(dessertmenu);\n      dinermenu.add(new menuitem("炒胡萝卜", "炒胡萝卜", true, 22));\n      dinermenu.add(new menuitem("炒鸡蛋", "炒鸡蛋", false, 23));\n\n      menucomponent menuroot = new menu("所有菜单", "根节点");\n      menuroot.add(pancakehousemenu);\n      menuroot.add(dinermenu);\n      menuroot.add(cafemenu);\n\n      waitress waitress = new waitress(menuroot);\n      waitress.printmenu();\n  }\n}\n\n\n# 组合迭代器（待完善）\n\n# 要点\n\n * 迭代器允许访问聚合的元素，而不需要暴露它的内部结构。\n * 迭代器将遍历聚合的工作封装进一个对象中。\n * 当使用迭代器的时候，我们依赖聚合提供遍历。\n * 迭代器提供了一个通用的接口，让我们遍历聚合的项，当我们编码使用聚合的项时，就可以使用多态机制。\n * 我们应该努力让一个类只分配一个责任。\n * 组合模式提供一个结构，可同时包容个别对象和组合对象。\n * 组合模式允许客户对个别对象以及组合对象一视同仁。\n * 组合结构内的任意对象称为组件，组件可以是组合，也可以是叶节点。\n * 在实现组合模式时，有许多设计上的折中。你要根据需要平衡透明性和安全性',charsets:{cjk:!0},lastUpdated:"2022/08/11, 00:48:36",lastUpdatedTimestamp:1660150116e3},{title:"State 模式",frontmatter:{title:"State 模式",date:"2022-08-14T11:11:27.000Z",permalink:"/pages/463f44/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/110.%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/110.状态模式.md",key:"v-7487d51a",path:"/pages/463f44/",headers:[{level:2,title:"状态模式（State Pattern）",slug:"状态模式-state-pattern",normalizedTitle:"状态模式（state pattern）",charIndex:2},{level:4,title:"定义",slug:"定义",normalizedTitle:"定义",charIndex:25},{level:4,title:"提出问题",slug:"提出问题",normalizedTitle:"提出问题",charIndex:164},{level:5,title:"万能糖果机",slug:"万能糖果机",normalizedTitle:"万能糖果机",charIndex:172},{level:5,title:"代码实现",slug:"代码实现",normalizedTitle:"代码实现",charIndex:181},{level:5,title:"新的设计",slug:"新的设计",normalizedTitle:"新的设计",charIndex:4263},{level:5,title:"类图",slug:"类图",normalizedTitle:"类图",charIndex:4433},{level:5,title:"优化后代码",slug:"优化后代码",normalizedTitle:"优化后代码",charIndex:4449},{level:4,title:"要点",slug:"要点",normalizedTitle:"要点",charIndex:10390}],headersStr:"状态模式（State Pattern） 定义 提出问题 万能糖果机 代码实现 新的设计 类图 优化后代码 要点",content:'# 状态模式（State Pattern）\n\n# 定义\n\n状态模式 允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。\n\n> 基本常识：策略模式和状态模式是双胞胎，在出生时才分开。策略模式是围绕可以互换的算法来创建业务的。然而，状态模式走的是更崇高的路，它通过改变对象内部的状态来帮助对象控制自己的行为。\n\n# 提出问题\n\n# 万能糖果机\n\n# 代码实现\n\n以下为代码的初步实现存在，但存在诸多问题\n\n 1. 这份代码没有遵循开闭原则\n 2. 这个设计其实不符合面向对象\n 3. 状态转换被隐藏在语句中，所以并不明显\n 4. 没有把会改变的那部分包装起来\n 5. 未来加入的代码可能会导致 bug\n\n\npublic class GumballMachine {\n  final static int SOLD_OUT = 0;      // 糖果售罄\n  final static int NO_QUARTER = 1;    // 没有25分钱\n  final static int HAS_QUARTER = 2;   // 有25分钱\n  final static int SOLD = 3;          // 售出糖果\n  \n  // 实例变量，持有当前的状态。初始化为“糖果售罄”状态。\n  int state = SOLD_OUT;\n  int count = 0;  // 糖果数量\n  \n  public GumballMachine(int count) {\n      this.count = count;\n      if (count > 0) state = NO_QUARTER;\n  }\n\n  // 投入钱\n  public void insertQuarter() {\n      switch (state) {\n          case HAS_QUARTER:       // 如果有25分钱，提示已经投过钱\n              System.out.println("您已经投过钱");\n              break;\n          case NO_QUARTER:\n              state = HAS_QUARTER;\n              System.out.println("您投入了25分钱");\n              break;\n          case SOLD_OUT:\n              System.out.println("您不能投入钱，糖果已经售罄");\n              break;\n          case SOLD:\n              System.out.println("请稍等，我们已经给出了糖果");\n              break;\n      }\n  }\n\n  // 退回钱\n  public void ejectQuarter() {\n      switch (state) {\n          case HAS_QUARTER:\n              state = NO_QUARTER;\n              System.out.println("退回钱");\n              break;\n          case NO_QUARTER:\n              System.out.println("您未投入钱，不能退回");\n              break;\n          case SOLD_OUT:\n              System.out.println("未收到钱，不能退回");  // 糖果售罄，不能投入钱，自然不能退回\n              break;\n          case SOLD:\n              System.out.println("转动曲柄，已经拿到糖果，不能退钱");\n              break;\n      }\n  }\n\n  // 转动曲柄\n  public void turnCrank() {\n      switch (state) {\n          case HAS_QUARTER:\n              System.out.println("转动成功，正在发放糖果");\n              state = SOLD;\n              dispense();\n              break;\n          case NO_QUARTER:\n              System.out.println("需要先投入钱");\n              break;\n          case SOLD_OUT:\n              System.out.println("sorry，糖果已售罄");\n              break;\n          case SOLD:\n              System.out.println("已经拿到糖果，不能拿两次糖果");\n              break;\n      }\n  }\n\n  // 发放糖果\n  public void dispense() {\n      switch (state) {\n          case SOLD:\n              System.out.println("一个糖果从槽里滚出来");\n              count--;\n              if (count == 0) {\n                  state = SOLD_OUT;\n                  System.out.println("糖果售罄");\n              } else {\n                  state = NO_QUARTER;\n              }\n              break;\n          // 以下情况不应该发生\n          case HAS_QUARTER:\n              System.out.println("ERROR【HAS_QUARTER】");\n              break;\n          case NO_QUARTER:\n              System.out.println("ERROR【NO_QUARTER】");\n              break;\n          case SOLD_OUT:\n              System.out.println("ERROR【SOLD_OUT】");\n              break;\n      }\n  }\n\n  @Override\n  public String toString() {\n      return "GumballMachine{" +\n              "state=" + state +\n              ", count=" + count +\n              \'}\';\n  }\n}\n\n\npublic class Main {\n  public static void main(String[] args) {\n      GumballMachine gumballMachine = new GumballMachine(5);\n\n      System.out.println(gumballMachine);\n\n      gumballMachine.insertQuarter();  // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n\n      System.out.println(gumballMachine);\n\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.ejectQuarter();  // 退回硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n\n      System.out.println(gumballMachine);\n\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n      gumballMachine.ejectQuarter();  // 退回硬币\n\n      System.out.println(gumballMachine);\n\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n      gumballMachine.insertQuarter(); // 投入硬币\n      gumballMachine.turnCrank();     // 转动曲柄\n\n      System.out.println(gumballMachine);\n  }\n}\n\n\n# 新的设计\n\n因为以上代码的缺陷，我们需要重新设计代码，使其便于维护与扩展\n\n 1. 首先，我们定义一个State接口。在这个接口内，糖果机的每个动作都有一个对应的方法。\n 2. 然后为机器中的每个状态实现状态类。这些类将负责在对应的状态下进行机器的行为。\n 3. 最后，我们要摆脱旧的条件代码，取而代之的方式是，将动作委托到状态类。\n\n# 类图\n\n\n状态模式类图\n\n\n# 优化后代码\n\npublic class GumballMachine {\n  private State soldOutState;     // 糖果售罄\n  private State noQuarterState;       // 没有25分钱\n  private State hasQuarterState;      // 有25分钱\n  private State soldState;        // 售出糖果\n  private State WinnerState;\n\n  // 实例变量，持有当前的状态。初始化为“糖果售罄”状态。\n  private State state = soldOutState;\n  private int count = 0;  // 糖果数量\n\n  public GumballMachine(int numerGumballs) {\n      soldOutState = new SoldOutState(this);\n      noQuarterState = new NoQuarterState(this);\n      hasQuarterState = new HasQuarterState(this);\n      soldState = new SoldState(this);\n      WinnerState = new WinnerState(this);\n      this.count = numerGumballs;\n      if (numerGumballs > 0) state = noQuarterState;\n  }\n\n  public void insertQuarter() {\n      state.insertQuarter();\n  }\n\n  public void ejectQuarter() {\n      state.ejectQuarter();\n  }\n\n  public void turnCrank() {\n      state.turnCrank();\n      state.dispense();\n  }\n\n  // 发放糖果\n  void releaseBall() {\n      System.out.println("一个糖果从槽里滚出来");\n      if (count != 0) count--;\n  }\n\n  public State getSoldOutState() {\n      return soldOutState;\n  }\n\n  public State getNoQuarterState() {\n      return noQuarterState;\n  }\n\n  public State getHasQuarterState() {\n      return hasQuarterState;\n  }\n\n  public State getSoldState() {\n      return soldState;\n  }\n\n  public State getState() {\n      return state;\n  }\n\n  public State getWinnerState() {\n      return WinnerState;\n  }\n\n  public void setState(State state) {\n      this.state = state;\n  }\n\n  public int getCount() {\n      return count;\n  }\n\n  @Override\n  public String toString() {\n      return "GumballMachine{" +\n              "state=" + state +\n              ", count=" + count +\n              \'}\';\n  }\n}\n\n\npublic interface State {\n  void insertQuarter();\n  void ejectQuarter();\n  void turnCrank();\n  void dispense();\n}\n\n\npublic class NoQuarterState implements State {\n  GumballMachine gumballMachine;\n\n  public NoQuarterState(GumballMachine gumballMachine) {\n      this.gumballMachine = gumballMachine;\n  }\n\n  @Override\n  public void insertQuarter() {\n      System.out.println("您投入了25分钱");\n      gumballMachine.setState(gumballMachine.getHasQuarterState());\n  }\n\n  @Override\n  public void ejectQuarter() {\n      System.out.println("您未投入钱，不能退回");\n  }\n\n  @Override\n  public void turnCrank() {\n      System.out.println("需要先投入钱");\n  }\n\n  @Override\n  public void dispense() {\n      // System.out.println("ERROR【NO_QUARTER】");\n  }\n}\n\n\npublic class HasQuarterState implements State {\n  Random random = new Random(System.currentTimeMillis());\n  GumballMachine gumballMachine;\n\n  public HasQuarterState(GumballMachine gumballMachine) {\n      this.gumballMachine = gumballMachine;\n  }\n\n  @Override\n  public void insertQuarter() {\n      System.out.println("您已经投过钱");   // 如果有25分钱，提示已经投过钱\n  }\n\n  @Override\n  public void ejectQuarter() {\n      gumballMachine.setState(gumballMachine.getNoQuarterState());\n      System.out.println("退回钱");\n  }\n\n  @Override\n  public void turnCrank() {\n      System.out.println("转动成功，正在发放糖果");\n      int winner = random.nextInt(10);\n      if (winner == 0 && gumballMachine.getCount() > 1) {\n          // 如果赢了并且有 2 颗以上糖果的话，就进入 WinnerState 状态\n          gumballMachine.setState(gumballMachine.getWinnerState());\n      } else {\n          gumballMachine.setState(gumballMachine.getSoldState());\n      }\n  }\n\n  @Override\n  public void dispense() {\n      // System.out.println("ERROR【HAS_QUARTER】");\n  }\n}\n\n\npublic class SoldOutState implements State {\n  GumballMachine gumballMachine;\n\n  public SoldOutState(GumballMachine gumballMachine) {\n      this.gumballMachine = gumballMachine;\n  }\n\n  @Override\n  public void insertQuarter() {\n      System.out.println("您不能投入钱，糖果已经售罄");\n  }\n\n  @Override\n  public void ejectQuarter() {\n      System.out.println("未收到钱，不能退回");  // 糖果售罄，不能投入钱，自然不能退回\n  }\n\n  @Override\n  public void turnCrank() {\n      System.out.println("sorry，糖果已售罄");\n  }\n\n  @Override\n  public void dispense() {\n      // System.out.println("ERROR【SOLD_OUT】");\n  }\n}\n\n\npublic class SoldState implements State {\n  GumballMachine gumballMachine;\n\n  public SoldState(GumballMachine gumballMachine) {\n      this.gumballMachine = gumballMachine;\n  }\n\n  @Override\n  public void insertQuarter() {\n      System.out.println("请稍等，我们已经给出了糖果");\n  }\n\n  @Override\n  public void ejectQuarter() {\n      System.out.println("转动曲柄，已经拿到糖果，不能退钱");\n  }\n\n  @Override\n  public void turnCrank() {\n      System.out.println("已经拿到糖果，不能拿两次糖果");\n  }\n\n  @Override\n  public void dispense() {\n      gumballMachine.releaseBall();\n      if (gumballMachine.getCount() > 0) {\n          gumballMachine.setState(gumballMachine.getNoQuarterState());\n      } else {\n          System.out.println("糖果售罄");\n          gumballMachine.setState(gumballMachine.getSoldOutState());\n      }\n  }\n}\n\n\n// 实现十个中一个\npublic class WinnerState implements State {\n  GumballMachine gumballMachine;\n\n  public WinnerState(GumballMachine gumballMachine) {\n      this.gumballMachine = gumballMachine;\n  }\n\n  @Override\n  public void insertQuarter() {\n\n  }\n\n  @Override\n  public void ejectQuarter() {\n\n  }\n\n  @Override\n  public void turnCrank() {\n\n  }\n\n  @Override\n  public void dispense() {\n      System.out.println("你赢了，将获得两个糖果");\n      gumballMachine.releaseBall();\n      if (gumballMachine.getCount() == 0) {\n          gumballMachine.setState(gumballMachine.getSoldOutState());\n      } else {\n          gumballMachine.releaseBall();\n          if (gumballMachine.getCount() > 0) {\n              gumballMachine.setState(gumballMachine.getNoQuarterState());\n          } else {\n              gumballMachine.setState(gumballMachine.getSoldOutState());\n          }\n      }\n  }\n}\n\n\npublic class Main {\n  public static void main(String[] args) {\n      GumballMachine gumballMachine = new GumballMachine(100);\n      for (int i = 0; i < 50; i++) {\n          gumballMachine.insertQuarter();\n          gumballMachine.turnCrank();\n          System.out.println(gumballMachine);\n      }\n  }\n}\n\n\n# 要点\n\n * 状态模式允许一个对象基于内部状态而拥有不同的行为。\n * 和程序状态机（PSM）不同，状态模式用类代表状态。\n * Context 会将行为委托给当前状态对象。\n * 通过将每个状态封装进一个类，我们把以后需要做的任何改变局部化了。\n * 状态模式和策略模式有相同的类图，但是它们的意图不同。\n * 策略模式通常会用行为或算法来配置 Context 类。\n * 状态模式允许 Context 随着状态的改变而改变行为。\n * 状态转换可以由 State 类或 Context 类控制。\n * 使用状态模式通常会导致设计中类的数目大量增加。\n * 状态类可以被多个 Context 实例共享。',normalizedContent:'# 状态模式（state pattern）\n\n# 定义\n\n状态模式 允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。\n\n> 基本常识：策略模式和状态模式是双胞胎，在出生时才分开。策略模式是围绕可以互换的算法来创建业务的。然而，状态模式走的是更崇高的路，它通过改变对象内部的状态来帮助对象控制自己的行为。\n\n# 提出问题\n\n# 万能糖果机\n\n# 代码实现\n\n以下为代码的初步实现存在，但存在诸多问题\n\n 1. 这份代码没有遵循开闭原则\n 2. 这个设计其实不符合面向对象\n 3. 状态转换被隐藏在语句中，所以并不明显\n 4. 没有把会改变的那部分包装起来\n 5. 未来加入的代码可能会导致 bug\n\n\npublic class gumballmachine {\n  final static int sold_out = 0;      // 糖果售罄\n  final static int no_quarter = 1;    // 没有25分钱\n  final static int has_quarter = 2;   // 有25分钱\n  final static int sold = 3;          // 售出糖果\n  \n  // 实例变量，持有当前的状态。初始化为“糖果售罄”状态。\n  int state = sold_out;\n  int count = 0;  // 糖果数量\n  \n  public gumballmachine(int count) {\n      this.count = count;\n      if (count > 0) state = no_quarter;\n  }\n\n  // 投入钱\n  public void insertquarter() {\n      switch (state) {\n          case has_quarter:       // 如果有25分钱，提示已经投过钱\n              system.out.println("您已经投过钱");\n              break;\n          case no_quarter:\n              state = has_quarter;\n              system.out.println("您投入了25分钱");\n              break;\n          case sold_out:\n              system.out.println("您不能投入钱，糖果已经售罄");\n              break;\n          case sold:\n              system.out.println("请稍等，我们已经给出了糖果");\n              break;\n      }\n  }\n\n  // 退回钱\n  public void ejectquarter() {\n      switch (state) {\n          case has_quarter:\n              state = no_quarter;\n              system.out.println("退回钱");\n              break;\n          case no_quarter:\n              system.out.println("您未投入钱，不能退回");\n              break;\n          case sold_out:\n              system.out.println("未收到钱，不能退回");  // 糖果售罄，不能投入钱，自然不能退回\n              break;\n          case sold:\n              system.out.println("转动曲柄，已经拿到糖果，不能退钱");\n              break;\n      }\n  }\n\n  // 转动曲柄\n  public void turncrank() {\n      switch (state) {\n          case has_quarter:\n              system.out.println("转动成功，正在发放糖果");\n              state = sold;\n              dispense();\n              break;\n          case no_quarter:\n              system.out.println("需要先投入钱");\n              break;\n          case sold_out:\n              system.out.println("sorry，糖果已售罄");\n              break;\n          case sold:\n              system.out.println("已经拿到糖果，不能拿两次糖果");\n              break;\n      }\n  }\n\n  // 发放糖果\n  public void dispense() {\n      switch (state) {\n          case sold:\n              system.out.println("一个糖果从槽里滚出来");\n              count--;\n              if (count == 0) {\n                  state = sold_out;\n                  system.out.println("糖果售罄");\n              } else {\n                  state = no_quarter;\n              }\n              break;\n          // 以下情况不应该发生\n          case has_quarter:\n              system.out.println("error【has_quarter】");\n              break;\n          case no_quarter:\n              system.out.println("error【no_quarter】");\n              break;\n          case sold_out:\n              system.out.println("error【sold_out】");\n              break;\n      }\n  }\n\n  @override\n  public string tostring() {\n      return "gumballmachine{" +\n              "state=" + state +\n              ", count=" + count +\n              \'}\';\n  }\n}\n\n\npublic class main {\n  public static void main(string[] args) {\n      gumballmachine gumballmachine = new gumballmachine(5);\n\n      system.out.println(gumballmachine);\n\n      gumballmachine.insertquarter();  // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n\n      system.out.println(gumballmachine);\n\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.ejectquarter();  // 退回硬币\n      gumballmachine.turncrank();     // 转动曲柄\n\n      system.out.println(gumballmachine);\n\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n      gumballmachine.ejectquarter();  // 退回硬币\n\n      system.out.println(gumballmachine);\n\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n      gumballmachine.insertquarter(); // 投入硬币\n      gumballmachine.turncrank();     // 转动曲柄\n\n      system.out.println(gumballmachine);\n  }\n}\n\n\n# 新的设计\n\n因为以上代码的缺陷，我们需要重新设计代码，使其便于维护与扩展\n\n 1. 首先，我们定义一个state接口。在这个接口内，糖果机的每个动作都有一个对应的方法。\n 2. 然后为机器中的每个状态实现状态类。这些类将负责在对应的状态下进行机器的行为。\n 3. 最后，我们要摆脱旧的条件代码，取而代之的方式是，将动作委托到状态类。\n\n# 类图\n\n\n状态模式类图\n\n\n# 优化后代码\n\npublic class gumballmachine {\n  private state soldoutstate;     // 糖果售罄\n  private state noquarterstate;       // 没有25分钱\n  private state hasquarterstate;      // 有25分钱\n  private state soldstate;        // 售出糖果\n  private state winnerstate;\n\n  // 实例变量，持有当前的状态。初始化为“糖果售罄”状态。\n  private state state = soldoutstate;\n  private int count = 0;  // 糖果数量\n\n  public gumballmachine(int numergumballs) {\n      soldoutstate = new soldoutstate(this);\n      noquarterstate = new noquarterstate(this);\n      hasquarterstate = new hasquarterstate(this);\n      soldstate = new soldstate(this);\n      winnerstate = new winnerstate(this);\n      this.count = numergumballs;\n      if (numergumballs > 0) state = noquarterstate;\n  }\n\n  public void insertquarter() {\n      state.insertquarter();\n  }\n\n  public void ejectquarter() {\n      state.ejectquarter();\n  }\n\n  public void turncrank() {\n      state.turncrank();\n      state.dispense();\n  }\n\n  // 发放糖果\n  void releaseball() {\n      system.out.println("一个糖果从槽里滚出来");\n      if (count != 0) count--;\n  }\n\n  public state getsoldoutstate() {\n      return soldoutstate;\n  }\n\n  public state getnoquarterstate() {\n      return noquarterstate;\n  }\n\n  public state gethasquarterstate() {\n      return hasquarterstate;\n  }\n\n  public state getsoldstate() {\n      return soldstate;\n  }\n\n  public state getstate() {\n      return state;\n  }\n\n  public state getwinnerstate() {\n      return winnerstate;\n  }\n\n  public void setstate(state state) {\n      this.state = state;\n  }\n\n  public int getcount() {\n      return count;\n  }\n\n  @override\n  public string tostring() {\n      return "gumballmachine{" +\n              "state=" + state +\n              ", count=" + count +\n              \'}\';\n  }\n}\n\n\npublic interface state {\n  void insertquarter();\n  void ejectquarter();\n  void turncrank();\n  void dispense();\n}\n\n\npublic class noquarterstate implements state {\n  gumballmachine gumballmachine;\n\n  public noquarterstate(gumballmachine gumballmachine) {\n      this.gumballmachine = gumballmachine;\n  }\n\n  @override\n  public void insertquarter() {\n      system.out.println("您投入了25分钱");\n      gumballmachine.setstate(gumballmachine.gethasquarterstate());\n  }\n\n  @override\n  public void ejectquarter() {\n      system.out.println("您未投入钱，不能退回");\n  }\n\n  @override\n  public void turncrank() {\n      system.out.println("需要先投入钱");\n  }\n\n  @override\n  public void dispense() {\n      // system.out.println("error【no_quarter】");\n  }\n}\n\n\npublic class hasquarterstate implements state {\n  random random = new random(system.currenttimemillis());\n  gumballmachine gumballmachine;\n\n  public hasquarterstate(gumballmachine gumballmachine) {\n      this.gumballmachine = gumballmachine;\n  }\n\n  @override\n  public void insertquarter() {\n      system.out.println("您已经投过钱");   // 如果有25分钱，提示已经投过钱\n  }\n\n  @override\n  public void ejectquarter() {\n      gumballmachine.setstate(gumballmachine.getnoquarterstate());\n      system.out.println("退回钱");\n  }\n\n  @override\n  public void turncrank() {\n      system.out.println("转动成功，正在发放糖果");\n      int winner = random.nextint(10);\n      if (winner == 0 && gumballmachine.getcount() > 1) {\n          // 如果赢了并且有 2 颗以上糖果的话，就进入 winnerstate 状态\n          gumballmachine.setstate(gumballmachine.getwinnerstate());\n      } else {\n          gumballmachine.setstate(gumballmachine.getsoldstate());\n      }\n  }\n\n  @override\n  public void dispense() {\n      // system.out.println("error【has_quarter】");\n  }\n}\n\n\npublic class soldoutstate implements state {\n  gumballmachine gumballmachine;\n\n  public soldoutstate(gumballmachine gumballmachine) {\n      this.gumballmachine = gumballmachine;\n  }\n\n  @override\n  public void insertquarter() {\n      system.out.println("您不能投入钱，糖果已经售罄");\n  }\n\n  @override\n  public void ejectquarter() {\n      system.out.println("未收到钱，不能退回");  // 糖果售罄，不能投入钱，自然不能退回\n  }\n\n  @override\n  public void turncrank() {\n      system.out.println("sorry，糖果已售罄");\n  }\n\n  @override\n  public void dispense() {\n      // system.out.println("error【sold_out】");\n  }\n}\n\n\npublic class soldstate implements state {\n  gumballmachine gumballmachine;\n\n  public soldstate(gumballmachine gumballmachine) {\n      this.gumballmachine = gumballmachine;\n  }\n\n  @override\n  public void insertquarter() {\n      system.out.println("请稍等，我们已经给出了糖果");\n  }\n\n  @override\n  public void ejectquarter() {\n      system.out.println("转动曲柄，已经拿到糖果，不能退钱");\n  }\n\n  @override\n  public void turncrank() {\n      system.out.println("已经拿到糖果，不能拿两次糖果");\n  }\n\n  @override\n  public void dispense() {\n      gumballmachine.releaseball();\n      if (gumballmachine.getcount() > 0) {\n          gumballmachine.setstate(gumballmachine.getnoquarterstate());\n      } else {\n          system.out.println("糖果售罄");\n          gumballmachine.setstate(gumballmachine.getsoldoutstate());\n      }\n  }\n}\n\n\n// 实现十个中一个\npublic class winnerstate implements state {\n  gumballmachine gumballmachine;\n\n  public winnerstate(gumballmachine gumballmachine) {\n      this.gumballmachine = gumballmachine;\n  }\n\n  @override\n  public void insertquarter() {\n\n  }\n\n  @override\n  public void ejectquarter() {\n\n  }\n\n  @override\n  public void turncrank() {\n\n  }\n\n  @override\n  public void dispense() {\n      system.out.println("你赢了，将获得两个糖果");\n      gumballmachine.releaseball();\n      if (gumballmachine.getcount() == 0) {\n          gumballmachine.setstate(gumballmachine.getsoldoutstate());\n      } else {\n          gumballmachine.releaseball();\n          if (gumballmachine.getcount() > 0) {\n              gumballmachine.setstate(gumballmachine.getnoquarterstate());\n          } else {\n              gumballmachine.setstate(gumballmachine.getsoldoutstate());\n          }\n      }\n  }\n}\n\n\npublic class main {\n  public static void main(string[] args) {\n      gumballmachine gumballmachine = new gumballmachine(100);\n      for (int i = 0; i < 50; i++) {\n          gumballmachine.insertquarter();\n          gumballmachine.turncrank();\n          system.out.println(gumballmachine);\n      }\n  }\n}\n\n\n# 要点\n\n * 状态模式允许一个对象基于内部状态而拥有不同的行为。\n * 和程序状态机（psm）不同，状态模式用类代表状态。\n * context 会将行为委托给当前状态对象。\n * 通过将每个状态封装进一个类，我们把以后需要做的任何改变局部化了。\n * 状态模式和策略模式有相同的类图，但是它们的意图不同。\n * 策略模式通常会用行为或算法来配置 context 类。\n * 状态模式允许 context 随着状态的改变而改变行为。\n * 状态转换可以由 state 类或 context 类控制。\n * 使用状态模式通常会导致设计中类的数目大量增加。\n * 状态类可以被多个 context 实例共享。',charsets:{cjk:!0},lastUpdated:"2022/08/14, 14:15:48",lastUpdatedTimestamp:1660457748e3},{title:"代理模式",frontmatter:{title:"代理模式",date:"2022-08-16T22:19:06.000Z",permalink:"/pages/cb203f/"},regularPath:"/01.Java%E7%9B%B8%E5%85%B3/04.%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/120.%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F.html",relativePath:"01.Java相关/04.设计模式/120.代理模式.md",key:"v-bed51406",path:"/pages/cb203f/",headers:[{level:2,title:"代理模式（Proxy Pattern）",slug:"代理模式-proxy-pattern",normalizedTitle:"代理模式（proxy pattern）",charIndex:2},{level:4,title:"定义",slug:"定义",normalizedTitle:"定义",charIndex:25},{level:4,title:"提出问题",slug:"提出问题",normalizedTitle:"提出问题",charIndex:66},{level:4,title:"测试 RMI",slug:"测试-rmi",normalizedTitle:"测试 rmi",charIndex:129},{level:4,title:"GumballMachine 远程代理",slug:"gumballmachine-远程代理",normalizedTitle:"gumballmachine 远程代理",charIndex:1662}],headersStr:"代理模式（Proxy Pattern） 定义 提出问题 测试 RMI GumballMachine 远程代理",content:'# 代理模式（Proxy Pattern）\n\n# 定义\n\n代理模式 为另一个对象提供一个替身或占位符以控制对这个对象的访问。\n\n# 提出问题\n\n书接上回，我们实现的糖果机已经可以正常工作了。现在我们想使糖果机获得更好的监控，创建一份能打印出来的报告。\n\n# 测试 RMI\n\n----------------------------------------\n\n\n\n\n/** 步骤一、制作远程接口\n * 1. 继承 Remote\n * 2. 所有方法都会抛出 RemoteException 异常\n * 3. 变量和返回值是元语（primitive）或者序列化（Serializable）的，因为需要进行网络 IO\n */\npublic interface MyRemote extends Remote {\n    public String sayHello() throws RemoteException;\n}\n\n\n/**\n * 步骤二、制作远程实现\n * 1. 实现远程接口 xxxRemote\n * 2. 继承 UnicastRemoteObject（使对象继承超类的远程功能）\n * 3. 创建无参构造器，并抛出异常\n * 4. 用 RMI Registry 注册此服务\n *\n *\n * 步骤三、产生 Stub 和 Skeleton（`rmic 包名.MyRemoteImpl`）\n * 步骤四、执行 remiregistry（保证启动目录可以访问类，最简单做法 classes 下启动）（`rmiregistry`）\n * 步骤五、启动服务（`java 包名.MyRemoteImpl`）\n */\npublic class MyRemoteImpl extends UnicastRemoteObject implements MyRemote {\n    protected MyRemoteImpl() throws RemoteException {}\n\n    @Override\n    public String sayHello() throws RemoteException {\n        return "Hello World!!!!!!!!!!!!!!";\n    }\n\n    public static void main(String[] args) {\n        try {\n            MyRemoteImpl service = new MyRemoteImpl();\n            // 先保证 RMI Registry 正在运行，然后注册服务（stub）\n            Naming.bind("RemoteHello", service);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n\n\npublic class MyRemoteClient {\n    public void go() {\n        try {\n            MyRemote serivce = (MyRemote) Naming.lookup("rmi://127.0.0.1/RemoteHello");\n            String s = serivce.sayHello();\n            System.out.println(s);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) {\n        new MyRemoteClient().go();\n    }\n}\n\n\n# GumballMachine 远程代理',normalizedContent:'# 代理模式（proxy pattern）\n\n# 定义\n\n代理模式 为另一个对象提供一个替身或占位符以控制对这个对象的访问。\n\n# 提出问题\n\n书接上回，我们实现的糖果机已经可以正常工作了。现在我们想使糖果机获得更好的监控，创建一份能打印出来的报告。\n\n# 测试 rmi\n\n----------------------------------------\n\n\n\n\n/** 步骤一、制作远程接口\n * 1. 继承 remote\n * 2. 所有方法都会抛出 remoteexception 异常\n * 3. 变量和返回值是元语（primitive）或者序列化（serializable）的，因为需要进行网络 io\n */\npublic interface myremote extends remote {\n    public string sayhello() throws remoteexception;\n}\n\n\n/**\n * 步骤二、制作远程实现\n * 1. 实现远程接口 xxxremote\n * 2. 继承 unicastremoteobject（使对象继承超类的远程功能）\n * 3. 创建无参构造器，并抛出异常\n * 4. 用 rmi registry 注册此服务\n *\n *\n * 步骤三、产生 stub 和 skeleton（`rmic 包名.myremoteimpl`）\n * 步骤四、执行 remiregistry（保证启动目录可以访问类，最简单做法 classes 下启动）（`rmiregistry`）\n * 步骤五、启动服务（`java 包名.myremoteimpl`）\n */\npublic class myremoteimpl extends unicastremoteobject implements myremote {\n    protected myremoteimpl() throws remoteexception {}\n\n    @override\n    public string sayhello() throws remoteexception {\n        return "hello world!!!!!!!!!!!!!!";\n    }\n\n    public static void main(string[] args) {\n        try {\n            myremoteimpl service = new myremoteimpl();\n            // 先保证 rmi registry 正在运行，然后注册服务（stub）\n            naming.bind("remotehello", service);\n        } catch (exception e) {\n            e.printstacktrace();\n        }\n    }\n}\n\n\npublic class myremoteclient {\n    public void go() {\n        try {\n            myremote serivce = (myremote) naming.lookup("rmi://127.0.0.1/remotehello");\n            string s = serivce.sayhello();\n            system.out.println(s);\n        } catch (exception e) {\n            e.printstacktrace();\n        }\n    }\n\n    public static void main(string[] args) {\n        new myremoteclient().go();\n    }\n}\n\n\n# gumballmachine 远程代理',charsets:{cjk:!0},lastUpdated:"2022/09/27, 16:57:46",lastUpdatedTimestamp:1664269066e3},{title:"Hadoop分布式搭建",frontmatter:{title:"Hadoop分布式搭建",date:"2022-02-23T12:55:03.000Z",permalink:"/pages/5d76a5/",categories:["大数据","Hadoop"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/01.Hadoop/01.Hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/01.Hadoop/01.Hadoop分布式搭建.md",key:"v-42c6f9fa",path:"/pages/5d76a5/",headers:[{level:2,title:"一、虚拟机环境准备",slug:"一、虚拟机环境准备",normalizedTitle:"一、虚拟机环境准备",charIndex:2},{level:3,title:"1.克隆虚拟机",slug:"_1-克隆虚拟机",normalizedTitle:"1.克隆虚拟机",charIndex:16},{level:3,title:"2.修改克隆虚拟机的静态IP",slug:"_2-修改克隆虚拟机的静态ip",normalizedTitle:"2.修改克隆虚拟机的静态ip",charIndex:28},{level:3,title:"3.修改主机名",slug:"_3-修改主机名",normalizedTitle:"3.修改主机名",charIndex:95},{level:3,title:"4.关闭防火墙(centos 7)",slug:"_4-关闭防火墙-centos-7",normalizedTitle:"4.关闭防火墙(centos 7)",charIndex:369},{level:3,title:"5.创建banana用户",slug:"_5-创建banana用户",normalizedTitle:"5.创建banana用户",charIndex:535},{level:3,title:"6.sudo配置banana用户具有root权限",slug:"_6-sudo配置banana用户具有root权限",normalizedTitle:"6.sudo配置banana用户具有root权限",charIndex:719},{level:2,title:"二、编写集群分发脚本xsync",slug:"二、编写集群分发脚本xsync",normalizedTitle:"二、编写集群分发脚本xsync",charIndex:1102},{level:3,title:"1.scp（secure copy）安全拷贝    [推、拉、第三方]",slug:"_1-scp-secure-copy-安全拷贝-推、拉、第三方",normalizedTitle:"1.scp（secure copy）安全拷贝    [推、拉、第三方]",charIndex:null},{level:3,title:"2.rsync 远程同步工具",slug:"_2-rsync-远程同步工具",normalizedTitle:"2.rsync 远程同步工具",charIndex:1478},{level:3,title:"3.xsync集群分发脚本",slug:"_3-xsync集群分发脚本",normalizedTitle:"3.xsync集群分发脚本",charIndex:1608},{level:2,title:"三、完全分布式运行模式",slug:"三、完全分布式运行模式",normalizedTitle:"三、完全分布式运行模式",charIndex:2262},{level:3,title:"1）准备3台客户机（关闭防火墙、静态ip、主机名称）",slug:"_1-准备3台客户机-关闭防火墙、静态ip、主机名称",normalizedTitle:"1）准备3台客户机（关闭防火墙、静态ip、主机名称）",charIndex:2278},{level:3,title:"2）安装JDK并配置环境变量",slug:"_2-安装jdk并配置环境变量",normalizedTitle:"2）安装jdk并配置环境变量",charIndex:2309},{level:3,title:"3）安装Hadoop并配置环境变量",slug:"_3-安装hadoop并配置环境变量",normalizedTitle:"3）安装hadoop并配置环境变量",charIndex:2626},{level:3,title:"4）配置集群",slug:"_4-配置集群",normalizedTitle:"4）配置集群",charIndex:2888},{level:3,title:"5）单点启动",slug:"_5-单点启动",normalizedTitle:"5）单点启动",charIndex:4567},{level:3,title:"6）配置ssh、群起集群",slug:"_6-配置ssh、群起集群",normalizedTitle:"6）配置ssh、群起集群",charIndex:4776},{level:3,title:"7）测试集群",slug:"_7-测试集群",normalizedTitle:"7）测试集群",charIndex:5898},{level:2,title:"四. 集群时间同步",slug:"四-集群时间同步",normalizedTitle:"四. 集群时间同步",charIndex:5980},{level:3,title:"1. 时间服务器配置",slug:"_1-时间服务器配置-必须root用户",normalizedTitle:"1. 时间服务器配置",charIndex:6035},{level:3,title:"2. 其他节点配置",slug:"_2-其他节点配置-必须root用户",normalizedTitle:"2. 其他节点配置",charIndex:7038}],headersStr:"一、虚拟机环境准备 1.克隆虚拟机 2.修改克隆虚拟机的静态IP 3.修改主机名 4.关闭防火墙(centos 7) 5.创建banana用户 6.sudo配置banana用户具有root权限 二、编写集群分发脚本xsync 1.scp（secure copy）安全拷贝    [推、拉、第三方] 2.rsync 远程同步工具 3.xsync集群分发脚本 三、完全分布式运行模式 1）准备3台客户机（关闭防火墙、静态ip、主机名称） 2）安装JDK并配置环境变量 3）安装Hadoop并配置环境变量 4）配置集群 5）单点启动 6）配置ssh、群起集群 7）测试集群 四. 集群时间同步 1. 时间服务器配置 2. 其他节点配置",content:'# 一、虚拟机环境准备\n\n\n# 1.克隆虚拟机\n\n\n# 2.修改克隆虚拟机的静态IP\n\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n\n\n# 3.修改主机名\n\n查看主机名hostname 修改主机名vi /etc/sysconfig/network (hostnamectl set-hostname hadoop102)\n\nNETWORKING=yes\nNETWORKING_IPV6=no\nHOSTNAME= hadoop101\n\n\n修改linux的主机映射文件（hosts文件）vim /etc/hosts 添加\n\n8.8.8.101 hadoop101\n8.8.8.102 hadoop102\n8.8.8.103 hadoop103\n\n\n修改完成后 重启设备 reboot\n\n\n# 4.关闭防火墙(centos 7)\n\n查看防火墙状态 firewall-cmd --state systemctl status firewalld\n停止firewall systemctl stop firewalld.service\n禁止firewall开机启动 systemctl disable firewalld\n\n\n# 5.创建banana用户\n\n添加一个用户 useradd banana\n设置用户密码 passwd banana\n查看用户是否存在 id banana\n查看创建了哪些用户 cat /etc/passwd\n删除用户 删除用户但保存用户主目录 userdel banana 删除用户和用户主目录 userdel -r banana\n显示自身用户名称 whoami\n\n\n# 6.sudo配置banana用户具有root权限\n\n修改配置文件 vi /etc/sudoers\n\n找到下面一行(91行)，在root下面添加一行\n\n##  Allow root to run any commands anywhere\nroot    ALL=(ALL)     ALL\nbanana   ALL=(ALL)     ALL\n\n\n或者配置成采用sudo命令时，不需要输入密码\n\n##  Allow root to run any commands anywhere\nroot      ALL=(ALL)     ALL\nbanana   ALL=(ALL)     NOPASSWD:ALL\n\n\n修改完毕，现在可以用banana帐号登录，然后用命令 sudo ，即可获得root权限进行操作(sudo useradd zhangsan)\n\n\n# 二、编写集群分发脚本xsync\n\n\n# 1.scp（secure copy）安全拷贝 [推、拉、第三方]\n\n定义：scp可以实现服务器与服务器之间的数据拷贝\n\n语法：scp -r $pdir/$fname $user@hadoop$host:$pdir/$fname\n\n即 scp -r banana@hadoop101:/soft/module root@hadoop103:/soft/module (在102上把101的文件拷贝到103上)\n\n\n\n\n\n注意：拷贝过来的配置文件别忘了source一下/etc/profile\n注意：拷贝过来的/soft/module目录，别忘了在hadoop102、hadoop103上修改所有文件的，所有者和所有者组。`sudo chown banana:banana -R /soft/module`\n\n\n# 2.rsync 远程同步工具\n\n用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去 语法:rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname\n\n\n# 3.xsync集群分发脚本\n\n定义：循环复制文件到所有节点的相同目录下 脚本实现\n\n1.在/home/banana目录下创建bin目录，并在bin目录下xsync创建文件\n\n2.文件内容\n\n# !/bin/bash\n# 1 获取输入参数个数，如果没有参数，直接退出\npcount=$\nif((pcount==0)); then\necho no args;\nexit;\nfi\n\n# 2 获取文件名称\np1=$1\nfname=`basename $p1`\necho fname=$fname\n\n# 3 获取上级目录到绝对路径\npdir=`cd -P $(dirname $p1); pwd`\necho pdir=$pdir\n\n# 4 获取当前用户名称\nuser=`whoami`\n\n# 5 循环\nfor((host=103; host<105; host++)); do\n        echo ------------------- hadoop$host --------------\n        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir\ndone\n\n\n3.修改脚本 xsync 具有执行权限 chmod 777 xsync\n\n4.调用脚本形式 xsync /home/banana/bin\n\n注意：如果将xsync放到/home/banana/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。\n\n\n# 三、完全分布式运行模式\n\n\n# 1）准备3台客户机（关闭防火墙、静态ip、主机名称）\n\n\n# 2）安装JDK并配置环境变量\n\n解压 tar -zxvf jdk-8u161-linux-x64.tar.gz -C /soft/module (/soft/module是自己新建的目录)\n\n配置环境变量 vim /etc/profile\n\n文件尾部加入：\nexport JAVA_HOME=/soft/module/jdk1.8.0_161/    #安装jdk的路径\nexport PATH=$PATH:$JAVA_HOME/bin\nexport CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar\n\n\n使配置生效 source /etc/profile\n\n\n# 3）安装Hadoop并配置环境变量\n\n解压 tar -zxvf hadoop-2.9.2.tar.gz -C /soft/module\n\n配置环境变量 vim /etc/profile\n\n文件尾部加入：\nexport HADOOP_HOME=/soft/module/hadoop-2.9.2                #自己安装的Hadoop路径\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n\n\n使配置生效 source /etc/profile\n\n\n# 4）配置集群\n\n       HADOOP101     HADOOP102         HADOOP103\nHDFS   NameNode      DataNode          SecondaryNameNode\n       DataNode                        DataNode\nYARN   NodeManager   ResourceManager   NodeManager\n                     NodeManager\n\n * 核心配置文件 vi core-site.xml\n\n\x3c!-- 指定HDFS中NameNode的地址 --\x3e\n<property>\n\t\t<name>fs.defaultFS</name>\n      <value>hdfs://hadoop101:9000</value>\n</property>\n\n\x3c!-- 指定Hadoop运行时产生文件的存储目录 --\x3e\n<property>\n\t\t<name>hadoop.tmp.dir</name>\n\t\t<value>/soft/module/hadoop-2.9.2/data/tmp</value>\n</property>\n\n\n * HDFS配置文件\n\n配置hadoop-env.sh vi hadoop-env.sh\n\nexport JAVA_HOME=/soft/module/jdk1.8.0_161\n\n\n配置hdfs-site.xml vi hdfs-site.xml\n\n<property>\n\t\t<name>dfs.replication</name>\n\t\t<value>3</value>\n</property>\n\n\x3c!-- 指定Hadoop辅助名称节点主机配置 --\x3e\n<property>\n      <name>dfs.namenode.secondary.http-address</name>\n      <value>hadoop103:50090</value>\n</property>\n\n\n * YARN配置文件\n\nvi yarn-env.sh\n\nexport JAVA_HOME=/soft/module/jdk1.8.0_161\n\n\nvi yarn-site.xml\n\n\x3c!-- Reducer获取数据的方式 --\x3e\n<property>\n\t\t<name>yarn.nodemanager.aux-services</name>\n\t\t<value>mapreduce_shuffle</value>\n</property>\n\n\x3c!-- 指定YARN的ResourceManager的地址 --\x3e\n<property>\n\t\t<name>yarn.resourcemanager.hostname</name>\n\t\t<value>hadoop102</value>\n</property>\n\n\n * MapReduce配置文件\n\n**配置mapred-env.sh vi mapred-env.sh **\n\nexport JAVA_HOME=/soft/module/jdk1.8.0_161\n\n\n配置mapred-site.xml cp mapred-site.xml.template mapred-site.xml vi mapred-site.xml\n\n在该文件中增加如下配置\n\n\x3c!-- 指定MR运行在Yarn上 --\x3e\n<property>\n\t\t<name>mapreduce.framework.name</name>\n\t\t<value>yarn</value>\n</property>\n\n\n * 分发配置好的hadoop配置文件 xsync /soft/module/hadoop-2.9.2/etc/hadoop\n * 在另外的节点上查看文件分发情况 cat /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml\n\n\n# 5）单点启动\n\n * 如果集群是第一次启动，需要格式化NameNode hadoop namenode -format\n * 在hadoop101上启动NameNode hadoop-daemon.sh start namenode\n * 在hadoop101、hadoop102以及hadoop103上分别启动DataNode hadoop-daemon.sh start datanode jps查看进程\n\n\n# 6）配置ssh、群起集群\n\n * 各节点间无密登录()\n\n生成公钥和私钥 (banana用户) (然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）)\nssh-keygen -t rsa\n\n将公钥拷贝到要免密登录的目标机器上\nssh-copy-id hadoop101\nssh-copy-id hadoop102\nssh-copy-id hadoop103\n\n\nssh-copy-id的使用方法: https://blog.csdn.net/qianggezhishen/article/details/71249699\n\n还需要在hadoop101上采用root账号，配置一下无密登录到hadoop101、hadoop102、hadoop103； 还需要在hadoop102上采用banana账号配置一下无密登录到hadoop101、hadoop102、hadoop103服务器上\n\n原因: NameNode和ResourceManager要远程启动其他节点, 或者参考链接: https://www.cnblogs.com/limaosheng/p/10444515.html#_label0\n\n\n\n\n * 配置从机DataNode 和 NodeManager(配置slaves) vim /soft/module/hadoop-2.9.2/etc/hadoop/slaves\n\n加上\nhadoop101\nhadoop102\nhadoop103\n\n分发文件\nxsync.sh /soft/module/hadoop-2.9.2/etc/hadoop/slaves\n\n\n * 启动集群\n   * 如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） hdfs namenode -format hdfs格式化注意事项:https://blog.csdn.net/gis_101/article/details/52821946?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task\n   * 启动HDFS 在namenode(hadoop101)节点上执行 sbin/start-dfs.sh\n   * 启动YARN 在ResouceManager(hadoop102)节点上执行 sbin/start-yarn.sh\n * 在网页上查看集群信息\n\n\n# 7）测试集群\n\n * 上传文件到集群\n * 查看文件存放在什么位置 (HDFS文件存储路径)(HDFS在磁盘存储文件内容)\n * 拼接文件\n * 下载文件\n\n\n# 四. 集群时间同步\n\nhadoop101作为时间服务器,其它节点定时获取hadoop101的时间\n\n\n\n\n# 1. 时间服务器配置 (必须root用户)\n\n * 检查ntp是否安装 rpm -qa|grep ntp 没有ntp-4.2.6p5-28.el7.centos.x86_64的话 安装ntp yum install -y ntp\n\n * 修改ntp配置文件 vim /etc/ntp.conf\n   \n   修改内容:\n\n一、修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）**\n# restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为\nrestrict 8.8.8.0 mask 255.255.255.0 nomodify notrap\n\n二、修改2（集群在局域网中，不使用其他互联网上的时间）**\nserver 0.centos.pool.ntp.org iburst\nserver 1.centos.pool.ntp.org iburst\nserver 2.centos.pool.ntp.org iburst\nserver 3.centos.pool.ntp.org iburst为\n# server 0.centos.pool.ntp.org iburst\n# server 1.centos.pool.ntp.org iburst\n# server 2.centos.pool.ntp.org iburst\n# server 3.centos.pool.ntp.org iburst\n\n三、添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）**\nserver 127.127.1.0\nfudge 127.127.1.0 stratum 10\n\n\n * 修改/etc/sysconfig/ntpd 文件 vim /etc/sysconfig/ntpd\n\n增加内容如下（让硬件时间与系统时间一起同步）\nSYNC_HWCLOCK=yes\n\n\n * 重新启动ntpd服务 service ntpd status 启动:service ntpd start systemctl start ntpd\n * 设置ntpd服务开机启动 chkconfig ntpd on systemctl enable ntpd (开放端口)\n\n\n# 2. 其他节点配置 (必须root用户)\n\n * 其他机器配置10分钟与时间服务器同步一次 crontab -e 编写定时任务\n\n*/10 * * * * /usr/sbin/ntpdate hadoop101\n\n\n * 修改任意机器时间 date -s "2017-9-11 11:11:11"\n * 十分钟后查看机器是否与时间服务器同步 date(测试时时间可设置短些)',normalizedContent:'# 一、虚拟机环境准备\n\n\n# 1.克隆虚拟机\n\n\n# 2.修改克隆虚拟机的静态ip\n\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n\n\n# 3.修改主机名\n\n查看主机名hostname 修改主机名vi /etc/sysconfig/network (hostnamectl set-hostname hadoop102)\n\nnetworking=yes\nnetworking_ipv6=no\nhostname= hadoop101\n\n\n修改linux的主机映射文件（hosts文件）vim /etc/hosts 添加\n\n8.8.8.101 hadoop101\n8.8.8.102 hadoop102\n8.8.8.103 hadoop103\n\n\n修改完成后 重启设备 reboot\n\n\n# 4.关闭防火墙(centos 7)\n\n查看防火墙状态 firewall-cmd --state systemctl status firewalld\n停止firewall systemctl stop firewalld.service\n禁止firewall开机启动 systemctl disable firewalld\n\n\n# 5.创建banana用户\n\n添加一个用户 useradd banana\n设置用户密码 passwd banana\n查看用户是否存在 id banana\n查看创建了哪些用户 cat /etc/passwd\n删除用户 删除用户但保存用户主目录 userdel banana 删除用户和用户主目录 userdel -r banana\n显示自身用户名称 whoami\n\n\n# 6.sudo配置banana用户具有root权限\n\n修改配置文件 vi /etc/sudoers\n\n找到下面一行(91行)，在root下面添加一行\n\n##  allow root to run any commands anywhere\nroot    all=(all)     all\nbanana   all=(all)     all\n\n\n或者配置成采用sudo命令时，不需要输入密码\n\n##  allow root to run any commands anywhere\nroot      all=(all)     all\nbanana   all=(all)     nopasswd:all\n\n\n修改完毕，现在可以用banana帐号登录，然后用命令 sudo ，即可获得root权限进行操作(sudo useradd zhangsan)\n\n\n# 二、编写集群分发脚本xsync\n\n\n# 1.scp（secure copy）安全拷贝 [推、拉、第三方]\n\n定义：scp可以实现服务器与服务器之间的数据拷贝\n\n语法：scp -r $pdir/$fname $user@hadoop$host:$pdir/$fname\n\n即 scp -r banana@hadoop101:/soft/module root@hadoop103:/soft/module (在102上把101的文件拷贝到103上)\n\n\n\n\n\n注意：拷贝过来的配置文件别忘了source一下/etc/profile\n注意：拷贝过来的/soft/module目录，别忘了在hadoop102、hadoop103上修改所有文件的，所有者和所有者组。`sudo chown banana:banana -r /soft/module`\n\n\n# 2.rsync 远程同步工具\n\n用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去 语法:rsync -rvl $pdir/$fname $user@hadoop$host:$pdir/$fname\n\n\n# 3.xsync集群分发脚本\n\n定义：循环复制文件到所有节点的相同目录下 脚本实现\n\n1.在/home/banana目录下创建bin目录，并在bin目录下xsync创建文件\n\n2.文件内容\n\n# !/bin/bash\n# 1 获取输入参数个数，如果没有参数，直接退出\npcount=$\nif((pcount==0)); then\necho no args;\nexit;\nfi\n\n# 2 获取文件名称\np1=$1\nfname=`basename $p1`\necho fname=$fname\n\n# 3 获取上级目录到绝对路径\npdir=`cd -p $(dirname $p1); pwd`\necho pdir=$pdir\n\n# 4 获取当前用户名称\nuser=`whoami`\n\n# 5 循环\nfor((host=103; host<105; host++)); do\n        echo ------------------- hadoop$host --------------\n        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir\ndone\n\n\n3.修改脚本 xsync 具有执行权限 chmod 777 xsync\n\n4.调用脚本形式 xsync /home/banana/bin\n\n注意：如果将xsync放到/home/banana/bin目录下仍然不能实现全局使用，可以将xsync移动到/usr/local/bin目录下。\n\n\n# 三、完全分布式运行模式\n\n\n# 1）准备3台客户机（关闭防火墙、静态ip、主机名称）\n\n\n# 2）安装jdk并配置环境变量\n\n解压 tar -zxvf jdk-8u161-linux-x64.tar.gz -c /soft/module (/soft/module是自己新建的目录)\n\n配置环境变量 vim /etc/profile\n\n文件尾部加入：\nexport java_home=/soft/module/jdk1.8.0_161/    #安装jdk的路径\nexport path=$path:$java_home/bin\nexport classpath=.:$java_home/lib/tools.jar:$java_home/lib/dt.jar\n\n\n使配置生效 source /etc/profile\n\n\n# 3）安装hadoop并配置环境变量\n\n解压 tar -zxvf hadoop-2.9.2.tar.gz -c /soft/module\n\n配置环境变量 vim /etc/profile\n\n文件尾部加入：\nexport hadoop_home=/soft/module/hadoop-2.9.2                #自己安装的hadoop路径\nexport path=$path:$hadoop_home/bin:$hadoop_home/sbin\n\n\n使配置生效 source /etc/profile\n\n\n# 4）配置集群\n\n       hadoop101     hadoop102         hadoop103\nhdfs   namenode      datanode          secondarynamenode\n       datanode                        datanode\nyarn   nodemanager   resourcemanager   nodemanager\n                     nodemanager\n\n * 核心配置文件 vi core-site.xml\n\n\x3c!-- 指定hdfs中namenode的地址 --\x3e\n<property>\n\t\t<name>fs.defaultfs</name>\n      <value>hdfs://hadoop101:9000</value>\n</property>\n\n\x3c!-- 指定hadoop运行时产生文件的存储目录 --\x3e\n<property>\n\t\t<name>hadoop.tmp.dir</name>\n\t\t<value>/soft/module/hadoop-2.9.2/data/tmp</value>\n</property>\n\n\n * hdfs配置文件\n\n配置hadoop-env.sh vi hadoop-env.sh\n\nexport java_home=/soft/module/jdk1.8.0_161\n\n\n配置hdfs-site.xml vi hdfs-site.xml\n\n<property>\n\t\t<name>dfs.replication</name>\n\t\t<value>3</value>\n</property>\n\n\x3c!-- 指定hadoop辅助名称节点主机配置 --\x3e\n<property>\n      <name>dfs.namenode.secondary.http-address</name>\n      <value>hadoop103:50090</value>\n</property>\n\n\n * yarn配置文件\n\nvi yarn-env.sh\n\nexport java_home=/soft/module/jdk1.8.0_161\n\n\nvi yarn-site.xml\n\n\x3c!-- reducer获取数据的方式 --\x3e\n<property>\n\t\t<name>yarn.nodemanager.aux-services</name>\n\t\t<value>mapreduce_shuffle</value>\n</property>\n\n\x3c!-- 指定yarn的resourcemanager的地址 --\x3e\n<property>\n\t\t<name>yarn.resourcemanager.hostname</name>\n\t\t<value>hadoop102</value>\n</property>\n\n\n * mapreduce配置文件\n\n**配置mapred-env.sh vi mapred-env.sh **\n\nexport java_home=/soft/module/jdk1.8.0_161\n\n\n配置mapred-site.xml cp mapred-site.xml.template mapred-site.xml vi mapred-site.xml\n\n在该文件中增加如下配置\n\n\x3c!-- 指定mr运行在yarn上 --\x3e\n<property>\n\t\t<name>mapreduce.framework.name</name>\n\t\t<value>yarn</value>\n</property>\n\n\n * 分发配置好的hadoop配置文件 xsync /soft/module/hadoop-2.9.2/etc/hadoop\n * 在另外的节点上查看文件分发情况 cat /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml\n\n\n# 5）单点启动\n\n * 如果集群是第一次启动，需要格式化namenode hadoop namenode -format\n * 在hadoop101上启动namenode hadoop-daemon.sh start namenode\n * 在hadoop101、hadoop102以及hadoop103上分别启动datanode hadoop-daemon.sh start datanode jps查看进程\n\n\n# 6）配置ssh、群起集群\n\n * 各节点间无密登录()\n\n生成公钥和私钥 (banana用户) (然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）)\nssh-keygen -t rsa\n\n将公钥拷贝到要免密登录的目标机器上\nssh-copy-id hadoop101\nssh-copy-id hadoop102\nssh-copy-id hadoop103\n\n\nssh-copy-id的使用方法: https://blog.csdn.net/qianggezhishen/article/details/71249699\n\n还需要在hadoop101上采用root账号，配置一下无密登录到hadoop101、hadoop102、hadoop103； 还需要在hadoop102上采用banana账号配置一下无密登录到hadoop101、hadoop102、hadoop103服务器上\n\n原因: namenode和resourcemanager要远程启动其他节点, 或者参考链接: https://www.cnblogs.com/limaosheng/p/10444515.html#_label0\n\n\n\n\n * 配置从机datanode 和 nodemanager(配置slaves) vim /soft/module/hadoop-2.9.2/etc/hadoop/slaves\n\n加上\nhadoop101\nhadoop102\nhadoop103\n\n分发文件\nxsync.sh /soft/module/hadoop-2.9.2/etc/hadoop/slaves\n\n\n * 启动集群\n   * 如果集群是第一次启动，需要格式化namenode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据） hdfs namenode -format hdfs格式化注意事项:https://blog.csdn.net/gis_101/article/details/52821946?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task\n   * 启动hdfs 在namenode(hadoop101)节点上执行 sbin/start-dfs.sh\n   * 启动yarn 在resoucemanager(hadoop102)节点上执行 sbin/start-yarn.sh\n * 在网页上查看集群信息\n\n\n# 7）测试集群\n\n * 上传文件到集群\n * 查看文件存放在什么位置 (hdfs文件存储路径)(hdfs在磁盘存储文件内容)\n * 拼接文件\n * 下载文件\n\n\n# 四. 集群时间同步\n\nhadoop101作为时间服务器,其它节点定时获取hadoop101的时间\n\n\n\n\n# 1. 时间服务器配置 (必须root用户)\n\n * 检查ntp是否安装 rpm -qa|grep ntp 没有ntp-4.2.6p5-28.el7.centos.x86_64的话 安装ntp yum install -y ntp\n\n * 修改ntp配置文件 vim /etc/ntp.conf\n   \n   修改内容:\n\n一、修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）**\n# restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap为\nrestrict 8.8.8.0 mask 255.255.255.0 nomodify notrap\n\n二、修改2（集群在局域网中，不使用其他互联网上的时间）**\nserver 0.centos.pool.ntp.org iburst\nserver 1.centos.pool.ntp.org iburst\nserver 2.centos.pool.ntp.org iburst\nserver 3.centos.pool.ntp.org iburst为\n# server 0.centos.pool.ntp.org iburst\n# server 1.centos.pool.ntp.org iburst\n# server 2.centos.pool.ntp.org iburst\n# server 3.centos.pool.ntp.org iburst\n\n三、添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）**\nserver 127.127.1.0\nfudge 127.127.1.0 stratum 10\n\n\n * 修改/etc/sysconfig/ntpd 文件 vim /etc/sysconfig/ntpd\n\n增加内容如下（让硬件时间与系统时间一起同步）\nsync_hwclock=yes\n\n\n * 重新启动ntpd服务 service ntpd status 启动:service ntpd start systemctl start ntpd\n * 设置ntpd服务开机启动 chkconfig ntpd on systemctl enable ntpd (开放端口)\n\n\n# 2. 其他节点配置 (必须root用户)\n\n * 其他机器配置10分钟与时间服务器同步一次 crontab -e 编写定时任务\n\n*/10 * * * * /usr/sbin/ntpdate hadoop101\n\n\n * 修改任意机器时间 date -s "2017-9-11 11:11:11"\n * 十分钟后查看机器是否与时间服务器同步 date(测试时时间可设置短些)',charsets:{cjk:!0},lastUpdated:"2023/02/04, 18:03:37",lastUpdatedTimestamp:1675505017e3},{title:"Hadoop高可用搭建",frontmatter:{title:"Hadoop高可用搭建",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/f9f70f/",categories:["大数据","Hadoop"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/01.Hadoop/02.Hadoop%E9%AB%98%E5%8F%AF%E7%94%A8%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/01.Hadoop/02.Hadoop高可用搭建.md",key:"v-30099682",path:"/pages/f9f70f/",headers:[{level:2,title:"前提",slug:"前提",normalizedTitle:"前提",charIndex:2},{level:2,title:"1. 简介",slug:"_1-简介",normalizedTitle:"1. 简介",charIndex:265},{level:2,title:"2. 配置(在之前搭建分布式集群的基础上)",slug:"_2-配置-在之前搭建分布式集群的基础上",normalizedTitle:"2. 配置(在之前搭建分布式集群的基础上)",charIndex:446},{level:3,title:"修改配置文件",slug:"修改配置文件",normalizedTitle:"修改配置文件",charIndex:472},{level:2,title:"3. 启动集群",slug:"_3-启动集群",normalizedTitle:"3. 启动集群",charIndex:3993},{level:2,title:"4. 激活namenode",slug:"_4-激活namenode",normalizedTitle:"4. 激活namenode",charIndex:4537},{level:2,title:"5. HA手动切换",slug:"_5-ha手动切换",normalizedTitle:"5. ha手动切换",charIndex:4813},{level:3,title:"附:自己出的小问题",slug:"附-自己出的小问题",normalizedTitle:"附:自己出的小问题",charIndex:4988},{level:3,title:"附: 一个玄学问题(已解决  是中文符号问题)",slug:"附-一个玄学问题-已解决-是中文符号问题",normalizedTitle:"附: 一个玄学问题(已解决  是中文符号问题)",charIndex:null},{level:3,title:"附:ssh知识",slug:"附-ssh知识",normalizedTitle:"附:ssh知识",charIndex:5883}],headersStr:"前提 1. 简介 2. 配置(在之前搭建分布式集群的基础上) 修改配置文件 3. 启动集群 4. 激活namenode 5. HA手动切换 附:自己出的小问题 附: 一个玄学问题(已解决  是中文符号问题) 附:ssh知识",content:"# 前提\n\n分布式搭建入口:https://www.cnblogs.com/Hephaestus/p/12213719.html 集群规划:\n\n            NAMENODE   DATANODE   JOURNALNODE\nhadoop100   是(nn2)                \nhadoop101   是(nn1)     是          是\nhadoop102              是          是\nhadoop103              是          是\n\n\n# 1. 简介\n\n高可用程序的类型\n主从方式(冷备)： 两个相同的应用程序,一个对外提供服务,成为主程序,另一个平时不运行为备程序,就是一个主程序的备份,一旦主程序出现问题,备份提供恢复操作\n双主互备(热备)： 两个相同的应用程序,同时对外提供服务(两个程序相互为对方备份的存在,双主热备),当启动一个出现问题时,另一个可以对外提供服务,不会造成服务器宕机\n\n\n# 2. 配置(在之前搭建分布式集群的基础上)\n\n\n# 修改配置文件\n\n * 修改核心配置文件: vim etc/hadoop/core-site.xml 加入\n\n<configuration>\n\n        \x3c!-- 指定HDFS中NameNode的地址 --\x3e\n        <property>\n                <name>fs.defaultFS</name>\n                \x3c!--hdfs://hadoop101:9000--\x3e\n                <value>hdfs://mycluster</value>\n        </property>\n\n        \x3c!-- 指定Hadoop运行时产生文件的存储目录 --\x3e\n        <property>\n                <name>hadoop.tmp.dir</name>\n                <value>/soft/module/hadoop-2.9.2/data/tmp</value>\n        </property>\n\n</configuration>\n\n\n * 修改hdfs配置文件: vim etc/hadoop/hdfs-site.xml 加入\n\n<configuration>\n\n        \x3c!--HA高可用配置--\x3e\n        \x3c!--集群起名--\x3e\n        <property>\n                <name>dfs.nameservices</name>\n                <value>mycluster</value>\n        </property>\n\n        \x3c!--指定mycluster的有哪些namenode，nn1,nn2 自己去的名--\x3e\n        <property>\n                <name>dfs.ha.namenodes.mycluster</name>\n                <value>nn1,nn2</value>\n        </property>\n\n        \x3c!--nn1 RPC端口 --\x3e\n        <property>\n                <name>dfs.namenode.rpc-address.mycluster.nn1</name>\n                <value>hadoop101:9000</value>\n        </property>\n\n        \x3c!--nn1 HTTP端口 --\x3e\n        <property>\n                <name>dfs.namenode.http-address.mycluster.nn1</name>\n                <value>hadoop101:50070</value>\n        </property>\n\n        \x3c!--nn2 RPC端口 --\x3e\n        <property>\n                <name>dfs.namenode.rpc-address.mycluster.nn2</name>\n                <value>hadoop100:9000</value>\n        </property>\n\n        \x3c!--nn2 HTTP端口 --\x3e\n        <property>\n                <name>dfs.namenode.http-address.mycluster.nn2</name>\n                <value>hadoop100:50070</value>\n        </property>\n\n        \x3c!--HA故障切换 --\x3e\n        \x3c!-- 当namnode故障，是否自动启动另一个namenode(默认值为false)--\x3e\n        <property>\n                <name>dfs.ha.automatic-failover.enabled </name>\n                <value>false</value>\n        </property>\n\n        \x3c!-- journalnode 配置 --\x3e\n        \x3c!-- mycluster的两个namenode共享editsa文件目录时，使用journalnode集群信息--\x3e\n        <property>\n                <name>dfs.namenode.shared.edits.dir</name>\n                <value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/mycluster</value>\n        </property>\n\n        \x3c!--当mycluster故障时，哪个实现类负责故障切换--\x3e\n        <property>\n                <name>dfs.client.failover.proxy.provider.mycluster</name>\n        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>\n        </property>\n\n        \x3c!--发生failover时，Standby的节点要执行一系列方法把原来那个Active节点中不健康的NameNode服务给杀掉，\n                这个叫做fence过程。sshfence会通过ssh远程调用fuser命令去找到Active节点的NameNode服务并杀死它--\x3e\n         \x3c!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行 --\x3e\n        <property>\n                <name>dfs.ha.fencing.methods</name>\n                <value>sshfence</value>\n         </property>\n\n        \x3c!--SSH私钥 使用sshfence隔离机制时需要ssh免登陆--\x3e\n        <property>\n                <name>dfs.ha.fencing.ssh.private-key-files</name>\x3c!--免密登录密钥位置--\x3e\n                \x3c!--<value>/home/hadoop/.ssh/id_rsa</value>--\x3e\n                <value>/home/banana/.ssh/id_rsa</value>\n        </property>\n\n        \x3c!--SSH超时时间 --\x3e\n        <property>\n                <name>dfs.ha.fencing.ssh.connect-timeout</name>\n                <value>30000</value>\n        </property>\n\n        \x3c!--Journal Node文件存储地址 --\x3e\n        <property>\n                 <name>dfs.journalnode.edits.dir</name>\n                <value>/soft/module/hadoop-2.9.2/data/tmp/journal</value>\n        </property>\n\n</configuration>\n\n\n * 修改从机配置文件: vim etc/hadoop/slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n * 分发配置文件 xsync.sh etc/hadoop/\n\n\n# 3. 启动集群\n\n * 启动journalnode集群\n   将journalnode部署在DataNode节点上 在DataNode节点执行 ./sbin/hadoop-daemon.sh start journalnode\n * 格式化namenode(一定要在journalnode集群启动后再进行格式化) (1) 先删除所有节点上的 tmp dfs/name dfs/data logs 等目录\n   (2) 在nn1(namenode1)上执行 ${HADOOP_HOME}/bin/hdfs namenode -format(注意一定是英文符'-') hdfs namenode -format(明明一样的命令问什么有时好使有时不好使????[中英文符号问题])\n   (3) 在hadoop101(nn1上)启动namenode hadoop-daemon.sh start namenode\n * namenode2同步namenode1上格式化后的信息(先启动nn1的namenode) 在nn2(namenode2)上执行 hdfs namenode -bootstrapStandby\n * 在namenode1启动集群 sbin/start-dfs.sh\n\n\n# 4. 激活namenode\n\n * 执行完前面的步骤后 此时namenode1和namenode2都是standby状态（通过web服务查看），还不能正常提供服务，需要将将其中一个节点切换到active状态。\n * 将namenode1切换为active状态 在namennode1执行 ./bin/hdfs haadmin -failover --forceactive nn2 nn1(这里nn2, nn1表示namenode的服务名，需要与hdfs-sit.xml中的配置保持一致。)然后查看namenode1和namenode2的状态\n\n\n# 5. HA手动切换\n\n * 在active状态的namenode执行 kill -9 xxx(进程id)\n * 切换namenode 在namenode2上切换为active ./bin/hdfs haadmin -failover --forceactive nn1 nn2(执行后日志会报错，是因为jar包版本的原因，不影响切换状态。)\n\n\n# 附:自己出的小问题\n\n> (1) 8.8.8.101:8485: Call From hadoop101/8.8.8.101 to hadoop101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused 问题:未启动journal集群(./sbin/hadoop-daemon.sh start journalnode)\n\n> (2) Unable to fetch namespace information from active NN at hadoop101/8.8.8.101:9000: Call From hadoop100/8.8.8.100 to hadoop101:9000 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused 问题:未启启动主机器的namenode:(./hadoop-daemon.sh start namenode)\n\n> (3) 对于拒绝连接问题:如果你的所有配置都是正确的，那么这个问题只能是host,network，firewall(当然还有你输命令的问题)\n\n\n# 附: 一个玄学问题(已解决 是中文符号问题)\n\n * 启动namenode不好使,jps发现没有namenode\n * 查看日志\n * 手动新建文件夹,发现报错no format,所以是hdfs namenode -format不好使 改为${HADOOP_HOME}/bin/hdfs namenode -format格式化就好使了, 之后重新格式化用hdfs namenode -format好使,不知道是什么原因\n\n\n# 附:ssh知识\n\nssh默认会把你每个你访问过计算机的公钥(public key)都记录在/root/.ssh/known_hosts。当再次访问该主机时，OpenSSH会校对公钥。如果公钥不同，OpenSSH则发出警告，避免你受到ONS Hijack之类的攻击。\n\n解决办法：\n\n1、手动删除/root/.ssh/known_hosts文件，放心在你再次使用ssh时它会再次自动生成。但这样也会把其他主机的公钥删 掉，下次登录需要重新输入密码，如果你有足够的耐心，也可以打开/root/.ssh/known_hosts文件，找到对应主机那一行手 动修改为正确的RSA key。\n\n2、根据网上其他人说的，修改配置文件“~/.ssh/config”，加上下面两行，重启服务器。\n\nStrictHostKeyChecking no\nUserKnownHostsFile /dev/null\n\n\n但不建议这么做，因为SSH登陆时会忽略known_hsots文件，不安全。",normalizedContent:"# 前提\n\n分布式搭建入口:https://www.cnblogs.com/hephaestus/p/12213719.html 集群规划:\n\n            namenode   datanode   journalnode\nhadoop100   是(nn2)                \nhadoop101   是(nn1)     是          是\nhadoop102              是          是\nhadoop103              是          是\n\n\n# 1. 简介\n\n高可用程序的类型\n主从方式(冷备)： 两个相同的应用程序,一个对外提供服务,成为主程序,另一个平时不运行为备程序,就是一个主程序的备份,一旦主程序出现问题,备份提供恢复操作\n双主互备(热备)： 两个相同的应用程序,同时对外提供服务(两个程序相互为对方备份的存在,双主热备),当启动一个出现问题时,另一个可以对外提供服务,不会造成服务器宕机\n\n\n# 2. 配置(在之前搭建分布式集群的基础上)\n\n\n# 修改配置文件\n\n * 修改核心配置文件: vim etc/hadoop/core-site.xml 加入\n\n<configuration>\n\n        \x3c!-- 指定hdfs中namenode的地址 --\x3e\n        <property>\n                <name>fs.defaultfs</name>\n                \x3c!--hdfs://hadoop101:9000--\x3e\n                <value>hdfs://mycluster</value>\n        </property>\n\n        \x3c!-- 指定hadoop运行时产生文件的存储目录 --\x3e\n        <property>\n                <name>hadoop.tmp.dir</name>\n                <value>/soft/module/hadoop-2.9.2/data/tmp</value>\n        </property>\n\n</configuration>\n\n\n * 修改hdfs配置文件: vim etc/hadoop/hdfs-site.xml 加入\n\n<configuration>\n\n        \x3c!--ha高可用配置--\x3e\n        \x3c!--集群起名--\x3e\n        <property>\n                <name>dfs.nameservices</name>\n                <value>mycluster</value>\n        </property>\n\n        \x3c!--指定mycluster的有哪些namenode，nn1,nn2 自己去的名--\x3e\n        <property>\n                <name>dfs.ha.namenodes.mycluster</name>\n                <value>nn1,nn2</value>\n        </property>\n\n        \x3c!--nn1 rpc端口 --\x3e\n        <property>\n                <name>dfs.namenode.rpc-address.mycluster.nn1</name>\n                <value>hadoop101:9000</value>\n        </property>\n\n        \x3c!--nn1 http端口 --\x3e\n        <property>\n                <name>dfs.namenode.http-address.mycluster.nn1</name>\n                <value>hadoop101:50070</value>\n        </property>\n\n        \x3c!--nn2 rpc端口 --\x3e\n        <property>\n                <name>dfs.namenode.rpc-address.mycluster.nn2</name>\n                <value>hadoop100:9000</value>\n        </property>\n\n        \x3c!--nn2 http端口 --\x3e\n        <property>\n                <name>dfs.namenode.http-address.mycluster.nn2</name>\n                <value>hadoop100:50070</value>\n        </property>\n\n        \x3c!--ha故障切换 --\x3e\n        \x3c!-- 当namnode故障，是否自动启动另一个namenode(默认值为false)--\x3e\n        <property>\n                <name>dfs.ha.automatic-failover.enabled </name>\n                <value>false</value>\n        </property>\n\n        \x3c!-- journalnode 配置 --\x3e\n        \x3c!-- mycluster的两个namenode共享editsa文件目录时，使用journalnode集群信息--\x3e\n        <property>\n                <name>dfs.namenode.shared.edits.dir</name>\n                <value>qjournal://hadoop101:8485;hadoop102:8485;hadoop103:8485/mycluster</value>\n        </property>\n\n        \x3c!--当mycluster故障时，哪个实现类负责故障切换--\x3e\n        <property>\n                <name>dfs.client.failover.proxy.provider.mycluster</name>\n        <value>org.apache.hadoop.hdfs.server.namenode.ha.configuredfailoverproxyprovider</value>\n        </property>\n\n        \x3c!--发生failover时，standby的节点要执行一系列方法把原来那个active节点中不健康的namenode服务给杀掉，\n                这个叫做fence过程。sshfence会通过ssh远程调用fuser命令去找到active节点的namenode服务并杀死它--\x3e\n         \x3c!-- 配置隔离机制方法，多个机制用换行分割，即每个机制暂用一行 --\x3e\n        <property>\n                <name>dfs.ha.fencing.methods</name>\n                <value>sshfence</value>\n         </property>\n\n        \x3c!--ssh私钥 使用sshfence隔离机制时需要ssh免登陆--\x3e\n        <property>\n                <name>dfs.ha.fencing.ssh.private-key-files</name>\x3c!--免密登录密钥位置--\x3e\n                \x3c!--<value>/home/hadoop/.ssh/id_rsa</value>--\x3e\n                <value>/home/banana/.ssh/id_rsa</value>\n        </property>\n\n        \x3c!--ssh超时时间 --\x3e\n        <property>\n                <name>dfs.ha.fencing.ssh.connect-timeout</name>\n                <value>30000</value>\n        </property>\n\n        \x3c!--journal node文件存储地址 --\x3e\n        <property>\n                 <name>dfs.journalnode.edits.dir</name>\n                <value>/soft/module/hadoop-2.9.2/data/tmp/journal</value>\n        </property>\n\n</configuration>\n\n\n * 修改从机配置文件: vim etc/hadoop/slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n * 分发配置文件 xsync.sh etc/hadoop/\n\n\n# 3. 启动集群\n\n * 启动journalnode集群\n   将journalnode部署在datanode节点上 在datanode节点执行 ./sbin/hadoop-daemon.sh start journalnode\n * 格式化namenode(一定要在journalnode集群启动后再进行格式化) (1) 先删除所有节点上的 tmp dfs/name dfs/data logs 等目录\n   (2) 在nn1(namenode1)上执行 ${hadoop_home}/bin/hdfs namenode -format(注意一定是英文符'-') hdfs namenode -format(明明一样的命令问什么有时好使有时不好使????[中英文符号问题])\n   (3) 在hadoop101(nn1上)启动namenode hadoop-daemon.sh start namenode\n * namenode2同步namenode1上格式化后的信息(先启动nn1的namenode) 在nn2(namenode2)上执行 hdfs namenode -bootstrapstandby\n * 在namenode1启动集群 sbin/start-dfs.sh\n\n\n# 4. 激活namenode\n\n * 执行完前面的步骤后 此时namenode1和namenode2都是standby状态（通过web服务查看），还不能正常提供服务，需要将将其中一个节点切换到active状态。\n * 将namenode1切换为active状态 在namennode1执行 ./bin/hdfs haadmin -failover --forceactive nn2 nn1(这里nn2, nn1表示namenode的服务名，需要与hdfs-sit.xml中的配置保持一致。)然后查看namenode1和namenode2的状态\n\n\n# 5. ha手动切换\n\n * 在active状态的namenode执行 kill -9 xxx(进程id)\n * 切换namenode 在namenode2上切换为active ./bin/hdfs haadmin -failover --forceactive nn1 nn2(执行后日志会报错，是因为jar包版本的原因，不影响切换状态。)\n\n\n# 附:自己出的小问题\n\n> (1) 8.8.8.101:8485: call from hadoop101/8.8.8.101 to hadoop101:8485 failed on connection exception: java.net.connectexception: 拒绝连接; for more details see: http://wiki.apache.org/hadoop/connectionrefused 问题:未启动journal集群(./sbin/hadoop-daemon.sh start journalnode)\n\n> (2) unable to fetch namespace information from active nn at hadoop101/8.8.8.101:9000: call from hadoop100/8.8.8.100 to hadoop101:9000 failed on connection exception: java.net.connectexception: 拒绝连接; for more details see: http://wiki.apache.org/hadoop/connectionrefused 问题:未启启动主机器的namenode:(./hadoop-daemon.sh start namenode)\n\n> (3) 对于拒绝连接问题:如果你的所有配置都是正确的，那么这个问题只能是host,network，firewall(当然还有你输命令的问题)\n\n\n# 附: 一个玄学问题(已解决 是中文符号问题)\n\n * 启动namenode不好使,jps发现没有namenode\n * 查看日志\n * 手动新建文件夹,发现报错no format,所以是hdfs namenode -format不好使 改为${hadoop_home}/bin/hdfs namenode -format格式化就好使了, 之后重新格式化用hdfs namenode -format好使,不知道是什么原因\n\n\n# 附:ssh知识\n\nssh默认会把你每个你访问过计算机的公钥(public key)都记录在/root/.ssh/known_hosts。当再次访问该主机时，openssh会校对公钥。如果公钥不同，openssh则发出警告，避免你受到ons hijack之类的攻击。\n\n解决办法：\n\n1、手动删除/root/.ssh/known_hosts文件，放心在你再次使用ssh时它会再次自动生成。但这样也会把其他主机的公钥删 掉，下次登录需要重新输入密码，如果你有足够的耐心，也可以打开/root/.ssh/known_hosts文件，找到对应主机那一行手 动修改为正确的rsa key。\n\n2、根据网上其他人说的，修改配置文件“~/.ssh/config”，加上下面两行，重启服务器。\n\nstricthostkeychecking no\nuserknownhostsfile /dev/null\n\n\n但不建议这么做，因为ssh登陆时会忽略known_hsots文件，不安全。",charsets:{cjk:!0},lastUpdated:"2022/11/22, 17:20:22",lastUpdatedTimestamp:1669108822e3},{title:"集群端口",frontmatter:{title:"集群端口",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/3e77b2/",categories:["大数据","Hadoop"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/01.Hadoop/03.%E9%9B%86%E7%BE%A4%E7%AB%AF%E5%8F%A3.html",relativePath:"02.大数据/01.Hadoop/03.集群端口.md",key:"v-f9f8fc5c",path:"/pages/3e77b2/",headers:[{level:2,title:"端口",slug:"端口",normalizedTitle:"端口",charIndex:2}],headersStr:"端口",content:"# 端口\n\n组件          节点                  默认端口    配置                                                                   用途说明\nHDFS        DataNode            50010   dfs.datanode.address                                                 datanode服务端口，用于数据传输\nHDFS        DataNode            50075   dfs.datanode.http.address                                            http服务的端口\nHDFS        DataNode            50475   dfs.datanode.https.address                                           https服务的端口\nHDFS        DataNode            50020   dfs.datanode.ipc.address                                             ipc服务的端口\nHDFS        NameNode            50070   dfs.namenode.http-address                                            http服务的端口\nHDFS        NameNode            50470   dfs.namenode.https-address                                           https服务的端口\nHDFS        NameNode            8020    fs.defaultFS                                                         接收Client连接的RPC端口，用于获取文件系统metadata信息。\nHDFS        journalnode         8485    dfs.journalnode.rpc-address                                          RPC服务\nHDFS        journalnode         8480    dfs.journalnode.http-address                                         HTTP服务\nHDFS        ZKFC                8019    dfs.ha.zkfc.port                                                     ZooKeeper FailoverController，用于NN HA\nYARN        ResourceManager     8032    yarn.resourcemanager.address                                         RM的applications manager(ASM)端口\nYARN        ResourceManager     8030    yarn.resourcemanager.scheduler.address                               scheduler组件的IPC端口\nYARN        ResourceManager     8031    yarn.resourcemanager.resource-tracker.address                        IPC\nYARN        ResourceManager     8033    yarn.resourcemanager.admin.address                                   IPC\nYARN        ResourceManager     8088    yarn.resourcemanager.webapp.address                                  http服务端口\nYARN        NodeManager         8040    yarn.nodemanager.localizer.address                                   localizer IPC\nYARN        NodeManager         8042    yarn.nodemanager.webapp.address                                      http服务端口\nYARN        NodeManager         8041    yarn.nodemanager.address                                             NM中container manager的端口\nYARN        JobHistory Server   10020   mapreduce.jobhistory.address                                         IPC\nYARN        JobHistory Server   19888   mapreduce.jobhistory.webapp.address                                  http服务端口\nHBase       Master              60000   hbase.master.port                                                    IPC\nHBase       Master              60010   hbase.master.info.port                                               http服务端口\nHBase       RegionServer        60020   hbase.regionserver.port                                              IPC\nHBase       RegionServer        60030   hbase.regionserver.info.port                                         http服务端口\nHBase       HQuorumPeer         2181    hbase.zookeeper.property.clientPort                                  HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。\nHBase       HQuorumPeer         2888    hbase.zookeeper.peerport                                             HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。\nHBase       HQuorumPeer         3888    hbase.zookeeper.leaderport                                           HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。\nHive        Metastore           9083    /etc/default/hive-metastore中export PORT=[port]                       来更新默认端口\nHive        HiveServer          10000   /etc/hive/conf/hive-env.sh中export                                    来更新默认端口\n                                        HIVE_SERVER2_THRIFT_PORT=[port]\nZooKeeper   Server              2181    /etc/zookeeper/conf/zoo.cfg中clientPort=[port]                        对客户端提供服务的端口\nZooKeeper   Server              2888    /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分   follower用来连接到leader，只在leader上监听该端口。\nZooKeeper   Server              3888    /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分   用于leader选举的。只在electionAlg是1,2或3(默认)时需要。",normalizedContent:"# 端口\n\n组件          节点                  默认端口    配置                                                                   用途说明\nhdfs        datanode            50010   dfs.datanode.address                                                 datanode服务端口，用于数据传输\nhdfs        datanode            50075   dfs.datanode.http.address                                            http服务的端口\nhdfs        datanode            50475   dfs.datanode.https.address                                           https服务的端口\nhdfs        datanode            50020   dfs.datanode.ipc.address                                             ipc服务的端口\nhdfs        namenode            50070   dfs.namenode.http-address                                            http服务的端口\nhdfs        namenode            50470   dfs.namenode.https-address                                           https服务的端口\nhdfs        namenode            8020    fs.defaultfs                                                         接收client连接的rpc端口，用于获取文件系统metadata信息。\nhdfs        journalnode         8485    dfs.journalnode.rpc-address                                          rpc服务\nhdfs        journalnode         8480    dfs.journalnode.http-address                                         http服务\nhdfs        zkfc                8019    dfs.ha.zkfc.port                                                     zookeeper failovercontroller，用于nn ha\nyarn        resourcemanager     8032    yarn.resourcemanager.address                                         rm的applications manager(asm)端口\nyarn        resourcemanager     8030    yarn.resourcemanager.scheduler.address                               scheduler组件的ipc端口\nyarn        resourcemanager     8031    yarn.resourcemanager.resource-tracker.address                        ipc\nyarn        resourcemanager     8033    yarn.resourcemanager.admin.address                                   ipc\nyarn        resourcemanager     8088    yarn.resourcemanager.webapp.address                                  http服务端口\nyarn        nodemanager         8040    yarn.nodemanager.localizer.address                                   localizer ipc\nyarn        nodemanager         8042    yarn.nodemanager.webapp.address                                      http服务端口\nyarn        nodemanager         8041    yarn.nodemanager.address                                             nm中container manager的端口\nyarn        jobhistory server   10020   mapreduce.jobhistory.address                                         ipc\nyarn        jobhistory server   19888   mapreduce.jobhistory.webapp.address                                  http服务端口\nhbase       master              60000   hbase.master.port                                                    ipc\nhbase       master              60010   hbase.master.info.port                                               http服务端口\nhbase       regionserver        60020   hbase.regionserver.port                                              ipc\nhbase       regionserver        60030   hbase.regionserver.info.port                                         http服务端口\nhbase       hquorumpeer         2181    hbase.zookeeper.property.clientport                                  hbase-managed zk mode，使用独立的zookeeper集群则不会启用该端口。\nhbase       hquorumpeer         2888    hbase.zookeeper.peerport                                             hbase-managed zk mode，使用独立的zookeeper集群则不会启用该端口。\nhbase       hquorumpeer         3888    hbase.zookeeper.leaderport                                           hbase-managed zk mode，使用独立的zookeeper集群则不会启用该端口。\nhive        metastore           9083    /etc/default/hive-metastore中export port=[port]                       来更新默认端口\nhive        hiveserver          10000   /etc/hive/conf/hive-env.sh中export                                    来更新默认端口\n                                        hive_server2_thrift_port=[port]\nzookeeper   server              2181    /etc/zookeeper/conf/zoo.cfg中clientport=[port]                        对客户端提供服务的端口\nzookeeper   server              2888    /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分   follower用来连接到leader，只在leader上监听该端口。\nzookeeper   server              3888    /etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分   用于leader选举的。只在electionalg是1,2或3(默认)时需要。",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"代码demo（mr hbase hive redis）",frontmatter:{title:"代码demo（mr hbase hive redis）",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/03a2bd/",categories:["大数据","Hadoop"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/01.Hadoop/04.%E4%BB%A3%E7%A0%81demo%EF%BC%88mr%20hbase%20hive%20redis%EF%BC%89.html",relativePath:"02.大数据/01.Hadoop/04.代码demo（mr hbase hive redis）.md",key:"v-2fa3e257",path:"/pages/03a2bd/",headers:[{level:2,title:"环境",slug:"环境",normalizedTitle:"环境",charIndex:2},{level:2,title:"MapReduce代码",slug:"mapreduce代码",normalizedTitle:"mapreduce代码",charIndex:137},{level:2,title:"hbase代码",slug:"hbase代码",normalizedTitle:"hbase代码",charIndex:4510},{level:2,title:"MySQL数据插入到HBase",slug:"mysql数据插入到hbase",normalizedTitle:"mysql数据插入到hbase",charIndex:15689},{level:2,title:"hive代码",slug:"hive代码",normalizedTitle:"hive代码",charIndex:25556},{level:2,title:"RedisApi",slug:"redisapi",normalizedTitle:"redisapi",charIndex:34702}],headersStr:"环境 MapReduce代码 hbase代码 MySQL数据插入到HBase hive代码 RedisApi",content:'# 环境\n\n----------------------------------------\n\n基于Windows下eclipse的MapReduce开发环境配置 https://www.cnblogs.com/Hephaestus/p/12608456.html\n\n\n# MapReduce代码\n\n----------------------------------------\n\nMyMapper\n\npackage mrproject;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.LongWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Mapper;\n\npublic class MyMapper extends Mapper<LongWritable, Text, Text, IntWritable> {\n\t /**\n     * map阶段的业务逻辑处理就写在map()方法中\n     * maptask会对每一行输入数据调用一次我们自定义的map()方法\n     * @throws InterruptedException\n     */\n\t private Text word = new Text();//Text是Hadoop针对字符串的序列化包装类\n     private IntWritable one = new IntWritable(1);//IntWritable是Hadoop针对整型的序列化包装类---更多关于Hadoop的序列化包装类请查阅相关资料\n     \n\t@Override\n\tprotected void map(LongWritable key, Text value, Context context)\n\t\t\tthrows IOException, InterruptedException {\n\t\t//将maptask传递给我们的文本内容先转换成string\n        String line=value.toString();\n        //按照空格行切割单词\n        String[] words=line.split(" ");\n        //将单词输出为<单词，1>\n        for(String w:words) {\n            word.set(w);\n           //将单词作为key，将次数1作为Value，以便于后续的数据分发，可以根据单词分发，以便于相同单词会到相同的reduce task\n            context.write(word,one);\n        }\n\t}\n\t\n}\n\n\nMyReducer\n\npackage mrproject;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Reducer;\n\npublic class MyReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n\t /**\n\t  * reducer中主要的方式就是reduce,用户处理map阶段产生的key-value数据，如下样例\n     * <angel,1> <angel,1> <angel,1> <angel,1> <angel,1>\n     * <hello,1> <hello,1> <hello,1> <hello,1> <hello,1> <hello,1>\n     * <banana,1> <banana,1> <banana,1> <banana,1> <banana,1> <banana,1>\n     * 入参key：是一组单词的kv对应的key,将相同单词的一组传递，如此时key是hello，那么参数二是一个迭代器，一组数\n     * @throws InterruptedException\n     * @throws IOException\n     */\n\tprivate IntWritable sum= new IntWritable();\n\t@Override\n\tprotected void reduce(Text key, Iterable<IntWritable> values,Context context) throws IOException, InterruptedException {\n\t\tint count=0;\n\t     /**\n\t             Iterator<IntWritable> iterator=values.iterator();\n\t             while(iterator.hasNext()) {\n\t                 count+=iterator.next().get();\n\t             }\n\t     */\n\t\t//此处的values是某个key对应的所有的value，例如上面数据angel对应了5个1\n\t             for(IntWritable value:values) {\n\t                 count+=value.get();\n\t             }\n\t             sum.set(count);\n\t             //上下文输出\n\t             context.write(key, sum);\n\t }   \n}\n\n\nMRApp\n\npackage mrproject;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n\n\n\npublic class MRApp {\n\tpublic static void main(String[] args) throws IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException {\n        //此处主要用于本地运行，如果生产环境使用shell命令运行，则命令中会有输入输出目录\n        //本地运行时为了方便没有给到args，此处代码处理下给个默认值\n        if(args.length <2)\n        {\n           args= new String[]{\n                     "hdfs://10.20.10.67:9000/input",\n                     "hdfs://10.20.10.67:9000/output4"\n           };   \n        }\n        Configuration conf=new Configuration();\n        /*\n         * 集群中节点都有配置文件\n        conf.set("mapreduce.framework.name.", "yarn");\n        conf.set("yarn.resourcemanager.hostname", "mini1");\n        */\n        Job job=Job.getInstance(conf);\n        //jar包在哪里,现在在客户端，传递参数\n        //任意运行，类加载器知道这个类的路径，就可以知道jar包所在的本地路径\n        job.setJarByClass(MRApp.class);\n        //指定本业务job要使用的mapper/Reducer业务类\n        job.setMapperClass(MyMapper.class);\n        job.setReducerClass(MyReducer.class);\n        //指定mapper输出数据的kv类型\n        job.setMapOutputKeyClass(Text.class);\n        job.setMapOutputValueClass(IntWritable.class);\n        //指定最终输出的数据kv类型\n        job.setOutputKeyClass(Text.class);\n        job.setOutputKeyClass(IntWritable.class);\n        //指定job的输入原始文件所在目录\n        FileInputFormat.setInputPaths(job, new Path(args[0]));\n        //指定job的输出结果所在目录\n        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n        //将job中配置的相关参数及job所用的java类在的jar包，提交给yarn去运行\n        //提交之后，此时客户端代码就执行完毕，退出\n        //job.submit();\n        //等集群返回结果在退出\n        boolean res=job.waitForCompletion(true);\n        System.exit(res?0:1);\n    }\n}\n\n\n\n# hbase代码\n\n----------------------------------------\n\n表操作(DDL DML)\n\npackage com.hrbu.hbase;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.Cell;\nimport org.apache.hadoop.hbase.CellUtil;\nimport org.apache.hadoop.hbase.CompareOperator;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.NamespaceDescriptor;\nimport org.apache.hadoop.hbase.NamespaceExistException;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Admin;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\nimport org.apache.hadoop.hbase.client.Connection;\nimport org.apache.hadoop.hbase.client.ConnectionFactory;\nimport org.apache.hadoop.hbase.client.Delete;\nimport org.apache.hadoop.hbase.client.Get;\nimport org.apache.hadoop.hbase.client.Put;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.ResultScanner;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.client.Table;\nimport org.apache.hadoop.hbase.client.TableDescriptor;\nimport org.apache.hadoop.hbase.client.TableDescriptorBuilder;\nimport org.apache.hadoop.hbase.filter.BinaryComparator;\nimport org.apache.hadoop.hbase.filter.CompareFilter;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.KeyOnlyFilter;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.RandomRowFilter;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.filter.ValueFilter;\nimport org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException;\nimport org.apache.hadoop.hbase.util.Bytes;\n\n/**\n * DDL: 1.判断表是否存在 2.创建表 3.创建命名空间 4.删除表 \n * DML: 5.插入数据 6.查数据(get) 7.查数据(scan) 8.删除数据\n */\npublic class TestApi {\n\n\tpublic static Connection connect = null;\n\tpublic static Admin admin = null;\n\tstatic {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 HBaseConfiguration 的单例方法实例化)\n\t\t\tConfiguration conf = HBaseConfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientPort", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = ConnectionFactory.createConnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getAdmin();\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\tSystem.out.println("创建hbase连接对象异常");\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("admin关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// 1.判断表是否存在\n\tpublic static void is_Exists(String tableName) throws IOException {\n\t\tif (admin.tableExists(TableName.valueOf(tableName))) {\n\t\t\tSystem.out.println(tableName + "表已经存在");\n\t\t} else {\n\t\t\tSystem.out.println(tableName + "表不存在");\n\t\t}\n\t}\n\n\t// 2.创建表\n\tpublic static void create_Table(String tableName) throws IOException {\n\t\tTableName tableNameTemp = TableName.valueOf(tableName);\n\t\tif (admin.tableExists(tableNameTemp)) {\n\t\t\tSystem.out.println(tableName + "表已经存在");\n\t\t} else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\tTableDescriptorBuilder tableBuilder = TableDescriptorBuilder.newBuilder(tableNameTemp);\n\t\t\t// 列族\n\t\t\tColumnFamilyDescriptor info1 = ColumnFamilyDescriptorBuilder.of("info1");\n\t\t\tColumnFamilyDescriptor info2 = ColumnFamilyDescriptorBuilder.of("info2");\n\t\t\tColumnFamilyDescriptor info3 = ColumnFamilyDescriptorBuilder.of("info3");\n\t\t\tList<ColumnFamilyDescriptor> cfList = new ArrayList<ColumnFamilyDescriptor>();\n\t\t\tcfList.add(info1);\n\t\t\tcfList.add(info2);\n\t\t\tcfList.add(info3);\n\t\t\ttableBuilder.setColumnFamilies(cfList);\n\t\t\t// 5.构建表描述\n\t\t\tTableDescriptor tableDesc = tableBuilder.build();\n\t\t\tadmin.createTable(tableDesc);\n\t\t\tSystem.out.println(tableName + "\\t表创建成功");\n\t\t}\n\t}\n\n\t// 3.创建命名空间\n\tpublic static void create_NameSpace(String nameSpace) {\n\t\t// 创建命名空间描述器\n\t\tNamespaceDescriptor descriptor = NamespaceDescriptor.create(nameSpace).build();\n\t\t//创建命名空间\n\t\ttry {\n\t\t\tadmin.createNamespace(descriptor);\n\t\t} catch(NamespaceExistException e) {\n\t\t\tSystem.out.println(nameSpace + "命名空间已存在");\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println("--我会被执行吗--");\n\t}\n\t// 4.删除表\n\tpublic static void drop_Table(String tableName) throws IOException {\n\t\tTableName tableNameTemp = TableName.valueOf(tableName);\n\t\tif (admin.tableExists(tableNameTemp)) {\n\t\t\tadmin.disableTable(tableNameTemp);\n\t\t\tadmin.deleteTable(tableNameTemp);\n\t\t\tSystem.out.println("表" + tableName + "删除成功！ ");\n\t\t} else {\n\t\t\tSystem.out.println("表" + tableName + "不存在！ ");\n\t\t}\n\t}\n\t// 5.插入数据\n\tpublic static void put_Data(String tableName, String rowKey, String columnFamily, String column, String value) {\n\t\tTable table = null;\n\t\ttry {\n\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\tPut put = new Put(Bytes.toBytes(rowKey));\n\t\t\tput.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value));\n\t\t\ttable.put(put);\n\t\t} catch(NoSuchColumnFamilyException e){\n\t\t\tSystem.out.println("异常:没有此列族");\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tSystem.out.println("数据插入成功");\n\t\t\n\t}\n\t// 6.查数据(get)\n\tpublic static void get_Data(String tableName, String rowKey, String columnFamily, String column) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\t//get.addFamily(Bytes.toBytes(columnFamily));\n\t\tget.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + "--" + columnFamily + "--" + column + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_Data(String tableName, String rowKey, String columnFamily) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\tget.addFamily(Bytes.toBytes(columnFamily));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + "--" + columnFamily + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_Data(String tableName, String rowKey) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\t// 打印单元格信息\n\tprivate static void print_Cells(Cell[] cells) {\n\t\tfor (Cell tempCell : cells) {\n\t\t\tSystem.out.println(Bytes.toString(CellUtil.cloneRow(tempCell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + Bytes.toString(CellUtil.cloneFamily(tempCell)) + ":" +  Bytes.toString(CellUtil.cloneQualifier(tempCell))\n\t\t\t\t\t+ ",timestamp=" + tempCell.getTimestamp() \n\t\t\t\t\t+ ", value=" + Bytes.toString(CellUtil.cloneValue(tempCell)) );\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_Cells2(Cell[] cells) {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tfor (Cell cell : cells) {\n\t\t\tString column = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n\t\t\tString value = Bytes.toString(cell.getValueArray(),cell.getValueOffset(),cell.getValueLength());\n\t\t\tsb.append(column).append(":").append(value).append(";\\t");\n\t\t}\n\t\tSystem.out.println(sb.toString());\n\t}\n\t// 7.查数据(scan)\n\tpublic static void scan_Data(String tableName) {\n\t\tTable table = null;\n\t\ttry {\n\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\tResultScanner results = table.getScanner(new Scan());\n\t\t\tSystem.out.println(tableName + "表\\nROW\\t\\tCOLUMN+CELL");\n\t\t\tfor (Result result : results) {\n\t\t\t\tCell[] cells = result.rawCells();\n\t\t\t\tprint_Cells(cells);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 7.2 查数据(scan + filter)\n\tpublic static void filter_Data(String tableName, Filter filter, int limit) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\tScan scan = new Scan().setFilter(filter).setLimit(limit);\n\t\tResultScanner resultScan = table.getScanner(scan);\n\t\tSystem.out.println(tableName + "表(filter)\\nROW\\t\\tCOLUMN+CELL");\n\t\tfor (Result result : resultScan) {\n\t\t\tCell[] cells = result.rawCells();\n\t\t\tprint_Cells(cells);\n\t\t}\n\t\ttable.close();\n\t}\n\t// 8. 删除多行数据\n\tpublic static void delete_Data(String tableName, String... rows) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t//Delete delete = new Delete(Bytes.toBytes(rowKey));\n\t\tList<Delete> deleteList = new ArrayList<Delete>();\n\t\tfor (String row:rows) {\n\t\t\tDelete delete = new Delete(Bytes.toBytes(row));\n\t\t\tdeleteList.add(delete);\n\t\t}\n\t\ttable.delete(deleteList);\n\t\ttable.close();\n\t\tSystem.out.println("删除成功");\n\t}\n\t// 8.1 删除单元格(Cell)数据\n\tpublic static void delete_Cell(String tableName,  String rowKey, String columnFamily, String column ) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\tDelete delete = new Delete(Bytes.toBytes(rowKey));\n\t\tdelete.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\t\t//删除最后一版本\n\t\t//delete.addColumns(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\t\t//删除所有版本\n\t\ttable.delete(delete);\n\t\ttable.close();\n\t}\n\n\tpublic static void main(String[] args) throws IOException {\n\t\tSystem.out.println("============================start=========================");\n\t\t// 1.判断表是否存在\n\t\t//is_Exists("student");\n\t\t\n\t\t// 3.创建命名空间\n\t\t//create_NameSpace("std");\n\t\t\n\t\t// 2.创建表\n\t\t//create_Table("std:stu");\n\t\t\n\t\t// 4.删除表\n\t\t//drop_Table("std:stu");\n\t\t\n\t\t// 5.插入数据\n\t\t//put_Data("std:stu", "1003", "info1", "addr", "beijing");\n\t\t//put_Data("std:stu", "1004", "info1", "sex", "男");\n\t\t//put_Data("std:stu", "1005", "info1", "class", "2");\n\t\t\n\t\t// 6.查数据(get)\n\t\tget_Data("std:stu", "1002");\n\t\tget_Data("std:stu", "1002", "info1");\n\t\t\n\t\t// 7.查数据(scan)\n\t\tscan_Data("std:stu");\n\t\t\n\t\t// 7.1 查数据(scan + filter)\n\t\t//filter_Data("std:stu", new PrefixFilter(Bytes.toBytes("100")), 10);\t//筛选出行键以row为前缀的所有的行\n\t\t//filter_Data("std:stu", new RandomRowFilter((float) 0.2), 10);\t//按照一定的几率（<=0会过滤掉所有的行，>=1会包含所有的行）来返回随机的结果集\n\t\t//filter_Data("std:stu", new KeyOnlyFilter(), 10); // 返回所有的行，但值全是空 \n\t\t//  筛选出匹配的所有的行  \n\t\tfilter_Data("std:stu", new RowFilter(CompareFilter.CompareOp.LESS, new BinaryComparator(Bytes.toBytes("1002"))), 10);\n\t\t\n\t\t// 8. 删除多行数据数据\n\t\t//delete_Data("std:stu", "1003","1004");\n\t\t\n\t\t// 8.1删除单元格数据\n\t\t//delete_Cell("std:stu", "1005", "info1", "name");\n\t\t\n\t\tscan_Data("std:stu");\n\t\t\n\t\tSystem.out.println("============================end==========================");\n\t\t// end:关闭资源和连接\n\t\tclose();\n\t}\n\n}\n\n\n\n# MySQL数据插入到HBase\n\n----------------------------------------\n\n插入HBase\n\npackage com.hrbu.hbase;\n\nimport java.io.IOException;\nimport java.util.List;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.Cell;\nimport org.apache.hadoop.hbase.CellUtil;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Admin;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\nimport org.apache.hadoop.hbase.client.Connection;\nimport org.apache.hadoop.hbase.client.ConnectionFactory;\nimport org.apache.hadoop.hbase.client.Put;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.ResultScanner;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.client.Table;\nimport org.apache.hadoop.hbase.client.TableDescriptor;\nimport org.apache.hadoop.hbase.client.TableDescriptorBuilder;\nimport org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException;\nimport org.apache.hadoop.hbase.util.Bytes;\n\npublic class Sqoop_Hbase {\n\tpublic static Connection connect = null;\n\tpublic static Admin admin = null;\n\tpublic static void init() {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 HBaseConfiguration 的单例方法实例化)\n\t\t\tConfiguration conf = HBaseConfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientPort", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = ConnectionFactory.createConnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getAdmin();\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\tSystem.out.println("创建hbase连接对象异常");\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("admin关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t}\n\t\n\t// 插入数据\n\tpublic static void put_Data(String tableName, String columnFamily,List<Staff> list) throws IOException {\n\t\t\n\t\tif(admin.tableExists(TableName.valueOf(tableName))) {\n\t\t\tSystem.out.println(tableName + "表已经存在");\n\t\t}else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\tTableDescriptorBuilder tableBuilder = TableDescriptorBuilder.newBuilder(TableName.valueOf(tableName));\n\t\t\t// 列族\n\t\t\tColumnFamilyDescriptor info1 = ColumnFamilyDescriptorBuilder.of(columnFamily);\n\t\t\ttableBuilder.setColumnFamily(info1);\n\t\t\t// 5.构建表描述\n\t\t\tTableDescriptor tableDesc = tableBuilder.build();\n\t\t\tadmin.createTable(tableDesc);\n\t\t\tSystem.out.println(tableName + "\\t表创建成功");\n\t\t\t\n\t\t\tTable table = null;\n\t\t\ttry {\n\t\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\t\t\t//解决数字(int double乱码) 先转字符,再转字符数组\n\t\t\t\t\tPut put = new Put(Bytes.toBytes(String.valueOf(list.get(i).getId())));\n\t\t\t\t\t//汉字乱码该怎么解决(将utf-8的汉字转换成unicode格式汉字码  不好使)\n\t\t\t\t\tput.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes("name"), Bytes.toBytes(list.get(i).getName()));\n\t\t\t\t\tput.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes("sex"), Bytes.toBytes(list.get(i).getSex()));\n\t\t\t\t\ttable.put(put);\n\t\t\t\t}\n\t\t\t} catch(NoSuchColumnFamilyException e){\n\t\t\t\tSystem.out.println("异常:没有此列族");\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}finally {\n\t\t\t\ttry {\n\t\t\t\t\tif(table!=null) {\n\t\t\t\t\t\ttable.close();\n\t\t\t\t\t}\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t//外部调用的方法(算是封装好的)\n\tpublic static void main_Use(String tableName, String columnFamily,List<Staff> list){\n\t\tinit();\n\t\ttry {\n\t\t\tput_Data(tableName, columnFamily, list);\n\t\t\tscan_Data(tableName);\n\t\t} catch (IOException e) {\n\t\t\t//e.printStackTrace();\n\t\t\tSystem.out.println("admin异常");\n\t\t}finally {\n\t\t\tclose();\n\t\t}\n\t\tSystem.out.println("插入数据成功");\n\t}\n\t\n\t\n\t/****************************以下为多余代码*****************************************/\n\t// 7.查数据(scan)\n\tpublic static void scan_Data(String tableName) {\n\t\tTable table = null;\n\t\ttry {\n\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\tResultScanner results = table.getScanner(new Scan());\n\t\t\tSystem.out.println(tableName + "表\\nROW\\t\\tCOLUMN+CELL");\n\t\t\tfor (Result result : results) {\n\t\t\t\tCell[] cells = result.rawCells();\n\t\t\t\tprint_Cells(cells);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_Cells(Cell[] cells) {\n\t\tfor (Cell tempCell : cells) {\n\t\t\tSystem.out.println(Bytes.toString(CellUtil.cloneRow(tempCell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + Bytes.toString(CellUtil.cloneFamily(tempCell)) + ":" +  Bytes.toString(CellUtil.cloneQualifier(tempCell))\n\t\t\t\t\t+ ",timestamp=" + tempCell.getTimestamp() \n\t\t\t\t\t+ ", value=" + Bytes.toString(CellUtil.cloneValue(tempCell)) );\n\t\t}\n\t}\n\t /**\n     * 1将utf-8的汉字转换成unicode格式汉字码\n     * @param string\n     * @return\n     */\n    public static String stringToUnicode(String string) {\n\n        StringBuffer unicode = new StringBuffer();\n        for (int i = 0; i < string.length(); i++) {\n            char c = string.charAt(i);\n            unicode.append("\\\\u" + Integer.toHexString(c));\n        }\n        String str = unicode.toString();\n\n        return str.replaceAll("\\\\\\\\", "0x");\n    }\n\n    /**\n     * 2将unicode的汉字码转换成utf-8格式的汉字\n     * @param unicode\n     * @return\n     */\n    public static String unicodeToString(String unicode) {\n\n        String str = unicode.replace("0x", "\\\\");\n\n        StringBuffer string = new StringBuffer();\n        String[] hex = str.split("\\\\\\\\u");\n        for (int i = 1; i < hex.length; i++) {\n            int data = Integer.parseInt(hex[i], 16);\n            string.append((char) data);\n        }\n        return string.toString();\n    }\n\n}\n\n\n读MySQL\n\npackage com.hrbu.hbase;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\nimport java.util.ArrayList;\nimport java.util.List;\n\n\npublic class Sqoop_Mysql {\n\tpublic static Connection connect = null;\n\t\n\tpublic static void init() {\n\t\t//驱动程序名\n\t\tString driver = "com.mysql.cj.jdbc.Driver";\n\t\t//url指向要访问的数据库名\n\t\tString url = "jdbc:mysql://hadoop1:3306/company?useUnicode=true&characterEncoding=utf-8&useSSL=false";\n\t\t//mysql配置时的用户名\n\t\tString username = "root";\n\t\t//密码\n\t\tString password = "123456789";\n\t\t\n\t\ttry {\n\t\t\t//加载驱动程序\n\t\t\tClass.forName(driver);\n\t\t\tconnect = DriverManager.getConnection(url,username,password);\n\t\t\tif (!connect.isClosed()) {\n                System.out.println("数据库连接成功");\n            }\n\t\t} catch (ClassNotFoundException|SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} \n\t}\n\t\n\tpublic static void close(){\n\t\tif(connect!=null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\t\n\tpublic static List<Staff> selectAllFromStaff() {\n\t\t//实例化Statement对象\n\t\tList<Staff> list = new ArrayList<Staff>();\n\t\tStatement stmt = null;\n\t\ttry {\n\t\t\tstmt = connect.createStatement();\n\t\t\tString sql = "select * from staff";\n\t\t\tResultSet resultSet = stmt.executeQuery(sql);\n\t\t\twhile(resultSet.next()) {\n\t\t\t\tStaff staff = new Staff();\n\t\t\t\tstaff.setId(resultSet.getInt("id"));\n\t\t\t\tstaff.setName(resultSet.getString("name"));\n\t\t\t\tstaff.setSex(resultSet.getString("sex"));\n\t\t\t\tlist.add(staff);\n\t\t\t}\n\t\t\t\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(stmt!=null) {\n\t\t\t\t\tstmt.close();\n\t\t\t\t}\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\treturn list;\n\t}\n\t\n\tpublic static void print(List<Staff> list) {\n\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\tSystem.out.println(list.get(i).getId() + "\\t" +list.get(i).getName() + "\\t" + list.get(i).getSex());\n\t\t}\n\t}\n\t//外部调用的方法(算是封装好的)\n\tpublic static List<Staff> main_Use() {\n\t\tinit();\n\t\tList<Staff> list = selectAllFromStaff();\n\t\tclose();\n\t\treturn list;\n\t}\n}\n\nclass Staff {\n\tint id;\n\tString name;\n\tString sex;\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\tpublic String getSex() {\n\t\treturn sex;\n\t}\n\tpublic void setSex(String sex) {\n\t\tthis.sex = sex;\n\t}\n}\n\n\nimport java.util.List;\n\npublic class Sqoop_Test {\n\tpublic static void main(String[] args) {\n\t\tList<Staff> list = Sqoop_Mysql.main_Use();\n\t\tSqoop_Hbase.main_Use("staff", "info", list);\n\t}\n}\n\n\npackage com.hrbu.hbase;\n\nimport java.io.IOException;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Admin;\nimport org.apache.hadoop.hbase.client.Connection;\nimport org.apache.hadoop.hbase.client.ConnectionFactory;\n\npublic class Test {\n\n\tpublic static void main(String[] args) throws IOException {\n\t\t// TODO Auto-generated method stub\n\t\tConfiguration conf = null;\n\t\tconf = HBaseConfiguration.create();\n\t\tconf.set("hbase.zookeeper.quorum", "192.168.1.100");\n\t\tconf.set("hbase.zookeeper.property.clientPort", "2181");\n\t\tSystem.out.println("11111111111111111111");\n\t\t//2. 创建连接对象\n\t\tConnection connect = null;\n\t\tconnect = ConnectionFactory.createConnection(conf);\n\t\tSystem.out.println("22222222222222222222");\n\t\t//3. 获取管理员对象\n\t\tAdmin admin = connect.getAdmin();\n\t\tSystem.out.println("333333333333333333333" + admin + "333" + connect);\n\t\t//System.out.println(admin.tableExists(TableName.valueOf("student")));\n\t\tif(admin.tableExists(TableName.valueOf("student"))) {\n\t\t\tSystem.out.println("表已经存在");\n\t\t}else {\n\t\t\tSystem.out.println("表不存在");\n\t\t}\n\t\tSystem.out.println("44444444444444444444");\n\t\tadmin.close();\n\t\tconnect.close();\n\t}\n\n}\n\n\n\n# hive代码\n\n----------------------------------------\n\n表操作\n\npackage com.hrbu.hive;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\npublic class ClusterTestApi {\n\t\n\t//驱动名称\n\tprivate static String driverName = "org.apache.hive.jdbc.HiveDriver";\n\t//连接用的url\n\tprivate static String url = "jdbc:hive2://8.8.8.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static String user = "banana";\n\tprivate static String password = "";\n\t\n\tprivate static Connection conn = null;\n\tprivate static Statement stmt = null;\n\tprivate static ResultSet rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@Before\t//表示在任意使用@Test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tClass.forName(driverName);\n\t\t\tconn = DriverManager.getConnection(url,user,password);\n\t\t\tstmt = conn.createStatement();\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t//释放资源\n\t@After //表示在任意使用@Test注解标注的public void方法之后执行\n\tpublic void destory() throws SQLException {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@Test\n\tpublic void create_DataBase() throws SQLException {\n\t\tString sql = "create database IF NOT EXISTS hive_jdbc_test";\t//create database IF NOT EXISTS hive_jdbc_test\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@Test\n\tpublic void create_StudentTable() throws SQLException {\n\t\t//String sql0 = "use hive_jdbc_test";\n\t\tString sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tSystem.out.println("Running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@Test\n\tpublic void show_DataBases() throws SQLException {\n\t\tString sql = "show Databases";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@Test\n\tpublic void show_Tables() throws SQLException {\n\t\tString sql = "show tables";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t//加载数据\n\t@Test\n\tpublic void load_Data() throws SQLException {\n\t\t//linux路径\n\t\tString filePath = " \'/soft/module/datas/short-student-utf8.txt\' ";\n\t\tString sql = "load data local inpath" + filePath + "overwrite into table student";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@Test\n\tpublic void select_Data() throws SQLException {\n\t\tString sql = "select * from test_db.student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\tSystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString("code") + "\\t" + rs.getString("name") + "\\t" + rs.getString("gender") + "\\t" + rs.getString("school") + "\\t" + rs.getString("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@Test\n\tpublic void count_Data() throws SQLException {\n\t\tString sql = "select count(*) from test_db.student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\tSystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getInt(1));\n\t\t}\n\t}\n\t//删除表\n\t@Test\n\tpublic void drop_table() throws SQLException {\n\t\tString sql = "drop table student";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("drop table success");\n\t}\n\t\n\t//删除数据库\n\t@Test\n\tpublic void drop_DataBase() throws SQLException {\n\t\t//强制删除数据库\n\t\t//String sql = "DROP DATABASE IF EXISTS hive_jdbc_test CASCADE";\n\t\tString sql = "DROP DATABASE IF EXISTS hive_jdbc_test";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("DROP DATABASE success");\n\t}\n\t\n\tpublic static void main(String[] args) throws SQLException {\n\t\tClusterTestApi test = new ClusterTestApi();\n\t\ttest.drop_DataBase();\n\t}\n}\n\n\npackage com.hrbu.hive;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\n\n\npublic class TeatApi {\n\t\n\t//驱动名称\n\tprivate static String driverName = "org.apache.hive.jdbc.HiveDriver";\n\t//连接用的url\n\tprivate static String url = "jdbc:hive2://192.168.1.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static String user = "root";\n\tprivate static String password = "";\n\t\n\tprivate static Connection conn = null;\n\tprivate static Statement stmt = null;\n\tprivate static ResultSet rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@Before\t//表示在任意使用@Test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tClass.forName(driverName);\n\t\t\tconn = DriverManager.getConnection(url,user,password);\n\t\t\tstmt = conn.createStatement();\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t//释放资源\n\t@After //表示在任意使用@Test注解标注的public void方法之后执行\n\tpublic void destory() throws SQLException {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@Test\n\tpublic void create_DataBase() throws SQLException {\n\t\tString sql = "create database IF NOT EXISTS hive_jdbc_test";\t//create database IF NOT EXISTS hive_jdbc_test\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@Test\n\tpublic void create_StudentTable() throws SQLException {\n\t\t//String sql0 = "use hive_jdbc_test";\n\t\tString sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tSystem.out.println("Running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@Test\n\tpublic void show_DataBases() throws SQLException {\n\t\tString sql = "show Databases";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@Test\n\tpublic void show_Tables() throws SQLException {\n\t\tString sql = "show tables";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t//加载数据\n\t@Test\n\tpublic void load_Data() throws SQLException {\n\t\t//linux路径\n\t\tString filePath = "\'/soft/datas/short-student-utf8.txt\'";\n\t\tString sql = "load data local inpath" + filePath + "overwrite into table test_db.student";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@Test\n\tpublic void select_Data() throws SQLException {\n\t\tString sql = "select * from test_db.student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\tSystem.out.println("学号\\t\\t\\t姓名\\t性别\\t学校\\t\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString("code") + "\\t" + rs.getString("name") + "\\t" + rs.getString("gender") + "\\t" + rs.getString("school") + "\\t" + rs.getString("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@Test\n\tpublic void count_Data() throws SQLException {\n\t\tString sql = "select count(*) from test_db.student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getInt(1));\n\t\t}\n\t}\n\t//删除表\n\t@Test\n\tpublic void drop_table() throws SQLException {\n\t\tString sql = "drop table student";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("drop table success");\n\t}\n\t\n\t//删除数据库\n\t@Test\n\tpublic void drop_DataBase() throws SQLException {\n\t\t//强制删除数据库\n\t\t//String sql = "DROP DATABASE IF EXISTS flume_hive CASCADE";\n\t\tString sql = "DROP DATABASE IF EXISTS hive_jdbc_test";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("DROP DATABASE success");\n\t}\n\t\n\tpublic static void main(String[] args) throws SQLException {\n\t\tnew TeatApi().drop_DataBase();\n\t}\n}\n\n\nUDF\n\npackage com.hrbu.hive;\n\n\nimport org.apache.commons.lang3.StringUtils;\nimport org.apache.hadoop.hive.ql.exec.UDF;\nimport org.apache.hadoop.io.Text;\n\npublic class GenderUDF extends UDF {\n\t/**\n\t * 方法名必须是evaluate,hive执行时会找它\n\t * 业务逻辑为:判断输入值,"M"返回男,"F"返回女,否则返回未知\n\t * \n\t */\n\tpublic Text evaluate(Text text) {\n\t\tString textStr = text.toString();\n\t\tif(StringUtils.isNotEmpty(textStr)) {\n\t\t\tif(textStr.equalsIgnoreCase("M")) {\n\t\t\t\treturn new Text("男");\n\t\t\t}else if(textStr.equalsIgnoreCase("F")){\n\t\t\t\treturn new Text("女");\n\t\t\t}else {\n\t\t\t\treturn new Text("未知");\n\t\t\t}\n\t\t\t\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\n\n\n# RedisApi\n\n----------------------------------------\n\npackage com.hrbu.RedisApi;\n\nimport java.util.HashMap;\n\nimport redis.clients.jedis.Jedis;\n\n/**\n * Hello world!\n *\n */\npublic class App \n{\n    public static void main( String[] args )\n    {\n    \tJedis jedis = new Jedis("8.8.8.8",6379);\n    \t//jedis.flushAll();\n        //System.out.println( "Hello World!" + jedis.ping());\n        /*****1.字符串(String)*****/\n//    \tjedis.set("name1", "aaa");\n//        System.out.println(jedis.get("name1"));\n//    \tjedis.del("name1");\n//    \t\n//    \tjedis.mset("name1","aaa","name2","bbb","name3","ccc");\n//    \tSystem.out.println(jedis.mget("name1","name2","name3"));\n//    \t\n//    \tSystem.out.println(jedis.exists("name1"));\n//    \tSystem.out.println(jedis.exists("name","name0","name1","name2","name3"));\n//    \tSystem.out.println(jedis.keys("*"));\n//    \tSystem.out.println(jedis.type("name1"));\n//    \tSystem.out.println(jedis.randomKey());\n//    \tSystem.out.println(jedis.flushDB());\n//    \tSystem.out.println(jedis.get("name1"));\n//    \tSystem.out.println(jedis.flushAll());\n//    \tSystem.out.println(jedis.randomKey());\n    \t\n    \t/****2.哈希(Hash)******/\n    \t/*\n    \tHashMap<String,String> hmap = new HashMap<String,String>();\n    \thmap.put("name5", "eee");\n    \thmap.put("name4", "ddd");\n    \thmap.put("id", "666");\n    \t// 设置值\n    \tjedis.hset("user", "name6", "fff");\n    \tjedis.hmset("user", hmap);\n    \t// 取值\n    \tSystem.out.println("hget:\\t" + jedis.hget("user", "name4"));\n    \tSystem.out.println("hmget:\\t" + jedis.hmget("user", "name4","name5","name6"));\n    \tSystem.out.println("hgetAll:\\t" + jedis.hgetAll("user"));\n    \tSystem.out.println("keys:\\t" + jedis.keys("*"));\n    \tSystem.out.println("hkeys:\\t" + jedis.hkeys("user"));\n    \tSystem.out.println("hvals:\\t" + jedis.hvals("user"));\n    \tSystem.out.println("hlen:\\t" + jedis.hlen("user"));\n    \t// 删除field\n    \tSystem.out.println("hdel\\t" + jedis.hdel("user","name4"));\n    \tSystem.out.println("hdel\\t" + jedis.hdel("user","name5","name6"));\n    \tSystem.out.println(jedis.hgetAll("user"));\n    \t// 清空\n    \tSystem.out.println(jedis.flushAll());\n    \tSystem.out.println(jedis.hgetAll("user"));\n    \t*/\n\n    \t\n    \t/*******3.列表List(类似于栈???)*********/\n    \t/*\n    \t// 放值\n    \tjedis.lpushx("list", "999");\n    \tjedis.lpush("list", "hhh","ggg","iii");\t\t//1或多到  开始\n    \tjedis.rpush("list", "kkk","jjj");\t\t\t//1或多到  末尾\n    \tjedis.lpushx("list", "666");\t\t\t\t// 插入已存在列表头部\n    \t// 取值\n    \tSystem.out.println(jedis.lrange("list", 0, 10));\t//获取指定范围元素\n    \tSystem.out.println(jedis.blpop("list","5"));\t\t//移出 第一个元素 等待超时\n    \tSystem.out.println(jedis.brpop("list", "5"));\t\t//移出 最后一个元素 等待超时\n    \tSystem.out.println(jedis.lindex("list", 3));\t\t//索引获取元素\n    \tSystem.out.println(jedis.llen("list"));\t\t\t\t//获取列表长度\n    \tSystem.out.println(jedis.lrange("list", 0, 10));\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t*/\n    \t\n    \t\n    \t/********4.集合(Set)****************/\n    \t/*\n    \t// 放值\n    \tjedis.sadd("set", "lll", "nnn", "mmm" ,"ooo");\n    \t// 取值\n    \tSystem.out.println(jedis.smembers("set"));\t\t// 所有元素\n    \tSystem.out.println(jedis.sismember("set", "ooo"));\t\t\t// key(value)是否存在\n    \tSystem.out.println(jedis.sismember("sett", "ooo"));\n    \tSystem.out.println(jedis.srem("set","ooo","mmm"));\t\t// 移除\n    \tSystem.out.println(jedis.smembers("set"));\n    \t// 运算\n    \tjedis.sadd("set", "set");\n    \tjedis.sadd("sett", "lll", "nnn", "mmm", "ooo", "sett");\n    \tSystem.out.println(jedis.sinter("set", "sett"));\t\t// 交集\n    \tSystem.out.println(jedis.sdiff("set", "sett"));\t\t\t// 差集\n    \tSystem.out.println(jedis.sunion("set", "sett"));\t\t// 并集\n    \t\n    \tSystem.out.println(jedis.scard("set"));\t\t// 元素数目\n    \tSystem.out.println(jedis.scard("sett"));\t\t// 元素数目\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t*/\n    \t\n    \t/********5.有序集合sorted set(zset)*************/\n    \tHashMap<String,Double> scoremap = new HashMap<String, Double>(); \n    \tscoremap.put("vvv", 0.22);\n    \tscoremap.put("ppp", 0.16);\n    \tscoremap.put("sss", 0.19);\n    \tscoremap.put("qqq", 0.17);\n    \tscoremap.put("www", 0.23);\n    \tscoremap.put("rrr", 0.18);\n    \tscoremap.put("uuu", 0.21);\n    \tscoremap.put("ttt", 0.20);\n    \t// 放值\n    \tjedis.zadd("zset", scoremap);\t\t// 添加元素或更新分数\n    \tjedis.zadd("zset", 0.24, "xxx");\n    \t// 元素查找修改\n    \tSystem.out.println(jedis.zrange("zset", 0, 10));\t\t// 根据索引返回区间\n    \tSystem.out.println(jedis.zcount("zset", 0.18, 0.21));\t\t// 根据分数返回元素数\n    \tSystem.out.println(jedis.zrem("zset", "sss", "ppp"));\t\t// 移除元素\n    \tSystem.out.println(jedis.zcard("zset"));\t\t\t\t\t// 元素数目\n    \tSystem.out.println(jedis.zincrby("zset", 1, "www"));\t\t// 分数增量\n    \tSystem.out.println(jedis.zscore("zset", "www"));\t\t// 返回分数值\n    \tSystem.out.println(jedis.zrank("zset", "www"));\t\t// 返回元素索引\n    \tSystem.out.println(jedis.zrangeByScore("zset", 0, 2));\t\t// 根据分数返回元素区间\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t\n    \t\n        jedis.close();\n    }\n}\n',normalizedContent:'# 环境\n\n----------------------------------------\n\n基于windows下eclipse的mapreduce开发环境配置 https://www.cnblogs.com/hephaestus/p/12608456.html\n\n\n# mapreduce代码\n\n----------------------------------------\n\nmymapper\n\npackage mrproject;\n\nimport java.io.ioexception;\n\nimport org.apache.hadoop.io.intwritable;\nimport org.apache.hadoop.io.longwritable;\nimport org.apache.hadoop.io.text;\nimport org.apache.hadoop.mapreduce.mapper;\n\npublic class mymapper extends mapper<longwritable, text, text, intwritable> {\n\t /**\n     * map阶段的业务逻辑处理就写在map()方法中\n     * maptask会对每一行输入数据调用一次我们自定义的map()方法\n     * @throws interruptedexception\n     */\n\t private text word = new text();//text是hadoop针对字符串的序列化包装类\n     private intwritable one = new intwritable(1);//intwritable是hadoop针对整型的序列化包装类---更多关于hadoop的序列化包装类请查阅相关资料\n     \n\t@override\n\tprotected void map(longwritable key, text value, context context)\n\t\t\tthrows ioexception, interruptedexception {\n\t\t//将maptask传递给我们的文本内容先转换成string\n        string line=value.tostring();\n        //按照空格行切割单词\n        string[] words=line.split(" ");\n        //将单词输出为<单词，1>\n        for(string w:words) {\n            word.set(w);\n           //将单词作为key，将次数1作为value，以便于后续的数据分发，可以根据单词分发，以便于相同单词会到相同的reduce task\n            context.write(word,one);\n        }\n\t}\n\t\n}\n\n\nmyreducer\n\npackage mrproject;\n\nimport java.io.ioexception;\n\nimport org.apache.hadoop.io.intwritable;\nimport org.apache.hadoop.io.text;\nimport org.apache.hadoop.mapreduce.reducer;\n\npublic class myreducer extends reducer<text, intwritable, text, intwritable> {\n\t /**\n\t  * reducer中主要的方式就是reduce,用户处理map阶段产生的key-value数据，如下样例\n     * <angel,1> <angel,1> <angel,1> <angel,1> <angel,1>\n     * <hello,1> <hello,1> <hello,1> <hello,1> <hello,1> <hello,1>\n     * <banana,1> <banana,1> <banana,1> <banana,1> <banana,1> <banana,1>\n     * 入参key：是一组单词的kv对应的key,将相同单词的一组传递，如此时key是hello，那么参数二是一个迭代器，一组数\n     * @throws interruptedexception\n     * @throws ioexception\n     */\n\tprivate intwritable sum= new intwritable();\n\t@override\n\tprotected void reduce(text key, iterable<intwritable> values,context context) throws ioexception, interruptedexception {\n\t\tint count=0;\n\t     /**\n\t             iterator<intwritable> iterator=values.iterator();\n\t             while(iterator.hasnext()) {\n\t                 count+=iterator.next().get();\n\t             }\n\t     */\n\t\t//此处的values是某个key对应的所有的value，例如上面数据angel对应了5个1\n\t             for(intwritable value:values) {\n\t                 count+=value.get();\n\t             }\n\t             sum.set(count);\n\t             //上下文输出\n\t             context.write(key, sum);\n\t }   \n}\n\n\nmrapp\n\npackage mrproject;\n\nimport java.io.ioexception;\n\nimport org.apache.hadoop.conf.configuration;\nimport org.apache.hadoop.fs.path;\nimport org.apache.hadoop.io.intwritable;\nimport org.apache.hadoop.io.text;\nimport org.apache.hadoop.mapreduce.job;\nimport org.apache.hadoop.mapreduce.lib.input.fileinputformat;\nimport org.apache.hadoop.mapreduce.lib.output.fileoutputformat;\n\n\n\npublic class mrapp {\n\tpublic static void main(string[] args) throws illegalargumentexception, ioexception, classnotfoundexception, interruptedexception {\n        //此处主要用于本地运行，如果生产环境使用shell命令运行，则命令中会有输入输出目录\n        //本地运行时为了方便没有给到args，此处代码处理下给个默认值\n        if(args.length <2)\n        {\n           args= new string[]{\n                     "hdfs://10.20.10.67:9000/input",\n                     "hdfs://10.20.10.67:9000/output4"\n           };   \n        }\n        configuration conf=new configuration();\n        /*\n         * 集群中节点都有配置文件\n        conf.set("mapreduce.framework.name.", "yarn");\n        conf.set("yarn.resourcemanager.hostname", "mini1");\n        */\n        job job=job.getinstance(conf);\n        //jar包在哪里,现在在客户端，传递参数\n        //任意运行，类加载器知道这个类的路径，就可以知道jar包所在的本地路径\n        job.setjarbyclass(mrapp.class);\n        //指定本业务job要使用的mapper/reducer业务类\n        job.setmapperclass(mymapper.class);\n        job.setreducerclass(myreducer.class);\n        //指定mapper输出数据的kv类型\n        job.setmapoutputkeyclass(text.class);\n        job.setmapoutputvalueclass(intwritable.class);\n        //指定最终输出的数据kv类型\n        job.setoutputkeyclass(text.class);\n        job.setoutputkeyclass(intwritable.class);\n        //指定job的输入原始文件所在目录\n        fileinputformat.setinputpaths(job, new path(args[0]));\n        //指定job的输出结果所在目录\n        fileoutputformat.setoutputpath(job, new path(args[1]));\n        //将job中配置的相关参数及job所用的java类在的jar包，提交给yarn去运行\n        //提交之后，此时客户端代码就执行完毕，退出\n        //job.submit();\n        //等集群返回结果在退出\n        boolean res=job.waitforcompletion(true);\n        system.exit(res?0:1);\n    }\n}\n\n\n\n# hbase代码\n\n----------------------------------------\n\n表操作(ddl dml)\n\npackage com.hrbu.hbase;\n\nimport java.io.ioexception;\nimport java.util.arraylist;\nimport java.util.list;\n\nimport org.apache.hadoop.conf.configuration;\nimport org.apache.hadoop.hbase.cell;\nimport org.apache.hadoop.hbase.cellutil;\nimport org.apache.hadoop.hbase.compareoperator;\nimport org.apache.hadoop.hbase.hbaseconfiguration;\nimport org.apache.hadoop.hbase.namespacedescriptor;\nimport org.apache.hadoop.hbase.namespaceexistexception;\nimport org.apache.hadoop.hbase.tablename;\nimport org.apache.hadoop.hbase.client.admin;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptor;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptorbuilder;\nimport org.apache.hadoop.hbase.client.connection;\nimport org.apache.hadoop.hbase.client.connectionfactory;\nimport org.apache.hadoop.hbase.client.delete;\nimport org.apache.hadoop.hbase.client.get;\nimport org.apache.hadoop.hbase.client.put;\nimport org.apache.hadoop.hbase.client.result;\nimport org.apache.hadoop.hbase.client.resultscanner;\nimport org.apache.hadoop.hbase.client.scan;\nimport org.apache.hadoop.hbase.client.table;\nimport org.apache.hadoop.hbase.client.tabledescriptor;\nimport org.apache.hadoop.hbase.client.tabledescriptorbuilder;\nimport org.apache.hadoop.hbase.filter.binarycomparator;\nimport org.apache.hadoop.hbase.filter.comparefilter;\nimport org.apache.hadoop.hbase.filter.filter;\nimport org.apache.hadoop.hbase.filter.keyonlyfilter;\nimport org.apache.hadoop.hbase.filter.prefixfilter;\nimport org.apache.hadoop.hbase.filter.randomrowfilter;\nimport org.apache.hadoop.hbase.filter.rowfilter;\nimport org.apache.hadoop.hbase.filter.valuefilter;\nimport org.apache.hadoop.hbase.regionserver.nosuchcolumnfamilyexception;\nimport org.apache.hadoop.hbase.util.bytes;\n\n/**\n * ddl: 1.判断表是否存在 2.创建表 3.创建命名空间 4.删除表 \n * dml: 5.插入数据 6.查数据(get) 7.查数据(scan) 8.删除数据\n */\npublic class testapi {\n\n\tpublic static connection connect = null;\n\tpublic static admin admin = null;\n\tstatic {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 hbaseconfiguration 的单例方法实例化)\n\t\t\tconfiguration conf = hbaseconfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientport", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = connectionfactory.createconnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getadmin();\n\t\t} catch (ioexception e) {\n\t\t\t// todo auto-generated catch block\n\t\t\tsystem.out.println("创建hbase连接对象异常");\n\t\t\te.printstacktrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("admin关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// 1.判断表是否存在\n\tpublic static void is_exists(string tablename) throws ioexception {\n\t\tif (admin.tableexists(tablename.valueof(tablename))) {\n\t\t\tsystem.out.println(tablename + "表已经存在");\n\t\t} else {\n\t\t\tsystem.out.println(tablename + "表不存在");\n\t\t}\n\t}\n\n\t// 2.创建表\n\tpublic static void create_table(string tablename) throws ioexception {\n\t\ttablename tablenametemp = tablename.valueof(tablename);\n\t\tif (admin.tableexists(tablenametemp)) {\n\t\t\tsystem.out.println(tablename + "表已经存在");\n\t\t} else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\ttabledescriptorbuilder tablebuilder = tabledescriptorbuilder.newbuilder(tablenametemp);\n\t\t\t// 列族\n\t\t\tcolumnfamilydescriptor info1 = columnfamilydescriptorbuilder.of("info1");\n\t\t\tcolumnfamilydescriptor info2 = columnfamilydescriptorbuilder.of("info2");\n\t\t\tcolumnfamilydescriptor info3 = columnfamilydescriptorbuilder.of("info3");\n\t\t\tlist<columnfamilydescriptor> cflist = new arraylist<columnfamilydescriptor>();\n\t\t\tcflist.add(info1);\n\t\t\tcflist.add(info2);\n\t\t\tcflist.add(info3);\n\t\t\ttablebuilder.setcolumnfamilies(cflist);\n\t\t\t// 5.构建表描述\n\t\t\ttabledescriptor tabledesc = tablebuilder.build();\n\t\t\tadmin.createtable(tabledesc);\n\t\t\tsystem.out.println(tablename + "\\t表创建成功");\n\t\t}\n\t}\n\n\t// 3.创建命名空间\n\tpublic static void create_namespace(string namespace) {\n\t\t// 创建命名空间描述器\n\t\tnamespacedescriptor descriptor = namespacedescriptor.create(namespace).build();\n\t\t//创建命名空间\n\t\ttry {\n\t\t\tadmin.createnamespace(descriptor);\n\t\t} catch(namespaceexistexception e) {\n\t\t\tsystem.out.println(namespace + "命名空间已存在");\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t\tsystem.out.println("--我会被执行吗--");\n\t}\n\t// 4.删除表\n\tpublic static void drop_table(string tablename) throws ioexception {\n\t\ttablename tablenametemp = tablename.valueof(tablename);\n\t\tif (admin.tableexists(tablenametemp)) {\n\t\t\tadmin.disabletable(tablenametemp);\n\t\t\tadmin.deletetable(tablenametemp);\n\t\t\tsystem.out.println("表" + tablename + "删除成功！ ");\n\t\t} else {\n\t\t\tsystem.out.println("表" + tablename + "不存在！ ");\n\t\t}\n\t}\n\t// 5.插入数据\n\tpublic static void put_data(string tablename, string rowkey, string columnfamily, string column, string value) {\n\t\ttable table = null;\n\t\ttry {\n\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\tput put = new put(bytes.tobytes(rowkey));\n\t\t\tput.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column), bytes.tobytes(value));\n\t\t\ttable.put(put);\n\t\t} catch(nosuchcolumnfamilyexception e){\n\t\t\tsystem.out.println("异常:没有此列族");\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t}finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (ioexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t\tsystem.out.println("数据插入成功");\n\t\t\n\t}\n\t// 6.查数据(get)\n\tpublic static void get_data(string tablename, string rowkey, string columnfamily, string column) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\t//get.addfamily(bytes.tobytes(columnfamily));\n\t\tget.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + "--" + columnfamily + "--" + column + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_data(string tablename, string rowkey, string columnfamily) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\tget.addfamily(bytes.tobytes(columnfamily));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + "--" + columnfamily + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_data(string tablename, string rowkey) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\t// 打印单元格信息\n\tprivate static void print_cells(cell[] cells) {\n\t\tfor (cell tempcell : cells) {\n\t\t\tsystem.out.println(bytes.tostring(cellutil.clonerow(tempcell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + bytes.tostring(cellutil.clonefamily(tempcell)) + ":" +  bytes.tostring(cellutil.clonequalifier(tempcell))\n\t\t\t\t\t+ ",timestamp=" + tempcell.gettimestamp() \n\t\t\t\t\t+ ", value=" + bytes.tostring(cellutil.clonevalue(tempcell)) );\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_cells2(cell[] cells) {\n\t\tstringbuilder sb = new stringbuilder();\n\t\tfor (cell cell : cells) {\n\t\t\tstring column = bytes.tostring(cell.getqualifierarray(), cell.getqualifieroffset(), cell.getqualifierlength());\n\t\t\tstring value = bytes.tostring(cell.getvaluearray(),cell.getvalueoffset(),cell.getvaluelength());\n\t\t\tsb.append(column).append(":").append(value).append(";\\t");\n\t\t}\n\t\tsystem.out.println(sb.tostring());\n\t}\n\t// 7.查数据(scan)\n\tpublic static void scan_data(string tablename) {\n\t\ttable table = null;\n\t\ttry {\n\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\tresultscanner results = table.getscanner(new scan());\n\t\t\tsystem.out.println(tablename + "表\\nrow\\t\\tcolumn+cell");\n\t\t\tfor (result result : results) {\n\t\t\t\tcell[] cells = result.rawcells();\n\t\t\t\tprint_cells(cells);\n\t\t\t}\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (ioexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 7.2 查数据(scan + filter)\n\tpublic static void filter_data(string tablename, filter filter, int limit) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\tscan scan = new scan().setfilter(filter).setlimit(limit);\n\t\tresultscanner resultscan = table.getscanner(scan);\n\t\tsystem.out.println(tablename + "表(filter)\\nrow\\t\\tcolumn+cell");\n\t\tfor (result result : resultscan) {\n\t\t\tcell[] cells = result.rawcells();\n\t\t\tprint_cells(cells);\n\t\t}\n\t\ttable.close();\n\t}\n\t// 8. 删除多行数据\n\tpublic static void delete_data(string tablename, string... rows) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t//delete delete = new delete(bytes.tobytes(rowkey));\n\t\tlist<delete> deletelist = new arraylist<delete>();\n\t\tfor (string row:rows) {\n\t\t\tdelete delete = new delete(bytes.tobytes(row));\n\t\t\tdeletelist.add(delete);\n\t\t}\n\t\ttable.delete(deletelist);\n\t\ttable.close();\n\t\tsystem.out.println("删除成功");\n\t}\n\t// 8.1 删除单元格(cell)数据\n\tpublic static void delete_cell(string tablename,  string rowkey, string columnfamily, string column ) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\tdelete delete = new delete(bytes.tobytes(rowkey));\n\t\tdelete.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column));\t\t//删除最后一版本\n\t\t//delete.addcolumns(bytes.tobytes(columnfamily), bytes.tobytes(column));\t\t//删除所有版本\n\t\ttable.delete(delete);\n\t\ttable.close();\n\t}\n\n\tpublic static void main(string[] args) throws ioexception {\n\t\tsystem.out.println("============================start=========================");\n\t\t// 1.判断表是否存在\n\t\t//is_exists("student");\n\t\t\n\t\t// 3.创建命名空间\n\t\t//create_namespace("std");\n\t\t\n\t\t// 2.创建表\n\t\t//create_table("std:stu");\n\t\t\n\t\t// 4.删除表\n\t\t//drop_table("std:stu");\n\t\t\n\t\t// 5.插入数据\n\t\t//put_data("std:stu", "1003", "info1", "addr", "beijing");\n\t\t//put_data("std:stu", "1004", "info1", "sex", "男");\n\t\t//put_data("std:stu", "1005", "info1", "class", "2");\n\t\t\n\t\t// 6.查数据(get)\n\t\tget_data("std:stu", "1002");\n\t\tget_data("std:stu", "1002", "info1");\n\t\t\n\t\t// 7.查数据(scan)\n\t\tscan_data("std:stu");\n\t\t\n\t\t// 7.1 查数据(scan + filter)\n\t\t//filter_data("std:stu", new prefixfilter(bytes.tobytes("100")), 10);\t//筛选出行键以row为前缀的所有的行\n\t\t//filter_data("std:stu", new randomrowfilter((float) 0.2), 10);\t//按照一定的几率（<=0会过滤掉所有的行，>=1会包含所有的行）来返回随机的结果集\n\t\t//filter_data("std:stu", new keyonlyfilter(), 10); // 返回所有的行，但值全是空 \n\t\t//  筛选出匹配的所有的行  \n\t\tfilter_data("std:stu", new rowfilter(comparefilter.compareop.less, new binarycomparator(bytes.tobytes("1002"))), 10);\n\t\t\n\t\t// 8. 删除多行数据数据\n\t\t//delete_data("std:stu", "1003","1004");\n\t\t\n\t\t// 8.1删除单元格数据\n\t\t//delete_cell("std:stu", "1005", "info1", "name");\n\t\t\n\t\tscan_data("std:stu");\n\t\t\n\t\tsystem.out.println("============================end==========================");\n\t\t// end:关闭资源和连接\n\t\tclose();\n\t}\n\n}\n\n\n\n# mysql数据插入到hbase\n\n----------------------------------------\n\n插入hbase\n\npackage com.hrbu.hbase;\n\nimport java.io.ioexception;\nimport java.util.list;\n\nimport org.apache.hadoop.conf.configuration;\nimport org.apache.hadoop.hbase.cell;\nimport org.apache.hadoop.hbase.cellutil;\nimport org.apache.hadoop.hbase.hbaseconfiguration;\nimport org.apache.hadoop.hbase.tablename;\nimport org.apache.hadoop.hbase.client.admin;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptor;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptorbuilder;\nimport org.apache.hadoop.hbase.client.connection;\nimport org.apache.hadoop.hbase.client.connectionfactory;\nimport org.apache.hadoop.hbase.client.put;\nimport org.apache.hadoop.hbase.client.result;\nimport org.apache.hadoop.hbase.client.resultscanner;\nimport org.apache.hadoop.hbase.client.scan;\nimport org.apache.hadoop.hbase.client.table;\nimport org.apache.hadoop.hbase.client.tabledescriptor;\nimport org.apache.hadoop.hbase.client.tabledescriptorbuilder;\nimport org.apache.hadoop.hbase.regionserver.nosuchcolumnfamilyexception;\nimport org.apache.hadoop.hbase.util.bytes;\n\npublic class sqoop_hbase {\n\tpublic static connection connect = null;\n\tpublic static admin admin = null;\n\tpublic static void init() {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 hbaseconfiguration 的单例方法实例化)\n\t\t\tconfiguration conf = hbaseconfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientport", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = connectionfactory.createconnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getadmin();\n\t\t} catch (ioexception e) {\n\t\t\t// todo auto-generated catch block\n\t\t\tsystem.out.println("创建hbase连接对象异常");\n\t\t\te.printstacktrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("admin关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t}\n\t\n\t// 插入数据\n\tpublic static void put_data(string tablename, string columnfamily,list<staff> list) throws ioexception {\n\t\t\n\t\tif(admin.tableexists(tablename.valueof(tablename))) {\n\t\t\tsystem.out.println(tablename + "表已经存在");\n\t\t}else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\ttabledescriptorbuilder tablebuilder = tabledescriptorbuilder.newbuilder(tablename.valueof(tablename));\n\t\t\t// 列族\n\t\t\tcolumnfamilydescriptor info1 = columnfamilydescriptorbuilder.of(columnfamily);\n\t\t\ttablebuilder.setcolumnfamily(info1);\n\t\t\t// 5.构建表描述\n\t\t\ttabledescriptor tabledesc = tablebuilder.build();\n\t\t\tadmin.createtable(tabledesc);\n\t\t\tsystem.out.println(tablename + "\\t表创建成功");\n\t\t\t\n\t\t\ttable table = null;\n\t\t\ttry {\n\t\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\t\t\t//解决数字(int double乱码) 先转字符,再转字符数组\n\t\t\t\t\tput put = new put(bytes.tobytes(string.valueof(list.get(i).getid())));\n\t\t\t\t\t//汉字乱码该怎么解决(将utf-8的汉字转换成unicode格式汉字码  不好使)\n\t\t\t\t\tput.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes("name"), bytes.tobytes(list.get(i).getname()));\n\t\t\t\t\tput.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes("sex"), bytes.tobytes(list.get(i).getsex()));\n\t\t\t\t\ttable.put(put);\n\t\t\t\t}\n\t\t\t} catch(nosuchcolumnfamilyexception e){\n\t\t\t\tsystem.out.println("异常:没有此列族");\n\t\t\t} catch (ioexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}finally {\n\t\t\t\ttry {\n\t\t\t\t\tif(table!=null) {\n\t\t\t\t\t\ttable.close();\n\t\t\t\t\t}\n\t\t\t\t} catch (ioexception e) {\n\t\t\t\t\te.printstacktrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t//外部调用的方法(算是封装好的)\n\tpublic static void main_use(string tablename, string columnfamily,list<staff> list){\n\t\tinit();\n\t\ttry {\n\t\t\tput_data(tablename, columnfamily, list);\n\t\t\tscan_data(tablename);\n\t\t} catch (ioexception e) {\n\t\t\t//e.printstacktrace();\n\t\t\tsystem.out.println("admin异常");\n\t\t}finally {\n\t\t\tclose();\n\t\t}\n\t\tsystem.out.println("插入数据成功");\n\t}\n\t\n\t\n\t/****************************以下为多余代码*****************************************/\n\t// 7.查数据(scan)\n\tpublic static void scan_data(string tablename) {\n\t\ttable table = null;\n\t\ttry {\n\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\tresultscanner results = table.getscanner(new scan());\n\t\t\tsystem.out.println(tablename + "表\\nrow\\t\\tcolumn+cell");\n\t\t\tfor (result result : results) {\n\t\t\t\tcell[] cells = result.rawcells();\n\t\t\t\tprint_cells(cells);\n\t\t\t}\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (ioexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_cells(cell[] cells) {\n\t\tfor (cell tempcell : cells) {\n\t\t\tsystem.out.println(bytes.tostring(cellutil.clonerow(tempcell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + bytes.tostring(cellutil.clonefamily(tempcell)) + ":" +  bytes.tostring(cellutil.clonequalifier(tempcell))\n\t\t\t\t\t+ ",timestamp=" + tempcell.gettimestamp() \n\t\t\t\t\t+ ", value=" + bytes.tostring(cellutil.clonevalue(tempcell)) );\n\t\t}\n\t}\n\t /**\n     * 1将utf-8的汉字转换成unicode格式汉字码\n     * @param string\n     * @return\n     */\n    public static string stringtounicode(string string) {\n\n        stringbuffer unicode = new stringbuffer();\n        for (int i = 0; i < string.length(); i++) {\n            char c = string.charat(i);\n            unicode.append("\\\\u" + integer.tohexstring(c));\n        }\n        string str = unicode.tostring();\n\n        return str.replaceall("\\\\\\\\", "0x");\n    }\n\n    /**\n     * 2将unicode的汉字码转换成utf-8格式的汉字\n     * @param unicode\n     * @return\n     */\n    public static string unicodetostring(string unicode) {\n\n        string str = unicode.replace("0x", "\\\\");\n\n        stringbuffer string = new stringbuffer();\n        string[] hex = str.split("\\\\\\\\u");\n        for (int i = 1; i < hex.length; i++) {\n            int data = integer.parseint(hex[i], 16);\n            string.append((char) data);\n        }\n        return string.tostring();\n    }\n\n}\n\n\n读mysql\n\npackage com.hrbu.hbase;\n\nimport java.sql.connection;\nimport java.sql.drivermanager;\nimport java.sql.resultset;\nimport java.sql.sqlexception;\nimport java.sql.statement;\nimport java.util.arraylist;\nimport java.util.list;\n\n\npublic class sqoop_mysql {\n\tpublic static connection connect = null;\n\t\n\tpublic static void init() {\n\t\t//驱动程序名\n\t\tstring driver = "com.mysql.cj.jdbc.driver";\n\t\t//url指向要访问的数据库名\n\t\tstring url = "jdbc:mysql://hadoop1:3306/company?useunicode=true&characterencoding=utf-8&usessl=false";\n\t\t//mysql配置时的用户名\n\t\tstring username = "root";\n\t\t//密码\n\t\tstring password = "123456789";\n\t\t\n\t\ttry {\n\t\t\t//加载驱动程序\n\t\t\tclass.forname(driver);\n\t\t\tconnect = drivermanager.getconnection(url,username,password);\n\t\t\tif (!connect.isclosed()) {\n                system.out.println("数据库连接成功");\n            }\n\t\t} catch (classnotfoundexception|sqlexception e) {\n\t\t\te.printstacktrace();\n\t\t} \n\t}\n\t\n\tpublic static void close(){\n\t\tif(connect!=null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (sqlexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t}\n\t\n\tpublic static list<staff> selectallfromstaff() {\n\t\t//实例化statement对象\n\t\tlist<staff> list = new arraylist<staff>();\n\t\tstatement stmt = null;\n\t\ttry {\n\t\t\tstmt = connect.createstatement();\n\t\t\tstring sql = "select * from staff";\n\t\t\tresultset resultset = stmt.executequery(sql);\n\t\t\twhile(resultset.next()) {\n\t\t\t\tstaff staff = new staff();\n\t\t\t\tstaff.setid(resultset.getint("id"));\n\t\t\t\tstaff.setname(resultset.getstring("name"));\n\t\t\t\tstaff.setsex(resultset.getstring("sex"));\n\t\t\t\tlist.add(staff);\n\t\t\t}\n\t\t\t\n\t\t} catch (sqlexception e) {\n\t\t\te.printstacktrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(stmt!=null) {\n\t\t\t\t\tstmt.close();\n\t\t\t\t}\n\t\t\t} catch (sqlexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t\treturn list;\n\t}\n\t\n\tpublic static void print(list<staff> list) {\n\t\tfor (int i = 0; i < list.size(); i++) {\n\t\t\tsystem.out.println(list.get(i).getid() + "\\t" +list.get(i).getname() + "\\t" + list.get(i).getsex());\n\t\t}\n\t}\n\t//外部调用的方法(算是封装好的)\n\tpublic static list<staff> main_use() {\n\t\tinit();\n\t\tlist<staff> list = selectallfromstaff();\n\t\tclose();\n\t\treturn list;\n\t}\n}\n\nclass staff {\n\tint id;\n\tstring name;\n\tstring sex;\n\tpublic int getid() {\n\t\treturn id;\n\t}\n\tpublic void setid(int id) {\n\t\tthis.id = id;\n\t}\n\tpublic string getname() {\n\t\treturn name;\n\t}\n\tpublic void setname(string name) {\n\t\tthis.name = name;\n\t}\n\tpublic string getsex() {\n\t\treturn sex;\n\t}\n\tpublic void setsex(string sex) {\n\t\tthis.sex = sex;\n\t}\n}\n\n\nimport java.util.list;\n\npublic class sqoop_test {\n\tpublic static void main(string[] args) {\n\t\tlist<staff> list = sqoop_mysql.main_use();\n\t\tsqoop_hbase.main_use("staff", "info", list);\n\t}\n}\n\n\npackage com.hrbu.hbase;\n\nimport java.io.ioexception;\n\nimport org.apache.hadoop.conf.configuration;\nimport org.apache.hadoop.hbase.hbaseconfiguration;\nimport org.apache.hadoop.hbase.tablename;\nimport org.apache.hadoop.hbase.client.admin;\nimport org.apache.hadoop.hbase.client.connection;\nimport org.apache.hadoop.hbase.client.connectionfactory;\n\npublic class test {\n\n\tpublic static void main(string[] args) throws ioexception {\n\t\t// todo auto-generated method stub\n\t\tconfiguration conf = null;\n\t\tconf = hbaseconfiguration.create();\n\t\tconf.set("hbase.zookeeper.quorum", "192.168.1.100");\n\t\tconf.set("hbase.zookeeper.property.clientport", "2181");\n\t\tsystem.out.println("11111111111111111111");\n\t\t//2. 创建连接对象\n\t\tconnection connect = null;\n\t\tconnect = connectionfactory.createconnection(conf);\n\t\tsystem.out.println("22222222222222222222");\n\t\t//3. 获取管理员对象\n\t\tadmin admin = connect.getadmin();\n\t\tsystem.out.println("333333333333333333333" + admin + "333" + connect);\n\t\t//system.out.println(admin.tableexists(tablename.valueof("student")));\n\t\tif(admin.tableexists(tablename.valueof("student"))) {\n\t\t\tsystem.out.println("表已经存在");\n\t\t}else {\n\t\t\tsystem.out.println("表不存在");\n\t\t}\n\t\tsystem.out.println("44444444444444444444");\n\t\tadmin.close();\n\t\tconnect.close();\n\t}\n\n}\n\n\n\n# hive代码\n\n----------------------------------------\n\n表操作\n\npackage com.hrbu.hive;\n\nimport java.sql.connection;\nimport java.sql.drivermanager;\nimport java.sql.resultset;\nimport java.sql.sqlexception;\nimport java.sql.statement;\n\nimport org.junit.after;\nimport org.junit.before;\nimport org.junit.test;\n\npublic class clustertestapi {\n\t\n\t//驱动名称\n\tprivate static string drivername = "org.apache.hive.jdbc.hivedriver";\n\t//连接用的url\n\tprivate static string url = "jdbc:hive2://8.8.8.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static string user = "banana";\n\tprivate static string password = "";\n\t\n\tprivate static connection conn = null;\n\tprivate static statement stmt = null;\n\tprivate static resultset rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@before\t//表示在任意使用@test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tclass.forname(drivername);\n\t\t\tconn = drivermanager.getconnection(url,user,password);\n\t\t\tstmt = conn.createstatement();\n\t\t} catch (exception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t}\n\t//释放资源\n\t@after //表示在任意使用@test注解标注的public void方法之后执行\n\tpublic void destory() throws sqlexception {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@test\n\tpublic void create_database() throws sqlexception {\n\t\tstring sql = "create database if not exists hive_jdbc_test";\t//create database if not exists hive_jdbc_test\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@test\n\tpublic void create_studenttable() throws sqlexception {\n\t\t//string sql0 = "use hive_jdbc_test";\n\t\tstring sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tsystem.out.println("running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@test\n\tpublic void show_databases() throws sqlexception {\n\t\tstring sql = "show databases";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@test\n\tpublic void show_tables() throws sqlexception {\n\t\tstring sql = "show tables";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t//加载数据\n\t@test\n\tpublic void load_data() throws sqlexception {\n\t\t//linux路径\n\t\tstring filepath = " \'/soft/module/datas/short-student-utf8.txt\' ";\n\t\tstring sql = "load data local inpath" + filepath + "overwrite into table student";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@test\n\tpublic void select_data() throws sqlexception {\n\t\tstring sql = "select * from test_db.student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\tsystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring("code") + "\\t" + rs.getstring("name") + "\\t" + rs.getstring("gender") + "\\t" + rs.getstring("school") + "\\t" + rs.getstring("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@test\n\tpublic void count_data() throws sqlexception {\n\t\tstring sql = "select count(*) from test_db.student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\tsystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getint(1));\n\t\t}\n\t}\n\t//删除表\n\t@test\n\tpublic void drop_table() throws sqlexception {\n\t\tstring sql = "drop table student";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("drop table success");\n\t}\n\t\n\t//删除数据库\n\t@test\n\tpublic void drop_database() throws sqlexception {\n\t\t//强制删除数据库\n\t\t//string sql = "drop database if exists hive_jdbc_test cascade";\n\t\tstring sql = "drop database if exists hive_jdbc_test";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("drop database success");\n\t}\n\t\n\tpublic static void main(string[] args) throws sqlexception {\n\t\tclustertestapi test = new clustertestapi();\n\t\ttest.drop_database();\n\t}\n}\n\n\npackage com.hrbu.hive;\n\nimport java.sql.connection;\nimport java.sql.drivermanager;\nimport java.sql.resultset;\nimport java.sql.sqlexception;\nimport java.sql.statement;\n\nimport org.junit.after;\nimport org.junit.before;\nimport org.junit.test;\n\n\n\npublic class teatapi {\n\t\n\t//驱动名称\n\tprivate static string drivername = "org.apache.hive.jdbc.hivedriver";\n\t//连接用的url\n\tprivate static string url = "jdbc:hive2://192.168.1.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static string user = "root";\n\tprivate static string password = "";\n\t\n\tprivate static connection conn = null;\n\tprivate static statement stmt = null;\n\tprivate static resultset rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@before\t//表示在任意使用@test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tclass.forname(drivername);\n\t\t\tconn = drivermanager.getconnection(url,user,password);\n\t\t\tstmt = conn.createstatement();\n\t\t} catch (exception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t}\n\t//释放资源\n\t@after //表示在任意使用@test注解标注的public void方法之后执行\n\tpublic void destory() throws sqlexception {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@test\n\tpublic void create_database() throws sqlexception {\n\t\tstring sql = "create database if not exists hive_jdbc_test";\t//create database if not exists hive_jdbc_test\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@test\n\tpublic void create_studenttable() throws sqlexception {\n\t\t//string sql0 = "use hive_jdbc_test";\n\t\tstring sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tsystem.out.println("running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@test\n\tpublic void show_databases() throws sqlexception {\n\t\tstring sql = "show databases";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@test\n\tpublic void show_tables() throws sqlexception {\n\t\tstring sql = "show tables";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t//加载数据\n\t@test\n\tpublic void load_data() throws sqlexception {\n\t\t//linux路径\n\t\tstring filepath = "\'/soft/datas/short-student-utf8.txt\'";\n\t\tstring sql = "load data local inpath" + filepath + "overwrite into table test_db.student";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@test\n\tpublic void select_data() throws sqlexception {\n\t\tstring sql = "select * from test_db.student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\tsystem.out.println("学号\\t\\t\\t姓名\\t性别\\t学校\\t\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring("code") + "\\t" + rs.getstring("name") + "\\t" + rs.getstring("gender") + "\\t" + rs.getstring("school") + "\\t" + rs.getstring("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@test\n\tpublic void count_data() throws sqlexception {\n\t\tstring sql = "select count(*) from test_db.student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getint(1));\n\t\t}\n\t}\n\t//删除表\n\t@test\n\tpublic void drop_table() throws sqlexception {\n\t\tstring sql = "drop table student";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("drop table success");\n\t}\n\t\n\t//删除数据库\n\t@test\n\tpublic void drop_database() throws sqlexception {\n\t\t//强制删除数据库\n\t\t//string sql = "drop database if exists flume_hive cascade";\n\t\tstring sql = "drop database if exists hive_jdbc_test";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("drop database success");\n\t}\n\t\n\tpublic static void main(string[] args) throws sqlexception {\n\t\tnew teatapi().drop_database();\n\t}\n}\n\n\nudf\n\npackage com.hrbu.hive;\n\n\nimport org.apache.commons.lang3.stringutils;\nimport org.apache.hadoop.hive.ql.exec.udf;\nimport org.apache.hadoop.io.text;\n\npublic class genderudf extends udf {\n\t/**\n\t * 方法名必须是evaluate,hive执行时会找它\n\t * 业务逻辑为:判断输入值,"m"返回男,"f"返回女,否则返回未知\n\t * \n\t */\n\tpublic text evaluate(text text) {\n\t\tstring textstr = text.tostring();\n\t\tif(stringutils.isnotempty(textstr)) {\n\t\t\tif(textstr.equalsignorecase("m")) {\n\t\t\t\treturn new text("男");\n\t\t\t}else if(textstr.equalsignorecase("f")){\n\t\t\t\treturn new text("女");\n\t\t\t}else {\n\t\t\t\treturn new text("未知");\n\t\t\t}\n\t\t\t\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\n\n\n# redisapi\n\n----------------------------------------\n\npackage com.hrbu.redisapi;\n\nimport java.util.hashmap;\n\nimport redis.clients.jedis.jedis;\n\n/**\n * hello world!\n *\n */\npublic class app \n{\n    public static void main( string[] args )\n    {\n    \tjedis jedis = new jedis("8.8.8.8",6379);\n    \t//jedis.flushall();\n        //system.out.println( "hello world!" + jedis.ping());\n        /*****1.字符串(string)*****/\n//    \tjedis.set("name1", "aaa");\n//        system.out.println(jedis.get("name1"));\n//    \tjedis.del("name1");\n//    \t\n//    \tjedis.mset("name1","aaa","name2","bbb","name3","ccc");\n//    \tsystem.out.println(jedis.mget("name1","name2","name3"));\n//    \t\n//    \tsystem.out.println(jedis.exists("name1"));\n//    \tsystem.out.println(jedis.exists("name","name0","name1","name2","name3"));\n//    \tsystem.out.println(jedis.keys("*"));\n//    \tsystem.out.println(jedis.type("name1"));\n//    \tsystem.out.println(jedis.randomkey());\n//    \tsystem.out.println(jedis.flushdb());\n//    \tsystem.out.println(jedis.get("name1"));\n//    \tsystem.out.println(jedis.flushall());\n//    \tsystem.out.println(jedis.randomkey());\n    \t\n    \t/****2.哈希(hash)******/\n    \t/*\n    \thashmap<string,string> hmap = new hashmap<string,string>();\n    \thmap.put("name5", "eee");\n    \thmap.put("name4", "ddd");\n    \thmap.put("id", "666");\n    \t// 设置值\n    \tjedis.hset("user", "name6", "fff");\n    \tjedis.hmset("user", hmap);\n    \t// 取值\n    \tsystem.out.println("hget:\\t" + jedis.hget("user", "name4"));\n    \tsystem.out.println("hmget:\\t" + jedis.hmget("user", "name4","name5","name6"));\n    \tsystem.out.println("hgetall:\\t" + jedis.hgetall("user"));\n    \tsystem.out.println("keys:\\t" + jedis.keys("*"));\n    \tsystem.out.println("hkeys:\\t" + jedis.hkeys("user"));\n    \tsystem.out.println("hvals:\\t" + jedis.hvals("user"));\n    \tsystem.out.println("hlen:\\t" + jedis.hlen("user"));\n    \t// 删除field\n    \tsystem.out.println("hdel\\t" + jedis.hdel("user","name4"));\n    \tsystem.out.println("hdel\\t" + jedis.hdel("user","name5","name6"));\n    \tsystem.out.println(jedis.hgetall("user"));\n    \t// 清空\n    \tsystem.out.println(jedis.flushall());\n    \tsystem.out.println(jedis.hgetall("user"));\n    \t*/\n\n    \t\n    \t/*******3.列表list(类似于栈???)*********/\n    \t/*\n    \t// 放值\n    \tjedis.lpushx("list", "999");\n    \tjedis.lpush("list", "hhh","ggg","iii");\t\t//1或多到  开始\n    \tjedis.rpush("list", "kkk","jjj");\t\t\t//1或多到  末尾\n    \tjedis.lpushx("list", "666");\t\t\t\t// 插入已存在列表头部\n    \t// 取值\n    \tsystem.out.println(jedis.lrange("list", 0, 10));\t//获取指定范围元素\n    \tsystem.out.println(jedis.blpop("list","5"));\t\t//移出 第一个元素 等待超时\n    \tsystem.out.println(jedis.brpop("list", "5"));\t\t//移出 最后一个元素 等待超时\n    \tsystem.out.println(jedis.lindex("list", 3));\t\t//索引获取元素\n    \tsystem.out.println(jedis.llen("list"));\t\t\t\t//获取列表长度\n    \tsystem.out.println(jedis.lrange("list", 0, 10));\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t*/\n    \t\n    \t\n    \t/********4.集合(set)****************/\n    \t/*\n    \t// 放值\n    \tjedis.sadd("set", "lll", "nnn", "mmm" ,"ooo");\n    \t// 取值\n    \tsystem.out.println(jedis.smembers("set"));\t\t// 所有元素\n    \tsystem.out.println(jedis.sismember("set", "ooo"));\t\t\t// key(value)是否存在\n    \tsystem.out.println(jedis.sismember("sett", "ooo"));\n    \tsystem.out.println(jedis.srem("set","ooo","mmm"));\t\t// 移除\n    \tsystem.out.println(jedis.smembers("set"));\n    \t// 运算\n    \tjedis.sadd("set", "set");\n    \tjedis.sadd("sett", "lll", "nnn", "mmm", "ooo", "sett");\n    \tsystem.out.println(jedis.sinter("set", "sett"));\t\t// 交集\n    \tsystem.out.println(jedis.sdiff("set", "sett"));\t\t\t// 差集\n    \tsystem.out.println(jedis.sunion("set", "sett"));\t\t// 并集\n    \t\n    \tsystem.out.println(jedis.scard("set"));\t\t// 元素数目\n    \tsystem.out.println(jedis.scard("sett"));\t\t// 元素数目\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t*/\n    \t\n    \t/********5.有序集合sorted set(zset)*************/\n    \thashmap<string,double> scoremap = new hashmap<string, double>(); \n    \tscoremap.put("vvv", 0.22);\n    \tscoremap.put("ppp", 0.16);\n    \tscoremap.put("sss", 0.19);\n    \tscoremap.put("qqq", 0.17);\n    \tscoremap.put("www", 0.23);\n    \tscoremap.put("rrr", 0.18);\n    \tscoremap.put("uuu", 0.21);\n    \tscoremap.put("ttt", 0.20);\n    \t// 放值\n    \tjedis.zadd("zset", scoremap);\t\t// 添加元素或更新分数\n    \tjedis.zadd("zset", 0.24, "xxx");\n    \t// 元素查找修改\n    \tsystem.out.println(jedis.zrange("zset", 0, 10));\t\t// 根据索引返回区间\n    \tsystem.out.println(jedis.zcount("zset", 0.18, 0.21));\t\t// 根据分数返回元素数\n    \tsystem.out.println(jedis.zrem("zset", "sss", "ppp"));\t\t// 移除元素\n    \tsystem.out.println(jedis.zcard("zset"));\t\t\t\t\t// 元素数目\n    \tsystem.out.println(jedis.zincrby("zset", 1, "www"));\t\t// 分数增量\n    \tsystem.out.println(jedis.zscore("zset", "www"));\t\t// 返回分数值\n    \tsystem.out.println(jedis.zrank("zset", "www"));\t\t// 返回元素索引\n    \tsystem.out.println(jedis.zrangebyscore("zset", 0, 2));\t\t// 根据分数返回元素区间\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t\n    \t\n        jedis.close();\n    }\n}\n',charsets:{cjk:!0},lastUpdated:"2022/08/11, 00:48:36",lastUpdatedTimestamp:1660150116e3},{title:"Zookeeper集群搭建",frontmatter:{title:"Zookeeper集群搭建",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/e2226d/",categories:["大数据","Zookeeper"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/02.Zookeeper/01.Zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/02.Zookeeper/01.Zookeeper集群搭建.md",key:"v-5063a9cb",path:"/pages/e2226d/",headers:[{level:2,title:"关于Zookeeper的节点为什么是奇数",slug:"关于zookeeper的节点为什么是奇数",normalizedTitle:"关于zookeeper的节点为什么是奇数",charIndex:416},{level:2,title:"1. 解压安装:",slug:"_1-解压安装",normalizedTitle:"1. 解压安装:",charIndex:1183},{level:2,title:"2.\t配置",slug:"_2-配置",normalizedTitle:"2.\t配置",charIndex:null},{level:2,title:"3.\t集群启动 测试服务",slug:"_3-集群启动-测试服务",normalizedTitle:"3.\t集群启动 测试服务",charIndex:null},{level:2,title:"4.\tHA故障自动转换",slug:"_4-ha故障自动转换",normalizedTitle:"4.\tha故障自动转换",charIndex:null},{level:3,title:"1)\t修改集群所有节点(NameNode和DataNode)的hdfs配置文件和核心配置文件:",slug:"_1-修改集群所有节点-namenode和datanode-的hdfs配置文件和核心配置文件",normalizedTitle:"1)\t修改集群所有节点(namenode和datanode)的hdfs配置文件和核心配置文件:",charIndex:null},{level:3,title:"2)\t启动测试",slug:"_2-启动测试",normalizedTitle:"2)\t启动测试",charIndex:null}],headersStr:"关于Zookeeper的节点为什么是奇数 1. 解压安装: 2.\t配置 3.\t集群启动 测试服务 4.\tHA故障自动转换 1)\t修改集群所有节点(NameNode和DataNode)的hdfs配置文件和核心配置文件: 2)\t启动测试",content:'这个是在之前的基础上搭建 hadoop完全分布式搭建:https://www.cnblogs.com/Hephaestus/p/12213719.html hadoop高可用搭建:https://www.cnblogs.com/Hephaestus/p/12420370.html 集群规划:\n\n            NAMENODE   DATANODE   JOURNALNODE   ZOOKEEPER(必须为奇数)\nhadoop100   是(nn2)                              \nhadoop101   是(nn1)     是          是             是\nhadoop102              是          是             是\nhadoop103              是          是             是\n\n\n# 关于Zookeeper的节点为什么是奇数\n\n(参考链接:https://www.cnblogs.com/ysocean/p/9860529.html#_label0)\n\n * 容错率 需要保证集群能够有半数进行投票\n\n> 2台服务器，至少2台正常运行才行（2的半数为1，半数以上最少为2），正常运行1台服务器都不允许挂掉，但是相对于 单节点服务器，2台服务器还有两个单点故障，所以直接排除了。 3台服务器，至少2台正常运行才行（3的半数为1.5，半数以上最少为2），正常运行可以允许1台服务器挂掉 4台服务器，至少3台正常运行才行（4的半数为2，半数以上最少为3），正常运行可以允许1台服务器挂掉 5台服务器，至少3台正常运行才行（5的半数为2.5，半数以上最少为3），正常运行可以允许2台服务器挂掉\n\n * 防脑裂 脑裂集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，小集群各自选出自己的leader节点，导致原有的集群出现多个leader节点的情况，这就是脑裂。\n\n> 3台服务器，投票选举半数为1.5，一台服务裂开，和另外两台服务器无法通行，这时候2台服务器的集群（2票大于半数1.5票），所以可以选举出leader，而 1 台服务器的集群无法选举。 4台服务器，投票选举半数为2，可以分成 1,3两个集群或者2,2两个集群，对于 1,3集群，3集群可以选举；对于2,2集群，则不能选择，造成没有leader节点。 5台服务器，投票选举半数为2.5，可以分成1,4两个集群，或者2,3两集群，这两个集群分别都只能选举一个集群，满足zookeeper集群搭建数目。\n\n以上分析，我们从容错率以及防止脑裂两方面说明了3台服务器是搭建集群的最少数目，4台发生脑裂时会造成没有leader节点的错误\n\n\n# 1. 解压安装:\n\n下载地址: 解压: tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /soft/module/ (自己要安装的目录) 文件夹重命名: mv apache-zookeeper-3.5.7 zookeeper-3.5.7\n\n\n# 2. 配置\n\n * 1) 进入到zookeeper-3.5.7/conf目录下 cp zoo_sample.cfg zoo.cfg 编辑 vim zoo.cfg,加入\n\ndataDir=/soft/module/zookeeper-3.5.7/zkData\ndataLogDir=/soft/module/zookeeper-3.5.7/logs\nclientPort=2181\n\n########hadoop101、102、103为 3个datanode节点########\n# 注: 文件可以这样写(不用0.0.0.0)(前提是把/etc/hosts前两行注释掉,否则会产生冲突)\nserver.1=hadoop101:2888:3888\nserver.2=hadoop102:2888:3888\nserver.3=hadoop103:2888:3888\n\n\n分发文件 xsync.sh zookeeper-3.5.7\n\n * 进入到zookeeper-3.5.7/conf目录下 ,mkdir zkData(上面配置文件zoo.cfg的路径) echo "1" > myid写入内容1(注意和配置文件中的server.1对应) 在其它节点分别执行操作 echo "2" > myid echo "3" > myid(和zoo.cfg对应!!! id必须在集群环境中服务器标识中是唯一的，且大小在1～255之间)\n\n\n# 3. 集群启动 测试服务\n\n * 启动 bin/zkServer.sh start\n * 查看状态 bin/zkServer.sh status 这种情况的一种可能是Zookeeper集群有节点未启动\n * 连接zookeeper服务 bin/zkCli.sh -server 8.8.8.103:2181 (自己的ip、端口号和zoo.cfg对应)\n\n> 拒绝连接 1).防火墙没关 2).配置文件问题 3).zk集群不是正常的关闭 (例如执行kill 命令zk的进程) 解决: 直接修改clientPort端口号，然后再启动，再关闭，把clientPort修改回来 注意，使用zookeeper需正常停止！！！不然，重启linux都不一定能解决问题！ 4).主机IP和端口号一定要正确!!! (我就是端口号错了…)\n\n\n# 4. HA故障自动转换\n\n\n * # 1) 修改集群所有节点(NameNode和DataNode)的hdfs配置文件和核心配置文件:\n   \n   vim /soft/module/hadoop-2.9.2/etc/hadoop/hdfs-site.xml\n\n\x3c!-- 当namnode故障，是否自动启动另一个namenode(默认值为false)--\x3e\n<property>\n\t\t\x3c!--这个之前好像错了 --\x3e\n        <name>dfs.ha.automatic-failover.enabled </name>\n        <value>true</value>\n</property>\n\n\nvim /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml\n\n\x3c!-- 指定zookeeper地址 --\x3e\n<property>\n    <name>ha.zookeeper.quorum</name>\n    \x3c!-- 端口号和配置文件zoo.cfg 对应 --\x3e\n    <value>hadoop101: 2181,hadoop102: 2181,hadoop103: 2181</value>\n</property>\n\n\n查看 mapred-site.xml yarn-site.xml主机名啥的不要出错 分发配置文件: xsync /soft/module/hadoop-2.9.2/etc/hadoop\n\n\n# 2) 启动测试\n\n * jps查看是否关闭所有服务, 没有的话关闭\n\n * 在所有节点上删除 dfs/data dfs/name tmp logs目录\n\n * 所有datanode节点启动zookeeper集群 ./bin/zkServer.sh start\n\n * 格式化zk集群: nn1上执行 bin/hdfs zkfc -formatZK\n\n * 所有datanode节点启动journalnode集群 ./sbin/hadoop-daemon.sh start journalnode\n\n * 格式化namenode: nn1上执行 ./bin/hdfs namenode -format\n\n * 启动datanode和namenode 所有datanode节点执行 ./sbin/hadoop-daemon.sh start datanode nn1 执行 ./sbin/hadoop-daemon.sh start namenode nn2 执行 ./bin/hdfs namenode -bootstrapStandby ./sbin/hadoop-daemon.sh start namenode 此时可以再UI界面看到\n\n * 启动zkfc服务 在nn1和nn2执行 ./sbin/hadoop-daemon.sh start zkfc 这时namenode1和namenode2会自动选举出active节点, 可以看到\n\n * 验证 处于active状态的节点 执行 kill -9 xxxxx(jps查看的namenode进程id), 可以看到',normalizedContent:'这个是在之前的基础上搭建 hadoop完全分布式搭建:https://www.cnblogs.com/hephaestus/p/12213719.html hadoop高可用搭建:https://www.cnblogs.com/hephaestus/p/12420370.html 集群规划:\n\n            namenode   datanode   journalnode   zookeeper(必须为奇数)\nhadoop100   是(nn2)                              \nhadoop101   是(nn1)     是          是             是\nhadoop102              是          是             是\nhadoop103              是          是             是\n\n\n# 关于zookeeper的节点为什么是奇数\n\n(参考链接:https://www.cnblogs.com/ysocean/p/9860529.html#_label0)\n\n * 容错率 需要保证集群能够有半数进行投票\n\n> 2台服务器，至少2台正常运行才行（2的半数为1，半数以上最少为2），正常运行1台服务器都不允许挂掉，但是相对于 单节点服务器，2台服务器还有两个单点故障，所以直接排除了。 3台服务器，至少2台正常运行才行（3的半数为1.5，半数以上最少为2），正常运行可以允许1台服务器挂掉 4台服务器，至少3台正常运行才行（4的半数为2，半数以上最少为3），正常运行可以允许1台服务器挂掉 5台服务器，至少3台正常运行才行（5的半数为2.5，半数以上最少为3），正常运行可以允许2台服务器挂掉\n\n * 防脑裂 脑裂集群的脑裂通常是发生在节点之间通信不可达的情况下，集群会分裂成不同的小集群，小集群各自选出自己的leader节点，导致原有的集群出现多个leader节点的情况，这就是脑裂。\n\n> 3台服务器，投票选举半数为1.5，一台服务裂开，和另外两台服务器无法通行，这时候2台服务器的集群（2票大于半数1.5票），所以可以选举出leader，而 1 台服务器的集群无法选举。 4台服务器，投票选举半数为2，可以分成 1,3两个集群或者2,2两个集群，对于 1,3集群，3集群可以选举；对于2,2集群，则不能选择，造成没有leader节点。 5台服务器，投票选举半数为2.5，可以分成1,4两个集群，或者2,3两集群，这两个集群分别都只能选举一个集群，满足zookeeper集群搭建数目。\n\n以上分析，我们从容错率以及防止脑裂两方面说明了3台服务器是搭建集群的最少数目，4台发生脑裂时会造成没有leader节点的错误\n\n\n# 1. 解压安装:\n\n下载地址: 解压: tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -c /soft/module/ (自己要安装的目录) 文件夹重命名: mv apache-zookeeper-3.5.7 zookeeper-3.5.7\n\n\n# 2. 配置\n\n * 1) 进入到zookeeper-3.5.7/conf目录下 cp zoo_sample.cfg zoo.cfg 编辑 vim zoo.cfg,加入\n\ndatadir=/soft/module/zookeeper-3.5.7/zkdata\ndatalogdir=/soft/module/zookeeper-3.5.7/logs\nclientport=2181\n\n########hadoop101、102、103为 3个datanode节点########\n# 注: 文件可以这样写(不用0.0.0.0)(前提是把/etc/hosts前两行注释掉,否则会产生冲突)\nserver.1=hadoop101:2888:3888\nserver.2=hadoop102:2888:3888\nserver.3=hadoop103:2888:3888\n\n\n分发文件 xsync.sh zookeeper-3.5.7\n\n * 进入到zookeeper-3.5.7/conf目录下 ,mkdir zkdata(上面配置文件zoo.cfg的路径) echo "1" > myid写入内容1(注意和配置文件中的server.1对应) 在其它节点分别执行操作 echo "2" > myid echo "3" > myid(和zoo.cfg对应!!! id必须在集群环境中服务器标识中是唯一的，且大小在1～255之间)\n\n\n# 3. 集群启动 测试服务\n\n * 启动 bin/zkserver.sh start\n * 查看状态 bin/zkserver.sh status 这种情况的一种可能是zookeeper集群有节点未启动\n * 连接zookeeper服务 bin/zkcli.sh -server 8.8.8.103:2181 (自己的ip、端口号和zoo.cfg对应)\n\n> 拒绝连接 1).防火墙没关 2).配置文件问题 3).zk集群不是正常的关闭 (例如执行kill 命令zk的进程) 解决: 直接修改clientport端口号，然后再启动，再关闭，把clientport修改回来 注意，使用zookeeper需正常停止！！！不然，重启linux都不一定能解决问题！ 4).主机ip和端口号一定要正确!!! (我就是端口号错了…)\n\n\n# 4. ha故障自动转换\n\n\n * # 1) 修改集群所有节点(namenode和datanode)的hdfs配置文件和核心配置文件:\n   \n   vim /soft/module/hadoop-2.9.2/etc/hadoop/hdfs-site.xml\n\n\x3c!-- 当namnode故障，是否自动启动另一个namenode(默认值为false)--\x3e\n<property>\n\t\t\x3c!--这个之前好像错了 --\x3e\n        <name>dfs.ha.automatic-failover.enabled </name>\n        <value>true</value>\n</property>\n\n\nvim /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml\n\n\x3c!-- 指定zookeeper地址 --\x3e\n<property>\n    <name>ha.zookeeper.quorum</name>\n    \x3c!-- 端口号和配置文件zoo.cfg 对应 --\x3e\n    <value>hadoop101: 2181,hadoop102: 2181,hadoop103: 2181</value>\n</property>\n\n\n查看 mapred-site.xml yarn-site.xml主机名啥的不要出错 分发配置文件: xsync /soft/module/hadoop-2.9.2/etc/hadoop\n\n\n# 2) 启动测试\n\n * jps查看是否关闭所有服务, 没有的话关闭\n\n * 在所有节点上删除 dfs/data dfs/name tmp logs目录\n\n * 所有datanode节点启动zookeeper集群 ./bin/zkserver.sh start\n\n * 格式化zk集群: nn1上执行 bin/hdfs zkfc -formatzk\n\n * 所有datanode节点启动journalnode集群 ./sbin/hadoop-daemon.sh start journalnode\n\n * 格式化namenode: nn1上执行 ./bin/hdfs namenode -format\n\n * 启动datanode和namenode 所有datanode节点执行 ./sbin/hadoop-daemon.sh start datanode nn1 执行 ./sbin/hadoop-daemon.sh start namenode nn2 执行 ./bin/hdfs namenode -bootstrapstandby ./sbin/hadoop-daemon.sh start namenode 此时可以再ui界面看到\n\n * 启动zkfc服务 在nn1和nn2执行 ./sbin/hadoop-daemon.sh start zkfc 这时namenode1和namenode2会自动选举出active节点, 可以看到\n\n * 验证 处于active状态的节点 执行 kill -9 xxxxx(jps查看的namenode进程id), 可以看到',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Hive集群搭建",frontmatter:{title:"Hive集群搭建",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/edf4cb/",categories:["大数据","Hive"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/03.Hive/01.Hive%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/03.Hive/01.Hive集群搭建.md",key:"v-7f6942cf",path:"/pages/edf4cb/",headers:[{level:2,title:"一. 先安装MySQL",slug:"一-先安装mysql",normalizedTitle:"一. 先安装mysql",charIndex:104},{level:3,title:"1.检查卸载mariadb-lib(Centos自带mariadb数据库)",slug:"_1-检查卸载mariadb-lib-centos自带mariadb数据库",normalizedTitle:"1.检查卸载mariadb-lib(centos自带mariadb数据库)",charIndex:120},{level:3,title:"2.安装MySQL",slug:"_2-安装mysql",normalizedTitle:"2.安装mysql",charIndex:264},{level:3,title:"3.初始化并启动",slug:"_3-初始化并启动",normalizedTitle:"3.初始化并启动",charIndex:691},{level:2,title:"二.安装配置Hive",slug:"二-安装配置hive",normalizedTitle:"二.安装配置hive",charIndex:1413},{level:3,title:"1.解压安装",slug:"_1-解压安装",normalizedTitle:"1.解压安装",charIndex:1654},{level:3,title:"2.文件配置",slug:"_2-文件配置",normalizedTitle:"2.文件配置",charIndex:1780},{level:3,title:"3.Hadoop集群配置",slug:"_3-hadoop集群配置",normalizedTitle:"3.hadoop集群配置",charIndex:2094},{level:3,title:"4.Hive 元数据配置到 MySql",slug:"_4-hive-元数据配置到-mysql",normalizedTitle:"4.hive 元数据配置到 mysql",charIndex:2566},{level:3,title:"5.启动和测试",slug:"_5-启动和测试",normalizedTitle:"5.启动和测试",charIndex:4604},{level:3,title:"6.Hive基本操作",slug:"_6-hive基本操作",normalizedTitle:"6.hive基本操作",charIndex:5634},{level:2,title:"三. java API环境准备",slug:"三-java-api环境准备",normalizedTitle:"三. java api环境准备",charIndex:6355},{level:3,title:"1. centos7启动服务",slug:"_1-centos7启动服务",normalizedTitle:"1. centos7启动服务",charIndex:6375},{level:3,title:"2. eclipse配置",slug:"_2-eclipse配置",normalizedTitle:"2. eclipse配置",charIndex:6941},{level:3,title:"附:一个错误",slug:"附-一个错误",normalizedTitle:"附:一个错误",charIndex:7660}],headersStr:"一. 先安装MySQL 1.检查卸载mariadb-lib(Centos自带mariadb数据库) 2.安装MySQL 3.初始化并启动 二.安装配置Hive 1.解压安装 2.文件配置 3.Hadoop集群配置 4.Hive 元数据配置到 MySql 5.启动和测试 6.Hive基本操作 三. java API环境准备 1. centos7启动服务 2. eclipse配置 附:一个错误",content:"安装hive的前提是先安装hadoop集群，并且hive只需要在hadoop的namenode节点中安装即可，可以不在datanode节点的机器上安装，启动hive的前提是需要hadoop在正常跑着\n\n\n# 一. 先安装MySQL\n\n\n# 1.检查卸载mariadb-lib(Centos自带mariadb数据库)\n\n * 检查CentOS的mariadb版本 rpm -qa|grep mariadb\n * 卸载: rpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n# 2.安装MySQL\n\n * 安装依赖: yum install -y libaio numactl perl net-tools\n * 解压MySQL tar -xvf mysql-5.7.18-1.el7.x86_64.rpm-bundle.tar.tar -C /soft/modlue\n * 安装(注意顺序不能变):\n   * rpm -ivh mysql-community-common-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-libs-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-client-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-server-5.7.18-1.el7.x86_64.rpm（依赖于common, client）\n\n\n# 3.初始化并启动\n\n * 初始化MySQL：mysqld --initialize\n * mysql默认安装在/var/lib下。更改mysql数据库所属于用户及其所属于组:chown mysql:mysql /var/lib/mysql -R\n * 启动MySQL：systemctl start mysqld.service\n * 获得初始密码(在/var/log目录)：grep 'password' mysqld.log\n * 更改密码:\n   * 进入MySQL命令行: mysql -u root -p 输入刚才获取的初始密码\n   * 更改密码:set password=password('123456789'); flush privileges;\n   * 注意:这里可能会出现Your password does not satisfy the current policy requirements.\n     可以设置密码强度为LOW:set global validate_password_policy=0;\n     设置密码长度:set global validate_password_length=4;(最少4位)\n     参考链接:https://blog.csdn.net/maxsky/article/details/51171474\n * 授权: grant all privileges on *.* to banana@'%' identified by ‘123456789' with grant option;(最好手打命令,拷贝老出错)\n * 用SQLyog等工具连接 测试\n\n\n# 二.安装配置Hive\n\n下载hive：https://downloads.apache.org/hive/\nhadoop2.9.2 + hive-2.3.6\n\n> Hive的运行模式 依据Hive的安装和metastore的设置机器，分为下面三个模式： 嵌入模式：使用自带的derby数据库 本地模式：将metastore放在mysql，并且mysql和hive安装在同一台机器上 远程模式：将metastore放在mysql，并且mysql和hive安装在不同一台机器上\n\n\n# 1.解压安装\n\n * 解压到/soft/module: tar -zxvf apache-hive-2.3.6-bin.tar.gz -C /soft/module/\n * 重命名: mv apache-hive-2.3.6-bin hive\n\n\n# 2.文件配置\n\n 1. 配置环境变量(略):sudo vim /etc/profile\n 2. hive-env.sh文件(conf目录下),拷贝样例 cp hive-env.sh.template hive-env.sh vim hive-env.sh\n\n# 配置 HADOOP_HOME 路径\nexport HADOOP_HOME=/soft/module/hadoop-2.9.2\n# 配置 HIVE_CONF_DIR 路径\nexport HIVE_CONF_DIR=/soft/module/hive/conf\n\nexport HIVE_AUX_JARS_PATH=/soft/module/hive/lib\n\n\n\n# 3.Hadoop集群配置\n\n 1. 必须启动hdfs和yarn sbin/start-dfs.sh sbin/start-yarn.sh\n 2. 创建目录 因为在hive-site.xml中有这样的配置：\n\n<name>hive.metastore.warehouse.dir</name>\n<value>/user/hive/warehouse</value>\n<name>hive.exec.scratchdir</name>\n<value>/tmp/hive</value>\n\n\n所以要在集群上新建目录\n\n * 在 HDFS 上创建/tmp 和/user/hive/warehouse 两个目录(可不操作，系统会自动创建)\n   hadoop fs -mkdir /tmp hadoop fs -mkdir -p /user/hive/warehouse\n * 并修改他们的同组权限可写\n   hadoop fs -chmod g+w /tmp hadoop fs -chmod g+w /user/hive/warehouse\n\n\n# 4.Hive 元数据配置到 MySql\n\n 1. 驱动拷贝 拷贝 mysql-connector-java-5.1.48.jar 到/soft/module/hive/lib/ cp mysql-connector-java-5.1.48.jar /soft/module/hive/lib/\n 2. 配置 Metastore 到 MySql\n\n * 在/opt/module/hive/conf 目录下修改 hive-site.xml vim hive-site.xml\n * 根据官方文档配置参数，拷贝数据到 hive-site.xml 文件中 https://cwiki.apache.org/confluence/display/Hive/AdminManual+MetastoreAdmin\n\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    \x3c!--将该name对应的value修改为MySQL的地址--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionURL</name>\n        <value>jdbc:mysql://hadoop100:3306/metastore?createDatabaseIfNotExist=true&amp;characterEncoding=UTF-8&amp;useSSL=false</value>\n        \x3c!-- 有同学时区报错, 需加上 &amp;serverTimezone=GMT%2B8 --\x3e\n        <description>JDBC connect string for a JDBC metastore</description>\n    </property>\n    \x3c!--将该name对应的value修改为MySQL驱动类路径：--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionDriverName</name>\n        <value>com.mysql.jdbc.Driver</value>\n        <description>Driver class name for a JDBC metastore</description>\n    </property>\n    \x3c!--将对应的value修改为MySQL数据库登录名--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionUserName</name>\n        <value>root</value>\n        <description>username to use against metastore database</description>\n    </property>\n    \x3c!--将对应的value修改为MySQL数据库的登录密码--\x3e\n    <property>\n        <name>javax.jdo.option.ConnectionPassword</name>\n        <value>123456789</value>\n        <description>password to use against metastore database</description>\n    </property>\n</configuration>\n\n\n2.1 第三步和第四步不做行吗??? 或者加上???(我自己没做3,4步)\n\n<property>\n   <name>system:java.io.tmpdir</name>\n   <value>/soft/module/hive/tmpdir</value>\n</property>\n \n<property>\n     <name>system:user.name</name>\n     <value>root</value>\n</property>\n\n\n 3. 修改hive-site.xml中的临时目录 将hive-site.xml文件中的${system:java.io.tmpdir}替换为hive的临时目录，例如我替换为/soft/module/hive/tmp/，该目录如果不存在则要自己手工创建，并且赋予读写权限。\n 4. 将配置文件中${system:user.name}都替换为root\n 5. 配置完毕后，如果启动 hive 异常，可以重新启动虚拟机。（重启后，别忘了启 动 hadoop 集群）\n\n\n# 5.启动和测试\n\nhttps://www.jianshu.com/p/7b1b21bf05c2\n\n> 1、关闭防火墙 2、开启 mysql外链权限 3、jar包冲突，删除hive下 4、配置hive-site.xml\n\n * 初始化数据库：cd $HIVE_HOME/bin schematool -initSchema -dbType mysql\n * 启动Hive: cd $HIVE_HOME/bin 进入Hive的bin目录./hive 执行hive启动\n * 测试Hive\n   * 简单测试show functions; desc function sum;\n   * 连接测试\n     在成功建立连接后，进入mysql数据库，会发现多了一个metastore数据库，这个数据库就是用来存储hive的元数据信息。\n   * 执行新建库 show databases; create database test_db; use test_db; show tables; create table student(id int,name string) row format delimited fields terminated by '\\t'; load data local inpath '/soft/module/hive/student.txt' into table student; insert into student values(1000,\"ss\");\n   * Hadoop的HDFS页面上查看\n   * MySQL的hive数据库中查看(可视化工具)\n\n----------------------------------------\n\n 1. 关闭 可以通过ps -ef|grep hive 来看hive 的端口号，然后kill 掉相关的进程。\n 2. 启动 命令 hive --service metastore & hive --service hiveserver2 & nohup hive --service metastore 2>&1 &\n    用来启动metastore nohup hive --service hiveserver2 2>&1 & 用来启动hiveserver2 可以通过查看日志，来确认是否正常启动。 注意！如果 hiveserver2 不启动，jdbc将无法正常连接\n\n\n# 6.Hive基本操作\n\n * 启动 hive bin/hive\n * 查看数据库hive> show databases;\n * 打开默认数据库 hive> use default;\n * 显示 default 数据库中的表hive> show tables;\n * 创建一张表hive> create table student(id int, name string);\n * 显示数据库中有几张表hive> show tables;\n * 查看表的结构hive> desc student;\n * 向表中插入数据hive> insert into student values(1000,\"ss\");\n * 查询表中数据hive> select * from student;\n * 退出 hive hive> quit;\n * 清空表 truncate table student;\n * 导入数据三种方式(数据间以tab分隔)\n   * hadoop -put方式: hadoop fs -put student.txt /user/hive/warehouse/test_db.db/student\n   * hive命令行(本地): load data local inpath '/soft/module/hive/student.txt' into table student;\n   * hive命令行(hdfs): load data inpath 'hdfs路径(user/...)' into table student;\n\n----------------------------------------\n\n\n# 三. java API环境准备\n\n\n# 1. centos7启动服务\n\n * 修改hadoop配置vim core-site.xml\n\n<property>\n    <name>hadoop.proxyuser.root.groups</name>\n    <value>*</value>   \n</property>  \n<property>      \n    <name>hadoop.proxyuser.root.hosts</name>\n    <value>*</value>\n</property>\n\n\n分发文件\n\n * 启动命令 /soft/module/hive/bin/hive --service hiveserver2 &(在native的namenode启动)\n   命令启动后挂起,两种方式解决这种不便:\n   * 重新打开一个xshell连接，做其他的Linux命令操作，服务启动的会话保留\n   * 使用Linux nohup命令，可以防止服务启动挂起nohup:ignoring input and appending output to 'nohup.out' 它会将服务启动的日志输出到当前目录下的nohup.out文件内，我们查看下内容cat nohup.out\n   * 启动后用jpsRunJar进程或在UI界面查看\n\n\n# 2. eclipse配置\n\n-jar包配置 - 挑选必须的jar包，编辑成自己的lib配置到工程中（推荐） 其实所有jar包都在${HIVE_HOME}/lib目录下，这里列示下需要的jar包名： ${HADOOP_HOME}/share/hadoop/common/hadoop-common-2.2.0.jar(mr工程中已存在，无需再次添加，如果新建项目需配置 $ { HIVE_HOME } /lib/hive-exec-0.11.0.jar $ { HIVE_HOME } /lib/hive-jdbc-0.11.0.jar $ { HIVE_HOME } /lib/hive-metastore-0.11.0.jar $ { HIVE_HOME } /lib/hive-service-0.11.0.jar $ { HIVE_HOME } /lib/libfb303-0.9.0.jar $ { HIVE_HOME } /lib/commons-logging-1.0.4.jar （此jar包已经存在就不要再次添加） $ { HIVE_HOME } /lib/slf4j-api-1.6.1.jar（此jar包已经存在就不要再次添加） - 导入jar包 - 修改pom.xml配置文件（不推荐，会下载额外很多无用包，而且时间很长在1小时左右）\n\n<dependency>\n    <groupId>org.apache.hive</groupId>\n    <artifactId>hive-jdbc</artifactId>\n    <version>2.3.6</version>\n</dependency>\n\n\n\n# 附:一个错误\n\n * User: banana is not allowed to impersonate root 修改配置文件core-site.xml\n\n<property>\n    <name>hadoop.proxyuser.banana.groups</name>\n    <value>*</value>   \n</property>  \n<property>      \n    <name>hadoop.proxyuser.banana.hosts</name>\n    <value>*</value>\n</property>\n\n\n * User: banana is not allowed to impersonate banana\n   这个应该是没在active的namenode上启动的原因, 但我自己就是在active上启动的啊,namenode总会莫名挂掉,最后直接把另一个namenode kill掉,就好使了\n   忘记分发文件core-site.xml两天了!!!!!!!!!!",normalizedContent:"安装hive的前提是先安装hadoop集群，并且hive只需要在hadoop的namenode节点中安装即可，可以不在datanode节点的机器上安装，启动hive的前提是需要hadoop在正常跑着\n\n\n# 一. 先安装mysql\n\n\n# 1.检查卸载mariadb-lib(centos自带mariadb数据库)\n\n * 检查centos的mariadb版本 rpm -qa|grep mariadb\n * 卸载: rpm -e mariadb-libs-5.5.60-1.el7_5.x86_64 --nodeps\n\n\n# 2.安装mysql\n\n * 安装依赖: yum install -y libaio numactl perl net-tools\n * 解压mysql tar -xvf mysql-5.7.18-1.el7.x86_64.rpm-bundle.tar.tar -c /soft/modlue\n * 安装(注意顺序不能变):\n   * rpm -ivh mysql-community-common-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-libs-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-client-5.7.18-1.el7.x86_64.rpm\n   * rpm -ivh mysql-community-server-5.7.18-1.el7.x86_64.rpm（依赖于common, client）\n\n\n# 3.初始化并启动\n\n * 初始化mysql：mysqld --initialize\n * mysql默认安装在/var/lib下。更改mysql数据库所属于用户及其所属于组:chown mysql:mysql /var/lib/mysql -r\n * 启动mysql：systemctl start mysqld.service\n * 获得初始密码(在/var/log目录)：grep 'password' mysqld.log\n * 更改密码:\n   * 进入mysql命令行: mysql -u root -p 输入刚才获取的初始密码\n   * 更改密码:set password=password('123456789'); flush privileges;\n   * 注意:这里可能会出现your password does not satisfy the current policy requirements.\n     可以设置密码强度为low:set global validate_password_policy=0;\n     设置密码长度:set global validate_password_length=4;(最少4位)\n     参考链接:https://blog.csdn.net/maxsky/article/details/51171474\n * 授权: grant all privileges on *.* to banana@'%' identified by ‘123456789' with grant option;(最好手打命令,拷贝老出错)\n * 用sqlyog等工具连接 测试\n\n\n# 二.安装配置hive\n\n下载hive：https://downloads.apache.org/hive/\nhadoop2.9.2 + hive-2.3.6\n\n> hive的运行模式 依据hive的安装和metastore的设置机器，分为下面三个模式： 嵌入模式：使用自带的derby数据库 本地模式：将metastore放在mysql，并且mysql和hive安装在同一台机器上 远程模式：将metastore放在mysql，并且mysql和hive安装在不同一台机器上\n\n\n# 1.解压安装\n\n * 解压到/soft/module: tar -zxvf apache-hive-2.3.6-bin.tar.gz -c /soft/module/\n * 重命名: mv apache-hive-2.3.6-bin hive\n\n\n# 2.文件配置\n\n 1. 配置环境变量(略):sudo vim /etc/profile\n 2. hive-env.sh文件(conf目录下),拷贝样例 cp hive-env.sh.template hive-env.sh vim hive-env.sh\n\n# 配置 hadoop_home 路径\nexport hadoop_home=/soft/module/hadoop-2.9.2\n# 配置 hive_conf_dir 路径\nexport hive_conf_dir=/soft/module/hive/conf\n\nexport hive_aux_jars_path=/soft/module/hive/lib\n\n\n\n# 3.hadoop集群配置\n\n 1. 必须启动hdfs和yarn sbin/start-dfs.sh sbin/start-yarn.sh\n 2. 创建目录 因为在hive-site.xml中有这样的配置：\n\n<name>hive.metastore.warehouse.dir</name>\n<value>/user/hive/warehouse</value>\n<name>hive.exec.scratchdir</name>\n<value>/tmp/hive</value>\n\n\n所以要在集群上新建目录\n\n * 在 hdfs 上创建/tmp 和/user/hive/warehouse 两个目录(可不操作，系统会自动创建)\n   hadoop fs -mkdir /tmp hadoop fs -mkdir -p /user/hive/warehouse\n * 并修改他们的同组权限可写\n   hadoop fs -chmod g+w /tmp hadoop fs -chmod g+w /user/hive/warehouse\n\n\n# 4.hive 元数据配置到 mysql\n\n 1. 驱动拷贝 拷贝 mysql-connector-java-5.1.48.jar 到/soft/module/hive/lib/ cp mysql-connector-java-5.1.48.jar /soft/module/hive/lib/\n 2. 配置 metastore 到 mysql\n\n * 在/opt/module/hive/conf 目录下修改 hive-site.xml vim hive-site.xml\n * 根据官方文档配置参数，拷贝数据到 hive-site.xml 文件中 https://cwiki.apache.org/confluence/display/hive/adminmanual+metastoreadmin\n\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    \x3c!--将该name对应的value修改为mysql的地址--\x3e\n    <property>\n        <name>javax.jdo.option.connectionurl</name>\n        <value>jdbc:mysql://hadoop100:3306/metastore?createdatabaseifnotexist=true&amp;characterencoding=utf-8&amp;usessl=false</value>\n        \x3c!-- 有同学时区报错, 需加上 &amp;servertimezone=gmt%2b8 --\x3e\n        <description>jdbc connect string for a jdbc metastore</description>\n    </property>\n    \x3c!--将该name对应的value修改为mysql驱动类路径：--\x3e\n    <property>\n        <name>javax.jdo.option.connectiondrivername</name>\n        <value>com.mysql.jdbc.driver</value>\n        <description>driver class name for a jdbc metastore</description>\n    </property>\n    \x3c!--将对应的value修改为mysql数据库登录名--\x3e\n    <property>\n        <name>javax.jdo.option.connectionusername</name>\n        <value>root</value>\n        <description>username to use against metastore database</description>\n    </property>\n    \x3c!--将对应的value修改为mysql数据库的登录密码--\x3e\n    <property>\n        <name>javax.jdo.option.connectionpassword</name>\n        <value>123456789</value>\n        <description>password to use against metastore database</description>\n    </property>\n</configuration>\n\n\n2.1 第三步和第四步不做行吗??? 或者加上???(我自己没做3,4步)\n\n<property>\n   <name>system:java.io.tmpdir</name>\n   <value>/soft/module/hive/tmpdir</value>\n</property>\n \n<property>\n     <name>system:user.name</name>\n     <value>root</value>\n</property>\n\n\n 3. 修改hive-site.xml中的临时目录 将hive-site.xml文件中的${system:java.io.tmpdir}替换为hive的临时目录，例如我替换为/soft/module/hive/tmp/，该目录如果不存在则要自己手工创建，并且赋予读写权限。\n 4. 将配置文件中${system:user.name}都替换为root\n 5. 配置完毕后，如果启动 hive 异常，可以重新启动虚拟机。（重启后，别忘了启 动 hadoop 集群）\n\n\n# 5.启动和测试\n\nhttps://www.jianshu.com/p/7b1b21bf05c2\n\n> 1、关闭防火墙 2、开启 mysql外链权限 3、jar包冲突，删除hive下 4、配置hive-site.xml\n\n * 初始化数据库：cd $hive_home/bin schematool -initschema -dbtype mysql\n * 启动hive: cd $hive_home/bin 进入hive的bin目录./hive 执行hive启动\n * 测试hive\n   * 简单测试show functions; desc function sum;\n   * 连接测试\n     在成功建立连接后，进入mysql数据库，会发现多了一个metastore数据库，这个数据库就是用来存储hive的元数据信息。\n   * 执行新建库 show databases; create database test_db; use test_db; show tables; create table student(id int,name string) row format delimited fields terminated by '\\t'; load data local inpath '/soft/module/hive/student.txt' into table student; insert into student values(1000,\"ss\");\n   * hadoop的hdfs页面上查看\n   * mysql的hive数据库中查看(可视化工具)\n\n----------------------------------------\n\n 1. 关闭 可以通过ps -ef|grep hive 来看hive 的端口号，然后kill 掉相关的进程。\n 2. 启动 命令 hive --service metastore & hive --service hiveserver2 & nohup hive --service metastore 2>&1 &\n    用来启动metastore nohup hive --service hiveserver2 2>&1 & 用来启动hiveserver2 可以通过查看日志，来确认是否正常启动。 注意！如果 hiveserver2 不启动，jdbc将无法正常连接\n\n\n# 6.hive基本操作\n\n * 启动 hive bin/hive\n * 查看数据库hive> show databases;\n * 打开默认数据库 hive> use default;\n * 显示 default 数据库中的表hive> show tables;\n * 创建一张表hive> create table student(id int, name string);\n * 显示数据库中有几张表hive> show tables;\n * 查看表的结构hive> desc student;\n * 向表中插入数据hive> insert into student values(1000,\"ss\");\n * 查询表中数据hive> select * from student;\n * 退出 hive hive> quit;\n * 清空表 truncate table student;\n * 导入数据三种方式(数据间以tab分隔)\n   * hadoop -put方式: hadoop fs -put student.txt /user/hive/warehouse/test_db.db/student\n   * hive命令行(本地): load data local inpath '/soft/module/hive/student.txt' into table student;\n   * hive命令行(hdfs): load data inpath 'hdfs路径(user/...)' into table student;\n\n----------------------------------------\n\n\n# 三. java api环境准备\n\n\n# 1. centos7启动服务\n\n * 修改hadoop配置vim core-site.xml\n\n<property>\n    <name>hadoop.proxyuser.root.groups</name>\n    <value>*</value>   \n</property>  \n<property>      \n    <name>hadoop.proxyuser.root.hosts</name>\n    <value>*</value>\n</property>\n\n\n分发文件\n\n * 启动命令 /soft/module/hive/bin/hive --service hiveserver2 &(在native的namenode启动)\n   命令启动后挂起,两种方式解决这种不便:\n   * 重新打开一个xshell连接，做其他的linux命令操作，服务启动的会话保留\n   * 使用linux nohup命令，可以防止服务启动挂起nohup:ignoring input and appending output to 'nohup.out' 它会将服务启动的日志输出到当前目录下的nohup.out文件内，我们查看下内容cat nohup.out\n   * 启动后用jpsrunjar进程或在ui界面查看\n\n\n# 2. eclipse配置\n\n-jar包配置 - 挑选必须的jar包，编辑成自己的lib配置到工程中（推荐） 其实所有jar包都在${hive_home}/lib目录下，这里列示下需要的jar包名： ${hadoop_home}/share/hadoop/common/hadoop-common-2.2.0.jar(mr工程中已存在，无需再次添加，如果新建项目需配置 $ { hive_home } /lib/hive-exec-0.11.0.jar $ { hive_home } /lib/hive-jdbc-0.11.0.jar $ { hive_home } /lib/hive-metastore-0.11.0.jar $ { hive_home } /lib/hive-service-0.11.0.jar $ { hive_home } /lib/libfb303-0.9.0.jar $ { hive_home } /lib/commons-logging-1.0.4.jar （此jar包已经存在就不要再次添加） $ { hive_home } /lib/slf4j-api-1.6.1.jar（此jar包已经存在就不要再次添加） - 导入jar包 - 修改pom.xml配置文件（不推荐，会下载额外很多无用包，而且时间很长在1小时左右）\n\n<dependency>\n    <groupid>org.apache.hive</groupid>\n    <artifactid>hive-jdbc</artifactid>\n    <version>2.3.6</version>\n</dependency>\n\n\n\n# 附:一个错误\n\n * user: banana is not allowed to impersonate root 修改配置文件core-site.xml\n\n<property>\n    <name>hadoop.proxyuser.banana.groups</name>\n    <value>*</value>   \n</property>  \n<property>      \n    <name>hadoop.proxyuser.banana.hosts</name>\n    <value>*</value>\n</property>\n\n\n * user: banana is not allowed to impersonate banana\n   这个应该是没在active的namenode上启动的原因, 但我自己就是在active上启动的啊,namenode总会莫名挂掉,最后直接把另一个namenode kill掉,就好使了\n   忘记分发文件core-site.xml两天了!!!!!!!!!!",charsets:{cjk:!0},lastUpdated:"2022/09/09, 11:16:19",lastUpdatedTimestamp:1662693379e3},{title:"Hive相关",frontmatter:{title:"Hive相关",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/dd806a/",categories:["大数据","Hive"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/03.Hive/02.Hive%E7%9B%B8%E5%85%B3.html",relativePath:"02.大数据/03.Hive/02.Hive相关.md",key:"v-786d75c7",path:"/pages/dd806a/",headers:[{level:2,title:"数据从本地导入",slug:"数据从本地导入",normalizedTitle:"数据从本地导入",charIndex:2},{level:2,title:"数据从hdfs导入",slug:"数据从hdfs导入",normalizedTitle:"数据从hdfs导入",charIndex:1085},{level:2,title:"表格操作",slug:"表格操作",normalizedTitle:"表格操作",charIndex:1178},{level:2,title:"数据操作",slug:"数据操作",normalizedTitle:"数据操作",charIndex:2037},{level:2,title:"hive复合(集合)数据类型",slug:"hive复合-集合-数据类型",normalizedTitle:"hive复合(集合)数据类型",charIndex:2171},{level:2,title:"管理表和外部表",slug:"管理表和外部表",normalizedTitle:"管理表和外部表",charIndex:3326},{level:2,title:"分区表(分目录)",slug:"分区表-分目录",normalizedTitle:"分区表(分目录)",charIndex:3880},{level:2,title:"分区表注意事项",slug:"分区表注意事项",normalizedTitle:"分区表注意事项",charIndex:5472},{level:2,title:"分桶表",slug:"分桶表",normalizedTitle:"分桶表",charIndex:6705},{level:2,title:"索引(待添加)",slug:"索引-待添加",normalizedTitle:"索引(待添加)",charIndex:8449},{level:2,title:"系统函数",slug:"系统函数",normalizedTitle:"系统函数",charIndex:8461},{level:3,title:"数学函数",slug:"数学函数",normalizedTitle:"数学函数",charIndex:8575},{level:3,title:"日期函数",slug:"日期函数",normalizedTitle:"日期函数",charIndex:9483},{level:3,title:"字符串函数",slug:"字符串函数",normalizedTitle:"字符串函数",charIndex:10229},{level:3,title:"聚合函数",slug:"聚合函数",normalizedTitle:"聚合函数",charIndex:13046},{level:3,title:"其他（运算符、字符匹配、条件、统计、复杂类型）",slug:"其他-运算符、字符匹配、条件、统计、复杂类型",normalizedTitle:"其他（运算符、字符匹配、条件、统计、复杂类型）",charIndex:13328},{level:3,title:"lateral view 与 explode 以及 reflect（待完善）",slug:"lateral-view-与-explode-以及-reflect-待完善",normalizedTitle:"lateral view 与 explode 以及 reflect（待完善）",charIndex:14054},{level:3,title:"窗口函数",slug:"窗口函数",normalizedTitle:"窗口函数",charIndex:14097},{level:2,title:"自定义函数(UDF、UDAF、UDTF)",slug:"自定义函数-udf、udaf、udtf",normalizedTitle:"自定义函数(udf、udaf、udtf)",charIndex:14927},{level:2,title:"Java API代码",slug:"java-api代码",normalizedTitle:"java api代码",charIndex:15481}],headersStr:"数据从本地导入 数据从hdfs导入 表格操作 数据操作 hive复合(集合)数据类型 管理表和外部表 分区表(分目录) 分区表注意事项 分桶表 索引(待添加) 系统函数 数学函数 日期函数 字符串函数 聚合函数 其他（运算符、字符匹配、条件、统计、复杂类型） lateral view 与 explode 以及 reflect（待完善） 窗口函数 自定义函数(UDF、UDAF、UDTF) Java API代码",content:'# 数据从本地导入\n\n表格信息:\n\nQD01012018070009        张先生  M       山东科技大学    计算机\nQD01012017050004        test张飞        M       北京邮电大学    软件工程\nQD01012017030001        学员秦小建      M       北京邮电大学    软件工程\nQD01012017050003        小四    M       北京邮电大学    软件工程\nQD01012017050006        thomas  M       哈弗    物理\nQD01012017050007        hello kity      F       哈弗    物理\nQD01012017050002        小星    M       深大    计算机\nQD010120180011 12345   M       12345   12345\nQD01012017050005        呵呵    F       北京化工大学    信息工程\nQD01012018070008        测试学生        M       qd      rg\nQD010120180010  123     F       123     123\n\n\n创建表格:\n\ncreate table student_2(code string,name string,gender string,school string,profession string)\n comment \'this is a student table\'\n row format delimited fields terminated by \'\\t\'\n stored as textfile; \n\ncreate table stu_kongge(id int, name string)  \nrow format delimited fields terminated by \' \';\n\n\n从本地导入数据:\n\nload data local inpath \'/soft/module/datas/short-student-utf8.txt\' into table student_2;\n\n查看：hadoop fs -cat /user/hive/warehouse/test_db.db/student_2/short-student-utf8.txt\n\n\n\n# 数据从hdfs导入\n\nload data inpath \'/ahb/datas/short-student-utf8_add.txt\' into table student;\n\n\n\n# 表格操作\n\n清除表内容: truncate table student;\t\n删除表: drop table student;\n重命名:  alter table student_2 rename to student;\n添加列: alter table student add columns (grade string,class string); --导入数据: 先清空表,再导入整理好的数据\n更改列顺序: ALTER TABLE 表名 CHANGE 列名 列名 STRING COMMENT \'列注释\' AFTER 列名;\n删除列: alter table student drop column class string;\n        alter table student replace columns (code string,name string,gender string,school string,profession string,grade string);\n修改列名与类型: alter table student change class banji double;(String转换为Double) --无法double to int转换为String to int或double to int转换为double to int 。\n替换列属性: \n        更新列:\n        ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]\n        增加和替换列:\n        ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)\n\n\n\n# 数据操作\n\n数据查询  select school,count(*) from student_2 group by school;\n数据更新  update student set grade=\'17\' where 1=1;  --配置文件和建表时有要求\n\n\n\n# hive复合(集合)数据类型\n\n * 建表\n\ncreate table t5_struct(\nid int,\nname string,\ninfo struct<city: string ,subway:string > ) \nrow format delimited fields terminated by \'\\t\'\ncollection items terminated by \',\';\n\n\n数据格式\n\n{\n    "name": "songsong",\n    "friends": ["bingbing" , "lili"],      //列表 Array\n    "children": {                     //键值对Map\n        "xiao song": 18 , "xiaoxiao song": 19\n    }\n    "address":{           //结构体Struct\n        "street": "hui long guan", \n        "city": "beijing"\n    }\n}\n\n\n * 创建表:[ terminate:终止,结束 ] [ street:街道 ]\n\ncreate table people(\n    name string,\n    friends array<string>,\n    children map<string,int>,\n    address struct<street:string,city:string>)\nrow format delimited\nfields terminated by \',\'\ncollection items terminated by \'_\'\nmap keys terminated by \':\';\n\n字段解释：\nrow format delimited fields terminated by \',\'   -- 列分隔符\ncollection items terminated by \'_\'          --MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)\nmap keys terminated by \':\'                          -- MAP 中的key 与 value 的分隔符\nlines terminated by \'\\n\';                              -- 行分隔符\n\n\n数据格式\n\n张伟,黄辉鸿_曾小贤_胡一菲,张小伟:18_张大伟:24,屌丝路_上海\n吕小布,陈美嘉_唐悠悠_关谷神奇,小小布:20_吕小小:25,幸福里_上海\n\n\n\n# 管理表和外部表\n\n理论\n\n> 因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。\n\n管理表和外部表的使用场景\n\n> 每天将收集到的网站日志定期流入HDFS 文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过 SELECT+INSERT 进入内部表。\n\n建外部表\n\ncreate external table if not exists default.emp( empno int,\nename string, \njob string, \nmgr int,\nhiredate string, \nsal  double, \ncomm double,\ndeptno int)\nrow format delimited fields terminated by \'\\t\';\n\n\n管理表和外部表相互转换\n\n内部表转为外部表\nalter table student2 set tblproperties(\'EXTERNAL\'=\'TRUE\');\n外部表转为内部表\nalter table student2 set tblproperties(\'EXTERNAL\'=\'FALSE\');\n\n\n\n# 分区表(分目录)\n\n建表\n\ncreate table student2(code string,name string,gender string,school string,profession string,grade string)\npartitioned by (class int)\nrow format delimited fields terminated by \'\\t\'\nstored as textfile;\n\n\n加载数据\n\nload data local inpath "/soft/datas/short-student-utf8_classNO1.txt" into table student2 partition(class=1)\n\n\n扩展\n\n多分区联合查询\n\n增加分区\n创建单个分区\nalter table student2 add partition(class=3);\n同时创建多个分区\nalter table studet2 add partition(class=4) partition(class=5)\n\n删除分区\n删除单个分区\nalter table student2 drop partition(class=3);\n同时删除多个分区\nalter table student2 drop partition(class=4),partition(class=5);\n\n查看分区表有多少分区\nshow partitions student2;\n\n查看分区表结构\ndesc formatted student2;\n批量删除分区\nalter table schema.table_name drop partition (ds&lt;\'2018-08-01\');\n\n批量删除分区脚本\n#!/bin/sh\nif [ $# == 3 ]; then\n    begin_date=`date -d "+0 day $2" +%Y-%m-%d`\n    end_date=`date -d "+0 day $3" +%Y-%m-%d`\n    date=${end_date}\n    sql=\'\'\n    while [[ "${date}" > "${begin_date}" || "${date}" = "${begin_date}" ]]\n          do\n              echo $date\n              sql=${sql}"ALTER TABLE $1 DROP IF EXISTS PARTITION(date = \'$date\');"\n              echo ${sql}\n              date=`date -d "$date -1 days" +"%Y-%m-%d"`\n          done \n    echo "hive -e \'${sql}\' "\n    hive -e "${sql}"\nelif [ $# == 1 ]; then\n    date=`date -d -1days \'+%Y-%m-%d\'`\n    echo "hive -e \'ALTER TABLE $1 DROP IF EXISTS PARTITION(date = \'$date\');\'"\n    hive -e "ALTER TABLE $1 DROP IF EXISTS PARTITION(date = \'$date\');"\nelse \n    echo \'Parameter error!\'\nfi\n————————————————\n原文链接：https://blog.csdn.net/fanlying/article/details/78688003\n\n\n\n# 分区表注意事项\n\n1.创建二级分区表\ncreate table student2(code string,name string,gender string,school string,profession string)\npartitioned by (grade string,class int)\nrow format delimited fields terminated by \'\\t\';\n\n2.加载到二级分区表\nload data local inpath "" into table student2 partition2 partition(grade="18",class=1);\nselect * from student2 where grade="" and class=""\n\n\n动态分区示例：源表字段和输出分区值之间的关系是根据位置而不是根据命名来匹配的，也可以静态分区和动态分区混用\n\ninsert overwrite table 目标表 partition(bdp_day, bdp_year)\nselect\nrel.release_session,\nrel.release_status,\nrel.device_num,\nrel.device_type,\nrel.sources,\nrel.channels,\nfrom_unixtime(rel.ct,\'HH\'),\nfrom_unixtime(rel.ct,\'yyyy-MM-dd HH:mm:ss\'),\nfrom_unixtime(rel.ct,\'yyyy-MM-dd\') as bdp_day  -- 分区字段\nfrom_unixtime(rel.ct,\'yyyy\') as x_year       -- 二级分区\nfrom 源表\n\n\n使用动态分区表必须配置的参数 ：\n\nset hive.exec.dynamic.partition =true  --（默认false）,表示开启动态分区功能\nset hive.exec.dynamic.partition.mode = nonstrict   -- (默认strict),表示允许所有分区都是动态的，否则必须有静态分区字段\n\n\n动态分区相关的调优参数：\n\nset  hive.exec.max.dynamic.partitions.pernode=100 （默认100，一般可以设置大一点，比如1000）\n       表示每个maper或reducer可以允许创建的最大动态分区个数，默认是100，超出则会报错。\nset hive.exec.max.dynamic.partitions =1000(默认值) \n       表示一个动态分区语句可以创建的最大动态分区个数，超出报错\nset hive.exec.max.created.files =10000(默认) 全局可以创建的最大文件个数，超出报错。\n\n\n\n# 分桶表\n\n注：分区针对的是数据的存储路径；分桶针对的是数据文件。 分桶后，桶内有序，整体不一定有序。\n\n> 数据加载通过hdfs dfs -put文件或者通过load data均不好使 原因：数据上传到hdfs上，这个过程怎么识别分桶字段，有怎么取hash值呢（必须经过MapReduce） load是put上去的\n\n缺点: 如果通过数据文件LOAD 到分桶表中，会存在额外的MR负担。 实际生产中分桶策略使用频率较低，更常见的还是使用数据分区。\n\n * 分区针对的是数据的存储路径；分桶针对的是数据文件。\n * Hive Load语句不会在加载数据的时候做任何转换工作，而是纯粹的把数据文件复制/移动到Hive表对应的地址。\n * 分桶表 加载数据 From Select 是经过MR(映射和归纳)的\n\n1.数据准备\n\n\n2.创建分桶表\ncreate table stu_buck(id int, name string) \nclustered by(id) into 4 buckets\nrow format delimited fields terminated by \'\\t\';\n\n3.查看表结构\ndesc formatted stu_buck;\n\n4. 导入数据到分桶表\nload data local inpath "/soft/datas/student.txt" into table stu_buck;\n\n===================不好使====================\n\n创建分桶表，数据通过子查询方式导入\n1.先创建普通表\ncreate table stu(id int, name string)\nrow format delimited fields terminated by \'\\t\';\n\n2.导入数据到普通表\nload data local inpath \'/soft/datas/student.txt\' into table stu;\n\n3.创建分桶表(清空分桶表)\ntruncate table stu_buck;\nselect * from stu_buck;\n\n4.通过子查询的方式导入数据到分桶表\ninsert into table stu_buck select id, name from stu;\n\n5.发现还是只有一个分桶\n\n6.设置属性\n    1.set hive.enforce.bucketing=true; #设置让hive强制分桶，自动按照分桶表的bucket 进行分桶 [程序自动分配reduce的数量从而适配相应的bucket;] \n    2.set mapreduce.job.reduces=-1;    #-1是不指定reduce数量\ninsert into table stu_buck select id, name from stu;\n\n7.查询分桶数据\n select * from stu_buck\n\n\n分桶抽样查询\n\nselect * from stu_buck tablesample(bucket 1 out of 4 on id);\n\n注：tablesample 是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y) 。\n\ny 必须是 table 总 bucket 数的倍数或者因子。hive 根据 y 的大小，决定抽样的比例。例如，table 总共分了 4 份，当 y=2 时，抽取(4/2=)2 个bucket 的数据，当 y=8 时，抽取(4/8=)1/2 个 bucket 的数据。\nx 表示从哪个 bucket 开始抽取，如果需要取多个分区，以后的分区号为当前分区号加上y。例如，table 总 bucket 数为 4，tablesample(bucket 1 out of 2)，表示总共抽取（4/2=）2 个\n\nbucket 的数据，抽取第 1(x)个和第 3(x+y)个 bucket 的数据。注意：x 的值必须小于等于 y 的值，否则\nFAILED: SemanticException [Error 10061]: \n\n\n\n# 索引(待添加)\n\n\n# 系统函数\n\n1.查看系统自带函数 show functions;\n2.显示自带函数用法 desc function upper;\n3.详细显示自带的函数的用法 desc function extended upper\n\n\n\n# 数学函数\n\n点击查看\n\nselect round(-2.5);    #四舍五入\nselect round(0.131415926,3);    #保留n位小数\nselect bround(2.5); select bround(3.5);    #2 4银行家舍入法(四舍六入五取偶)\n银行家舍入法:四舍六入五考虑，五后非空就进一，五后为空看奇偶，五前为偶应舍去，五前为奇要进一\nselect bround(2.55554,3);  #2.556 银行家舍入法,保留d位小数\nselect floor(-2.54); #向下取整(即在数轴上左边的整数)\nselect ceil(-2.54);  #向上取整\nselect rand(); select rand(2);    #返回一个DOUBLE型随机数\nselect exp(2.5); #e的a幂次方\nselect ln(2.5);  #自然数为底d的对数\nselect log10(10.0);  #以10为底d的对数\nselect log2(2.0);  #以2为底数d的对数\nselect log(3,9);  #select log(DOUBLE base, DOUBLE a)以base为底的对数\nselect pow(2,10);  #a的p次幂\nselect sqrt(81);  #a的平方根 \nselect bin(5); select bin(15); #二进制a的STRING类型 bin(BIGINT a)\nselect hex(15); #十六进制a的STRING类型 hex的逆方法 unhex(STRING a)\nselect conv(15,10,2); #把十进制的15转换为二进制\nselect abs(-3);  #绝对值\nselect pmod(13,4);  #取模\nselect sin(60);  #正弦值  \nselect asin(1);  #反正弦值 定义域[-1,1]\nselect e(); # 求e\nselect pi(); # 求pi\nselect factorial(5);  #阶乘\n\n\n\n# 日期函数\n\n点击查看\n\n#获取当前时间戳\nselect unix_timestamp(); \n#UNIX时间戳转日期函数\nselect from_unixtime(1585294471,\'yyyy-MM-dd hh:mm:ss\'); \n#日期转UNIX时间戳函数 指定格式日期转UNIX时间戳函数\nselect unix_timestamp("2020-03-27 03:34:31"); \nselect unix_timestamp("2020-03-27 03:34:31","yyyy-MM-dd hh:mm:ss");\n#日期时间转日期\nselect to_date(\'2020-03-27 03:34:31\');\n#日期取年 select year(\'2020-03-27 03:34:31\');\n#日期取月 select month(\'2020-03-27 03:34:31\');\n#日期取日 select day(\'2020-03-27 03:34:31\');\n#日期取时 select hour(\'2020-03-27 03:34:31\');\n#日期取分 select minute(\'2020-03-27 15:34:31\');\n#日期取秒 select second(\'2020-03-27 15:34:31\');\n#日期转周 select weekofyear(\'2020-03-27 15:34:31\');\n#日期比较 select datediff("2020-3-27","2020-3-2");\n#日期增加 select date_add("2020-3-27",25);\n#日期减少 select date_sub("2020-3-27",25);\n\n\n\n# 字符串函数\n\n点击查看\n\n--字符串模糊匹配\n-- LIKE、RLIKE、REGEXP、regexp_replace、regexp_extract\n\n-- 字符串长度                  select length("hello world");\n-- 字符串反转                  select reverse("洛河飘香茶香飘河洛!");\n-- 字符串连接                  select concat("Hello","World");\n-- 带分隔符字符串连接           select concat_ws("\\t","name","age","sex");\n-- 字符串截取                  substr(str,start),substring(str,start,len)\n                              select substring("洛河飘香茶香飘河洛",4);\n                              select substring("洛河飘香茶香飘河洛",4,3);\n-- 字符串转大写函数             upper,ucase\n                              select upper("Hello World");\n-- 字符串转小写函数：           lower,lcase\n                              select lcase("Hello World");\n-- 去空格(两边)                select trim(" Hello World ");\n-- 左去空格                    select ltrim(" Hello World ");\n-- 右去空格                    select rtrim(" Hello World ");\n-- 正则表达式替换 将字符串A中的符合java正则表达式B的部分替换为C   regexp_replace(string A, string B, string C)\n                              select regexp_replace(\'hello world\', \'or|ll\', \' \');\n-- 正则表达式解析 将字符串subject按照pattern正则表达式的规则拆分，返回index指定的字符 regexp_extract(string subject, string pattern, int index)\n-- 注意，在有些情况下要使用转义字符，下面的等号要用双竖线转义，这是java正则表达式的规则\n                              select regexp_extract(\'foothebar\', \'foo(.*?)(bar)\', 1);\n                              select regexp_extract(\'foothebar\', \'foo(.*?)(bar)\', 2);\n-- URL解析函数 parse_url(string urlString, string partToExtract [, string keyToExtract])\n-- 返回URL中指定的部分。partToExtract的有效值为：HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO\n                              select parse_url("https://www.bilibili.com/video/BV1yE411v7Pq/?spm_id_from=333.788.videocard.1","HOST");\n-- json解析函数 解析json的字符串json_string,返回path指定的内容。如果输入的json字符串无效，那么返回NULL\nselect get_json_object(\'{"store":\n{"fruit":\\[{"weight":8,"type":"apple"},{"weight":9,"type":"pear"}],\n"bicycle":{"price":19.95,"color":"red"}\n},\n"email":"amy@only_for_json_udf_test.net",\n"owner":"amy"\n}\',\'$.owner\');\n\n-- 空格字符串函数 返回长度为n的字符串           select space(10); select length(space(10));\n-- 重复字符串函数 返回重复n次后的str字符串      select repeat(\'hello\',3);\n-- 首字符ascii函数 返回字符串str第一个字符的ascii码      select ascii("hello");\n-- 左补足函数 将str进行用pad进行左补足到len位 lpad(string str, int len, string pad) select lpad("string",10,"do"); #dodostring\n-- 右补足函数                                 select rpad("string",10,"do");\n-- 分割字符串函数 按照pat字符串分割str，会返回分割后的字符串数组 split(string str, string pat)\n                                             select split("pneumonoultramicroscopicsilicovolcanoconiosis","n");\n                                             结果:["p","eumo","oultramicroscopicsilicovolca","oco","iosis"]\n-- 集合查找函数 str在strlist第一次出现的位置，strlist用逗号分割,0未找到   find_in_set(string str, string strList)\n                                             select find_in_set(\'ab\',\'ef,ab,de\');\n\n\n\n\n# 聚合函数\n\n点击查看\n\ncount(),max(),min(),sum(),avg() 等常用的聚合函数\n\n\n> 注意：\n> 聚合操作时要注意 null 值\n> count(*) 包含 null 值，统计所有行数\n> count(id) 不包含 null 值\n> min 求最小值是不包含 null，除非所有值都是 null\n> avg 求平均值也是不包含 null\n\n-- 非空集合总体变量函数: var_pop\n-- 非空集合样本变量函数: var_samp\n-- 总体标准偏离函数: stddev_pop\n-- 中位数函数: percentile\n\n\n\n# 其他（运算符、字符匹配、条件、统计、复杂类型）\n\n点击查看\n\n关系运算 =. <. >. IS NULL. LIKE. PLIKE. REGEXP\n数学运算+ - * / % &  | ~ ^\n逻辑运算AND OR NOT\n条件函数\n-- if(boolean testCondition, T valueTrue, T valueFalseOrNull)\n-- 条件判断函数：case when \n-- 非空查找函数:coalesce(T v1, T v2, …)\n\n集合统计函数等等...count 直方图: histogram_numeric 中位数函数: percentile 总体标准偏离函数: stddev_pop\n复合类型构建map. struct. array\n-- Map类型构建:map (key1, value1, key2, value2, …)\n-- Struct 类型构建:struct(val1, val2, val3, …)\n-- array 类型构建:array(val1, val2, …)\n\n复杂类型访问操作A[n]  M[key]  S.x\n-- array 类型访问:语法: A[n]\n-- map 类型访问:语法: M[key]\n-- struct 类型访问:语法: S.x\n\n复杂类型长度统计函数 size(Map<k .V>) size(Array<T>) 类型转换函数\n-- Map 类型长度函数:语法: size(Map<k .V>)\n-- array 类型长度函数:语法: size(Array<T>)\n-- 类型转换函数: cast  语法: cast(expr as <type>)\n\n\n\n# lateral view 与 explode 以及 reflect（待完善）\n\n\n# 窗口函数\n\n点击查看\n\n# SUM、AVG、MIN、MAX\n\n# ROW_NUMBER、RANK、DENSE_RANK、NTILE\n-- ROW_NUMBER()： ROW_NUMBER()从 1 开始，按照顺序，生成分组内记录的序列\n-- RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位。\n-- DENSE_RANK()生成数据项在分组中的排名，排名相等会在名次中不会留下空位。\n-- ntile 可以看成是：把有序的数据集合平均分配到指定的数量（num）个桶中, 将桶号分配给每一行。如果不能平均分配，则优先分配较小编号的桶，并且各个桶中能放的行数最多相差 1。\n\n# LAG、LEAD、FIRST_VALUE、LAST_VALUE\n-- LAG(col,n,DEFAULT) 用于统计窗口内往上第 n 行值。\n-- LEAD(col,n,DEFAULT) 用于统计窗口内往下第 n 行值。\n-- FIRST_VALUE 取分组内排序后，截止到当前行，第一个值。\n-- LAST_VALUE 取分组内排序后，截止到当前行，最后一个值。\n\n# CUME_DIST\n此函数的结果和 order by 的排序顺序有关系。CUME_DIST：小于等于当前值的行数/分组内总行数。 order 默认顺序 ：正序\n比如，统计小于等于当前薪水的人数，所占总人数的比例。\n\n# GROUPING SETS、GROUPING__ID、CUBE、ROLLUP\n-- grouping sets 是一种将多个 group by 逻辑写在一个 sql 语句中的便利写法。等价于将不同维度的 GROUP BY 结果集进行 UNION ALL。\n-- CUBE ： 根据 GROUP BY 的维度的所有组合进行聚合。  \n-- ROLLUP ： 是 CUBE 的子集，以最左侧的维度为主，从该维度进行层级聚合。比如，以 month 维度进行层级聚合：\n\n\n\n\n# 自定义函数(UDF、UDAF、UDTF)\n\n * UDF（User-Defined-Function） 一进一出\n * UDAF（User-Defined Aggregation Function） 聚集函数，多进一出 类似于：count/max/min\n * UDTF（User-Defined Table-Generating Functions） 一进多出\n\nUDF\n\nhttps://www.cnblogs.com/swordfall/p/11167486.html\n\n1.继承 org.apache.hadoop.hive.ql.exec.UDF\n   \n2.实现 evaluate()函数,此函数支持重载\n\n3.在 hive 命令行创建函数\n   1.添加jar\n   add jar /soft/module/datas/GenderUDF.jar\n   2.创建function\n   create temporary function [dbname.]gender_udf as "com.hrbu.hive.GenderUDF"\n   \n4.在hive命令行删除函数\ndrop temporary function if exists [dbname.]gender_udf\n\n\n\n# Java API代码\n\npackage com.hrbu.hive;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\n\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\n\n\npublic class TeatApi {\n\t\n\t//驱动名称\n\tprivate static String driverName = "org.apache.hive.jdbc.HiveDriver";\n\t//连接用的url\n\tprivate static String url = "jdbc:hive2://192.168.1.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static String user = "";\n\tprivate static String password = "";\n\t\n\tprivate static Connection conn = null;\n\tprivate static Statement stmt = null;\n\tprivate static ResultSet rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@Before\t//表示在任意使用@Test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tClass.forName(driverName);\n\t\t\tconn = DriverManager.getConnection(url,user,password);\n\t\t\tstmt = conn.createStatement();\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t//释放资源\n\t@After //表示在任意使用@Test注解标注的public void方法之后执行\n\tpublic void destory() throws SQLException {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@Test\n\tpublic void create_DataBase() throws SQLException {\n\t\tString sql = "create database IF NOT EXISTS hive_jdbc_test";\t//create database IF NOT EXISTS hive_jdbc_test\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@Test\n\tpublic void create_StudentTable() throws SQLException {\n\t\t//String sql0 = "use hive_jdbc_test";\n\t\tString sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tSystem.out.println("Running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@Test\n\tpublic void show_DataBases() throws SQLException {\n\t\tString sql = "show Databases";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@Test\n\tpublic void show_Tables() throws SQLException {\n\t\tString sql = "show tables";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString(1));\n\t\t}\n\t}\n\t//加载数据\n\t@Test\n\tpublic void load_Data() throws SQLException {\n\t\t//linux路径\n\t\tString filePath = "\'/soft/datas/short-student-utf8.txt\'";\n\t\tString sql = "load data local inpath" + filePath + "overwrite into table student";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@Test\n\tpublic void select_Data() throws SQLException {\n\t\tString sql = "select * from student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\tSystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getString("code") + "\\t" + rs.getString("name") + "\\t" + rs.getString("gender") + "\\t" + rs.getString("school") + "\\t" + rs.getString("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@Test\n\tpublic void count_Data() throws SQLException {\n\t\tString sql = "select count(*) from student";\n\t\tSystem.out.println("Running " + sql);\n\t\trs = stmt.executeQuery(sql);\n\t\tSystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tSystem.out.println(rs.getInt(1));\n\t\t}\n\t}\n\t\n\t//删除数据库\n\t@Test\n\tpublic void drop_DataBase() throws SQLException {\n\t\t//强制删除数据库\n\t\t//String sql = "DROP DATABASE IF EXISTS hive_jdbc_test CASCADE";\n\t\tString sql = "DROP DATABASE IF EXISTS hive_jdbc_test";\n\t\tSystem.out.println("Running " + sql);\n\t\tstmt.execute(sql);\n\t\tSystem.out.println("DROP DATABASE success");\n\t}\n}\n',normalizedContent:'# 数据从本地导入\n\n表格信息:\n\nqd01012018070009        张先生  m       山东科技大学    计算机\nqd01012017050004        test张飞        m       北京邮电大学    软件工程\nqd01012017030001        学员秦小建      m       北京邮电大学    软件工程\nqd01012017050003        小四    m       北京邮电大学    软件工程\nqd01012017050006        thomas  m       哈弗    物理\nqd01012017050007        hello kity      f       哈弗    物理\nqd01012017050002        小星    m       深大    计算机\nqd010120180011 12345   m       12345   12345\nqd01012017050005        呵呵    f       北京化工大学    信息工程\nqd01012018070008        测试学生        m       qd      rg\nqd010120180010  123     f       123     123\n\n\n创建表格:\n\ncreate table student_2(code string,name string,gender string,school string,profession string)\n comment \'this is a student table\'\n row format delimited fields terminated by \'\\t\'\n stored as textfile; \n\ncreate table stu_kongge(id int, name string)  \nrow format delimited fields terminated by \' \';\n\n\n从本地导入数据:\n\nload data local inpath \'/soft/module/datas/short-student-utf8.txt\' into table student_2;\n\n查看：hadoop fs -cat /user/hive/warehouse/test_db.db/student_2/short-student-utf8.txt\n\n\n\n# 数据从hdfs导入\n\nload data inpath \'/ahb/datas/short-student-utf8_add.txt\' into table student;\n\n\n\n# 表格操作\n\n清除表内容: truncate table student;\t\n删除表: drop table student;\n重命名:  alter table student_2 rename to student;\n添加列: alter table student add columns (grade string,class string); --导入数据: 先清空表,再导入整理好的数据\n更改列顺序: alter table 表名 change 列名 列名 string comment \'列注释\' after 列名;\n删除列: alter table student drop column class string;\n        alter table student replace columns (code string,name string,gender string,school string,profession string,grade string);\n修改列名与类型: alter table student change class banji double;(string转换为double) --无法double to int转换为string to int或double to int转换为double to int 。\n替换列属性: \n        更新列:\n        alter table table_name change [column] col_old_name col_new_name column_type [comment col_comment] [first|after column_name]\n        增加和替换列:\n        alter table table_name add|replace columns (col_name data_type [comment col_comment], ...)\n\n\n\n# 数据操作\n\n数据查询  select school,count(*) from student_2 group by school;\n数据更新  update student set grade=\'17\' where 1=1;  --配置文件和建表时有要求\n\n\n\n# hive复合(集合)数据类型\n\n * 建表\n\ncreate table t5_struct(\nid int,\nname string,\ninfo struct<city: string ,subway:string > ) \nrow format delimited fields terminated by \'\\t\'\ncollection items terminated by \',\';\n\n\n数据格式\n\n{\n    "name": "songsong",\n    "friends": ["bingbing" , "lili"],      //列表 array\n    "children": {                     //键值对map\n        "xiao song": 18 , "xiaoxiao song": 19\n    }\n    "address":{           //结构体struct\n        "street": "hui long guan", \n        "city": "beijing"\n    }\n}\n\n\n * 创建表:[ terminate:终止,结束 ] [ street:街道 ]\n\ncreate table people(\n    name string,\n    friends array<string>,\n    children map<string,int>,\n    address struct<street:string,city:string>)\nrow format delimited\nfields terminated by \',\'\ncollection items terminated by \'_\'\nmap keys terminated by \':\';\n\n字段解释：\nrow format delimited fields terminated by \',\'   -- 列分隔符\ncollection items terminated by \'_\'          --map struct 和 array 的分隔符(数据分割符号)\nmap keys terminated by \':\'                          -- map 中的key 与 value 的分隔符\nlines terminated by \'\\n\';                              -- 行分隔符\n\n\n数据格式\n\n张伟,黄辉鸿_曾小贤_胡一菲,张小伟:18_张大伟:24,屌丝路_上海\n吕小布,陈美嘉_唐悠悠_关谷神奇,小小布:20_吕小小:25,幸福里_上海\n\n\n\n# 管理表和外部表\n\n理论\n\n> 因为表是外部表，所以 hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。\n\n管理表和外部表的使用场景\n\n> 每天将收集到的网站日志定期流入hdfs 文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过 select+insert 进入内部表。\n\n建外部表\n\ncreate external table if not exists default.emp( empno int,\nename string, \njob string, \nmgr int,\nhiredate string, \nsal  double, \ncomm double,\ndeptno int)\nrow format delimited fields terminated by \'\\t\';\n\n\n管理表和外部表相互转换\n\n内部表转为外部表\nalter table student2 set tblproperties(\'external\'=\'true\');\n外部表转为内部表\nalter table student2 set tblproperties(\'external\'=\'false\');\n\n\n\n# 分区表(分目录)\n\n建表\n\ncreate table student2(code string,name string,gender string,school string,profession string,grade string)\npartitioned by (class int)\nrow format delimited fields terminated by \'\\t\'\nstored as textfile;\n\n\n加载数据\n\nload data local inpath "/soft/datas/short-student-utf8_classno1.txt" into table student2 partition(class=1)\n\n\n扩展\n\n多分区联合查询\n\n增加分区\n创建单个分区\nalter table student2 add partition(class=3);\n同时创建多个分区\nalter table studet2 add partition(class=4) partition(class=5)\n\n删除分区\n删除单个分区\nalter table student2 drop partition(class=3);\n同时删除多个分区\nalter table student2 drop partition(class=4),partition(class=5);\n\n查看分区表有多少分区\nshow partitions student2;\n\n查看分区表结构\ndesc formatted student2;\n批量删除分区\nalter table schema.table_name drop partition (ds&lt;\'2018-08-01\');\n\n批量删除分区脚本\n#!/bin/sh\nif [ $# == 3 ]; then\n    begin_date=`date -d "+0 day $2" +%y-%m-%d`\n    end_date=`date -d "+0 day $3" +%y-%m-%d`\n    date=${end_date}\n    sql=\'\'\n    while [[ "${date}" > "${begin_date}" || "${date}" = "${begin_date}" ]]\n          do\n              echo $date\n              sql=${sql}"alter table $1 drop if exists partition(date = \'$date\');"\n              echo ${sql}\n              date=`date -d "$date -1 days" +"%y-%m-%d"`\n          done \n    echo "hive -e \'${sql}\' "\n    hive -e "${sql}"\nelif [ $# == 1 ]; then\n    date=`date -d -1days \'+%y-%m-%d\'`\n    echo "hive -e \'alter table $1 drop if exists partition(date = \'$date\');\'"\n    hive -e "alter table $1 drop if exists partition(date = \'$date\');"\nelse \n    echo \'parameter error!\'\nfi\n————————————————\n原文链接：https://blog.csdn.net/fanlying/article/details/78688003\n\n\n\n# 分区表注意事项\n\n1.创建二级分区表\ncreate table student2(code string,name string,gender string,school string,profession string)\npartitioned by (grade string,class int)\nrow format delimited fields terminated by \'\\t\';\n\n2.加载到二级分区表\nload data local inpath "" into table student2 partition2 partition(grade="18",class=1);\nselect * from student2 where grade="" and class=""\n\n\n动态分区示例：源表字段和输出分区值之间的关系是根据位置而不是根据命名来匹配的，也可以静态分区和动态分区混用\n\ninsert overwrite table 目标表 partition(bdp_day, bdp_year)\nselect\nrel.release_session,\nrel.release_status,\nrel.device_num,\nrel.device_type,\nrel.sources,\nrel.channels,\nfrom_unixtime(rel.ct,\'hh\'),\nfrom_unixtime(rel.ct,\'yyyy-mm-dd hh:mm:ss\'),\nfrom_unixtime(rel.ct,\'yyyy-mm-dd\') as bdp_day  -- 分区字段\nfrom_unixtime(rel.ct,\'yyyy\') as x_year       -- 二级分区\nfrom 源表\n\n\n使用动态分区表必须配置的参数 ：\n\nset hive.exec.dynamic.partition =true  --（默认false）,表示开启动态分区功能\nset hive.exec.dynamic.partition.mode = nonstrict   -- (默认strict),表示允许所有分区都是动态的，否则必须有静态分区字段\n\n\n动态分区相关的调优参数：\n\nset  hive.exec.max.dynamic.partitions.pernode=100 （默认100，一般可以设置大一点，比如1000）\n       表示每个maper或reducer可以允许创建的最大动态分区个数，默认是100，超出则会报错。\nset hive.exec.max.dynamic.partitions =1000(默认值) \n       表示一个动态分区语句可以创建的最大动态分区个数，超出报错\nset hive.exec.max.created.files =10000(默认) 全局可以创建的最大文件个数，超出报错。\n\n\n\n# 分桶表\n\n注：分区针对的是数据的存储路径；分桶针对的是数据文件。 分桶后，桶内有序，整体不一定有序。\n\n> 数据加载通过hdfs dfs -put文件或者通过load data均不好使 原因：数据上传到hdfs上，这个过程怎么识别分桶字段，有怎么取hash值呢（必须经过mapreduce） load是put上去的\n\n缺点: 如果通过数据文件load 到分桶表中，会存在额外的mr负担。 实际生产中分桶策略使用频率较低，更常见的还是使用数据分区。\n\n * 分区针对的是数据的存储路径；分桶针对的是数据文件。\n * hive load语句不会在加载数据的时候做任何转换工作，而是纯粹的把数据文件复制/移动到hive表对应的地址。\n * 分桶表 加载数据 from select 是经过mr(映射和归纳)的\n\n1.数据准备\n\n\n2.创建分桶表\ncreate table stu_buck(id int, name string) \nclustered by(id) into 4 buckets\nrow format delimited fields terminated by \'\\t\';\n\n3.查看表结构\ndesc formatted stu_buck;\n\n4. 导入数据到分桶表\nload data local inpath "/soft/datas/student.txt" into table stu_buck;\n\n===================不好使====================\n\n创建分桶表，数据通过子查询方式导入\n1.先创建普通表\ncreate table stu(id int, name string)\nrow format delimited fields terminated by \'\\t\';\n\n2.导入数据到普通表\nload data local inpath \'/soft/datas/student.txt\' into table stu;\n\n3.创建分桶表(清空分桶表)\ntruncate table stu_buck;\nselect * from stu_buck;\n\n4.通过子查询的方式导入数据到分桶表\ninsert into table stu_buck select id, name from stu;\n\n5.发现还是只有一个分桶\n\n6.设置属性\n    1.set hive.enforce.bucketing=true; #设置让hive强制分桶，自动按照分桶表的bucket 进行分桶 [程序自动分配reduce的数量从而适配相应的bucket;] \n    2.set mapreduce.job.reduces=-1;    #-1是不指定reduce数量\ninsert into table stu_buck select id, name from stu;\n\n7.查询分桶数据\n select * from stu_buck\n\n\n分桶抽样查询\n\nselect * from stu_buck tablesample(bucket 1 out of 4 on id);\n\n注：tablesample 是抽样语句，语法：tablesample(bucket x out of y) 。\n\ny 必须是 table 总 bucket 数的倍数或者因子。hive 根据 y 的大小，决定抽样的比例。例如，table 总共分了 4 份，当 y=2 时，抽取(4/2=)2 个bucket 的数据，当 y=8 时，抽取(4/8=)1/2 个 bucket 的数据。\nx 表示从哪个 bucket 开始抽取，如果需要取多个分区，以后的分区号为当前分区号加上y。例如，table 总 bucket 数为 4，tablesample(bucket 1 out of 2)，表示总共抽取（4/2=）2 个\n\nbucket 的数据，抽取第 1(x)个和第 3(x+y)个 bucket 的数据。注意：x 的值必须小于等于 y 的值，否则\nfailed: semanticexception [error 10061]: \n\n\n\n# 索引(待添加)\n\n\n# 系统函数\n\n1.查看系统自带函数 show functions;\n2.显示自带函数用法 desc function upper;\n3.详细显示自带的函数的用法 desc function extended upper\n\n\n\n# 数学函数\n\n点击查看\n\nselect round(-2.5);    #四舍五入\nselect round(0.131415926,3);    #保留n位小数\nselect bround(2.5); select bround(3.5);    #2 4银行家舍入法(四舍六入五取偶)\n银行家舍入法:四舍六入五考虑，五后非空就进一，五后为空看奇偶，五前为偶应舍去，五前为奇要进一\nselect bround(2.55554,3);  #2.556 银行家舍入法,保留d位小数\nselect floor(-2.54); #向下取整(即在数轴上左边的整数)\nselect ceil(-2.54);  #向上取整\nselect rand(); select rand(2);    #返回一个double型随机数\nselect exp(2.5); #e的a幂次方\nselect ln(2.5);  #自然数为底d的对数\nselect log10(10.0);  #以10为底d的对数\nselect log2(2.0);  #以2为底数d的对数\nselect log(3,9);  #select log(double base, double a)以base为底的对数\nselect pow(2,10);  #a的p次幂\nselect sqrt(81);  #a的平方根 \nselect bin(5); select bin(15); #二进制a的string类型 bin(bigint a)\nselect hex(15); #十六进制a的string类型 hex的逆方法 unhex(string a)\nselect conv(15,10,2); #把十进制的15转换为二进制\nselect abs(-3);  #绝对值\nselect pmod(13,4);  #取模\nselect sin(60);  #正弦值  \nselect asin(1);  #反正弦值 定义域[-1,1]\nselect e(); # 求e\nselect pi(); # 求pi\nselect factorial(5);  #阶乘\n\n\n\n# 日期函数\n\n点击查看\n\n#获取当前时间戳\nselect unix_timestamp(); \n#unix时间戳转日期函数\nselect from_unixtime(1585294471,\'yyyy-mm-dd hh:mm:ss\'); \n#日期转unix时间戳函数 指定格式日期转unix时间戳函数\nselect unix_timestamp("2020-03-27 03:34:31"); \nselect unix_timestamp("2020-03-27 03:34:31","yyyy-mm-dd hh:mm:ss");\n#日期时间转日期\nselect to_date(\'2020-03-27 03:34:31\');\n#日期取年 select year(\'2020-03-27 03:34:31\');\n#日期取月 select month(\'2020-03-27 03:34:31\');\n#日期取日 select day(\'2020-03-27 03:34:31\');\n#日期取时 select hour(\'2020-03-27 03:34:31\');\n#日期取分 select minute(\'2020-03-27 15:34:31\');\n#日期取秒 select second(\'2020-03-27 15:34:31\');\n#日期转周 select weekofyear(\'2020-03-27 15:34:31\');\n#日期比较 select datediff("2020-3-27","2020-3-2");\n#日期增加 select date_add("2020-3-27",25);\n#日期减少 select date_sub("2020-3-27",25);\n\n\n\n# 字符串函数\n\n点击查看\n\n--字符串模糊匹配\n-- like、rlike、regexp、regexp_replace、regexp_extract\n\n-- 字符串长度                  select length("hello world");\n-- 字符串反转                  select reverse("洛河飘香茶香飘河洛!");\n-- 字符串连接                  select concat("hello","world");\n-- 带分隔符字符串连接           select concat_ws("\\t","name","age","sex");\n-- 字符串截取                  substr(str,start),substring(str,start,len)\n                              select substring("洛河飘香茶香飘河洛",4);\n                              select substring("洛河飘香茶香飘河洛",4,3);\n-- 字符串转大写函数             upper,ucase\n                              select upper("hello world");\n-- 字符串转小写函数：           lower,lcase\n                              select lcase("hello world");\n-- 去空格(两边)                select trim(" hello world ");\n-- 左去空格                    select ltrim(" hello world ");\n-- 右去空格                    select rtrim(" hello world ");\n-- 正则表达式替换 将字符串a中的符合java正则表达式b的部分替换为c   regexp_replace(string a, string b, string c)\n                              select regexp_replace(\'hello world\', \'or|ll\', \' \');\n-- 正则表达式解析 将字符串subject按照pattern正则表达式的规则拆分，返回index指定的字符 regexp_extract(string subject, string pattern, int index)\n-- 注意，在有些情况下要使用转义字符，下面的等号要用双竖线转义，这是java正则表达式的规则\n                              select regexp_extract(\'foothebar\', \'foo(.*?)(bar)\', 1);\n                              select regexp_extract(\'foothebar\', \'foo(.*?)(bar)\', 2);\n-- url解析函数 parse_url(string urlstring, string parttoextract [, string keytoextract])\n-- 返回url中指定的部分。parttoextract的有效值为：host, path, query, ref, protocol, authority, file, and userinfo\n                              select parse_url("https://www.bilibili.com/video/bv1ye411v7pq/?spm_id_from=333.788.videocard.1","host");\n-- json解析函数 解析json的字符串json_string,返回path指定的内容。如果输入的json字符串无效，那么返回null\nselect get_json_object(\'{"store":\n{"fruit":\\[{"weight":8,"type":"apple"},{"weight":9,"type":"pear"}],\n"bicycle":{"price":19.95,"color":"red"}\n},\n"email":"amy@only_for_json_udf_test.net",\n"owner":"amy"\n}\',\'$.owner\');\n\n-- 空格字符串函数 返回长度为n的字符串           select space(10); select length(space(10));\n-- 重复字符串函数 返回重复n次后的str字符串      select repeat(\'hello\',3);\n-- 首字符ascii函数 返回字符串str第一个字符的ascii码      select ascii("hello");\n-- 左补足函数 将str进行用pad进行左补足到len位 lpad(string str, int len, string pad) select lpad("string",10,"do"); #dodostring\n-- 右补足函数                                 select rpad("string",10,"do");\n-- 分割字符串函数 按照pat字符串分割str，会返回分割后的字符串数组 split(string str, string pat)\n                                             select split("pneumonoultramicroscopicsilicovolcanoconiosis","n");\n                                             结果:["p","eumo","oultramicroscopicsilicovolca","oco","iosis"]\n-- 集合查找函数 str在strlist第一次出现的位置，strlist用逗号分割,0未找到   find_in_set(string str, string strlist)\n                                             select find_in_set(\'ab\',\'ef,ab,de\');\n\n\n\n\n# 聚合函数\n\n点击查看\n\ncount(),max(),min(),sum(),avg() 等常用的聚合函数\n\n\n> 注意：\n> 聚合操作时要注意 null 值\n> count(*) 包含 null 值，统计所有行数\n> count(id) 不包含 null 值\n> min 求最小值是不包含 null，除非所有值都是 null\n> avg 求平均值也是不包含 null\n\n-- 非空集合总体变量函数: var_pop\n-- 非空集合样本变量函数: var_samp\n-- 总体标准偏离函数: stddev_pop\n-- 中位数函数: percentile\n\n\n\n# 其他（运算符、字符匹配、条件、统计、复杂类型）\n\n点击查看\n\n关系运算 =. <. >. is null. like. plike. regexp\n数学运算+ - * / % &  | ~ ^\n逻辑运算and or not\n条件函数\n-- if(boolean testcondition, t valuetrue, t valuefalseornull)\n-- 条件判断函数：case when \n-- 非空查找函数:coalesce(t v1, t v2, …)\n\n集合统计函数等等...count 直方图: histogram_numeric 中位数函数: percentile 总体标准偏离函数: stddev_pop\n复合类型构建map. struct. array\n-- map类型构建:map (key1, value1, key2, value2, …)\n-- struct 类型构建:struct(val1, val2, val3, …)\n-- array 类型构建:array(val1, val2, …)\n\n复杂类型访问操作a[n]  m[key]  s.x\n-- array 类型访问:语法: a[n]\n-- map 类型访问:语法: m[key]\n-- struct 类型访问:语法: s.x\n\n复杂类型长度统计函数 size(map<k .v>) size(array<t>) 类型转换函数\n-- map 类型长度函数:语法: size(map<k .v>)\n-- array 类型长度函数:语法: size(array<t>)\n-- 类型转换函数: cast  语法: cast(expr as <type>)\n\n\n\n# lateral view 与 explode 以及 reflect（待完善）\n\n\n# 窗口函数\n\n点击查看\n\n# sum、avg、min、max\n\n# row_number、rank、dense_rank、ntile\n-- row_number()： row_number()从 1 开始，按照顺序，生成分组内记录的序列\n-- rank() 生成数据项在分组中的排名，排名相等会在名次中留下空位。\n-- dense_rank()生成数据项在分组中的排名，排名相等会在名次中不会留下空位。\n-- ntile 可以看成是：把有序的数据集合平均分配到指定的数量（num）个桶中, 将桶号分配给每一行。如果不能平均分配，则优先分配较小编号的桶，并且各个桶中能放的行数最多相差 1。\n\n# lag、lead、first_value、last_value\n-- lag(col,n,default) 用于统计窗口内往上第 n 行值。\n-- lead(col,n,default) 用于统计窗口内往下第 n 行值。\n-- first_value 取分组内排序后，截止到当前行，第一个值。\n-- last_value 取分组内排序后，截止到当前行，最后一个值。\n\n# cume_dist\n此函数的结果和 order by 的排序顺序有关系。cume_dist：小于等于当前值的行数/分组内总行数。 order 默认顺序 ：正序\n比如，统计小于等于当前薪水的人数，所占总人数的比例。\n\n# grouping sets、grouping__id、cube、rollup\n-- grouping sets 是一种将多个 group by 逻辑写在一个 sql 语句中的便利写法。等价于将不同维度的 group by 结果集进行 union all。\n-- cube ： 根据 group by 的维度的所有组合进行聚合。  \n-- rollup ： 是 cube 的子集，以最左侧的维度为主，从该维度进行层级聚合。比如，以 month 维度进行层级聚合：\n\n\n\n\n# 自定义函数(udf、udaf、udtf)\n\n * udf（user-defined-function） 一进一出\n * udaf（user-defined aggregation function） 聚集函数，多进一出 类似于：count/max/min\n * udtf（user-defined table-generating functions） 一进多出\n\nudf\n\nhttps://www.cnblogs.com/swordfall/p/11167486.html\n\n1.继承 org.apache.hadoop.hive.ql.exec.udf\n   \n2.实现 evaluate()函数,此函数支持重载\n\n3.在 hive 命令行创建函数\n   1.添加jar\n   add jar /soft/module/datas/genderudf.jar\n   2.创建function\n   create temporary function [dbname.]gender_udf as "com.hrbu.hive.genderudf"\n   \n4.在hive命令行删除函数\ndrop temporary function if exists [dbname.]gender_udf\n\n\n\n# java api代码\n\npackage com.hrbu.hive;\n\nimport java.sql.connection;\nimport java.sql.drivermanager;\nimport java.sql.resultset;\nimport java.sql.sqlexception;\nimport java.sql.statement;\n\nimport org.junit.after;\nimport org.junit.before;\nimport org.junit.test;\n\n\n\npublic class teatapi {\n\t\n\t//驱动名称\n\tprivate static string drivername = "org.apache.hive.jdbc.hivedriver";\n\t//连接用的url\n\tprivate static string url = "jdbc:hive2://192.168.1.100:10000/default";\n\t//用户名与密码无需提供\n\tprivate static string user = "";\n\tprivate static string password = "";\n\t\n\tprivate static connection conn = null;\n\tprivate static statement stmt = null;\n\tprivate static resultset rs = null;\n\t\n\t/**\n\t * junit单元测试方法,关键技术是注解\n\t * 1可以随时测试某个方法,不用再写main函数与多余的代码\n\t * 2面向切面的before和after使我们的代码结构更加合理\n\t */\n\t//加载驱动,创建连接\n\t@before\t//表示在任意使用@test注解标注的public void方法之前执行\n\tpublic void init() {\n\t\ttry {\n\t\t\tclass.forname(drivername);\n\t\t\tconn = drivermanager.getconnection(url,user,password);\n\t\t\tstmt = conn.createstatement();\n\t\t} catch (exception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t}\n\t//释放资源\n\t@after //表示在任意使用@test注解标注的public void方法之后执行\n\tpublic void destory() throws sqlexception {\n\t\tif(rs != null) {\n\t\t\trs.close();\n\t\t}\n\t\tif(stmt != null) {\n\t\t\tstmt.close();\n\t\t}\n\t\tif(conn != null) {\n\t\t\tconn.close();\n\t\t}\n\t}\n\t//创建数据库\n\t@test\n\tpublic void create_database() throws sqlexception {\n\t\tstring sql = "create database if not exists hive_jdbc_test";\t//create database if not exists hive_jdbc_test\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create database success");\n\t}\n\t//创建表格\n\t@test\n\tpublic void create_studenttable() throws sqlexception {\n\t\t//string sql0 = "use hive_jdbc_test";\n\t\tstring sql = "create table student(code string,name string,gender string,school string,profession string)\\r\\n" + \n\t\t\t\t" comment \'this is a student table\'\\r\\n" + \n\t\t\t\t" row format delimited fields terminated by \'\\\\t\'\\r\\n" + \n\t\t\t\t" stored as textfile";\n\t\tsystem.out.println("running create table student");\n\t\t//stmt.execute(sql0);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("create table student success");\n\t}\n\t\n\t// 查询所有数据库\n\t@test\n\tpublic void show_databases() throws sqlexception {\n\t\tstring sql = "show databases";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t// 查询当前数据库中所有表\n\t@test\n\tpublic void show_tables() throws sqlexception {\n\t\tstring sql = "show tables";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring(1));\n\t\t}\n\t}\n\t//加载数据\n\t@test\n\tpublic void load_data() throws sqlexception {\n\t\t//linux路径\n\t\tstring filepath = "\'/soft/datas/short-student-utf8.txt\'";\n\t\tstring sql = "load data local inpath" + filepath + "overwrite into table student";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("load data local success");\n\t}\n\t//查询数据\n\t@test\n\tpublic void select_data() throws sqlexception {\n\t\tstring sql = "select * from student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\tsystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getstring("code") + "\\t" + rs.getstring("name") + "\\t" + rs.getstring("gender") + "\\t" + rs.getstring("school") + "\\t" + rs.getstring("profession"));\n\t\t}\n\t}\n\t//统计查询(运行mapreduce作业)\n\t@test\n\tpublic void count_data() throws sqlexception {\n\t\tstring sql = "select count(*) from student";\n\t\tsystem.out.println("running " + sql);\n\t\trs = stmt.executequery(sql);\n\t\tsystem.out.println("学号\\t姓名\\t性别\\t学校\\t专业");\n\t\twhile(rs.next()) {\n\t\t\tsystem.out.println(rs.getint(1));\n\t\t}\n\t}\n\t\n\t//删除数据库\n\t@test\n\tpublic void drop_database() throws sqlexception {\n\t\t//强制删除数据库\n\t\t//string sql = "drop database if exists hive_jdbc_test cascade";\n\t\tstring sql = "drop database if exists hive_jdbc_test";\n\t\tsystem.out.println("running " + sql);\n\t\tstmt.execute(sql);\n\t\tsystem.out.println("drop database success");\n\t}\n}\n',charsets:{cjk:!0},lastUpdated:"2022/07/07, 11:20:39",lastUpdatedTimestamp:1657164039e3},{title:"HSQL",frontmatter:{title:"HSQL",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/dd807a/",categories:["大数据","Hive"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/03.Hive/03.HSQL.html",relativePath:"02.大数据/03.Hive/03.HSQL.md",key:"v-bb3e9386",path:"/pages/dd807a/",headers:[{level:2,title:"函数",slug:"函数",normalizedTitle:"函数",charIndex:2},{level:3,title:"collect_list",slug:"collect-list",normalizedTitle:"collect_list",charIndex:9},{level:2,title:"SQL实例",slug:"sql实例",normalizedTitle:"sql实例",charIndex:658},{level:3,title:"炸裂函数（一行变多行）",slug:"炸裂函数-一行变多行",normalizedTitle:"炸裂函数（一行变多行）",charIndex:668},{level:2,title:"HSQL执行计划",slug:"hsql执行计划",normalizedTitle:"hsql执行计划",charIndex:845}],headersStr:"函数 collect_list SQL实例 炸裂函数（一行变多行） HSQL执行计划",content:"# 函数\n\n\n# collect_list\n\nDROP TABLE IF EXISTS tmp_prgdb.tmp_dwa_user_attribute_day_007;\nCREATE TABLE tmp_prgdb.tmp_dwa_user_attribute_day_007 STORED AS ORC AS\nselect\n          user_id\n         ,collect_list(visit_time) as visit_page_top5       --近30天浏览页面名称\n    from (\n            select\n                     user_id\n                    ,visit_time\n                    ,row_number() over(PARTITION BY user_id ORDER BY visit_time desc) rn_desc\n               from dwm_db.dwm_cp_ubh_visit_day\n              where day_id >= DATE_SUB('${DAY_ID}',30)\n                and day_id <= DATE_ADD('${DAY_ID}',1)\n         ) B4\n   where B4.rn_desc <= 5\ngroup by user_id\n\n\n\n# SQL实例\n\n\n# 炸裂函数（一行变多行）\n\n效果上类似于笛卡尔积（join不加条件）\n\nselect user_id,kv \nfrom dws_md_event_info_day \nlateral view explode(split(`event_property`,',')) tmp as kv \nwhere etl_date='2020-11-04';\n\n\n\n# HSQL执行计划\n\n博客",normalizedContent:"# 函数\n\n\n# collect_list\n\ndrop table if exists tmp_prgdb.tmp_dwa_user_attribute_day_007;\ncreate table tmp_prgdb.tmp_dwa_user_attribute_day_007 stored as orc as\nselect\n          user_id\n         ,collect_list(visit_time) as visit_page_top5       --近30天浏览页面名称\n    from (\n            select\n                     user_id\n                    ,visit_time\n                    ,row_number() over(partition by user_id order by visit_time desc) rn_desc\n               from dwm_db.dwm_cp_ubh_visit_day\n              where day_id >= date_sub('${day_id}',30)\n                and day_id <= date_add('${day_id}',1)\n         ) b4\n   where b4.rn_desc <= 5\ngroup by user_id\n\n\n\n# sql实例\n\n\n# 炸裂函数（一行变多行）\n\n效果上类似于笛卡尔积（join不加条件）\n\nselect user_id,kv \nfrom dws_md_event_info_day \nlateral view explode(split(`event_property`,',')) tmp as kv \nwhere etl_date='2020-11-04';\n\n\n\n# hsql执行计划\n\n博客",charsets:{cjk:!0},lastUpdated:"2025/01/02, 13:03:48",lastUpdatedTimestamp:1735794228e3},{title:"Kafka集群搭建",frontmatter:{title:"Kafka集群搭建",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/bfa383/",categories:["大数据","Kafka"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/04.Kafka/01.Kafka%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/04.Kafka/01.Kafka集群搭建.md",key:"v-555e21cf",path:"/pages/bfa383/",headers:[{level:3,title:"1.下载安装",slug:"_1-下载安装",normalizedTitle:"1.下载安装",charIndex:156},{level:3,title:"2.修改配置文件",slug:"_2-修改配置文件",normalizedTitle:"2.修改配置文件",charIndex:336},{level:3,title:"3.启动集群",slug:"_3-启动集群",normalizedTitle:"3.启动集群",charIndex:1303},{level:3,title:"4.kafka命令行操作",slug:"_4-kafka命令行操作",normalizedTitle:"4.kafka命令行操作",charIndex:1634}],headersStr:"1.下载安装 2.修改配置文件 3.启动集群 4.kafka命令行操作",content:"理论\n\n * 消息队列\n   * 异步(两个不用同时在线)\n   * 削峰\n\n点对点模式\n\n发布订阅模式\n\n> 消费者拉取(kafka)(缺点：长轮询)(优点：消费者决定速率) 消息队列推送\n\n==在此之前,要安装好jdk和Zookeeper集群== 安装位置:我猜是和Zookeeper安装的机器一样\n\n\n# 1.下载安装\n\n * 在官网下载(最新版本?)(一般不会出现版本兼容问题): kafka_2.12-2.4.1.tgz\n * 上传到虚拟机\n * 解压安装: tar -zxvf /soft/software/kafka_2.12-2.4.1.tgz -C /soft/module/\n * 重命名: mv kafka_2.12-2.4.1 kafka\n\n\n# 2.修改配置文件\n\n 1. 在kafka目录下新建文件夹: mkdir logs\n 2. 修改配置文件: cd config/ vim server.properties\n\n#broker 的全局唯一编号，不能重复\nbroker.id=0\n#删除 topic 功能使能彻底删除\ndelete.topic.enable=true\n#kafka 运行日志存放的路径\nlog.dirs=/soft/module/kafka/logs\n#配置连接Zookeeper 集群地址\nzookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181\n\n#后面不是必须配置的内容\n#处理网络请求的线程数量\nnum.network.threads=3\n#用来处理磁盘 IO 的线程数量\nnum.io.threads=8\n#发送套接字的缓冲区大小\nsocket.send.buffer.bytes=102400 \n#接收套接字的缓冲区大小\nsocket.receive.buffer.bytes=102400 \n#请求套接字的缓冲区大小\nsocket.request.max.bytes=104857600\n#topic 在当前 broker 上的分区个数\nnum.partitions=1\n#用来恢复和清理 data 下数据的线程数量\nnum.recovery.threads.per.data.dir=1 \n#segment 文件保留的最长时间，超时将被删除\nlog.retention.hours=168\n\n\n 3. 配置环境变量 sudo vim /etc/profile\n\n#KAFKA_HOME 环境变量配置\nexport KAFKA_HOME=/soft/module/kafka export PATH=$PATH:$KAFKA_HOME/bin\n\n\nsource /etc/profile 4. 分发文件 5. 修改集群其它机器kafka配置 分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2 注：broker.id不得重复\n\n\n# 3.启动集群\n\n先启动Zookeeper\n\n 1. 单机启动 启动: bin/kafka-server-start.sh -daemon config/server.properties 关闭: bin/kafka-server-stop.sh stop\n 2. 集群启动 启动脚本\n\nfor i in hadoop101 hadoop102 hadoop103 do\necho \"========== $i ==========\"\nssh\t$i\t'/soft/module/kafka/bin/kafka-server-start.sh\n/soft/module/kafka/config/server.properties' done\n\n\n 3. \n\n\n# 4.kafka命令行操作\n\n 1. 查看当前服务器中的所有 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --list\n\n 2. 创建 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --create --replication-factor 3 --partitions 1 --topic first --topic 定义 topic 名 --replication-factor 定义副本数 --partitions 定义分区数\n\n 3. 删除 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic first 需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除。\n\n 4. 发送消息\n\nbin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic first\n>hello world\n>atguigu\tatguigu\n\n\n 5. 消费消息\n\nbin/kafka-console-consumer.sh \\\n--bootstrap-server hadoop1:9092 --topic first\n\nbin/kafka-console-consumer.sh \\\n--bootstrap-server hadoop1:9092 --from-beginning --topic first\n\n\n\n 6. 查看某个Topic 的详情 bin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic first\n 7. 修改分区数 bin/kafka-topics.sh --zookeeper hadoop1:2181 --alter --topic first --partitions 6",normalizedContent:"理论\n\n * 消息队列\n   * 异步(两个不用同时在线)\n   * 削峰\n\n点对点模式\n\n发布订阅模式\n\n> 消费者拉取(kafka)(缺点：长轮询)(优点：消费者决定速率) 消息队列推送\n\n==在此之前,要安装好jdk和zookeeper集群== 安装位置:我猜是和zookeeper安装的机器一样\n\n\n# 1.下载安装\n\n * 在官网下载(最新版本?)(一般不会出现版本兼容问题): kafka_2.12-2.4.1.tgz\n * 上传到虚拟机\n * 解压安装: tar -zxvf /soft/software/kafka_2.12-2.4.1.tgz -c /soft/module/\n * 重命名: mv kafka_2.12-2.4.1 kafka\n\n\n# 2.修改配置文件\n\n 1. 在kafka目录下新建文件夹: mkdir logs\n 2. 修改配置文件: cd config/ vim server.properties\n\n#broker 的全局唯一编号，不能重复\nbroker.id=0\n#删除 topic 功能使能彻底删除\ndelete.topic.enable=true\n#kafka 运行日志存放的路径\nlog.dirs=/soft/module/kafka/logs\n#配置连接zookeeper 集群地址\nzookeeper.connect=hadoop101:2181,hadoop102:2181,hadoop103:2181\n\n#后面不是必须配置的内容\n#处理网络请求的线程数量\nnum.network.threads=3\n#用来处理磁盘 io 的线程数量\nnum.io.threads=8\n#发送套接字的缓冲区大小\nsocket.send.buffer.bytes=102400 \n#接收套接字的缓冲区大小\nsocket.receive.buffer.bytes=102400 \n#请求套接字的缓冲区大小\nsocket.request.max.bytes=104857600\n#topic 在当前 broker 上的分区个数\nnum.partitions=1\n#用来恢复和清理 data 下数据的线程数量\nnum.recovery.threads.per.data.dir=1 \n#segment 文件保留的最长时间，超时将被删除\nlog.retention.hours=168\n\n\n 3. 配置环境变量 sudo vim /etc/profile\n\n#kafka_home 环境变量配置\nexport kafka_home=/soft/module/kafka export path=$path:$kafka_home/bin\n\n\nsource /etc/profile 4. 分发文件 5. 修改集群其它机器kafka配置 分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2 注：broker.id不得重复\n\n\n# 3.启动集群\n\n先启动zookeeper\n\n 1. 单机启动 启动: bin/kafka-server-start.sh -daemon config/server.properties 关闭: bin/kafka-server-stop.sh stop\n 2. 集群启动 启动脚本\n\nfor i in hadoop101 hadoop102 hadoop103 do\necho \"========== $i ==========\"\nssh\t$i\t'/soft/module/kafka/bin/kafka-server-start.sh\n/soft/module/kafka/config/server.properties' done\n\n\n 3. \n\n\n# 4.kafka命令行操作\n\n 1. 查看当前服务器中的所有 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --list\n\n 2. 创建 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --create --replication-factor 3 --partitions 1 --topic first --topic 定义 topic 名 --replication-factor 定义副本数 --partitions 定义分区数\n\n 3. 删除 topic bin/kafka-topics.sh --zookeeper hadoop1:2181 --delete --topic first 需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除。\n\n 4. 发送消息\n\nbin/kafka-console-producer.sh --broker-list hadoop1:9092 --topic first\n>hello world\n>atguigu\tatguigu\n\n\n 5. 消费消息\n\nbin/kafka-console-consumer.sh \\\n--bootstrap-server hadoop1:9092 --topic first\n\nbin/kafka-console-consumer.sh \\\n--bootstrap-server hadoop1:9092 --from-beginning --topic first\n\n\n\n 6. 查看某个topic 的详情 bin/kafka-topics.sh --zookeeper hadoop1:2181 --describe --topic first\n 7. 修改分区数 bin/kafka-topics.sh --zookeeper hadoop1:2181 --alter --topic first --partitions 6",charsets:{cjk:!0},lastUpdated:"2025/06/27, 12:02:59",lastUpdatedTimestamp:1750996979e3},{title:"HBase集群搭建",frontmatter:{title:"HBase集群搭建",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/b22228/",categories:["大数据","HBase"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/05.HBase/01.HBase%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/05.HBase/01.HBase集群搭建.md",key:"v-92803bde",path:"/pages/b22228/",headers:[{level:2,title:"1. 写在前面",slug:"_1-写在前面",normalizedTitle:"1. 写在前面",charIndex:218},{level:3,title:"1)版本兼容",slug:"_1-版本兼容",normalizedTitle:"1)版本兼容",charIndex:230},{level:3,title:"2) 集群规划",slug:"_2-集群规划",normalizedTitle:"2) 集群规划",charIndex:389},{level:2,title:"2. 解压安装",slug:"_2-解压安装",normalizedTitle:"2. 解压安装",charIndex:828},{level:2,title:"3. 修改配置文件",slug:"_3-修改配置文件",normalizedTitle:"3. 修改配置文件",charIndex:1109},{level:2,title:"4. 启动服务",slug:"_4-启动服务",normalizedTitle:"4. 启动服务",charIndex:3139},{level:2,title:"附个错误:",slug:"附个错误",normalizedTitle:"附个错误:",charIndex:3482}],headersStr:"1. 写在前面 1)版本兼容 2) 集群规划 2. 解压安装 3. 修改配置文件 4. 启动服务 附个错误:",content:"HA+Zookeeper搭建\n\nhadoop完全分布式搭建: https://www.cnblogs.com/Hephaestus/p/12213719.html\n\nhadoop高可用搭建: https://www.cnblogs.com/Hephaestus/p/12420370.html\n\nZookeeper集群搭建: https://www.cnblogs.com/Hephaestus/p/12421265.html\n\n\n# 1. 写在前面\n\n\n# 1)版本兼容\n\nhadoop2.9.2 + Zookeeper3.5.7 + HBase2.2.3 版本兼容官方文档: http://hbase.apache.org/book.html#configuration\n\n下载地址: https://hbase.apache.org/downloads.html\n\n\n# 2) 集群规划\n\n            NAMENODE   DATANODE   JOURNALNODE   ZOOKEEPER   HBASE\nhadoop100   是(nn2)                                          HMaster\nhadoop101   是(nn1)     是          是             是           备份HMaster\n                                                            HRegionServer\nhadoop102              是          是             是           HRegionServer\nhadoop103              是          是             是           HRegionServer\n\n\n# 2. 解压安装\n\n * 解压安装: tar -zxvf hbase-2.2.3-bin.tar.gz -C /soft/module\n * 为方便起见 重命名: mv hbase-2.2.3 hbase\n * 配置环境变量(可不配置)\n   * 修改系统环境变量 sudo vim /etc/profile\n\n# HBase 环境变量配置\nexport HBASE_HOME=/soft/module/hbase  \nexport PATH=$PATH:$HBASE_HOME/bin\n\n\n使配置生效: sudo source /etc/profile\n\n\n# 3. 修改配置文件\n\n * 1)修改hbase脚本文件: vim conf/hbase-env.sh\n\nexport JAVA_HOME=/soft/module/jdk1.8.0_161\nexport HBASE_MANAGES_ZK=false        # line126\n\n\n * 2)修改hbase配置文件: vim conf/hbase-site.xml\n\n        \x3c!-- 每个regionServer的共享目录,用来持久化Hbase,默认情况下在/tmp/hbase下面 --\x3e\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://mycluster/HBase</value>\n                <description>\n                        一定要把hadoop中的core-site.xml和hdf-site.xml复制到hbase的conf目录下，才能成功解析该集群名称；如果是hadoop单namenode集群，配置写成hdfs://master:9000/hbase (master是namenode主机名)\n                </description>\n        </property>\n\n        \x3c!-- hbase集群模式,false表示hbase的单机，true表示是分布式模式 --\x3e\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n\n        \x3c!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --\x3e\n        \x3c!-- hbase master节点的端口 --\x3e\n        <property>\n                <name>hbase.master.port</name>\n                <value>16000</value>\n        </property>\n\n        \x3c!-- hbase依赖的zk地址 --\x3e\n        <property>\n                <name>hbase.zookeeper.quorum</name>\n                <value>hadoop101,hadoop102,hadoop103</value>\n        </property>\n\n        <property>\n                <name>hbase.zookeeper.property.dataDir</name>\n                <value>/soft/module/zookeeper-3.5.7/zkData</value>\n        </property>\n\n        \x3c!--出错后加的这玩意,不懂是啥 | 在分布式情况下, 一定设置为false--\x3e\n        <property>\n                <name>hbase.unsafe.stream.capability.enforce</name>\n                <value>false</value>\n        </property>\n\n\n * 3) 修改 regionservers: vim regionservers\n\n> RegionServer是HBase集群运行在每个工作节点上的服务。它是整个HBase系统的关键所在，一方面它维护了Region的状态，提供了对于Region的管理和服务；另一方面，它与Master交互，上传Region的负载信息上传，参与Master的分布式协调管理\n\nhadoop101\nhadoop102\nhadoop103\n\n\n * 4) 软连接 hadoop 配置文件到 HBase： ln -s /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml /soft/module/hbase/conf/core-site.xml ln -s /soft/module/hadoop-2.9.2/etc/hadoop/hdfs-site.xml /soft/module/hbase/conf/hdfs-site.xml\n\n * 5) 分发hbase文件 xsync.sh hbase\n\n\n# 4. 启动服务\n\n * 1) 先保证 Zookeeper 集群的正常部署，并启动 在每个节点上执行: bin/zkServer.sh start\n * 2) Hadoop 集群的正常部署并启动 对应节点启动:start-dfs.sh /soft/module/hadoop-2.9.2/sbin/start-yarn.sh\n * 3) hbase启动\n   * 单节点启动: 在hadoop101: bin/hbase-daemon.sh start master 在hadoop101: bin/hbase-daemon.sh start regionserver\n   * 集群启动 启动: bin/start-hbase.sh 停止: bin/stop-hbase.sh\n\n\n# 附个错误:\n\n 1. \n\n> java.lang.IllegalStateException: The procedure WAL relies on the ability to hsync for proper operation during component failures, but the underlying filesystem does not support doing so. Please check the config value of 'hbase.procedure.store.wal.use.hsync' to set the desired level of robustness and ensure the config value of 'hbase.wal.dir' points to a FileSystem mount that can provide it.\n\nhbase-site.xml增加配置\n\n<property>\n    <name>hbase.unsafe.stream.capability.enforce</name>\n    <value>false</value>\n</property>\n\n\n2)启动时报错\n\n> java.lang.NoClassDefFoundError: org/apache/htrace/SamplerBuilder java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMasterCommandLine$LocalHMasterorg.apache.htrace.SamplerBuilder 原因：jar包缺失 解决方法：把lib\\client-facing-thirdparty包中的htrace-core-3.1.0-incubating.jar复制一个到lib包下即可\n\n----------------------------------------\n\n参考链接: https://blog.csdn.net/qq_35488412/article/details/78623518",normalizedContent:"ha+zookeeper搭建\n\nhadoop完全分布式搭建: https://www.cnblogs.com/hephaestus/p/12213719.html\n\nhadoop高可用搭建: https://www.cnblogs.com/hephaestus/p/12420370.html\n\nzookeeper集群搭建: https://www.cnblogs.com/hephaestus/p/12421265.html\n\n\n# 1. 写在前面\n\n\n# 1)版本兼容\n\nhadoop2.9.2 + zookeeper3.5.7 + hbase2.2.3 版本兼容官方文档: http://hbase.apache.org/book.html#configuration\n\n下载地址: https://hbase.apache.org/downloads.html\n\n\n# 2) 集群规划\n\n            namenode   datanode   journalnode   zookeeper   hbase\nhadoop100   是(nn2)                                          hmaster\nhadoop101   是(nn1)     是          是             是           备份hmaster\n                                                            hregionserver\nhadoop102              是          是             是           hregionserver\nhadoop103              是          是             是           hregionserver\n\n\n# 2. 解压安装\n\n * 解压安装: tar -zxvf hbase-2.2.3-bin.tar.gz -c /soft/module\n * 为方便起见 重命名: mv hbase-2.2.3 hbase\n * 配置环境变量(可不配置)\n   * 修改系统环境变量 sudo vim /etc/profile\n\n# hbase 环境变量配置\nexport hbase_home=/soft/module/hbase  \nexport path=$path:$hbase_home/bin\n\n\n使配置生效: sudo source /etc/profile\n\n\n# 3. 修改配置文件\n\n * 1)修改hbase脚本文件: vim conf/hbase-env.sh\n\nexport java_home=/soft/module/jdk1.8.0_161\nexport hbase_manages_zk=false        # line126\n\n\n * 2)修改hbase配置文件: vim conf/hbase-site.xml\n\n        \x3c!-- 每个regionserver的共享目录,用来持久化hbase,默认情况下在/tmp/hbase下面 --\x3e\n        <property>\n                <name>hbase.rootdir</name>\n                <value>hdfs://mycluster/hbase</value>\n                <description>\n                        一定要把hadoop中的core-site.xml和hdf-site.xml复制到hbase的conf目录下，才能成功解析该集群名称；如果是hadoop单namenode集群，配置写成hdfs://master:9000/hbase (master是namenode主机名)\n                </description>\n        </property>\n\n        \x3c!-- hbase集群模式,false表示hbase的单机，true表示是分布式模式 --\x3e\n        <property>\n                <name>hbase.cluster.distributed</name>\n                <value>true</value>\n        </property>\n\n        \x3c!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --\x3e\n        \x3c!-- hbase master节点的端口 --\x3e\n        <property>\n                <name>hbase.master.port</name>\n                <value>16000</value>\n        </property>\n\n        \x3c!-- hbase依赖的zk地址 --\x3e\n        <property>\n                <name>hbase.zookeeper.quorum</name>\n                <value>hadoop101,hadoop102,hadoop103</value>\n        </property>\n\n        <property>\n                <name>hbase.zookeeper.property.datadir</name>\n                <value>/soft/module/zookeeper-3.5.7/zkdata</value>\n        </property>\n\n        \x3c!--出错后加的这玩意,不懂是啥 | 在分布式情况下, 一定设置为false--\x3e\n        <property>\n                <name>hbase.unsafe.stream.capability.enforce</name>\n                <value>false</value>\n        </property>\n\n\n * 3) 修改 regionservers: vim regionservers\n\n> regionserver是hbase集群运行在每个工作节点上的服务。它是整个hbase系统的关键所在，一方面它维护了region的状态，提供了对于region的管理和服务；另一方面，它与master交互，上传region的负载信息上传，参与master的分布式协调管理\n\nhadoop101\nhadoop102\nhadoop103\n\n\n * 4) 软连接 hadoop 配置文件到 hbase： ln -s /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml /soft/module/hbase/conf/core-site.xml ln -s /soft/module/hadoop-2.9.2/etc/hadoop/hdfs-site.xml /soft/module/hbase/conf/hdfs-site.xml\n\n * 5) 分发hbase文件 xsync.sh hbase\n\n\n# 4. 启动服务\n\n * 1) 先保证 zookeeper 集群的正常部署，并启动 在每个节点上执行: bin/zkserver.sh start\n * 2) hadoop 集群的正常部署并启动 对应节点启动:start-dfs.sh /soft/module/hadoop-2.9.2/sbin/start-yarn.sh\n * 3) hbase启动\n   * 单节点启动: 在hadoop101: bin/hbase-daemon.sh start master 在hadoop101: bin/hbase-daemon.sh start regionserver\n   * 集群启动 启动: bin/start-hbase.sh 停止: bin/stop-hbase.sh\n\n\n# 附个错误:\n\n 1. \n\n> java.lang.illegalstateexception: the procedure wal relies on the ability to hsync for proper operation during component failures, but the underlying filesystem does not support doing so. please check the config value of 'hbase.procedure.store.wal.use.hsync' to set the desired level of robustness and ensure the config value of 'hbase.wal.dir' points to a filesystem mount that can provide it.\n\nhbase-site.xml增加配置\n\n<property>\n    <name>hbase.unsafe.stream.capability.enforce</name>\n    <value>false</value>\n</property>\n\n\n2)启动时报错\n\n> java.lang.noclassdeffounderror: org/apache/htrace/samplerbuilder java.lang.runtimeexception: failed construction of master: class org.apache.hadoop.hbase.master.hmastercommandline$localhmasterorg.apache.htrace.samplerbuilder 原因：jar包缺失 解决方法：把lib\\client-facing-thirdparty包中的htrace-core-3.1.0-incubating.jar复制一个到lib包下即可\n\n----------------------------------------\n\n参考链接: https://blog.csdn.net/qq_35488412/article/details/78623518",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"HBase基础学习",frontmatter:{title:"HBase基础学习",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/e15afa/",categories:["大数据","HBase"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/05.HBase/02.HBase%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0.html",relativePath:"02.大数据/05.HBase/02.HBase基础学习.md",key:"v-9b1324b0",path:"/pages/e15afa/",headers:[{level:2,title:"hbase shell",slug:"hbase-shell",normalizedTitle:"hbase shell",charIndex:2},{level:2,title:"hbase架构原理",slug:"hbase架构原理",normalizedTitle:"hbase架构原理",charIndex:936},{level:2,title:"hbase写流程",slug:"hbase写流程",normalizedTitle:"hbase写流程",charIndex:1326},{level:2,title:"hbase MemStore Flush",slug:"hbase-memstore-flush",normalizedTitle:"hbase memstore flush",charIndex:1709},{level:2,title:"hbase读流程",slug:"hbase读流程",normalizedTitle:"hbase读流程",charIndex:2609},{level:2,title:"StoreFile Compaction",slug:"storefile-compaction",normalizedTitle:"storefile compaction",charIndex:3092},{level:2,title:"Region Split",slug:"region-split",normalizedTitle:"region split",charIndex:3474},{level:2,title:"代码Api",slug:"代码api",normalizedTitle:"代码api",charIndex:4266}],headersStr:"hbase shell hbase架构原理 hbase写流程 hbase MemStore Flush hbase读流程 StoreFile Compaction Region Split 代码Api",content:'# hbase shell\n\n> 此时一个异常： org.apache.hadoop.hbase.PleaseHoldException: Master is initializing 原因：配置修改后，zk里的hbase表未删除 解决:https://blog.csdn.net/RONE321/article/details/99940862\n\n扫描所有版本信息\n\nscan \'student\',{RAW=>TRUE,VERSIONS=>5}\n\n\n创建表\n\ncreate \'student\',\'info\'\n\n\n已有表新建/删除列族\n\nalter \'student\',\'columnfamily2\'\nalter \'student\',{NAME=>\'info2\',METHOD=>\'delete\'}\nalter \'student\',{NAME=>\'info1\',VERSIONS=>\'3\'}\n\n\n查看表是否存在 exists \'student\'\n\n表是否不可用/可用\n\nis_disabled \'student\'\nis_enabled \'student\'\n\n\n列出所有表 list\n\n查看单个表 describe/desc \'student\'\n\n加入数据 put \'student\',1,\'info:id\',100\n\n修改表记录 put \'student\',1,\'info:name\',\'abc\'\n\n查看表数据\n\nscan \'student\'\nget \'student\',1\nget \'student\',1,\'info:id\'\n\n\n删除表记录 delete \'student\',1,\'info:name\'\n\n删除rowkey deleteall \'student\',1\n\n清空表 truncate \'student\'\n\n删除表\n\n1.disable \'student\'\n2.drop \'student\'\n\n\n停用表 disable \'student\'\n\n表可用 enable \'student\'\n\n命名空间操作\n\nlist_namespace\ncreate_namespace \'bigdata\'\ncreate \'bigdata:student\',\'info\'\n\n\n\n# hbase架构原理\n\n\n\n1） StoreFile\n保存实际数据的物理文件， StoreFile 以 HFile 的形式存储在 HDFS 上。每个 Store 会有一个或多个StoreFile（HFile），数据在每个 StoreFile 中都是有序的。\n2） MemStore\n写缓存， 由于 HFile 中的数据要求是有序的， 所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFile。\n3） WAL\n由于数据要经 MemStore 排序后才能刷写到 HFile， 但把数据保存在内存中会有很高的\n概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建\n\n\n\n# hbase写流程\n\n\n\n1） Client 先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server。\n2）访问对应的 Region Server，获取 hbase:meta 表，根据读请求的namespace:table/rowkey，\n查询出目标数据位于哪个 Region Server 中的哪个 Region 中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。\n3）与目标 Region Server 进行通讯；\n4）将数据顺序写入（追加）到 WAL；\n5）将数据写入对应的 MemStore，数据会在 MemStore 进行排序；\n6）向客户端发送 ack；\n7） 等达到 MemStore 的刷写时机后，将数据刷写到 HFile。\n\n\n\n# hbase MemStore Flush\n\n\n\nMemStore 刷写时机：\n1.当某个 memstroe 的大小达到了 hbase.hregion.memstore.flush.size（默认值 128M） ，\n其所在 region 的所有 memstore 都会刷写。\n当 memstore 的大小达到了\nhbase.hregion.memstore.flush.size（默认值 128M）\n* hbase.hregion.memstore.block.multiplier（默认值 4）\n时，会阻止继续往该 memstore 写数据。\n2.当 region server 中 memstore 的总大小达到\njava_heapsize\n*hbase.regionserver.global.memstore.size（默认值 0.4）\n*hbase.regionserver.global.memstore.size.lower.limit（默认值 0.95） ，\nregion 会按照其所有 memstore 的大小顺序（由大到小）依次进行刷写。直到 region server\n中所有 memstore 的总大小减小到上述值以下。\n当 region server 中 memstore 的总大小达到\njava_heapsize*hbase.regionserver.global.memstore.size（默认值 0.4）\n时，会阻止继续往所有的 memstore 写数据。\n3. 到达自动刷写的时间，也会触发 memstore flush。自动刷新的时间间隔由该属性进行\n配置 hbase.regionserver.optionalcacheflushinterval（默认 1 小时） 。\n4.当 WAL 文件的数量超过 hbase.regionserver.max.logs， region 会按照时间顺序依次进\n行刷写，直到 WAL 文件数量减小到 hbase.regionserver.max.log 以下（该属性名已经废弃，\n现无需手动设置， 最大值为 32）。\n\n\n\n# hbase读流程\n\n\n\n1） Client 先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server。\n2）访问对应的 Region Server，获取 hbase:meta 表，根据读请求的 namespace:table/rowkey，\n查询出目标数据位于哪个 Region Server 中的哪个 Region 中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。\n3）与目标 Region Server 进行通讯；\n4） 分别在 Block Cache（读缓存）， MemStore 和 Store File（HFile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（time stamp）或者不同的类型（Put/Delete）。\n5） 将从文件中查询到的数据块（Block， HFile 数据存储单元，默认大小为 64KB）缓存到\nBlock Cache。\n6） 将合并后的最终结果返回给客户端。\n\n\n\n# StoreFile Compaction\n\n\n\n由于 memstore每次刷写都会生成一个新的 HFile，且同一个字段的不同版本（timestamp）\n和不同类型（Put/Delete）有可能会分布在不同的 HFile 中，因此查询时需要遍历所有的 HFile。为了减少 HFile 的个数，以及清理掉过期和删除的数据，会进行 StoreFile Compaction。\nCompaction 分为两种，分别是 Minor Compaction 和 Major Compaction。Minor Compaction\n会将临近的若干个较小的 HFile 合并成一个较大的 HFile，但不会清理过期和删除的数据。\nMajor Compaction 会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且会清理掉过期和删除的数据。\n\n\n\n# Region Split\n\n\n\n默认情况下，每个 Table 起初只有一个 Region，随着数据的不断写入， Region 会自动进\n行拆分。刚拆分时，两个子 Region 都位于当前的 Region Server，但处于负载均衡的考虑，\nHMaster 有可能会将某个 Region 转移给其他的 Region Server。\nRegion Split 时机：\n1.当 1个 region中的某个 Store下所有 StoreFile的总大小超过 hbase.hregion.max.filesize，该 Region 就会进行拆分（0.94 版本之前）。\n2. 当 1 个 region 中 的 某 个 Store 下 所 有 StoreFile 的 总 大 小 超 过 Min(R^2 *\n"hbase.hregion.memstore.flush.size",hbase.hregion.max.filesize")， 该 Region 就会进行拆分，其中 R 为当前 Region Server 中属于该 Table 的个数（0.94 版本之后）。\n\n表预分区\nHBase预分区\n概念：\nHBase表被创建时，只有1个Region，当一个Region过大达到默认的阈值时（默认10GB大小）,HBase中该Region将会进行split，分裂为2个Region，以此类推。\n表在进行split的时候，会耗费大量的资源，频繁的分区对HBase的性能有巨大的影响。\n所以，HBase提供了预分区功能，即用户可以在创建表的时候对表按照一定的规则分区。\n作用：\n避免HBase经常split，产生不必要的资源消耗，提高HBase的性能。\n预分区的方法：\n1.HBase Shell\n2.HBase Shell（通过读取split文件）\n3.HBase Java API\n\n\n\n# 代码Api\n\npackage com.hrbu.test;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.Cell;\nimport org.apache.hadoop.hbase.CellUtil;\nimport org.apache.hadoop.hbase.CompareOperator;\nimport org.apache.hadoop.hbase.HBaseConfiguration;\nimport org.apache.hadoop.hbase.NamespaceDescriptor;\nimport org.apache.hadoop.hbase.NamespaceExistException;\nimport org.apache.hadoop.hbase.TableName;\nimport org.apache.hadoop.hbase.client.Admin;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;\nimport org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;\nimport org.apache.hadoop.hbase.client.Connection;\nimport org.apache.hadoop.hbase.client.ConnectionFactory;\nimport org.apache.hadoop.hbase.client.Delete;\nimport org.apache.hadoop.hbase.client.Get;\nimport org.apache.hadoop.hbase.client.Put;\nimport org.apache.hadoop.hbase.client.Result;\nimport org.apache.hadoop.hbase.client.ResultScanner;\nimport org.apache.hadoop.hbase.client.Scan;\nimport org.apache.hadoop.hbase.client.Table;\nimport org.apache.hadoop.hbase.client.TableDescriptor;\nimport org.apache.hadoop.hbase.client.TableDescriptorBuilder;\nimport org.apache.hadoop.hbase.filter.BinaryComparator;\nimport org.apache.hadoop.hbase.filter.CompareFilter;\nimport org.apache.hadoop.hbase.filter.Filter;\nimport org.apache.hadoop.hbase.filter.KeyOnlyFilter;\nimport org.apache.hadoop.hbase.filter.PrefixFilter;\nimport org.apache.hadoop.hbase.filter.RandomRowFilter;\nimport org.apache.hadoop.hbase.filter.RowFilter;\nimport org.apache.hadoop.hbase.filter.ValueFilter;\nimport org.apache.hadoop.hbase.regionserver.NoSuchColumnFamilyException;\nimport org.apache.hadoop.hbase.util.Bytes;\n\n/**\n * DDL: 1.判断表是否存在 2.创建表 3.创建命名空间 4.删除表 \n * DML: 5.插入数据 6.查数据(get) 7.查数据(scan) 8.删除数据\n */\npublic class TestApi {\n\n\tpublic static Connection connect = null;\n\tpublic static Admin admin = null;\n\tstatic {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 HBaseConfiguration 的单例方法实例化)\n\t\t\tConfiguration conf = HBaseConfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientPort", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = ConnectionFactory.createConnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getAdmin();\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\tSystem.out.println("创建hbase连接对象异常");\n\t\t\te.printStackTrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("admin关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tSystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// 1.判断表是否存在\n\tpublic static void is_Exists(String tableName) throws IOException {\n\t\tif (admin.tableExists(TableName.valueOf(tableName))) {\n\t\t\tSystem.out.println(tableName + "表已经存在");\n\t\t} else {\n\t\t\tSystem.out.println(tableName + "表不存在");\n\t\t}\n\t}\n\n\t// 2.创建表\n\tpublic static void create_Table(String tableName) throws IOException {\n\t\tTableName tableNameTemp = TableName.valueOf(tableName);\n\t\tif (admin.tableExists(tableNameTemp)) {\n\t\t\tSystem.out.println(tableName + "表已经存在");\n\t\t} else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\tTableDescriptorBuilder tableBuilder = TableDescriptorBuilder.newBuilder(tableNameTemp);\n\t\t\t// 列族\n\t\t\tColumnFamilyDescriptor info1 = ColumnFamilyDescriptorBuilder.of("info1");\n\t\t\tColumnFamilyDescriptor info2 = ColumnFamilyDescriptorBuilder.of("info2");\n\t\t\tColumnFamilyDescriptor info3 = ColumnFamilyDescriptorBuilder.of("info3");\n\t\t\tList<ColumnFamilyDescriptor> cfList = new ArrayList<ColumnFamilyDescriptor>();\n\t\t\tcfList.add(info1);\n\t\t\tcfList.add(info2);\n\t\t\tcfList.add(info3);\n\t\t\ttableBuilder.setColumnFamilies(cfList);\n\t\t\t// 5.构建表描述\n\t\t\tTableDescriptor tableDesc = tableBuilder.build();\n\t\t\tadmin.createTable(tableDesc);\n\t\t\tSystem.out.println(tableName + "\\t表创建成功");\n\t\t}\n\t}\n\n\t// 3.创建命名空间\n\tpublic static void create_NameSpace(String nameSpace) {\n\t\t// 创建命名空间描述器\n\t\tNamespaceDescriptor descriptor = NamespaceDescriptor.create(nameSpace).build();\n\t\t//创建命名空间\n\t\ttry {\n\t\t\tadmin.createNamespace(descriptor);\n\t\t} catch(NamespaceExistException e) {\n\t\t\tSystem.out.println(nameSpace + "命名空间已存在");\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println("--我会被执行吗--");\n\t}\n\t// 4.删除表\n\tpublic static void drop_Table(String tableName) throws IOException {\n\t\tTableName tableNameTemp = TableName.valueOf(tableName);\n\t\tif (admin.tableExists(tableNameTemp)) {\n\t\t\tadmin.disableTable(tableNameTemp);\n\t\t\tadmin.deleteTable(tableNameTemp);\n\t\t\tSystem.out.println("表" + tableName + "删除成功！ ");\n\t\t} else {\n\t\t\tSystem.out.println("表" + tableName + "不存在！ ");\n\t\t}\n\t}\n\t// 5.插入数据\n\tpublic static void put_Data(String tableName, String rowKey, String columnFamily, String column, String value) {\n\t\tTable table = null;\n\t\ttry {\n\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\tPut put = new Put(Bytes.toBytes(rowKey));\n\t\t\tput.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value));\n\t\t\ttable.put(put);\n\t\t} catch(NoSuchColumnFamilyException e){\n\t\t\tSystem.out.println("异常:没有此列族");\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t}finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tSystem.out.println("数据插入成功");\n\t\t\n\t}\n\t// 6.查数据(get)\n\tpublic static void get_Data(String tableName, String rowKey, String columnFamily, String column) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\t//get.addFamily(Bytes.toBytes(columnFamily));\n\t\tget.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + "--" + columnFamily + "--" + column + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_Data(String tableName, String rowKey, String columnFamily) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\tget.addFamily(Bytes.toBytes(columnFamily));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + "--" + columnFamily + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_Data(String tableName, String rowKey) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t\n\t\tGet get = new Get(Bytes.toBytes(rowKey));\n\t\tResult result = table.get(get);\n\t\tCell[] cells = result.rawCells();\n\t\tSystem.out.println(tableName + "--" + rowKey + ":");\n\t\tprint_Cells2(cells);\n\t\ttable.close();\n\t}\n\t// 打印单元格信息\n\tprivate static void print_Cells(Cell[] cells) {\n\t\tfor (Cell tempCell : cells) {\n\t\t\tSystem.out.println(Bytes.toString(CellUtil.cloneRow(tempCell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + Bytes.toString(CellUtil.cloneFamily(tempCell)) + ":" +  Bytes.toString(CellUtil.cloneQualifier(tempCell))\n\t\t\t\t\t+ ",timestamp=" + tempCell.getTimestamp() \n\t\t\t\t\t+ ", value=" + Bytes.toString(CellUtil.cloneValue(tempCell)) );\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_Cells2(Cell[] cells) {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tfor (Cell cell : cells) {\n\t\t\tString column = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n\t\t\tString value = Bytes.toString(cell.getValueArray(),cell.getValueOffset(),cell.getValueLength());\n\t\t\tsb.append(column).append(":").append(value).append(";\\t");\n\t\t}\n\t\tSystem.out.println(sb.toString());\n\t}\n\t// 7.查数据(scan)\n\tpublic static void scan_Data(String tableName) {\n\t\tTable table = null;\n\t\ttry {\n\t\t\ttable = connect.getTable(TableName.valueOf(tableName));\n\t\t\tResultScanner results = table.getScanner(new Scan());\n\t\t\tSystem.out.println(tableName + "表\\nROW\\t\\tCOLUMN+CELL");\n\t\t\tfor (Result result : results) {\n\t\t\t\tCell[] cells = result.rawCells();\n\t\t\t\tprint_Cells(cells);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (IOException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 7.2 查数据(scan + filter)\n\tpublic static void filter_Data(String tableName, Filter filter, int limit) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\tScan scan = new Scan().setFilter(filter).setLimit(limit);\n\t\tResultScanner resultScan = table.getScanner(scan);\n\t\tSystem.out.println(tableName + "表(filter)\\nROW\\t\\tCOLUMN+CELL");\n\t\tfor (Result result : resultScan) {\n\t\t\tCell[] cells = result.rawCells();\n\t\t\tprint_Cells(cells);\n\t\t}\n\t\ttable.close();\n\t}\n\t// 8. 删除多行数据\n\tpublic static void delete_Data(String tableName, String... rows) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\t//Delete delete = new Delete(Bytes.toBytes(rowKey));\n\t\tList<Delete> deleteList = new ArrayList<Delete>();\n\t\tfor (String row:rows) {\n\t\t\tDelete delete = new Delete(Bytes.toBytes(row));\n\t\t\tdeleteList.add(delete);\n\t\t}\n\t\ttable.delete(deleteList);\n\t\ttable.close();\n\t\tSystem.out.println("删除成功");\n\t}\n\t// 8.1 删除单元格(Cell)数据\n\tpublic static void delete_Cell(String tableName,  String rowKey, String columnFamily, String column ) throws IOException {\n\t\tTable table = connect.getTable(TableName.valueOf(tableName));\n\t\tDelete delete = new Delete(Bytes.toBytes(rowKey));\n\t\tdelete.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\t\t//删除最后一版本\n\t\t//delete.addColumns(Bytes.toBytes(columnFamily), Bytes.toBytes(column));\t\t//删除所有版本\n\t\ttable.delete(delete);\n\t\ttable.close();\n\t}\n\n\tpublic static void main(String[] args) throws IOException {\n\t\tSystem.out.println("============================start=========================");\n\t\t// 1.判断表是否存在\n\t\t//is_Exists("student");\n\t\t\n\t\t// 3.创建命名空间\n\t\t//create_NameSpace("std");\n\t\t\n\t\t// 2.创建表\n\t\t//create_Table("std:stu");\n\t\t\n\t\t// 4.删除表\n\t\t//drop_Table("std:stu");\n\t\t\n\t\t// 5.插入数据\n\t\t//put_Data("std:stu", "1003", "info1", "addr", "beijing");\n\t\t//put_Data("std:stu", "1004", "info1", "sex", "男");\n\t\t//put_Data("std:stu", "1005", "info1", "class", "2");\n\t\t\n\t\t// 6.查数据(get)\n\t\tget_Data("std:stu", "1002");\n\t\tget_Data("std:stu", "1002", "info1");\n\t\t\n\t\t// 7.查数据(scan)\n\t\tscan_Data("std:stu");\n\t\t\n\t\t// 7.1 查数据(scan + filter)\n\t\t//filter_Data("std:stu", new PrefixFilter(Bytes.toBytes("100")), 10);\t//筛选出行键以row为前缀的所有的行\n\t\t//filter_Data("std:stu", new RandomRowFilter((float) 0.2), 10);\t//按照一定的几率（<=0会过滤掉所有的行，>=1会包含所有的行）来返回随机的结果集\n\t\t//filter_Data("std:stu", new KeyOnlyFilter(), 10); // 返回所有的行，但值全是空 \n\t\t//  筛选出匹配的所有的行  \n\t\tfilter_Data("std:stu", new RowFilter(CompareFilter.CompareOp.LESS, new BinaryComparator(Bytes.toBytes("1002"))), 10);\n\t\t\n\t\t// 8. 删除多行数据数据\n\t\t//delete_Data("std:stu", "1003","1004");\n\t\t\n\t\t// 8.1删除单元格数据\n\t\t//delete_Cell("std:stu", "1005", "info1", "name");\n\t\t\n\t\tscan_Data("std:stu");\n\t\t\n\t\tSystem.out.println("============================end==========================");\n\t\t// end:关闭资源和连接\n\t\tclose();\n\t}\n\n}\n\n',normalizedContent:'# hbase shell\n\n> 此时一个异常： org.apache.hadoop.hbase.pleaseholdexception: master is initializing 原因：配置修改后，zk里的hbase表未删除 解决:https://blog.csdn.net/rone321/article/details/99940862\n\n扫描所有版本信息\n\nscan \'student\',{raw=>true,versions=>5}\n\n\n创建表\n\ncreate \'student\',\'info\'\n\n\n已有表新建/删除列族\n\nalter \'student\',\'columnfamily2\'\nalter \'student\',{name=>\'info2\',method=>\'delete\'}\nalter \'student\',{name=>\'info1\',versions=>\'3\'}\n\n\n查看表是否存在 exists \'student\'\n\n表是否不可用/可用\n\nis_disabled \'student\'\nis_enabled \'student\'\n\n\n列出所有表 list\n\n查看单个表 describe/desc \'student\'\n\n加入数据 put \'student\',1,\'info:id\',100\n\n修改表记录 put \'student\',1,\'info:name\',\'abc\'\n\n查看表数据\n\nscan \'student\'\nget \'student\',1\nget \'student\',1,\'info:id\'\n\n\n删除表记录 delete \'student\',1,\'info:name\'\n\n删除rowkey deleteall \'student\',1\n\n清空表 truncate \'student\'\n\n删除表\n\n1.disable \'student\'\n2.drop \'student\'\n\n\n停用表 disable \'student\'\n\n表可用 enable \'student\'\n\n命名空间操作\n\nlist_namespace\ncreate_namespace \'bigdata\'\ncreate \'bigdata:student\',\'info\'\n\n\n\n# hbase架构原理\n\n\n\n1） storefile\n保存实际数据的物理文件， storefile 以 hfile 的形式存储在 hdfs 上。每个 store 会有一个或多个storefile（hfile），数据在每个 storefile 中都是有序的。\n2） memstore\n写缓存， 由于 hfile 中的数据要求是有序的， 所以数据是先存储在 memstore 中，排好序后，等到达刷写时机才会刷写到 hfile，每次刷写都会形成一个新的 hfile。\n3） wal\n由于数据要经 memstore 排序后才能刷写到 hfile， 但把数据保存在内存中会有很高的\n概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 write-ahead logfile 的文件中，然后再写入 memstore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建\n\n\n\n# hbase写流程\n\n\n\n1） client 先访问 zookeeper，获取 hbase:meta 表位于哪个 region server。\n2）访问对应的 region server，获取 hbase:meta 表，根据读请求的namespace:table/rowkey，\n查询出目标数据位于哪个 region server 中的哪个 region 中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。\n3）与目标 region server 进行通讯；\n4）将数据顺序写入（追加）到 wal；\n5）将数据写入对应的 memstore，数据会在 memstore 进行排序；\n6）向客户端发送 ack；\n7） 等达到 memstore 的刷写时机后，将数据刷写到 hfile。\n\n\n\n# hbase memstore flush\n\n\n\nmemstore 刷写时机：\n1.当某个 memstroe 的大小达到了 hbase.hregion.memstore.flush.size（默认值 128m） ，\n其所在 region 的所有 memstore 都会刷写。\n当 memstore 的大小达到了\nhbase.hregion.memstore.flush.size（默认值 128m）\n* hbase.hregion.memstore.block.multiplier（默认值 4）\n时，会阻止继续往该 memstore 写数据。\n2.当 region server 中 memstore 的总大小达到\njava_heapsize\n*hbase.regionserver.global.memstore.size（默认值 0.4）\n*hbase.regionserver.global.memstore.size.lower.limit（默认值 0.95） ，\nregion 会按照其所有 memstore 的大小顺序（由大到小）依次进行刷写。直到 region server\n中所有 memstore 的总大小减小到上述值以下。\n当 region server 中 memstore 的总大小达到\njava_heapsize*hbase.regionserver.global.memstore.size（默认值 0.4）\n时，会阻止继续往所有的 memstore 写数据。\n3. 到达自动刷写的时间，也会触发 memstore flush。自动刷新的时间间隔由该属性进行\n配置 hbase.regionserver.optionalcacheflushinterval（默认 1 小时） 。\n4.当 wal 文件的数量超过 hbase.regionserver.max.logs， region 会按照时间顺序依次进\n行刷写，直到 wal 文件数量减小到 hbase.regionserver.max.log 以下（该属性名已经废弃，\n现无需手动设置， 最大值为 32）。\n\n\n\n# hbase读流程\n\n\n\n1） client 先访问 zookeeper，获取 hbase:meta 表位于哪个 region server。\n2）访问对应的 region server，获取 hbase:meta 表，根据读请求的 namespace:table/rowkey，\n查询出目标数据位于哪个 region server 中的哪个 region 中。并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。\n3）与目标 region server 进行通讯；\n4） 分别在 block cache（读缓存）， memstore 和 store file（hfile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（time stamp）或者不同的类型（put/delete）。\n5） 将从文件中查询到的数据块（block， hfile 数据存储单元，默认大小为 64kb）缓存到\nblock cache。\n6） 将合并后的最终结果返回给客户端。\n\n\n\n# storefile compaction\n\n\n\n由于 memstore每次刷写都会生成一个新的 hfile，且同一个字段的不同版本（timestamp）\n和不同类型（put/delete）有可能会分布在不同的 hfile 中，因此查询时需要遍历所有的 hfile。为了减少 hfile 的个数，以及清理掉过期和删除的数据，会进行 storefile compaction。\ncompaction 分为两种，分别是 minor compaction 和 major compaction。minor compaction\n会将临近的若干个较小的 hfile 合并成一个较大的 hfile，但不会清理过期和删除的数据。\nmajor compaction 会将一个 store 下的所有的 hfile 合并成一个大 hfile，并且会清理掉过期和删除的数据。\n\n\n\n# region split\n\n\n\n默认情况下，每个 table 起初只有一个 region，随着数据的不断写入， region 会自动进\n行拆分。刚拆分时，两个子 region 都位于当前的 region server，但处于负载均衡的考虑，\nhmaster 有可能会将某个 region 转移给其他的 region server。\nregion split 时机：\n1.当 1个 region中的某个 store下所有 storefile的总大小超过 hbase.hregion.max.filesize，该 region 就会进行拆分（0.94 版本之前）。\n2. 当 1 个 region 中 的 某 个 store 下 所 有 storefile 的 总 大 小 超 过 min(r^2 *\n"hbase.hregion.memstore.flush.size",hbase.hregion.max.filesize")， 该 region 就会进行拆分，其中 r 为当前 region server 中属于该 table 的个数（0.94 版本之后）。\n\n表预分区\nhbase预分区\n概念：\nhbase表被创建时，只有1个region，当一个region过大达到默认的阈值时（默认10gb大小）,hbase中该region将会进行split，分裂为2个region，以此类推。\n表在进行split的时候，会耗费大量的资源，频繁的分区对hbase的性能有巨大的影响。\n所以，hbase提供了预分区功能，即用户可以在创建表的时候对表按照一定的规则分区。\n作用：\n避免hbase经常split，产生不必要的资源消耗，提高hbase的性能。\n预分区的方法：\n1.hbase shell\n2.hbase shell（通过读取split文件）\n3.hbase java api\n\n\n\n# 代码api\n\npackage com.hrbu.test;\n\nimport java.io.ioexception;\nimport java.util.arraylist;\nimport java.util.list;\n\nimport org.apache.hadoop.conf.configuration;\nimport org.apache.hadoop.hbase.cell;\nimport org.apache.hadoop.hbase.cellutil;\nimport org.apache.hadoop.hbase.compareoperator;\nimport org.apache.hadoop.hbase.hbaseconfiguration;\nimport org.apache.hadoop.hbase.namespacedescriptor;\nimport org.apache.hadoop.hbase.namespaceexistexception;\nimport org.apache.hadoop.hbase.tablename;\nimport org.apache.hadoop.hbase.client.admin;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptor;\nimport org.apache.hadoop.hbase.client.columnfamilydescriptorbuilder;\nimport org.apache.hadoop.hbase.client.connection;\nimport org.apache.hadoop.hbase.client.connectionfactory;\nimport org.apache.hadoop.hbase.client.delete;\nimport org.apache.hadoop.hbase.client.get;\nimport org.apache.hadoop.hbase.client.put;\nimport org.apache.hadoop.hbase.client.result;\nimport org.apache.hadoop.hbase.client.resultscanner;\nimport org.apache.hadoop.hbase.client.scan;\nimport org.apache.hadoop.hbase.client.table;\nimport org.apache.hadoop.hbase.client.tabledescriptor;\nimport org.apache.hadoop.hbase.client.tabledescriptorbuilder;\nimport org.apache.hadoop.hbase.filter.binarycomparator;\nimport org.apache.hadoop.hbase.filter.comparefilter;\nimport org.apache.hadoop.hbase.filter.filter;\nimport org.apache.hadoop.hbase.filter.keyonlyfilter;\nimport org.apache.hadoop.hbase.filter.prefixfilter;\nimport org.apache.hadoop.hbase.filter.randomrowfilter;\nimport org.apache.hadoop.hbase.filter.rowfilter;\nimport org.apache.hadoop.hbase.filter.valuefilter;\nimport org.apache.hadoop.hbase.regionserver.nosuchcolumnfamilyexception;\nimport org.apache.hadoop.hbase.util.bytes;\n\n/**\n * ddl: 1.判断表是否存在 2.创建表 3.创建命名空间 4.删除表 \n * dml: 5.插入数据 6.查数据(get) 7.查数据(scan) 8.删除数据\n */\npublic class testapi {\n\n\tpublic static connection connect = null;\n\tpublic static admin admin = null;\n\tstatic {\n\t\ttry {\n\t\t\t// 1. 获取配置文件信息(使用 hbaseconfiguration 的单例方法实例化)\n\t\t\tconfiguration conf = hbaseconfiguration.create();\n\t\t\t//conf.set("hbase.zookeeper.quorum", "hadoop101,hadoop102,hadoop103");\n\n\t\t\tconf.set("hbase.zookeeper.quorum", "hadoop1");\n\t\t\tconf.set("hbase.zookeeper.property.clientport", "2181");\n\n\t\t\t// 2. 创建连接对象\n\t\t\tconnect = connectionfactory.createconnection(conf);\n\n\t\t\t// 3. 获取管理员对象\n\t\t\tadmin = connect.getadmin();\n\t\t} catch (ioexception e) {\n\t\t\t// todo auto-generated catch block\n\t\t\tsystem.out.println("创建hbase连接对象异常");\n\t\t\te.printstacktrace();\n\t\t}\n\n\t}\n\n\t// 关闭资源和连接\n\tpublic static void close() {\n\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("admin关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t\tif (connect != null) {\n\t\t\ttry {\n\t\t\t\tconnect.close();\n\t\t\t} catch (ioexception e) {\n\t\t\t\tsystem.out.println("hbase连接对象关闭异常");\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// 1.判断表是否存在\n\tpublic static void is_exists(string tablename) throws ioexception {\n\t\tif (admin.tableexists(tablename.valueof(tablename))) {\n\t\t\tsystem.out.println(tablename + "表已经存在");\n\t\t} else {\n\t\t\tsystem.out.println(tablename + "表不存在");\n\t\t}\n\t}\n\n\t// 2.创建表\n\tpublic static void create_table(string tablename) throws ioexception {\n\t\ttablename tablenametemp = tablename.valueof(tablename);\n\t\tif (admin.tableexists(tablenametemp)) {\n\t\t\tsystem.out.println(tablename + "表已经存在");\n\t\t} else {\n\t\t\t// 4.通过表实例来执行表结构信息\n\t\t\ttabledescriptorbuilder tablebuilder = tabledescriptorbuilder.newbuilder(tablenametemp);\n\t\t\t// 列族\n\t\t\tcolumnfamilydescriptor info1 = columnfamilydescriptorbuilder.of("info1");\n\t\t\tcolumnfamilydescriptor info2 = columnfamilydescriptorbuilder.of("info2");\n\t\t\tcolumnfamilydescriptor info3 = columnfamilydescriptorbuilder.of("info3");\n\t\t\tlist<columnfamilydescriptor> cflist = new arraylist<columnfamilydescriptor>();\n\t\t\tcflist.add(info1);\n\t\t\tcflist.add(info2);\n\t\t\tcflist.add(info3);\n\t\t\ttablebuilder.setcolumnfamilies(cflist);\n\t\t\t// 5.构建表描述\n\t\t\ttabledescriptor tabledesc = tablebuilder.build();\n\t\t\tadmin.createtable(tabledesc);\n\t\t\tsystem.out.println(tablename + "\\t表创建成功");\n\t\t}\n\t}\n\n\t// 3.创建命名空间\n\tpublic static void create_namespace(string namespace) {\n\t\t// 创建命名空间描述器\n\t\tnamespacedescriptor descriptor = namespacedescriptor.create(namespace).build();\n\t\t//创建命名空间\n\t\ttry {\n\t\t\tadmin.createnamespace(descriptor);\n\t\t} catch(namespaceexistexception e) {\n\t\t\tsystem.out.println(namespace + "命名空间已存在");\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t}\n\t\tsystem.out.println("--我会被执行吗--");\n\t}\n\t// 4.删除表\n\tpublic static void drop_table(string tablename) throws ioexception {\n\t\ttablename tablenametemp = tablename.valueof(tablename);\n\t\tif (admin.tableexists(tablenametemp)) {\n\t\t\tadmin.disabletable(tablenametemp);\n\t\t\tadmin.deletetable(tablenametemp);\n\t\t\tsystem.out.println("表" + tablename + "删除成功！ ");\n\t\t} else {\n\t\t\tsystem.out.println("表" + tablename + "不存在！ ");\n\t\t}\n\t}\n\t// 5.插入数据\n\tpublic static void put_data(string tablename, string rowkey, string columnfamily, string column, string value) {\n\t\ttable table = null;\n\t\ttry {\n\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\tput put = new put(bytes.tobytes(rowkey));\n\t\t\tput.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column), bytes.tobytes(value));\n\t\t\ttable.put(put);\n\t\t} catch(nosuchcolumnfamilyexception e){\n\t\t\tsystem.out.println("异常:没有此列族");\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t}finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (ioexception e) {\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t\tsystem.out.println("数据插入成功");\n\t\t\n\t}\n\t// 6.查数据(get)\n\tpublic static void get_data(string tablename, string rowkey, string columnfamily, string column) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\t//get.addfamily(bytes.tobytes(columnfamily));\n\t\tget.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + "--" + columnfamily + "--" + column + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_data(string tablename, string rowkey, string columnfamily) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\tget.addfamily(bytes.tobytes(columnfamily));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + "--" + columnfamily + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\tpublic static void get_data(string tablename, string rowkey) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t\n\t\tget get = new get(bytes.tobytes(rowkey));\n\t\tresult result = table.get(get);\n\t\tcell[] cells = result.rawcells();\n\t\tsystem.out.println(tablename + "--" + rowkey + ":");\n\t\tprint_cells2(cells);\n\t\ttable.close();\n\t}\n\t// 打印单元格信息\n\tprivate static void print_cells(cell[] cells) {\n\t\tfor (cell tempcell : cells) {\n\t\t\tsystem.out.println(bytes.tostring(cellutil.clonerow(tempcell)) \n\t\t\t\t\t+ "\\t\\tcolumn=" + bytes.tostring(cellutil.clonefamily(tempcell)) + ":" +  bytes.tostring(cellutil.clonequalifier(tempcell))\n\t\t\t\t\t+ ",timestamp=" + tempcell.gettimestamp() \n\t\t\t\t\t+ ", value=" + bytes.tostring(cellutil.clonevalue(tempcell)) );\n\t\t}\n\t}\n\t// 打印单元格信息\n\tprivate static void print_cells2(cell[] cells) {\n\t\tstringbuilder sb = new stringbuilder();\n\t\tfor (cell cell : cells) {\n\t\t\tstring column = bytes.tostring(cell.getqualifierarray(), cell.getqualifieroffset(), cell.getqualifierlength());\n\t\t\tstring value = bytes.tostring(cell.getvaluearray(),cell.getvalueoffset(),cell.getvaluelength());\n\t\t\tsb.append(column).append(":").append(value).append(";\\t");\n\t\t}\n\t\tsystem.out.println(sb.tostring());\n\t}\n\t// 7.查数据(scan)\n\tpublic static void scan_data(string tablename) {\n\t\ttable table = null;\n\t\ttry {\n\t\t\ttable = connect.gettable(tablename.valueof(tablename));\n\t\t\tresultscanner results = table.getscanner(new scan());\n\t\t\tsystem.out.println(tablename + "表\\nrow\\t\\tcolumn+cell");\n\t\t\tfor (result result : results) {\n\t\t\t\tcell[] cells = result.rawcells();\n\t\t\t\tprint_cells(cells);\n\t\t\t}\n\t\t} catch (ioexception e) {\n\t\t\te.printstacktrace();\n\t\t} finally {\n\t\t\ttry {\n\t\t\t\tif(table!=null) {\n\t\t\t\t\ttable.close();\n\t\t\t\t}\n\t\t\t} catch (ioexception e) {\n\t\t\t\t// todo auto-generated catch block\n\t\t\t\te.printstacktrace();\n\t\t\t}\n\t\t}\n\t}\n\t// 7.2 查数据(scan + filter)\n\tpublic static void filter_data(string tablename, filter filter, int limit) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\tscan scan = new scan().setfilter(filter).setlimit(limit);\n\t\tresultscanner resultscan = table.getscanner(scan);\n\t\tsystem.out.println(tablename + "表(filter)\\nrow\\t\\tcolumn+cell");\n\t\tfor (result result : resultscan) {\n\t\t\tcell[] cells = result.rawcells();\n\t\t\tprint_cells(cells);\n\t\t}\n\t\ttable.close();\n\t}\n\t// 8. 删除多行数据\n\tpublic static void delete_data(string tablename, string... rows) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\t//delete delete = new delete(bytes.tobytes(rowkey));\n\t\tlist<delete> deletelist = new arraylist<delete>();\n\t\tfor (string row:rows) {\n\t\t\tdelete delete = new delete(bytes.tobytes(row));\n\t\t\tdeletelist.add(delete);\n\t\t}\n\t\ttable.delete(deletelist);\n\t\ttable.close();\n\t\tsystem.out.println("删除成功");\n\t}\n\t// 8.1 删除单元格(cell)数据\n\tpublic static void delete_cell(string tablename,  string rowkey, string columnfamily, string column ) throws ioexception {\n\t\ttable table = connect.gettable(tablename.valueof(tablename));\n\t\tdelete delete = new delete(bytes.tobytes(rowkey));\n\t\tdelete.addcolumn(bytes.tobytes(columnfamily), bytes.tobytes(column));\t\t//删除最后一版本\n\t\t//delete.addcolumns(bytes.tobytes(columnfamily), bytes.tobytes(column));\t\t//删除所有版本\n\t\ttable.delete(delete);\n\t\ttable.close();\n\t}\n\n\tpublic static void main(string[] args) throws ioexception {\n\t\tsystem.out.println("============================start=========================");\n\t\t// 1.判断表是否存在\n\t\t//is_exists("student");\n\t\t\n\t\t// 3.创建命名空间\n\t\t//create_namespace("std");\n\t\t\n\t\t// 2.创建表\n\t\t//create_table("std:stu");\n\t\t\n\t\t// 4.删除表\n\t\t//drop_table("std:stu");\n\t\t\n\t\t// 5.插入数据\n\t\t//put_data("std:stu", "1003", "info1", "addr", "beijing");\n\t\t//put_data("std:stu", "1004", "info1", "sex", "男");\n\t\t//put_data("std:stu", "1005", "info1", "class", "2");\n\t\t\n\t\t// 6.查数据(get)\n\t\tget_data("std:stu", "1002");\n\t\tget_data("std:stu", "1002", "info1");\n\t\t\n\t\t// 7.查数据(scan)\n\t\tscan_data("std:stu");\n\t\t\n\t\t// 7.1 查数据(scan + filter)\n\t\t//filter_data("std:stu", new prefixfilter(bytes.tobytes("100")), 10);\t//筛选出行键以row为前缀的所有的行\n\t\t//filter_data("std:stu", new randomrowfilter((float) 0.2), 10);\t//按照一定的几率（<=0会过滤掉所有的行，>=1会包含所有的行）来返回随机的结果集\n\t\t//filter_data("std:stu", new keyonlyfilter(), 10); // 返回所有的行，但值全是空 \n\t\t//  筛选出匹配的所有的行  \n\t\tfilter_data("std:stu", new rowfilter(comparefilter.compareop.less, new binarycomparator(bytes.tobytes("1002"))), 10);\n\t\t\n\t\t// 8. 删除多行数据数据\n\t\t//delete_data("std:stu", "1003","1004");\n\t\t\n\t\t// 8.1删除单元格数据\n\t\t//delete_cell("std:stu", "1005", "info1", "name");\n\t\t\n\t\tscan_data("std:stu");\n\t\t\n\t\tsystem.out.println("============================end==========================");\n\t\t// end:关闭资源和连接\n\t\tclose();\n\t}\n\n}\n\n',charsets:{cjk:!0},lastUpdated:"2025/03/28, 16:47:15",lastUpdatedTimestamp:1743151635e3},{title:"Spark环境搭建",frontmatter:{title:"Spark环境搭建",date:"2022-02-27T17:35:00.000Z",permalink:"/pages/7d157d/",categories:["大数据","Spark"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/06.Spark/01.Spark%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/06.Spark/01.Spark环境搭建.md",key:"v-a16758b4",path:"/pages/7d157d/",headers:[{level:2,title:"1.安装使用",slug:"_1-安装使用",normalizedTitle:"1.安装使用",charIndex:128},{level:3,title:"1）进入spark安装目录下的conf文件夹",slug:"_1-进入spark安装目录下的conf文件夹",normalizedTitle:"1）进入spark安装目录下的conf文件夹",charIndex:139},{level:3,title:"2）修改配置文件名称",slug:"_2-修改配置文件名称",normalizedTitle:"2）修改配置文件名称",charIndex:182},{level:3,title:"3）修改slave文件，添加work节点：",slug:"_3-修改slave文件-添加work节点",normalizedTitle:"3）修改slave文件，添加work节点：",charIndex:262},{level:3,title:"4）修改spark-env.sh文件，添加如下配置：",slug:"_4-修改spark-env-sh文件-添加如下配置",normalizedTitle:"4）修改spark-env.sh文件，添加如下配置：",charIndex:332},{level:3,title:"5）分发spark包",slug:"_5-分发spark包",normalizedTitle:"5）分发spark包",charIndex:491},{level:3,title:"6）启动(在Master)",slug:"_6-启动-在master",normalizedTitle:"6）启动(在master)",charIndex:520},{level:3,title:"7）官方求PI案例",slug:"_7-官方求pi案例",normalizedTitle:"7）官方求pi案例",charIndex:945},{level:3,title:"8）启动spark shell",slug:"_8-启动spark-shell",normalizedTitle:"8）启动spark shell",charIndex:1135},{level:2,title:"2.JobHistoryServer配置",slug:"_2-jobhistoryserver配置",normalizedTitle:"2.jobhistoryserver配置",charIndex:1540},{level:3,title:"1）修改spark-default.conf.template名称",slug:"_1-修改spark-default-conf-template名称",normalizedTitle:"1）修改spark-default.conf.template名称",charIndex:1565},{level:3,title:"2）修改spark-default.conf文件，开启Log：",slug:"_2-修改spark-default-conf文件-开启log",normalizedTitle:"2）修改spark-default.conf文件，开启log：",charIndex:1656},{level:3,title:"3）修改spark-env.sh文件，添加如下配置：",slug:"_3-修改spark-env-sh文件-添加如下配置",normalizedTitle:"3）修改spark-env.sh文件，添加如下配置：",charIndex:1870},{level:3,title:"4）分发配置文件",slug:"_4-分发配置文件",normalizedTitle:"4）分发配置文件",charIndex:2446},{level:3,title:"5）启动历史服务",slug:"_5-启动历史服务",normalizedTitle:"5）启动历史服务",charIndex:2505},{level:3,title:"6）再次执行任务",slug:"_6-再次执行任务",normalizedTitle:"6）再次执行任务",charIndex:2547},{level:3,title:"7）查看历史服务",slug:"_7-查看历史服务",normalizedTitle:"7）查看历史服务",charIndex:2736},{level:2,title:"3.HA配置",slug:"_3-ha配置",normalizedTitle:"3.ha配置",charIndex:2766},{level:3,title:"1）zookeeper正常安装并启动",slug:"_1-zookeeper正常安装并启动",normalizedTitle:"1）zookeeper正常安装并启动",charIndex:2777},{level:3,title:"2）修改spark-env.sh文件添加如下配置：",slug:"_2-修改spark-env-sh文件添加如下配置",normalizedTitle:"2）修改spark-env.sh文件添加如下配置：",charIndex:2800},{level:3,title:"3）分发配置文件",slug:"_3-分发配置文件",normalizedTitle:"3）分发配置文件",charIndex:3093},{level:3,title:"4）在hadoop100上(Master)启动全部节点",slug:"_4-在hadoop100上-master-启动全部节点",normalizedTitle:"4）在hadoop100上(master)启动全部节点",charIndex:3126},{level:3,title:"5）在hadoop101上单独启动master节点",slug:"_5-在hadoop101上单独启动master节点",normalizedTitle:"5）在hadoop101上单独启动master节点",charIndex:3177},{level:3,title:"6）spark HA集群访问",slug:"_6-spark-ha集群访问",normalizedTitle:"6）spark ha集群访问",charIndex:3229},{level:3,title:"7) 执行程序",slug:"_7-执行程序",normalizedTitle:"7) 执行程序",charIndex:3384},{level:3,title:"附:修改SparkUI界面默认端口号",slug:"附-修改sparkui界面默认端口号",normalizedTitle:"附:修改sparkui界面默认端口号",charIndex:3958},{level:2,title:"1.安装使用",slug:"_1-安装使用-2",normalizedTitle:"1.安装使用",charIndex:128},{level:3,title:"1）修改hadoop配置文件yarn-site.xml",slug:"_1-修改hadoop配置文件yarn-site-xml",normalizedTitle:"1）修改hadoop配置文件yarn-site.xml",charIndex:4251},{level:3,title:"2）修改spark-env.sh",slug:"_2-修改spark-env-sh",normalizedTitle:"2）修改spark-env.sh",charIndex:2800},{level:3,title:"3）分发配置文件",slug:"_3-分发配置文件-2",normalizedTitle:"3）分发配置文件",charIndex:3093},{level:3,title:"4）执行一个程序",slug:"_4-执行一个程序",normalizedTitle:"4）执行一个程序",charIndex:4914},{level:2,title:"2. 日志查看",slug:"_2-日志查看",normalizedTitle:"2. 日志查看",charIndex:5111},{level:3,title:"1）修改配置文件spark-defaults.conf",slug:"_1-修改配置文件spark-defaults-conf",normalizedTitle:"1）修改配置文件spark-defaults.conf",charIndex:5123},{level:3,title:"2）重启spark历史服务",slug:"_2-重启spark历史服务",normalizedTitle:"2）重启spark历史服务",charIndex:5243},{level:3,title:"3）提交任务到Yarn执行",slug:"_3-提交任务到yarn执行",normalizedTitle:"3）提交任务到yarn执行",charIndex:5545},{level:3,title:"4）Web页面查看日志",slug:"_4-web页面查看日志",normalizedTitle:"4）web页面查看日志",charIndex:5719}],headersStr:"1.安装使用 1）进入spark安装目录下的conf文件夹 2）修改配置文件名称 3）修改slave文件，添加work节点： 4）修改spark-env.sh文件，添加如下配置： 5）分发spark包 6）启动(在Master) 7）官方求PI案例 8）启动spark shell 2.JobHistoryServer配置 1）修改spark-default.conf.template名称 2）修改spark-default.conf文件，开启Log： 3）修改spark-env.sh文件，添加如下配置： 4）分发配置文件 5）启动历史服务 6）再次执行任务 7）查看历史服务 3.HA配置 1）zookeeper正常安装并启动 2）修改spark-env.sh文件添加如下配置： 3）分发配置文件 4）在hadoop100上(Master)启动全部节点 5）在hadoop101上单独启动master节点 6）spark HA集群访问 7) 执行程序 附:修改SparkUI界面默认端口号 1.安装使用 1）修改hadoop配置文件yarn-site.xml 2）修改spark-env.sh 3）分发配置文件 4）执行一个程序 2. 日志查看 1）修改配置文件spark-defaults.conf 2）重启spark历史服务 3）提交任务到Yarn执行 4）Web页面查看日志",content:'# 集群规划\n\n首先我们要确认我们的Linux主机是否安装了scala，如果没有安装则需要安装，5台机器都需要安装\n\n学习scala时使用的是2.12版本，所以我们选择spark2.4.2及以上的版本\n\n\n# Spark Standalone模式\n\n\n# 1.安装使用\n\n\n# 1）进入spark安装目录下的conf文件夹\n\ncd spark/conf/\n\n\n# 2）修改配置文件名称\n\nmv slaves.template slaves mv spark-env.sh.template spark-env.sh\n\n\n# 3）修改slave文件，添加work节点：\n\nvim slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n\n# 4）修改spark-env.sh文件，添加如下配置：\n\nvim spark-env.sh\n\nexport JAVA_HOME=/soft/module/jdk1.8.0_161\nexport SPARK_MASTER_HOST=hadoop100\nexport SPARK_MASTER_PORT=7077\n\n\n\n# 5）分发spark包\n\nxsync spark/\n\n\n# 6）启动(在Master)\n\nsbin/start-all.sh xcall.sh\n\n------------------- hadoop100 --------------\n10021 Jps\n9944 Master\n------------------- hadoop101 --------------\n9159 Jps\n9096 Worker\n------------------- hadoop102 --------------\n8740 Worker\n8804 Jps\n------------------- hadoop103 --------------\n8749 Worker\n8813 Jps\n\n\n网页查看：hadoop100:8080 注意：如果遇到 “JAVA_HOME not set” 异常，可以在sbin目录下的spark-config.sh 文件中加入如下配置： export JAVA_HOME=XXXX\n\n\n# 7）官方求PI案例\n\nbin/spark-submit \\\n--class org.apache.spark.examples.SparkPi \\\n--executor-memory 1G \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n\n# 8）启动spark shell\n\n/soft/module/spark/bin/spark-shell \\\n--master spark://hadoop100:7077 \\\n--executor-memory 1g \\\n--total-executor-cores 2\n\n\n参数：--master spark://hadoop100:7077指定要连接的集群的master 执行WordCount程序\n\nscala>sc.textFile("input").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect\n\nres0: Array[(String, Int)] = Array((hadoop,6), (oozie,3), (spark,3), (hive,3), (atguigu,3), (hbase,6))\n\nscala>\n\n\n\n# 2.JobHistoryServer配置\n\n\n# 1）修改spark-default.conf.template名称\n\nmv spark-defaults.conf.template spark-defaults.conf\n\n\n# 2）修改spark-default.conf文件，开启Log：\n\nvim spark-defaults.conf\n\nspark.eventLog.enabled           true\nspark.eventLog.dir               hdfs://hadoop100:9000/directory\n\n\n注意：HDFS上的目录需要提前存在。 hadoop fs -mkdir /directory\n\n\n# 3）修改spark-env.sh文件，添加如下配置：\n\nvim spark-env.sh\n\nexport SPARK_HISTORY_OPTS="\n-Dspark.history.ui.port=18080 \n-Dspark.history.retainedApplications=30 \n-Dspark.history.fs.logDirectory=hdfs://hadoop100:9000/directory"\n\n\n参数描述： spark.eventLog.dir：Application在运行过程中所有的信息均记录在该属性指定的路径下；\n\nspark.history.ui.port=18080 WEBUI访问的端口号为18080\n\nspark.history.fs.logDirectory=hdfs://hadoop102:9000/directory 配置了该属性后，在start-history-server.sh时就无需再显式的指定路径，Spark History Server页面只展示该指定路径下的信息\n\nspark.history.retainedApplications=30指定保存Application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。\n\n\n# 4）分发配置文件\n\nxsync spark-defaults.conf xsync spark-env.sh\n\n\n# 5）启动历史服务\n\nsbin/stop-history-server.sh\n\n\n# 6）再次执行任务\n\nbin/spark-submit \\\n--class org.apache.spark.examples.SparkPi \\\n--executor-memory 1G \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n\n# 7）查看历史服务\n\nhadoop100:18080\n\n\n# 3.HA配置\n\n\n# 1）zookeeper正常安装并启动\n\n\n# 2）修改spark-env.sh文件添加如下配置：\n\nvim spark-env.sh\n\n注释掉如下内容：\n\n#SPARK_MASTER_HOST=hadoop100\n#SPARK_MASTER_PORT=7077\n\n\n添加上如下内容：\n\nexport SPARK_DAEMON_JAVA_OPTS="\n-Dspark.deploy.recoveryMode=ZOOKEEPER \n-Dspark.deploy.zookeeper.url=hadoop101,hadoop102,hadoop103 \n-Dspark.deploy.zookeeper.dir=/spark"\n\n\n\n# 3）分发配置文件\n\nxsync spark-env.sh\n\n\n# 4）在hadoop100上(Master)启动全部节点\n\nsbin/start-all.sh\n\n\n# 5）在hadoop101上单独启动master节点\n\nsbin/start-master.sh\n\n\n# 6）spark HA集群访问\n\n/soft/module/spark/bin/spark-shell \\\n--master spark://hadoop100:7077,hadoop102:7077 \\\n--executor-memory 2g \\\n--total-executor-cores 2\n\n\n\n# 7) 执行程序\n\nbin/spark-submit \\\n--class org.apache.spark.examples.SparkPi \\\n--master spark://hadoop100:7077,hadoop101:7077 \\\n--executor-memory 1G \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n./spark-shell --master spark://hadoop100:7077,hadoop101:7077\n\nhadoop fs -mkdir -p /spark/input\nhadoop fs -put RELEASE /spark/input\n\nsc.textFile("/spark/input").flatMap(_.split(" ")).map(word=>(word,1)).reduceByKey(_+_).map(entry=>(entry._2,entry._1)).sortByKey(false,1).map(entry=>(entry._2,entry._1)).saveAsTextFile("/spark/output/")\n\n\n\n# 附:修改SparkUI界面默认端口号\n\nSparkUI界面默认端口号为8080(可能会被占用,被占用后默认+1HTTP ERROR 404 Not Found),两种方法修改\n\n 1. 修改conf/spark-env.sh, 加上export SPARK_MASTER_WEBUI_PORT=8082\n 2. 修改 sbin/start-master.sh\n\nif [ "$SPARK_MASTER_WEBUI_PORT" = "" ]; then\n  SPARK_MASTER_WEBUI_PORT=8082\nfi\n\n\n\n# Spark Yarn模式\n\n\n# 1.安装使用\n\n\n# 1）修改hadoop配置文件yarn-site.xml\n\n添加如下内容：vim yarn-site.xml\n\n        \x3c!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --\x3e\n        <property>\n                <name>yarn.nodemanager.pmem-check-enabled</name>\n                <value>false</value>\n        </property>\n        \x3c!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --\x3e\n        <property>\n                <name>yarn.nodemanager.vmem-check-enabled</name>\n                <value>false</value>\n        </property>\n\n\n\n# 2）修改spark-env.sh\n\n添加如下配置：vim spark-env.sh\n\nYARN_CONF_DIR=/soft/module/hadoop-2.9.2/etc/hadoop\n\n\n\n# 3）分发配置文件\n\nxsync /soft/module/hadoop-2.9.2/etc/hadoop/yarn-site.xml xsync spark-env.sh\n\n\n# 4）执行一个程序\n\nbin/spark-submit \\\n--class org.apache.spark.examples.SparkPi \\\n--master yarn \\\n--deploy-mode client \\\n./examples/jars/spark-examples_2.11-2.1.1.jar \\\n100\n\n\n注意：在提交任务之前需启动HDFS以及YARN集群。\n\n\n# 2. 日志查看\n\n\n# 1）修改配置文件spark-defaults.conf\n\n添加如下内容：\n\nspark.yarn.historyServer.address=hadoop102:18080\nspark.history.ui.port=18080\n\n\n\n# 2）重启spark历史服务\n\nsbin/stop-history-server.sh\n\nstopping org.apache.spark.deploy.history.HistoryServer\n\n\nsbin/start-history-server.sh\n\nstarting org.apache.spark.deploy.history.HistoryServer, logging to /opt/module/spark/logs/spark-atguigu-org.apache.spark.deploy.history.HistoryServer-1-hadoop102.out\n\n\n\n# 3）提交任务到Yarn执行\n\nbin/spark-submit \\\n--class org.apache.spark.examples.SparkPi \\\n--master yarn \\\n--deploy-mode client \\\n./examples/jars/spark-examples_2.11-2.1.1.jar \\\n100\n\n\n\n# 4）Web页面查看日志\n\nhadoop100:8088 ``\n\n\n# 附：spark 三种部署模式的区别对比\n\n源网页:https://www.cnblogs.com/eric666666/p/11228825.html\n\n在这三种部署模式中，standalone作为spark自带的分布式部署模式，是最简单也是最基本的spark应用程序部署模式，这里就不再赘述。\n\n这里就讲一下yarn和mesos的区别：\n\n(1) 就两种框架本身而言，mesos上可部署yarn框架。而yarn是更通用的一种部署框架，而且技术较成熟。\n\n(2) mesos双层调度机制，能支持多种调度模式，而Yarn通过Resource　Mananger管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos可接入如yarn一般的分布式部署框架，但Mesos要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个framework想要接入mesos时，需要修改自己的调度器，以便向mesos注册，并获取mesos分配给自己的资源， 这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个mesos系统采用了双层调度框架：第一层，由mesos将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。\n\n(3) mesos可实现粗、细粒度资源调度，可动态分配资源，而Yarn只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：\n\n粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个executor占用多少资源，内部可运行多少个executor）申请好，运行过程中不能改变。 　　 　　细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个Task运行完之后可以马上释放对应的资源。每个Task会汇报状态给Mesos slave和Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于MapReduce调度模式，每个Task完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。 　　 　　从yarn和mesos的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用yarn部署spark，原因是，我司早已有较成熟的hadoop的框架，考虑到使用的方便性，采用了yarn模式的部署。',normalizedContent:'# 集群规划\n\n首先我们要确认我们的linux主机是否安装了scala，如果没有安装则需要安装，5台机器都需要安装\n\n学习scala时使用的是2.12版本，所以我们选择spark2.4.2及以上的版本\n\n\n# spark standalone模式\n\n\n# 1.安装使用\n\n\n# 1）进入spark安装目录下的conf文件夹\n\ncd spark/conf/\n\n\n# 2）修改配置文件名称\n\nmv slaves.template slaves mv spark-env.sh.template spark-env.sh\n\n\n# 3）修改slave文件，添加work节点：\n\nvim slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n\n# 4）修改spark-env.sh文件，添加如下配置：\n\nvim spark-env.sh\n\nexport java_home=/soft/module/jdk1.8.0_161\nexport spark_master_host=hadoop100\nexport spark_master_port=7077\n\n\n\n# 5）分发spark包\n\nxsync spark/\n\n\n# 6）启动(在master)\n\nsbin/start-all.sh xcall.sh\n\n------------------- hadoop100 --------------\n10021 jps\n9944 master\n------------------- hadoop101 --------------\n9159 jps\n9096 worker\n------------------- hadoop102 --------------\n8740 worker\n8804 jps\n------------------- hadoop103 --------------\n8749 worker\n8813 jps\n\n\n网页查看：hadoop100:8080 注意：如果遇到 “java_home not set” 异常，可以在sbin目录下的spark-config.sh 文件中加入如下配置： export java_home=xxxx\n\n\n# 7）官方求pi案例\n\nbin/spark-submit \\\n--class org.apache.spark.examples.sparkpi \\\n--executor-memory 1g \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n\n# 8）启动spark shell\n\n/soft/module/spark/bin/spark-shell \\\n--master spark://hadoop100:7077 \\\n--executor-memory 1g \\\n--total-executor-cores 2\n\n\n参数：--master spark://hadoop100:7077指定要连接的集群的master 执行wordcount程序\n\nscala>sc.textfile("input").flatmap(_.split(" ")).map((_,1)).reducebykey(_+_).collect\n\nres0: array[(string, int)] = array((hadoop,6), (oozie,3), (spark,3), (hive,3), (atguigu,3), (hbase,6))\n\nscala>\n\n\n\n# 2.jobhistoryserver配置\n\n\n# 1）修改spark-default.conf.template名称\n\nmv spark-defaults.conf.template spark-defaults.conf\n\n\n# 2）修改spark-default.conf文件，开启log：\n\nvim spark-defaults.conf\n\nspark.eventlog.enabled           true\nspark.eventlog.dir               hdfs://hadoop100:9000/directory\n\n\n注意：hdfs上的目录需要提前存在。 hadoop fs -mkdir /directory\n\n\n# 3）修改spark-env.sh文件，添加如下配置：\n\nvim spark-env.sh\n\nexport spark_history_opts="\n-dspark.history.ui.port=18080 \n-dspark.history.retainedapplications=30 \n-dspark.history.fs.logdirectory=hdfs://hadoop100:9000/directory"\n\n\n参数描述： spark.eventlog.dir：application在运行过程中所有的信息均记录在该属性指定的路径下；\n\nspark.history.ui.port=18080 webui访问的端口号为18080\n\nspark.history.fs.logdirectory=hdfs://hadoop102:9000/directory 配置了该属性后，在start-history-server.sh时就无需再显式的指定路径，spark history server页面只展示该指定路径下的信息\n\nspark.history.retainedapplications=30指定保存application历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。\n\n\n# 4）分发配置文件\n\nxsync spark-defaults.conf xsync spark-env.sh\n\n\n# 5）启动历史服务\n\nsbin/stop-history-server.sh\n\n\n# 6）再次执行任务\n\nbin/spark-submit \\\n--class org.apache.spark.examples.sparkpi \\\n--executor-memory 1g \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n\n# 7）查看历史服务\n\nhadoop100:18080\n\n\n# 3.ha配置\n\n\n# 1）zookeeper正常安装并启动\n\n\n# 2）修改spark-env.sh文件添加如下配置：\n\nvim spark-env.sh\n\n注释掉如下内容：\n\n#spark_master_host=hadoop100\n#spark_master_port=7077\n\n\n添加上如下内容：\n\nexport spark_daemon_java_opts="\n-dspark.deploy.recoverymode=zookeeper \n-dspark.deploy.zookeeper.url=hadoop101,hadoop102,hadoop103 \n-dspark.deploy.zookeeper.dir=/spark"\n\n\n\n# 3）分发配置文件\n\nxsync spark-env.sh\n\n\n# 4）在hadoop100上(master)启动全部节点\n\nsbin/start-all.sh\n\n\n# 5）在hadoop101上单独启动master节点\n\nsbin/start-master.sh\n\n\n# 6）spark ha集群访问\n\n/soft/module/spark/bin/spark-shell \\\n--master spark://hadoop100:7077,hadoop102:7077 \\\n--executor-memory 2g \\\n--total-executor-cores 2\n\n\n\n# 7) 执行程序\n\nbin/spark-submit \\\n--class org.apache.spark.examples.sparkpi \\\n--master spark://hadoop100:7077,hadoop101:7077 \\\n--executor-memory 1g \\\n--total-executor-cores 2 \\\n./examples/jars/spark-examples_2.12-3.0.0-preview2.jar \\\n100\n\n\n./spark-shell --master spark://hadoop100:7077,hadoop101:7077\n\nhadoop fs -mkdir -p /spark/input\nhadoop fs -put release /spark/input\n\nsc.textfile("/spark/input").flatmap(_.split(" ")).map(word=>(word,1)).reducebykey(_+_).map(entry=>(entry._2,entry._1)).sortbykey(false,1).map(entry=>(entry._2,entry._1)).saveastextfile("/spark/output/")\n\n\n\n# 附:修改sparkui界面默认端口号\n\nsparkui界面默认端口号为8080(可能会被占用,被占用后默认+1http error 404 not found),两种方法修改\n\n 1. 修改conf/spark-env.sh, 加上export spark_master_webui_port=8082\n 2. 修改 sbin/start-master.sh\n\nif [ "$spark_master_webui_port" = "" ]; then\n  spark_master_webui_port=8082\nfi\n\n\n\n# spark yarn模式\n\n\n# 1.安装使用\n\n\n# 1）修改hadoop配置文件yarn-site.xml\n\n添加如下内容：vim yarn-site.xml\n\n        \x3c!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是true --\x3e\n        <property>\n                <name>yarn.nodemanager.pmem-check-enabled</name>\n                <value>false</value>\n        </property>\n        \x3c!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --\x3e\n        <property>\n                <name>yarn.nodemanager.vmem-check-enabled</name>\n                <value>false</value>\n        </property>\n\n\n\n# 2）修改spark-env.sh\n\n添加如下配置：vim spark-env.sh\n\nyarn_conf_dir=/soft/module/hadoop-2.9.2/etc/hadoop\n\n\n\n# 3）分发配置文件\n\nxsync /soft/module/hadoop-2.9.2/etc/hadoop/yarn-site.xml xsync spark-env.sh\n\n\n# 4）执行一个程序\n\nbin/spark-submit \\\n--class org.apache.spark.examples.sparkpi \\\n--master yarn \\\n--deploy-mode client \\\n./examples/jars/spark-examples_2.11-2.1.1.jar \\\n100\n\n\n注意：在提交任务之前需启动hdfs以及yarn集群。\n\n\n# 2. 日志查看\n\n\n# 1）修改配置文件spark-defaults.conf\n\n添加如下内容：\n\nspark.yarn.historyserver.address=hadoop102:18080\nspark.history.ui.port=18080\n\n\n\n# 2）重启spark历史服务\n\nsbin/stop-history-server.sh\n\nstopping org.apache.spark.deploy.history.historyserver\n\n\nsbin/start-history-server.sh\n\nstarting org.apache.spark.deploy.history.historyserver, logging to /opt/module/spark/logs/spark-atguigu-org.apache.spark.deploy.history.historyserver-1-hadoop102.out\n\n\n\n# 3）提交任务到yarn执行\n\nbin/spark-submit \\\n--class org.apache.spark.examples.sparkpi \\\n--master yarn \\\n--deploy-mode client \\\n./examples/jars/spark-examples_2.11-2.1.1.jar \\\n100\n\n\n\n# 4）web页面查看日志\n\nhadoop100:8088 ``\n\n\n# 附：spark 三种部署模式的区别对比\n\n源网页:https://www.cnblogs.com/eric666666/p/11228825.html\n\n在这三种部署模式中，standalone作为spark自带的分布式部署模式，是最简单也是最基本的spark应用程序部署模式，这里就不再赘述。\n\n这里就讲一下yarn和mesos的区别：\n\n(1) 就两种框架本身而言，mesos上可部署yarn框架。而yarn是更通用的一种部署框架，而且技术较成熟。\n\n(2) mesos双层调度机制，能支持多种调度模式，而yarn通过resource　mananger管理集群资源，只能使用一种调度模式。mesos 的双层调度机制为：mesos可接入如yarn一般的分布式部署框架，但mesos要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个framework想要接入mesos时，需要修改自己的调度器，以便向mesos注册，并获取mesos分配给自己的资源， 这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个mesos系统采用了双层调度框架：第一层，由mesos将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。\n\n(3) mesos可实现粗、细粒度资源调度，可动态分配资源，而yarn只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：\n\n粗粒度模式（coarse-grained mode）：程序运行之前就要把所需要的各种资源（每个executor占用多少资源，内部可运行多少个executor）申请好，运行过程中不能改变。 　　 　　细粒度模式（fine-grained mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动executor，但每个executor占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos会为每个executor动态分配资源，每分配一些，便可以运行一个新任务，单个task运行完之后可以马上释放对应的资源。每个task会汇报状态给mesos slave和mesos master，便于更加细粒度管理和容错，这种调度模式类似于mapreduce调度模式，每个task完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。 　　 　　从yarn和mesos的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用yarn部署spark，原因是，我司早已有较成熟的hadoop的框架，考虑到使用的方便性，采用了yarn模式的部署。',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Spark相关知识",frontmatter:{title:"Spark相关知识",date:"2022-02-27T17:37:46.000Z",permalink:"/pages/b3ba00/",categories:["大数据","Spark"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/06.Spark/02.Spark%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86.html",relativePath:"02.大数据/06.Spark/02.Spark相关知识.md",key:"v-6c2b8593",path:"/pages/b3ba00/",headers:[{level:2,title:"spark-sql可调参数",slug:"spark-sql可调参数",normalizedTitle:"spark-sql可调参数",charIndex:2},{level:2,title:"Spark数据类型",slug:"spark数据类型",normalizedTitle:"spark数据类型",charIndex:3306},{level:3,title:"RDD、DataFrame、DataSet创建,及相互转换",slug:"rdd、dataframe、dataset创建-及相互转换",normalizedTitle:"rdd、dataframe、dataset创建,及相互转换",charIndex:3320},{level:2,title:"Spark代码学习",slug:"spark代码学习",normalizedTitle:"spark代码学习",charIndex:4156},{level:3,title:"第一个spark程序",slug:"第一个spark程序",normalizedTitle:"第一个spark程序",charIndex:4212},{level:3,title:"WordCount",slug:"wordcount",normalizedTitle:"wordcount",charIndex:4977},{level:2,title:"Spark SQL（sqlContext）",slug:"spark-sql-sqlcontext",normalizedTitle:"spark sql（sqlcontext）",charIndex:6951},{level:3,title:"第一个例子",slug:"第一个例子",normalizedTitle:"第一个例子",charIndex:6977},{level:3,title:"SparkSQL CLI(hiveContext)",slug:"sparksql-cli-hivecontext",normalizedTitle:"sparksql cli(hivecontext)",charIndex:9639},{level:2,title:"Spark Streaming知识点",slug:"spark-streaming知识点",normalizedTitle:"spark streaming知识点",charIndex:10321},{level:3,title:"Dstream基础",slug:"dstream基础",normalizedTitle:"dstream基础",charIndex:10386},{level:3,title:"高级来源",slug:"高级来源",normalizedTitle:"高级来源",charIndex:10730},{level:3,title:"文件数据源(文件系统)",slug:"文件数据源-文件系统",normalizedTitle:"文件数据源(文件系统)",charIndex:12013},{level:3,title:"mysql(队列)数据源",slug:"mysql-队列-数据源",normalizedTitle:"mysql(队列)数据源",charIndex:13114},{level:3,title:"自定义数据源",slug:"自定义数据源",normalizedTitle:"自定义数据源",charIndex:16534},{level:3,title:"有状态数据统计UpdateStateByKey",slug:"有状态数据统计updatestatebykey",normalizedTitle:"有状态数据统计updatestatebykey",charIndex:18650},{level:3,title:"Window滑动",slug:"window滑动",normalizedTitle:"window滑动",charIndex:20926},{level:3,title:"转换 transfrom",slug:"转换-transfrom",normalizedTitle:"转换 transfrom",charIndex:23320},{level:3,title:"DStream.foreachRDD(DStream输出)",slug:"dstream-foreachrdd-dstream输出",normalizedTitle:"dstream.foreachrdd(dstream输出)",charIndex:23339}],headersStr:"spark-sql可调参数 Spark数据类型 RDD、DataFrame、DataSet创建,及相互转换 Spark代码学习 第一个spark程序 WordCount Spark SQL（sqlContext） 第一个例子 SparkSQL CLI(hiveContext) Spark Streaming知识点 Dstream基础 高级来源 文件数据源(文件系统) mysql(队列)数据源 自定义数据源 有状态数据统计UpdateStateByKey Window滑动 转换 transfrom DStream.foreachRDD(DStream输出)",content:'# spark-sql可调参数\n\n----------------------------------------\n\n#Job ID /Name\nspark.app.name=clsfd_ad_attr_map_w_mvca_ins\n\n#yarn 进行调度，也可以是mesos，yarn，以及standalone\n\n#一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。\nspark.master=yarn\n\n#激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。\n#需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。\n#对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor\nspark.shuffle.service.enabled=true\n\n#在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。\nspark.dynamicAllocation.enabled=true\n\n# 如果所有的executor都移除了，重新请求时启动的初始executor数\nspark.dynamicAllocation.initialExecutors=20\n\n# 最少保留的executor数\nspark.dynamicAllocation.minExecutors=10\n\n# 最多使用的executor数，默认为你申请的最大executor数\nspark.dynamicAllocation.maxExecutors=100\n\n# 可以是cluster也可以是Client\nspark.submit.deployMode=cluster\n\n# 指定提交到Yarn的资源池\nspark.yarn.queue=hdlq-data-batch-low\n\n# 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。\nspark.driver.memory=8g\n# excutor的核心数\nspark.executor.cores=16\n# 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead\nspark.executor.memory=32g\nspark.yarn.executor.memoryOverhead=2g\n\n# shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。\nspark.sql.shuffle.partitions=100\n\n# 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize \n# 这个参数只适用于未加工的RDD不适用于dataframe\n# 没有join和聚合计算操作，这个参数将是无效设置\nspark.default.parallelism\n\n# 打包传入一个分区的最大字节，在读取文件的时候。\nspark.sql.files.maxPartitionBytes=128MB\n\n# 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。\n# 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。\nspark.sql.files.openCostInBytes=4MB\n\n# Spark 事件总线是SparkListenerEvent事件的阻塞队列大小\nspark.scheduler.listenerbus.eventqueue.size=100000\n\n# 是否启动推测机制\nspark.speculation=false\n\n# 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。\n# 2表示比其他task慢两倍时，启动推测机制\nspark.speculation.multiplier=2\n\n# 推测机制的检测周期\nspark.speculation.interval=5000ms\n\n# 完成task的百分比时启动推测\nspark.speculation.quantile=0.6\n\n# 最多允许失败的Executor数量。\nspark.task.maxFailures=10\n\n# spark序列化 对于优化<网络性能>极为重要，将RDD以序列化格式来保存减少内存占用.\nspark.serializer=org.apache.spark.serializer.KryoSerializer\n\n# 因为spark是基于内存的机制，所以默认是开启RDD的压缩\nspark.rdd.compress=true\n\n# Spark的安全管理\n#https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala\nspark.ui.view.acls=*\nspark.ui.view.acls.groups=*\n\n# 表示配置GC线程数为3\nspark.executor.extraJavaOptions="-XX:ParallelGCThreads=3"\n\n# 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB\nspark.sql.autoBroadcastJoinThreshold=104857600\n\n# 广播等待超时，这里单位是秒\nspark.sql.broadcastTimeout=300\n\n# 心跳检测间隔\nspark.yarn.scheduler.heartbeat.interval-ms=10000\n\nspark.sql.broadcastTimeout\n\n#缓存表问题\n#spark2.+采用：\n#spark.catalog.cacheTable("tableName")缓存表，spark.catalog.uncacheTable("tableName")解除缓存。\n#spark 1.+采用：\n#sqlContext.cacheTable("tableName")缓存，sqlContext.uncacheTable("tableName") 解除缓存\n#Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。\n\n#假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。\nspark.sql.inMemoryColumnarStorage.compressed=true\n\n#控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险\nspark.sql.inMemoryColumnarStorage.batchSize=10000\n\n\n\n# Spark数据类型\n\n\n# RDD、DataFrame、DataSet创建,及相互转换\n\nRDD创建(RDD整体上分为Value类型和Key-Value类型)\n\n * 从内存(集合)创建\n\nval rdd = sc.parallelize(Array(1,2,3,4,5,6,7,8))\nval rdd1 = sc.makeRDD(Array(1,2,3,4,5,6,7,8))\n\n\n * 从磁盘创建\n\nval rdd2= sc.textFile("hdfs://hadoop102:9000/RELEASE")\n\n\n * 从其他RDD转化\n\nDataFrame创建(SparkSession是创建DataFrame和执行SQL的入口)\n\n * 通过Spark的数据源进行创建；\n\nval df = spark.read.json("/opt/module/spark/examples/src/main/resources/people.json")\n\n\n * 从一个存在的RDD进行转换；\n * 还可以从Hive Table进行查询返回\n\nDataSet创建(Dataset是具有强类型的数据集合，需要提供对应的类型信息)\n\n * 内存创建 1）创建一个样例类\n\n  scala> case class Person(name: String, age: Long)\n  defined class Person\n\n\n2）创建DataSet\n\n  scala> val caseClassDS = Seq(Person("Andy", 32)).toDS()\n  caseClassDS: org.apache.spark.sql.Dataset[Person] = [name: string, age: bigint]\n\n\n * 通过DataFrame或RDD转化\n\n相互转化 ![](rdd df ds相互转换.jpg)\n\n待扩展 三者共性和区别 用户自定义函数 Spark数据源\n\n\n# Spark代码学习\n\n----------------------------------------\n\n\n# 第一个spark程序\n\n import org.apache.spark.{SparkConf, SparkContext}\n \n object FirstSpark {\n   def main(args: Array[String]): Unit = {\n //        println("hello spark!")\n     val conf = new SparkConf().setAppName("mySpark")\n     .setMaster("local") //本机的park就用local.远端的就写ip，因为我的park环境是在云端连接不方便这里我先用local\n     //如果是打成jar包运行则需要去掉setMaster("local")因为在参数中会指定。\n \n     //sc对象为spark运行时的上下文\n     val sc = new SparkContext(conf)\n     //使用list初始化1个RDD并使用map函数*3\n     val rdd = sc.parallelize(List(1, 2, 3, 4, 5, 6)).map(_ * 3)\n     //取出大于10的元素\n     val mappedRDD = rdd.filter(_ > 10).collect()\n     //对集合求和\n     println(rdd.reduce(_ + _))\n     //输出大于10的元素\n     for (arg <- mappedRDD)\n       print(arg + " ")\n     println()\n     println("run success")\n \n     sc.stop()\n   }\n }\n\n\n\n# WordCount\n\n import org.apache.spark.{SparkConf, SparkContext}\n \n object WordCount {\n   def main(args: Array[String]): Unit = {\n     /**\n     第一步：创建spark的配置对象sparkconf,设置spark程序的运行时的配置信息，例如说通过setMaster来设置程序\n       链接spark集群的master的URL，如果设置为local，则代表spark程序在本地运行，\n      */\n     val conf = new SparkConf()   //创建SparkConf对象\n     .setAppName("WordCount")    //设置应用程序的名称,在程序运行的监控界面可以看到这个名字\n     //conf.setMaster("local")//此时，程序在本地执行，不需要安装spark集群\n     //"spark://192.168.1.100:7077"\n     //conf.setMaster(args(0))//指定spark运行是集群模式 一般我们不在代码中指定，我们在提交的时候指定\n     /**\n     第二步：创建SparkContext对象，\n     SparkContext是spark程序所有功能的唯一入口，无论是采用Scala，Java，Python，R等都必须有一个SparkContext\n     SparkContext核心作用：初始化spark应用程序运行时候所需要的核心组件，包括DAGScheduler，TaskScheduler,SchedulerBackend\n     同时还会负责Spark程序往Master注册程序等\n     SparkContext是整个spark应用程序中最为至关重要的一个对象\n      */\n     val sc=new SparkContext(conf)   //创建SparkContext对象，通过传入SparkContext实例来定制Spark运行的具体参数和配置信息\n     /**\n     第3步：根据具体的数据来源 (HDFS,HBase,Local等)通过SparkContext来创建RDD\n     RDD的创建有3种方式，外部的数据来源，根据scala集合，由其他的RDD操作\n     数据会被RDD划分成为一系列的Partitions,分配到每个Partition的数据属于一个Task的处理范畴\n      */\n     val line=sc.textFile(args(0),1)  //读取本地的一个文件并且设置为1个partition\n     //val line =sc.textFile("hdfs://192.168.18.140:9000/input/LICENSE.txt")   //指定HDFS的路径，这个也可以到时候在参数传入\n     /**\n     第4步：对初始的RDD进行Transformation级别的处理，例如Map、filter等高阶函数等的编程来进行具体的数据计算\n      在对每一行的字符串拆分成单个单词\n      在单词的拆分的基础上对每个单词实例计算为1，也就是word=>(word,1)\n      在对每个单词实例计数为1基础上统计每个单词在文件中出现的总次数\n      */\n     val words=line.flatMap(_.split(" "))\n     val pairs=words.map(word=>(word,1))\n     val wordcounts=pairs.reduceByKey(_+_)\n \n     //key value反转，按key排序，再反转回来\n     val sortWords = wordcounts.map(x => (x._2,x._1)).sortByKey(false).map(x => (x._2,x._1))\n     sortWords.saveAsTextFile(args(1)) //存储到文件系统\n \n     //sortWords.foreach(wordNum=>println(wordNum._1+":"+wordNum._2)) //本地模式用这个打印\n     sortWords.collect().foreach(wordNum=>println(wordNum._1+":"+wordNum._2))\n     sc.stop()\n   }\n }\n\n\n\n# Spark SQL（sqlContext）\n\n\n# 第一个例子\n\npackage sparkSQL\n\nimport org.apache.spark.sql.{DataFrame, SparkSession}\n\nobject SparkSqlJson {\n  def main(args: Array[String]): Unit = {\n    //在代码中使用sparkSql,我们只需要一个SparkSession即可搞定\n    //创建一个SparkSession实例\n    val sparkSession: SparkSession = SparkSession.builder() //创建 SparkSession.Builder，初始化SparkSession.\n      .appName("spark SQL basic example")\n      .master("local[*]") //在idea里设置master为local\n      .getOrCreate() //当SparkSession.GetOrCreate()被调用，SparkSession发生变化，将会返回一个线程和它的子线程。这将会确定给定的线程接受带有隔离会话的SparkSession，而不是全局的context。\n\n    //读入数据文件,该文件是从spark example中拷贝的,具体路径spark/examples/src/main/resources/下\n    val dataFrame: DataFrame = sparkSession.read.json(args(0)) //"data\\\\people.json"\n\n    //显示数据集\n    println("----------------1.显示数据集--------------------------")\n    dataFrame.show()\n    //显示数据集的模式\n    println("----------------2.显示数据集的模式--------------------------")\n    dataFrame.printSchema()\n    //查询name列并显示\n    println("----------------3.查询name列并显示--------------------------")\n    dataFrame.select("name").show()\n\n\n    //引入spark的隐式转换功能,我们可以使用$符号+列名的形式对列进行计算\n    //这里的sparkSession不是某个包下面的东西，而是我们SparkSession.builder()对应的变量值\n    import sparkSession.implicits._\n    //查询姓名,并age+1后显示\n    println("----------------4.查询姓名,并age+1后显示--------------------------")\n    dataFrame.select($"name", $"age" + 1).show()\n    //过滤年龄大于21的并显示\n    println("----------------5.过滤年龄大于21的并显示--------------------------")\n    dataFrame.filter($"age" > 21).show()\n    //以年龄分组并计算每组的人数\n    println("----------------6.以年龄分组并计算每组的人数--------------------------")\n    dataFrame.groupBy("age").count().show()\n\n    //将dataframe注册为临时表people\n    dataFrame.createOrReplaceTempView("people")\n    //直接使用sql语句查询people表\n    val sqlDF: DataFrame = sparkSession.sql("SELECT * FROM people")\n    //显示结果集\n    println("----------------7.查询临时表,显示结果集--------------------------")\n    sqlDF.show()\n\n    //创建全局表\n    dataFrame.createGlobalTempView("people")\n    //查询全局people表\n    println("----------------8.查询全局people表--------------------------")\n    sparkSession.sql("SELECT * FROM global_temp.people").show()\n    //全局表是可以跨session的\n    println("----------------9.全局表跨session查询--------------------------")\n    sparkSession.newSession().sql("SELECT * FROM global_temp.people").show()\n  }\n}\n\n\n添加依赖\n\n\x3c!--SparkSQL添加依赖--\x3e\n<dependency>\n    <groupId>org.apache.parquet</groupId>\n    <artifactId>parquet-jackson</artifactId>\n    <version>1.10.1</version>\n</dependency>\n\n\n打jar包测试\n\nbin/spark-submit \\\n--class sparkSQL.SparkSqlJson \\\n--master spark://hadoop1:7077 \\\n--executor-memory 1G \\\n--total-executor-cores 1 \\\n./myjar/SparkSQLJson.jar \\\nfile:///soft/spark/examples/src/main/resources/people.json\n\n\n\n# SparkSQL CLI(hiveContext)\n\n在spark下链接hadoop的core-site.xml 以及配置hive-site.xml的hive.metastore.uris并链接\n\n<configuration>\n  <property>\n    <name>hive.metastore.uris</name>\n    <value>thrift://hadoop100:9083</value>\n    <description>Thrift URI for the remote metastore. Used by metastore client to connect to remote metastore.</description>\n  </property>\n</configuration>\n\nln -s /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml /soft/module/spark/conf/core-site.xml\nln -s /soft/module/hive/conf/hive-site.xml /soft/module/spark/conf/hive-site.xml\n\n然后启动hive的metastore服务，使用nohup命令后台启动\nnohup hive --service metastore > metastore.log 2>&1 &\n\n启动spark-sql\n/soft/module/spark/bin/spark-sql\n\n\n\n# Spark Streaming知识点\n\n----------------------------------------\n\n\n# Dstream基础\n\n * ssc.socketTextStream()方法 TCP套接字连接 (截图在命令行练习)\n * streamingContext.fileStream(dataDirectory)方法, 可以从任何文件系统(如：HDFS、S3、NFS等）的文件中读取数据，然后创建一个DStream。\n\n> 需要注意的是：读取的必须是具有相同的数据格式的文件；创建的文件必须在dataDirectory目录下，并通过自动移动或重命名成数据目录；文件一旦移动就不能被改变，如果文件被不断追加,新的数据将不会被阅读。\n\n * 对于简单的文本文件，可以使用一个简单的方法streamingContext.textFileStream(dataDirectory)来读取数据\n\n\n# 高级来源\n\nSpark Streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到Spark Streaming 的 Maven 工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。\n\n每个接收器都以 Spark 执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 CPU 核心。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。(意思是核心数 >= 接收器数n + 1)\n\n官方示例WordCount\n\npackage sparkstreaming\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n//import org.apache.spark.streaming.StreamingContext._\n\n/**\n * 官方示例WordCount\n */\nobject SparkStreaming {\n  def main(args: Array[String]): Unit = {\n\n    //1.初始化Spark配置信息\n    val conf = new SparkConf().setMaster("local[2]").setAppName("NetworkWordCount")\n\n    //2.初始化SparkStreamingContext\n    val ssc = new StreamingContext(conf, Seconds(5)) //以5s为时间窗口进行数据处理\n\n    //3.通过监控端口创建DStream，读进来的数据为一行行\n    val lines = ssc.socketTextStream("hadoop1", 9999)\n\n    //将每一行数据做切分，形成一个个单词\n    val words = lines.flatMap(_.split(" "))\n\n\n    //将单词映射成元组（word,1）\n    val pairs = words.map(word => (word, 1))\n    //将相同的单词次数做统计\n    val wordCounts = pairs.reduceByKey(_ + _)\n\n    // Print the first ten elements of each RDD generated in this DStream to the console\n    //打印\n    wordCounts.print()\n    ssc.start()     // Start the computation\n    ssc.awaitTermination()  // Wait for the computation to terminate\n\n  }\n}\n\n\n\n# 文件数据源(文件系统)\n\npackage sparkstreaming\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming.dstream.DStream\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\n/**\n * 文件数据源(文件系统)\n */\nobject FileSource {\n  def main(args: Array[String]): Unit = {\n    //1.初始化Spark配置信息\n\n    val sparkConf: SparkConf = new SparkConf().setMaster("local[*]")\n      .setAppName("Stream WordCount")\n\n    //2.初始化Spark StreamingContext\n    val ssc: StreamingContext = new StreamingContext(sparkConf, Seconds(5))\n\n    //3.监控文件夹创建DStream\n    val dirStream: DStream[String] = ssc.textFileStream("hdfs://hadoop1:9000/fileStream")\n\n    //4.将每一行数据做切分, 形成一个个单词\n    val wordStream: DStream[String] = dirStream.flatMap(_.split(" "))\n\n    //5.将单词映射为元组\n    val wordAndOneStream: DStream[(String, Int)] = wordStream.map((_, 1))\n\n    //6.将相同的单词做次数统计\n    val wordAndCountStream: DStream[(String, Int)] = wordAndOneStream.reduceByKey(_ + _)\n\n    //7.打印\n    wordAndCountStream.print()\n\n    //8.启动StreamContext\n    ssc.start()\n    ssc.awaitTermination() // 调用StreamingContext的awaitTermination()方法， 来等待应用程序的终止。\n  }\n}\n\n\n\n# mysql(队列)数据源\n\n添加依赖\n\n\x3c!--连接mysql添加依赖--\x3e\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>8.0.17</version>\n</dependency>\n\n\npackage sparkstreaming.mysqlandqueue\n\nimport java.sql.{Connection, DriverManager, ResultSet, Statement}\n\nobject DB {\n\n  //初始化数据连接\n  var connection: Connection = _\n  var statement : Statement = _\n\n  def conn {\n    // 访问本地MySQL服务器，通过3306端口访问mysql数据库\n    val url = "jdbc:mysql://localhost:3306/demo-3?useUnicode=true&characterEncoding=utf-8&serverTimezone=GMT%2B8&useSSL=false"\n    //驱动名称\n    val driver = "com.mysql.cj.jdbc.Driver"\n\n    val username = "root"\n    val password = "123456789"\n\n\n    Class.forName(driver) //.newInstance()\n    connection = DriverManager.getConnection(url, username, password)\n    statement = connection.createStatement //(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY)\n  }\n\n  //从数据库中取出每个用户的名字，是个String有序队列\n  def getMessage : Seq[String] = {\n    conn\n    var setName = Seq("")\n    try {\n      // Execute Query，查询用户表 sec_user 是我的用户表，有name属性。\n      val rs = statement.executeQuery("select ci_id, ci_name from city")\n      // Iterate Over ResultSet\n      while (rs.next) {\n        // 返回行号\n        // println(rs.getRow)\n        val ci_name = rs.getString("ci_name")\n        setName = setName :+ ci_name\n      }\n    } finally {\n      close\n    }\n    return setName\n  }\n\n  def close: Unit ={\n    connection.close\n  }\n//  def main(args: Array[String]): Unit = {\n//    println(getMessage)\n//  }\n}\n\n\npackage sparkstreaming.mysqlandqueue\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.streaming.dstream.{DStream, InputDStream}\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\nimport scala.collection.mutable\n\n/**\n * RDD队列数据源 + mysql\n */\nobject MySparkStreaming {\n  def main(args: Array[String]) {\n\n    // 1.创建spark实例\n    val sparkConf = new SparkConf().setAppName("QueueStream").setMaster("local")\n\n    // 2.初始化sparkStreamingContext ，Seconds是多久去Rdd中取一次数据。\n    val ssc = new StreamingContext(sparkConf, Seconds(3))\n\n    // 3.创建RDD队列\n    val rddQueue = new mutable.Queue[RDD[String]]()\n\n    // 4.创建QueueInputStream, 从rdd队列中读取输入流\n    val inputStream: InputDStream[String] = ssc.queueStream(rddQueue)\n\n    // 5.处理队列中的RDD数据\n    //将输入流中的每个元素（每个元素都是一个String）后面添加一个“a“字符，并返回一个新的rdd。\n    val mappedStream: DStream[(String, Int)] = inputStream.map(x => (x + "*", 1))\n    // reduceByKey(_ + _)对每个元素统计次数。map(x => (x._2,x._1))是将map的key和value 交换位置。\n    // 后边是过滤次数超过1次的且String 相等于“testa“\n    val reducedStream: DStream[(String, Int)] = mappedStream.reduceByKey(_ + _)\n        .filter(x => x._1.length>4)\n      //.map(x => (x._2, x._1)).filter((x) => x._1 > 1).filter((x) => x._2.equals("testa"))\n\n    // 6.打印结果\n    reducedStream.print()\n    //将每次计算的结果存储在./out/resulted处。\n    //reducedStream.saveAsTextFiles("data/resulted")\n\n    // 7.启动任务\n    ssc.start()\n\n    //从数据库中查出每个用户的姓名，返回的是一个String有序队列seq，因为生成RDD的对象必须是seq。\n    val seq = DB.getMessage\n    //println(seq)\n\n    // 8.创建循环并向RDD队列中放入RDD\n    // 将seq生成RDD然后放入Spark的Streaming的RDD队列，作为输入流。\n    for (i <- 1 to 3) {\n      rddQueue.synchronized {\n        rddQueue += ssc.sparkContext.makeRDD(seq, 10)\n        // 打印到控制台\n        //rddQueue.foreach(rdd => rdd.foreach(println(_)))\n      }\n      Thread.sleep(3000)\n    }\n    ssc.stop()\n    //ssc.awaitTermination() // 调用StreamingContext的awaitTermination()方法， 来等待应用程序的终止。\n  }\n}\n\n\n\n# 自定义数据源\n\npackage sparkstreaming.udsource\n\nimport java.io.{BufferedReader, InputStreamReader}\nimport java.net.Socket\nimport java.nio.charset.StandardCharsets\n\nimport org.apache.spark.storage.StorageLevel\nimport org.apache.spark.streaming.receiver.Receiver\n\n/**\n * 自定义数据源\n * 需要继承Receiver 并实现onStart onStop方法\n */\nclass CustomerReceiver(host:String, port:Int) extends Receiver[String](StorageLevel.MEMORY_ONLY){\n  //最初启动的时候，调用该方法，作用为：读数据并将数据发送给Spark\n  override def onStart(): Unit ={\n    new Thread("Socket Receiver") {\n      override def run() {\n        receive()\n      }\n    }.start()\n  }\n\n  //读数据并将数据发送给Spark\n  def receive(): Unit = {\n\n    //创建一个Socket\n    var socket: Socket = new Socket(host, port)\n\n    //定义一个变量，用来接收端口传过来的数据\n    var input: String = null\n\n    //创建一个BufferedReader用于读取端口传来的数据\n    val reader = new BufferedReader(new InputStreamReader(socket.getInputStream, StandardCharsets.UTF_8))\n\n    //读取数据\n    input = reader.readLine()\n\n    //当receiver没有关闭并且输入数据不为空，则循环发送数据给Spark\n    while (!isStopped() && input != null) {\n      store(input)\n      input = reader.readLine()\n    }\n\n    //跳出循环则关闭资源\n    reader.close()\n    socket.close()\n\n    //重启任务\n    restart("restart")\n  }\n\n\n  override def onStop(): Unit ={\n\n  }\n}\n\n\npackage sparkstreaming.udsource\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\n\nobject UDSource {\n  def main(args: Array[String]): Unit = {\n\n    //1.初始化Spark配置信息\n    val sparkConf = new SparkConf().setMaster("local[*]")\n      .setAppName("StreamWordCount")\n\n    //2.初始化SparkStreamingContext\n    val ssc = new StreamingContext(sparkConf, Seconds(5))\n\n    //3.创建自定义receiver的Streaming\n    val lineStream = ssc.receiverStream(new CustomerReceiver("hadoop102", 9999))\n\n    //4.将每一行数据做切分，形成一个个单词\n    val wordStreams = lineStream.flatMap(_.split("\\t"))\n\n    //5.将单词映射成元组（word,1）\n    val wordAndOneStreams = wordStreams.map((_, 1))\n\n    //6.将相同的单词次数做统计\n    val wordAndCountStreams = wordAndOneStreams.reduceByKey(_ + _)\n\n    //7.打印\n    wordAndCountStreams.print()\n\n    //8.启动SparkStreamingContext\n    ssc.start()\n    ssc.awaitTermination()\n  }\n}\n\n\n\n# 有状态数据统计UpdateStateByKey\n\npackage com.hrbu\n\nimport org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, InputDStream}\nimport org.apache.spark.streaming.kafka010.{ConsumerStrategies, KafkaUtils, LocationStrategies}\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.{SparkConf, SparkContext}\n\n/**\n * @title 有状态数据统计\n * 有状态转化操作  (UpdateStateByKey)  类似UDAF的Buffer???\n * 对之前的数据也有更新\n * 保存到文件(数据大  防止宕机)\n */\nobject DataStreaming_02 {\n  def main(args: Array[String]): Unit = {\n    val config = Map(\n      "spark.cores" -> "local[*]",\n      "kafka.topic" -> "datastreaming"\n    )\n\n    // 创建配置对象\n    val sparkConf: SparkConf = new SparkConf().setAppName("DataStreaming").setMaster(config("spark.cores"))\n    // 创建SparkSession\n    val spark: SparkSession = SparkSession.builder().config(sparkConf).getOrCreate()\n    // 创建sparkContext\n    val sc: SparkContext = spark.sparkContext\n    // 创建spark StreamingContext\n    val ssc = new StreamingContext(sc, Seconds(5))\n\n    // 保存数据状态 需要设置检查点路径\n    sc.setCheckpointDir("checkpoint")\n\n    // 创建到Kafka的连接\n    val kafkaPara = Map(\n      "bootstrap.servers" -> "hadoop1:9092",\n      "key.deserializer" -> classOf[StringDeserializer],\n      "value.deserializer" -> classOf[StringDeserializer],\n      "group.id" -> "data",\n      "auto.offset.reset" -> "latest"\n    )\n\n    val kafkaStream: InputDStream[ConsumerRecord[String, String]] = KafkaUtils.createDirectStream[String, String](\n      ssc,\n      LocationStrategies.PreferConsistent,\n      ConsumerStrategies.Subscribe[String, String](Array(config("kafka.topic")), kafkaPara)\n    )\n\n    // 取到消息队列里的值\n    val valueDStream: DStream[String] = kafkaStream.flatMap(t => t.value().split(" "))\n\n    val mapDStream: DStream[(String, Int)] = valueDStream.map((_, 1))\n\n    // 将转换结构后的数据进行聚合处理\n    val stateDStream: DStream[(String, Int)] = mapDStream.updateStateByKey {\n      case (seq, buffer) => {\n        val sum: Int = buffer.getOrElse(0) + seq.sum\n        Option(sum)\n      }\n    }\n\n    stateDStream.print()\n\n    // 对读入的DStream进行分析\n\n\n    // 启动采集器\n    ssc.start()\n    // 等待采集器停止\n    ssc.awaitTermination()\n  }\n}\n\n\n\n# Window滑动\n\npackage com.hrbu\n\nimport org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, InputDStream}\nimport org.apache.spark.streaming.kafka010.{ConsumerStrategies, KafkaUtils, LocationStrategies}\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.{SparkConf, SparkContext}\n\n\nobject DataStreaming03_Window {\n  def main(args: Array[String]): Unit = {\n    TestScala\n  }\n\n  def TestScala(): Unit ={\n    // Scala语法\n    val ints = List(1, 2, 3, 4, 5, 6)\n    // 滑动窗口函数(窗口大小 步长)\n    val iter: Iterator[List[Int]] = ints.sliding(3, 3)\n\n    for( list <- iter){\n      println(list.mkString(","))\n    }\n  }\n\n  // 随时间改变(随时间推移  少一部分  多一部分)\n  def sparkMain(){\n    val config = Map(\n      "spark.cores" -> "local[*]",\n      "kafka.topic" -> "datastreaming"\n    )\n\n    // 创建配置对象\n    val sparkConf: SparkConf = new SparkConf().setAppName("DataStreaming").setMaster(config("spark.cores"))\n    // 创建SparkSession\n    val spark: SparkSession = SparkSession.builder().config(sparkConf).getOrCreate()\n    // 创建sparkContext\n    val sc: SparkContext = spark.sparkContext\n    // 创建spark StreamingContext\n    val ssc = new StreamingContext(sc, Seconds(3))\n\n    // 创建到Kafka的连接\n    val kafkaPara = Map(\n      "bootstrap.servers" -> "hadoop1:9092",\n      "key.deserializer" -> classOf[StringDeserializer],\n      "value.deserializer" -> classOf[StringDeserializer],\n      "group.id" -> "data",\n      "auto.offset.reset" -> "latest"\n    )\n\n    val kafkaStream: InputDStream[ConsumerRecord[String, String]] = KafkaUtils.createDirectStream[String, String](\n      ssc,\n      LocationStrategies.PreferConsistent,\n      ConsumerStrategies.Subscribe[String, String](Array(config("kafka.topic")), kafkaPara)\n    )\n\n    // 窗口大小为采集周期的整数倍 窗口滑动步长也应该为采集周期的整数倍\n    val windowDStream: DStream[ConsumerRecord[String, String]] = kafkaStream.window(Seconds(9), Seconds(3))\n\n    // 取到消息队列里的值\n    val valueDStream: DStream[String] = windowDStream.flatMap(t => t.value().split(" "))\n\n    val mapDStream: DStream[(String, Int)] = valueDStream.map((_, 1))\n\n    // 数据聚合处理\n    val reduceDStream: DStream[(String, Int)] = mapDStream.reduceByKey(_ + _)\n\n    reduceDStream.print()\n\n    // 启动采集器\n    ssc.start()\n    // 等待采集器停止\n    ssc.awaitTermination()\n  }\n}\n\n\n\n# 转换 transfrom\n\n\n\n\n# DStream.foreachRDD(DStream输出)\n\n一个DStream包含一个或多个RDD\n\n通用的输出操作foreachRDD()，它用来对DStream中的RDD运行任意计算。这和transform() 有些类似，都可以让我们访问任意RDD。在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作。 比如，常见的用例之一是把数据写到诸如MySQL的外部数据库中。 注意： （1）连接不能写在driver层面； （2）如果写在foreach则每个RDD都创建，得不偿失； （3）增加foreachPartition，在分区创建。',normalizedContent:'# spark-sql可调参数\n\n----------------------------------------\n\n#job id /name\nspark.app.name=clsfd_ad_attr_map_w_mvca_ins\n\n#yarn 进行调度，也可以是mesos，yarn，以及standalone\n\n#一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkcontext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。\nspark.master=yarn\n\n#激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。\n#需要设置spark.dynamicallocation.enabled 为true，同事指定外部shuffle服务。\n#对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor\nspark.shuffle.service.enabled=true\n\n#在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。\nspark.dynamicallocation.enabled=true\n\n# 如果所有的executor都移除了，重新请求时启动的初始executor数\nspark.dynamicallocation.initialexecutors=20\n\n# 最少保留的executor数\nspark.dynamicallocation.minexecutors=10\n\n# 最多使用的executor数，默认为你申请的最大executor数\nspark.dynamicallocation.maxexecutors=100\n\n# 可以是cluster也可以是client\nspark.submit.deploymode=cluster\n\n# 指定提交到yarn的资源池\nspark.yarn.queue=hdlq-data-batch-low\n\n# 在yarn-cluster模式下，申请yarn app master（包括driver）所用的内存。\nspark.driver.memory=8g\n# excutor的核心数\nspark.executor.cores=16\n# 一个executor对应一个jvm进程。executor占用的内存分为两部分：executormemory和memoryoverhead\nspark.executor.memory=32g\nspark.yarn.executor.memoryoverhead=2g\n\n# shuffle分区数100，根据数据量进行调控，这儿配置了join时shuffle的分区数和聚合数据时的分区数。\nspark.sql.shuffle.partitions=100\n\n# 如果用户没有指定并行度，下面这个参数将是rdd中的分区数，它是由join,reducebykey和parallelize \n# 这个参数只适用于未加工的rdd不适用于dataframe\n# 没有join和聚合计算操作，这个参数将是无效设置\nspark.default.parallelism\n\n# 打包传入一个分区的最大字节，在读取文件的时候。\nspark.sql.files.maxpartitionbytes=128mb\n\n# 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。\n# 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。\nspark.sql.files.opencostinbytes=4mb\n\n# spark 事件总线是sparklistenerevent事件的阻塞队列大小\nspark.scheduler.listenerbus.eventqueue.size=100000\n\n# 是否启动推测机制\nspark.speculation=false\n\n# 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后spark会选取最快的作为最终结果。\n# 2表示比其他task慢两倍时，启动推测机制\nspark.speculation.multiplier=2\n\n# 推测机制的检测周期\nspark.speculation.interval=5000ms\n\n# 完成task的百分比时启动推测\nspark.speculation.quantile=0.6\n\n# 最多允许失败的executor数量。\nspark.task.maxfailures=10\n\n# spark序列化 对于优化<网络性能>极为重要，将rdd以序列化格式来保存减少内存占用.\nspark.serializer=org.apache.spark.serializer.kryoserializer\n\n# 因为spark是基于内存的机制，所以默认是开启rdd的压缩\nspark.rdd.compress=true\n\n# spark的安全管理\n#https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/securitymanager.scala\nspark.ui.view.acls=*\nspark.ui.view.acls.groups=*\n\n# 表示配置gc线程数为3\nspark.executor.extrajavaoptions="-xx:parallelgcthreads=3"\n\n# 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持hive metastore表。这里设置的是10mb\nspark.sql.autobroadcastjointhreshold=104857600\n\n# 广播等待超时，这里单位是秒\nspark.sql.broadcasttimeout=300\n\n# 心跳检测间隔\nspark.yarn.scheduler.heartbeat.interval-ms=10000\n\nspark.sql.broadcasttimeout\n\n#缓存表问题\n#spark2.+采用：\n#spark.catalog.cachetable("tablename")缓存表，spark.catalog.uncachetable("tablename")解除缓存。\n#spark 1.+采用：\n#sqlcontext.cachetable("tablename")缓存，sqlcontext.uncachetable("tablename") 解除缓存\n#sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和gc压力。\n\n#假如设置为true，sparksql会根据统计信息自动的为每个列选择压缩方式进行压缩。\nspark.sql.inmemorycolumnarstorage.compressed=true\n\n#控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有oom的风险\nspark.sql.inmemorycolumnarstorage.batchsize=10000\n\n\n\n# spark数据类型\n\n\n# rdd、dataframe、dataset创建,及相互转换\n\nrdd创建(rdd整体上分为value类型和key-value类型)\n\n * 从内存(集合)创建\n\nval rdd = sc.parallelize(array(1,2,3,4,5,6,7,8))\nval rdd1 = sc.makerdd(array(1,2,3,4,5,6,7,8))\n\n\n * 从磁盘创建\n\nval rdd2= sc.textfile("hdfs://hadoop102:9000/release")\n\n\n * 从其他rdd转化\n\ndataframe创建(sparksession是创建dataframe和执行sql的入口)\n\n * 通过spark的数据源进行创建；\n\nval df = spark.read.json("/opt/module/spark/examples/src/main/resources/people.json")\n\n\n * 从一个存在的rdd进行转换；\n * 还可以从hive table进行查询返回\n\ndataset创建(dataset是具有强类型的数据集合，需要提供对应的类型信息)\n\n * 内存创建 1）创建一个样例类\n\n  scala> case class person(name: string, age: long)\n  defined class person\n\n\n2）创建dataset\n\n  scala> val caseclassds = seq(person("andy", 32)).tods()\n  caseclassds: org.apache.spark.sql.dataset[person] = [name: string, age: bigint]\n\n\n * 通过dataframe或rdd转化\n\n相互转化 ![](rdd df ds相互转换.jpg)\n\n待扩展 三者共性和区别 用户自定义函数 spark数据源\n\n\n# spark代码学习\n\n----------------------------------------\n\n\n# 第一个spark程序\n\n import org.apache.spark.{sparkconf, sparkcontext}\n \n object firstspark {\n   def main(args: array[string]): unit = {\n //        println("hello spark!")\n     val conf = new sparkconf().setappname("myspark")\n     .setmaster("local") //本机的park就用local.远端的就写ip，因为我的park环境是在云端连接不方便这里我先用local\n     //如果是打成jar包运行则需要去掉setmaster("local")因为在参数中会指定。\n \n     //sc对象为spark运行时的上下文\n     val sc = new sparkcontext(conf)\n     //使用list初始化1个rdd并使用map函数*3\n     val rdd = sc.parallelize(list(1, 2, 3, 4, 5, 6)).map(_ * 3)\n     //取出大于10的元素\n     val mappedrdd = rdd.filter(_ > 10).collect()\n     //对集合求和\n     println(rdd.reduce(_ + _))\n     //输出大于10的元素\n     for (arg <- mappedrdd)\n       print(arg + " ")\n     println()\n     println("run success")\n \n     sc.stop()\n   }\n }\n\n\n\n# wordcount\n\n import org.apache.spark.{sparkconf, sparkcontext}\n \n object wordcount {\n   def main(args: array[string]): unit = {\n     /**\n     第一步：创建spark的配置对象sparkconf,设置spark程序的运行时的配置信息，例如说通过setmaster来设置程序\n       链接spark集群的master的url，如果设置为local，则代表spark程序在本地运行，\n      */\n     val conf = new sparkconf()   //创建sparkconf对象\n     .setappname("wordcount")    //设置应用程序的名称,在程序运行的监控界面可以看到这个名字\n     //conf.setmaster("local")//此时，程序在本地执行，不需要安装spark集群\n     //"spark://192.168.1.100:7077"\n     //conf.setmaster(args(0))//指定spark运行是集群模式 一般我们不在代码中指定，我们在提交的时候指定\n     /**\n     第二步：创建sparkcontext对象，\n     sparkcontext是spark程序所有功能的唯一入口，无论是采用scala，java，python，r等都必须有一个sparkcontext\n     sparkcontext核心作用：初始化spark应用程序运行时候所需要的核心组件，包括dagscheduler，taskscheduler,schedulerbackend\n     同时还会负责spark程序往master注册程序等\n     sparkcontext是整个spark应用程序中最为至关重要的一个对象\n      */\n     val sc=new sparkcontext(conf)   //创建sparkcontext对象，通过传入sparkcontext实例来定制spark运行的具体参数和配置信息\n     /**\n     第3步：根据具体的数据来源 (hdfs,hbase,local等)通过sparkcontext来创建rdd\n     rdd的创建有3种方式，外部的数据来源，根据scala集合，由其他的rdd操作\n     数据会被rdd划分成为一系列的partitions,分配到每个partition的数据属于一个task的处理范畴\n      */\n     val line=sc.textfile(args(0),1)  //读取本地的一个文件并且设置为1个partition\n     //val line =sc.textfile("hdfs://192.168.18.140:9000/input/license.txt")   //指定hdfs的路径，这个也可以到时候在参数传入\n     /**\n     第4步：对初始的rdd进行transformation级别的处理，例如map、filter等高阶函数等的编程来进行具体的数据计算\n      在对每一行的字符串拆分成单个单词\n      在单词的拆分的基础上对每个单词实例计算为1，也就是word=>(word,1)\n      在对每个单词实例计数为1基础上统计每个单词在文件中出现的总次数\n      */\n     val words=line.flatmap(_.split(" "))\n     val pairs=words.map(word=>(word,1))\n     val wordcounts=pairs.reducebykey(_+_)\n \n     //key value反转，按key排序，再反转回来\n     val sortwords = wordcounts.map(x => (x._2,x._1)).sortbykey(false).map(x => (x._2,x._1))\n     sortwords.saveastextfile(args(1)) //存储到文件系统\n \n     //sortwords.foreach(wordnum=>println(wordnum._1+":"+wordnum._2)) //本地模式用这个打印\n     sortwords.collect().foreach(wordnum=>println(wordnum._1+":"+wordnum._2))\n     sc.stop()\n   }\n }\n\n\n\n# spark sql（sqlcontext）\n\n\n# 第一个例子\n\npackage sparksql\n\nimport org.apache.spark.sql.{dataframe, sparksession}\n\nobject sparksqljson {\n  def main(args: array[string]): unit = {\n    //在代码中使用sparksql,我们只需要一个sparksession即可搞定\n    //创建一个sparksession实例\n    val sparksession: sparksession = sparksession.builder() //创建 sparksession.builder，初始化sparksession.\n      .appname("spark sql basic example")\n      .master("local[*]") //在idea里设置master为local\n      .getorcreate() //当sparksession.getorcreate()被调用，sparksession发生变化，将会返回一个线程和它的子线程。这将会确定给定的线程接受带有隔离会话的sparksession，而不是全局的context。\n\n    //读入数据文件,该文件是从spark example中拷贝的,具体路径spark/examples/src/main/resources/下\n    val dataframe: dataframe = sparksession.read.json(args(0)) //"data\\\\people.json"\n\n    //显示数据集\n    println("----------------1.显示数据集--------------------------")\n    dataframe.show()\n    //显示数据集的模式\n    println("----------------2.显示数据集的模式--------------------------")\n    dataframe.printschema()\n    //查询name列并显示\n    println("----------------3.查询name列并显示--------------------------")\n    dataframe.select("name").show()\n\n\n    //引入spark的隐式转换功能,我们可以使用$符号+列名的形式对列进行计算\n    //这里的sparksession不是某个包下面的东西，而是我们sparksession.builder()对应的变量值\n    import sparksession.implicits._\n    //查询姓名,并age+1后显示\n    println("----------------4.查询姓名,并age+1后显示--------------------------")\n    dataframe.select($"name", $"age" + 1).show()\n    //过滤年龄大于21的并显示\n    println("----------------5.过滤年龄大于21的并显示--------------------------")\n    dataframe.filter($"age" > 21).show()\n    //以年龄分组并计算每组的人数\n    println("----------------6.以年龄分组并计算每组的人数--------------------------")\n    dataframe.groupby("age").count().show()\n\n    //将dataframe注册为临时表people\n    dataframe.createorreplacetempview("people")\n    //直接使用sql语句查询people表\n    val sqldf: dataframe = sparksession.sql("select * from people")\n    //显示结果集\n    println("----------------7.查询临时表,显示结果集--------------------------")\n    sqldf.show()\n\n    //创建全局表\n    dataframe.createglobaltempview("people")\n    //查询全局people表\n    println("----------------8.查询全局people表--------------------------")\n    sparksession.sql("select * from global_temp.people").show()\n    //全局表是可以跨session的\n    println("----------------9.全局表跨session查询--------------------------")\n    sparksession.newsession().sql("select * from global_temp.people").show()\n  }\n}\n\n\n添加依赖\n\n\x3c!--sparksql添加依赖--\x3e\n<dependency>\n    <groupid>org.apache.parquet</groupid>\n    <artifactid>parquet-jackson</artifactid>\n    <version>1.10.1</version>\n</dependency>\n\n\n打jar包测试\n\nbin/spark-submit \\\n--class sparksql.sparksqljson \\\n--master spark://hadoop1:7077 \\\n--executor-memory 1g \\\n--total-executor-cores 1 \\\n./myjar/sparksqljson.jar \\\nfile:///soft/spark/examples/src/main/resources/people.json\n\n\n\n# sparksql cli(hivecontext)\n\n在spark下链接hadoop的core-site.xml 以及配置hive-site.xml的hive.metastore.uris并链接\n\n<configuration>\n  <property>\n    <name>hive.metastore.uris</name>\n    <value>thrift://hadoop100:9083</value>\n    <description>thrift uri for the remote metastore. used by metastore client to connect to remote metastore.</description>\n  </property>\n</configuration>\n\nln -s /soft/module/hadoop-2.9.2/etc/hadoop/core-site.xml /soft/module/spark/conf/core-site.xml\nln -s /soft/module/hive/conf/hive-site.xml /soft/module/spark/conf/hive-site.xml\n\n然后启动hive的metastore服务，使用nohup命令后台启动\nnohup hive --service metastore > metastore.log 2>&1 &\n\n启动spark-sql\n/soft/module/spark/bin/spark-sql\n\n\n\n# spark streaming知识点\n\n----------------------------------------\n\n\n# dstream基础\n\n * ssc.sockettextstream()方法 tcp套接字连接 (截图在命令行练习)\n * streamingcontext.filestream(datadirectory)方法, 可以从任何文件系统(如：hdfs、s3、nfs等）的文件中读取数据，然后创建一个dstream。\n\n> 需要注意的是：读取的必须是具有相同的数据格式的文件；创建的文件必须在datadirectory目录下，并通过自动移动或重命名成数据目录；文件一旦移动就不能被改变，如果文件被不断追加,新的数据将不会被阅读。\n\n * 对于简单的文本文件，可以使用一个简单的方法streamingcontext.textfilestream(datadirectory)来读取数据\n\n\n# 高级来源\n\nspark streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到spark streaming 的 maven 工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。\n\n每个接收器都以 spark 执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 cpu 核心。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。(意思是核心数 >= 接收器数n + 1)\n\n官方示例wordcount\n\npackage sparkstreaming\n\nimport org.apache.spark.sparkconf\nimport org.apache.spark.streaming.{seconds, streamingcontext}\n//import org.apache.spark.streaming.streamingcontext._\n\n/**\n * 官方示例wordcount\n */\nobject sparkstreaming {\n  def main(args: array[string]): unit = {\n\n    //1.初始化spark配置信息\n    val conf = new sparkconf().setmaster("local[2]").setappname("networkwordcount")\n\n    //2.初始化sparkstreamingcontext\n    val ssc = new streamingcontext(conf, seconds(5)) //以5s为时间窗口进行数据处理\n\n    //3.通过监控端口创建dstream，读进来的数据为一行行\n    val lines = ssc.sockettextstream("hadoop1", 9999)\n\n    //将每一行数据做切分，形成一个个单词\n    val words = lines.flatmap(_.split(" "))\n\n\n    //将单词映射成元组（word,1）\n    val pairs = words.map(word => (word, 1))\n    //将相同的单词次数做统计\n    val wordcounts = pairs.reducebykey(_ + _)\n\n    // print the first ten elements of each rdd generated in this dstream to the console\n    //打印\n    wordcounts.print()\n    ssc.start()     // start the computation\n    ssc.awaittermination()  // wait for the computation to terminate\n\n  }\n}\n\n\n\n# 文件数据源(文件系统)\n\npackage sparkstreaming\n\nimport org.apache.spark.sparkconf\nimport org.apache.spark.streaming.dstream.dstream\nimport org.apache.spark.streaming.{seconds, streamingcontext}\n\n/**\n * 文件数据源(文件系统)\n */\nobject filesource {\n  def main(args: array[string]): unit = {\n    //1.初始化spark配置信息\n\n    val sparkconf: sparkconf = new sparkconf().setmaster("local[*]")\n      .setappname("stream wordcount")\n\n    //2.初始化spark streamingcontext\n    val ssc: streamingcontext = new streamingcontext(sparkconf, seconds(5))\n\n    //3.监控文件夹创建dstream\n    val dirstream: dstream[string] = ssc.textfilestream("hdfs://hadoop1:9000/filestream")\n\n    //4.将每一行数据做切分, 形成一个个单词\n    val wordstream: dstream[string] = dirstream.flatmap(_.split(" "))\n\n    //5.将单词映射为元组\n    val wordandonestream: dstream[(string, int)] = wordstream.map((_, 1))\n\n    //6.将相同的单词做次数统计\n    val wordandcountstream: dstream[(string, int)] = wordandonestream.reducebykey(_ + _)\n\n    //7.打印\n    wordandcountstream.print()\n\n    //8.启动streamcontext\n    ssc.start()\n    ssc.awaittermination() // 调用streamingcontext的awaittermination()方法， 来等待应用程序的终止。\n  }\n}\n\n\n\n# mysql(队列)数据源\n\n添加依赖\n\n\x3c!--连接mysql添加依赖--\x3e\n<dependency>\n    <groupid>mysql</groupid>\n    <artifactid>mysql-connector-java</artifactid>\n    <version>8.0.17</version>\n</dependency>\n\n\npackage sparkstreaming.mysqlandqueue\n\nimport java.sql.{connection, drivermanager, resultset, statement}\n\nobject db {\n\n  //初始化数据连接\n  var connection: connection = _\n  var statement : statement = _\n\n  def conn {\n    // 访问本地mysql服务器，通过3306端口访问mysql数据库\n    val url = "jdbc:mysql://localhost:3306/demo-3?useunicode=true&characterencoding=utf-8&servertimezone=gmt%2b8&usessl=false"\n    //驱动名称\n    val driver = "com.mysql.cj.jdbc.driver"\n\n    val username = "root"\n    val password = "123456789"\n\n\n    class.forname(driver) //.newinstance()\n    connection = drivermanager.getconnection(url, username, password)\n    statement = connection.createstatement //(resultset.type_forward_only, resultset.concur_read_only)\n  }\n\n  //从数据库中取出每个用户的名字，是个string有序队列\n  def getmessage : seq[string] = {\n    conn\n    var setname = seq("")\n    try {\n      // execute query，查询用户表 sec_user 是我的用户表，有name属性。\n      val rs = statement.executequery("select ci_id, ci_name from city")\n      // iterate over resultset\n      while (rs.next) {\n        // 返回行号\n        // println(rs.getrow)\n        val ci_name = rs.getstring("ci_name")\n        setname = setname :+ ci_name\n      }\n    } finally {\n      close\n    }\n    return setname\n  }\n\n  def close: unit ={\n    connection.close\n  }\n//  def main(args: array[string]): unit = {\n//    println(getmessage)\n//  }\n}\n\n\npackage sparkstreaming.mysqlandqueue\n\nimport org.apache.spark.sparkconf\nimport org.apache.spark.rdd.rdd\nimport org.apache.spark.streaming.dstream.{dstream, inputdstream}\nimport org.apache.spark.streaming.{seconds, streamingcontext}\n\nimport scala.collection.mutable\n\n/**\n * rdd队列数据源 + mysql\n */\nobject mysparkstreaming {\n  def main(args: array[string]) {\n\n    // 1.创建spark实例\n    val sparkconf = new sparkconf().setappname("queuestream").setmaster("local")\n\n    // 2.初始化sparkstreamingcontext ，seconds是多久去rdd中取一次数据。\n    val ssc = new streamingcontext(sparkconf, seconds(3))\n\n    // 3.创建rdd队列\n    val rddqueue = new mutable.queue[rdd[string]]()\n\n    // 4.创建queueinputstream, 从rdd队列中读取输入流\n    val inputstream: inputdstream[string] = ssc.queuestream(rddqueue)\n\n    // 5.处理队列中的rdd数据\n    //将输入流中的每个元素（每个元素都是一个string）后面添加一个“a“字符，并返回一个新的rdd。\n    val mappedstream: dstream[(string, int)] = inputstream.map(x => (x + "*", 1))\n    // reducebykey(_ + _)对每个元素统计次数。map(x => (x._2,x._1))是将map的key和value 交换位置。\n    // 后边是过滤次数超过1次的且string 相等于“testa“\n    val reducedstream: dstream[(string, int)] = mappedstream.reducebykey(_ + _)\n        .filter(x => x._1.length>4)\n      //.map(x => (x._2, x._1)).filter((x) => x._1 > 1).filter((x) => x._2.equals("testa"))\n\n    // 6.打印结果\n    reducedstream.print()\n    //将每次计算的结果存储在./out/resulted处。\n    //reducedstream.saveastextfiles("data/resulted")\n\n    // 7.启动任务\n    ssc.start()\n\n    //从数据库中查出每个用户的姓名，返回的是一个string有序队列seq，因为生成rdd的对象必须是seq。\n    val seq = db.getmessage\n    //println(seq)\n\n    // 8.创建循环并向rdd队列中放入rdd\n    // 将seq生成rdd然后放入spark的streaming的rdd队列，作为输入流。\n    for (i <- 1 to 3) {\n      rddqueue.synchronized {\n        rddqueue += ssc.sparkcontext.makerdd(seq, 10)\n        // 打印到控制台\n        //rddqueue.foreach(rdd => rdd.foreach(println(_)))\n      }\n      thread.sleep(3000)\n    }\n    ssc.stop()\n    //ssc.awaittermination() // 调用streamingcontext的awaittermination()方法， 来等待应用程序的终止。\n  }\n}\n\n\n\n# 自定义数据源\n\npackage sparkstreaming.udsource\n\nimport java.io.{bufferedreader, inputstreamreader}\nimport java.net.socket\nimport java.nio.charset.standardcharsets\n\nimport org.apache.spark.storage.storagelevel\nimport org.apache.spark.streaming.receiver.receiver\n\n/**\n * 自定义数据源\n * 需要继承receiver 并实现onstart onstop方法\n */\nclass customerreceiver(host:string, port:int) extends receiver[string](storagelevel.memory_only){\n  //最初启动的时候，调用该方法，作用为：读数据并将数据发送给spark\n  override def onstart(): unit ={\n    new thread("socket receiver") {\n      override def run() {\n        receive()\n      }\n    }.start()\n  }\n\n  //读数据并将数据发送给spark\n  def receive(): unit = {\n\n    //创建一个socket\n    var socket: socket = new socket(host, port)\n\n    //定义一个变量，用来接收端口传过来的数据\n    var input: string = null\n\n    //创建一个bufferedreader用于读取端口传来的数据\n    val reader = new bufferedreader(new inputstreamreader(socket.getinputstream, standardcharsets.utf_8))\n\n    //读取数据\n    input = reader.readline()\n\n    //当receiver没有关闭并且输入数据不为空，则循环发送数据给spark\n    while (!isstopped() && input != null) {\n      store(input)\n      input = reader.readline()\n    }\n\n    //跳出循环则关闭资源\n    reader.close()\n    socket.close()\n\n    //重启任务\n    restart("restart")\n  }\n\n\n  override def onstop(): unit ={\n\n  }\n}\n\n\npackage sparkstreaming.udsource\n\nimport org.apache.spark.sparkconf\nimport org.apache.spark.streaming.{seconds, streamingcontext}\n\nobject udsource {\n  def main(args: array[string]): unit = {\n\n    //1.初始化spark配置信息\n    val sparkconf = new sparkconf().setmaster("local[*]")\n      .setappname("streamwordcount")\n\n    //2.初始化sparkstreamingcontext\n    val ssc = new streamingcontext(sparkconf, seconds(5))\n\n    //3.创建自定义receiver的streaming\n    val linestream = ssc.receiverstream(new customerreceiver("hadoop102", 9999))\n\n    //4.将每一行数据做切分，形成一个个单词\n    val wordstreams = linestream.flatmap(_.split("\\t"))\n\n    //5.将单词映射成元组（word,1）\n    val wordandonestreams = wordstreams.map((_, 1))\n\n    //6.将相同的单词次数做统计\n    val wordandcountstreams = wordandonestreams.reducebykey(_ + _)\n\n    //7.打印\n    wordandcountstreams.print()\n\n    //8.启动sparkstreamingcontext\n    ssc.start()\n    ssc.awaittermination()\n  }\n}\n\n\n\n# 有状态数据统计updatestatebykey\n\npackage com.hrbu\n\nimport org.apache.kafka.clients.consumer.consumerrecord\nimport org.apache.kafka.common.serialization.stringdeserializer\nimport org.apache.spark.sql.sparksession\nimport org.apache.spark.streaming.dstream.{dstream, inputdstream}\nimport org.apache.spark.streaming.kafka010.{consumerstrategies, kafkautils, locationstrategies}\nimport org.apache.spark.streaming.{seconds, streamingcontext}\nimport org.apache.spark.{sparkconf, sparkcontext}\n\n/**\n * @title 有状态数据统计\n * 有状态转化操作  (updatestatebykey)  类似udaf的buffer???\n * 对之前的数据也有更新\n * 保存到文件(数据大  防止宕机)\n */\nobject datastreaming_02 {\n  def main(args: array[string]): unit = {\n    val config = map(\n      "spark.cores" -> "local[*]",\n      "kafka.topic" -> "datastreaming"\n    )\n\n    // 创建配置对象\n    val sparkconf: sparkconf = new sparkconf().setappname("datastreaming").setmaster(config("spark.cores"))\n    // 创建sparksession\n    val spark: sparksession = sparksession.builder().config(sparkconf).getorcreate()\n    // 创建sparkcontext\n    val sc: sparkcontext = spark.sparkcontext\n    // 创建spark streamingcontext\n    val ssc = new streamingcontext(sc, seconds(5))\n\n    // 保存数据状态 需要设置检查点路径\n    sc.setcheckpointdir("checkpoint")\n\n    // 创建到kafka的连接\n    val kafkapara = map(\n      "bootstrap.servers" -> "hadoop1:9092",\n      "key.deserializer" -> classof[stringdeserializer],\n      "value.deserializer" -> classof[stringdeserializer],\n      "group.id" -> "data",\n      "auto.offset.reset" -> "latest"\n    )\n\n    val kafkastream: inputdstream[consumerrecord[string, string]] = kafkautils.createdirectstream[string, string](\n      ssc,\n      locationstrategies.preferconsistent,\n      consumerstrategies.subscribe[string, string](array(config("kafka.topic")), kafkapara)\n    )\n\n    // 取到消息队列里的值\n    val valuedstream: dstream[string] = kafkastream.flatmap(t => t.value().split(" "))\n\n    val mapdstream: dstream[(string, int)] = valuedstream.map((_, 1))\n\n    // 将转换结构后的数据进行聚合处理\n    val statedstream: dstream[(string, int)] = mapdstream.updatestatebykey {\n      case (seq, buffer) => {\n        val sum: int = buffer.getorelse(0) + seq.sum\n        option(sum)\n      }\n    }\n\n    statedstream.print()\n\n    // 对读入的dstream进行分析\n\n\n    // 启动采集器\n    ssc.start()\n    // 等待采集器停止\n    ssc.awaittermination()\n  }\n}\n\n\n\n# window滑动\n\npackage com.hrbu\n\nimport org.apache.kafka.clients.consumer.consumerrecord\nimport org.apache.kafka.common.serialization.stringdeserializer\nimport org.apache.spark.sql.sparksession\nimport org.apache.spark.streaming.dstream.{dstream, inputdstream}\nimport org.apache.spark.streaming.kafka010.{consumerstrategies, kafkautils, locationstrategies}\nimport org.apache.spark.streaming.{seconds, streamingcontext}\nimport org.apache.spark.{sparkconf, sparkcontext}\n\n\nobject datastreaming03_window {\n  def main(args: array[string]): unit = {\n    testscala\n  }\n\n  def testscala(): unit ={\n    // scala语法\n    val ints = list(1, 2, 3, 4, 5, 6)\n    // 滑动窗口函数(窗口大小 步长)\n    val iter: iterator[list[int]] = ints.sliding(3, 3)\n\n    for( list <- iter){\n      println(list.mkstring(","))\n    }\n  }\n\n  // 随时间改变(随时间推移  少一部分  多一部分)\n  def sparkmain(){\n    val config = map(\n      "spark.cores" -> "local[*]",\n      "kafka.topic" -> "datastreaming"\n    )\n\n    // 创建配置对象\n    val sparkconf: sparkconf = new sparkconf().setappname("datastreaming").setmaster(config("spark.cores"))\n    // 创建sparksession\n    val spark: sparksession = sparksession.builder().config(sparkconf).getorcreate()\n    // 创建sparkcontext\n    val sc: sparkcontext = spark.sparkcontext\n    // 创建spark streamingcontext\n    val ssc = new streamingcontext(sc, seconds(3))\n\n    // 创建到kafka的连接\n    val kafkapara = map(\n      "bootstrap.servers" -> "hadoop1:9092",\n      "key.deserializer" -> classof[stringdeserializer],\n      "value.deserializer" -> classof[stringdeserializer],\n      "group.id" -> "data",\n      "auto.offset.reset" -> "latest"\n    )\n\n    val kafkastream: inputdstream[consumerrecord[string, string]] = kafkautils.createdirectstream[string, string](\n      ssc,\n      locationstrategies.preferconsistent,\n      consumerstrategies.subscribe[string, string](array(config("kafka.topic")), kafkapara)\n    )\n\n    // 窗口大小为采集周期的整数倍 窗口滑动步长也应该为采集周期的整数倍\n    val windowdstream: dstream[consumerrecord[string, string]] = kafkastream.window(seconds(9), seconds(3))\n\n    // 取到消息队列里的值\n    val valuedstream: dstream[string] = windowdstream.flatmap(t => t.value().split(" "))\n\n    val mapdstream: dstream[(string, int)] = valuedstream.map((_, 1))\n\n    // 数据聚合处理\n    val reducedstream: dstream[(string, int)] = mapdstream.reducebykey(_ + _)\n\n    reducedstream.print()\n\n    // 启动采集器\n    ssc.start()\n    // 等待采集器停止\n    ssc.awaittermination()\n  }\n}\n\n\n\n# 转换 transfrom\n\n\n\n\n# dstream.foreachrdd(dstream输出)\n\n一个dstream包含一个或多个rdd\n\n通用的输出操作foreachrdd()，它用来对dstream中的rdd运行任意计算。这和transform() 有些类似，都可以让我们访问任意rdd。在foreachrdd()中，可以重用我们在spark中实现的所有行动操作。 比如，常见的用例之一是把数据写到诸如mysql的外部数据库中。 注意： （1）连接不能写在driver层面； （2）如果写在foreach则每个rdd都创建，得不偿失； （3）增加foreachpartition，在分区创建。',charsets:{cjk:!0},lastUpdated:"2025/03/28, 17:04:32",lastUpdatedTimestamp:1743152672e3},{title:"Flink环境搭建",frontmatter:{title:"Flink环境搭建",date:"2022-02-28T08:55:04.000Z",permalink:"/pages/415096/",categories:["大数据","Flink"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/07.Flink/01.Flink%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html",relativePath:"02.大数据/07.Flink/01.Flink环境搭建.md",key:"v-e35d4030",path:"/pages/415096/",headers:[{level:2,title:"集群规划",slug:"集群规划",normalizedTitle:"集群规划",charIndex:2},{level:2,title:"一. standalone cluster HA",slug:"一-standalone-cluster-ha",normalizedTitle:"一. standalone cluster ha",charIndex:216},{level:3,title:"1. 安装",slug:"_1-安装",normalizedTitle:"1. 安装",charIndex:245},{level:3,title:"2.修改配置文件",slug:"_2-修改配置文件",normalizedTitle:"2.修改配置文件",charIndex:529},{level:3,title:"3. 启动服务",slug:"_3-启动服务",normalizedTitle:"3. 启动服务",charIndex:2509},{level:2,title:"二. flink on yarn(Yarn cluster HA )",slug:"二-flink-on-yarn-yarn-cluster-ha",normalizedTitle:"二. flink on yarn(yarn cluster ha )",charIndex:3052},{level:3,title:"0. yarn高可用？",slug:"_0-yarn高可用",normalizedTitle:"0. yarn高可用？",charIndex:3145},{level:3,title:"1. 修改配置文件",slug:"_1-修改配置文件",normalizedTitle:"1. 修改配置文件",charIndex:3161},{level:3,title:"2. 启动",slug:"_2-启动",normalizedTitle:"2. 启动",charIndex:3835},{level:3,title:"错误",slug:"错误",normalizedTitle:"错误",charIndex:4092}],headersStr:"集群规划 一. standalone cluster HA 1. 安装 2.修改配置文件 3. 启动服务 二. flink on yarn(Yarn cluster HA ) 0. yarn高可用？ 1. 修改配置文件 2. 启动 错误",content:"# 集群规划\n\n主机          ZOOKEEPER   JOBMANAGER   TASKMANAGER\nhadoop100               是            \nhadoop101   是           是            是\nhadoop102   是                        是\nhadoop103   是                        是\n\n\n# 一. standalone cluster HA\n\n\n# 1. 安装\n\n 1. 下载安装包 flink-1.9.2-bin-scala_2.12.tgz\n 2. 上传解压 tar -zxvf flink-1.9.2-bin-scala_2.12.tgz -C /soft/module/ 重命名 mv flink-1.9.2/ flink\n 3. 配置环境变量 sudo vim /etc/profile\n\n# flink环境变量\nexport FLINK_HOME=/soft/module/flink\nexport PATH=$PATH:$FLINK_HOME/bin\n\n\nsource /etc/profile\n\n\n# 2.修改配置文件\n\n 1. 修改zoo.cfg文件 vim conf/zoo.cfg 和Zookeeper配置相同\n\n# The port at which the clients will connect\nclientPort=2181\n#######################cluster##########################\nserver.1=hadoop101:2888:3888\nserver.2=hadoop102:2888:3888\nserver.3=hadoop103:2888:3888\n\n\n 2. 修改flink-conf.yaml文件(需要注意的是 配置:后要有空格) vim conf/flink-conf.yaml\n\n# jobmanager服务主机名,这条配置只在单机模式下有用 用于taskmanager寻找jobmanager 及后续通信\n# 集群模式下这条会被忽略,集群模式下flink会寻找conf/master中的主机配置\njobmanager.rpc.address: hadoop100\n#jobmanager rpc 端口号\njobmanager.rpc.port: 6123\n#jobmanager内存\njobmanager.heap.size: 1024m\n#jobmanager内存\ntaskmanager.heap.size: 1024m\n# taskmanager服务中插槽个数,其实就是子任务task的个数\ntaskmanager.numberOfTaskSlots: 1\n# The parallelism used for programs that did not specify and other parallelism.\n# 程序默认并行度\nparallelism.default: 1\n\n# 开启集群模式\nhigh-availability: zookeeper\n# 开启hdfs存储目录\nhigh-availability.storageDir: hdfs:///flink/ha/\n# 指定Zookeeper集群地址\nhigh-availability.zookeeper.quorum: hadoop101:2181,hadoop102:2181,hadoop103:2181\n\n# <class-name-of-factory>.\n# 启用检查点,存储于文件系统\nstate.backend: filesystem\n\n# Directory for checkpoints filesystem, when using any of the default bundled\n# state backends.\n# 检查点的文件存储位置,这里我们指定的事hdfs集群地址\n# 这里的检查点是指程序运行过程中的检查点,以便快速恢复程序运行或恢复到某个正确运行的时刻\nstate.checkpoints.dir: hdfs://mycluster:9000/flink-checkpoints\n# Default target directory for savepoints, optional.\n# 对应外部应用程序的检查点文件存储位置  记录数据的处理进度\n# 例如flink处理到30% 重启了 启动之后在30%的位置继续处理\nstate.savepoints.dir: hdfs://mycluster:9000/flink-checkpoints\n\n# full模式是一个任务失败了,结束所有任务,然后重启所有任务  简单粗暴但是龙一直造成内存溢出\n# region模式是查出具体出错的任务,然后单独重启这一任务\njobmanager.execution.failover-strategy: region\n\n\n 3. 修改masters和slaves文件 vim conf/masters\n\nhadoop100:8081\nhadoop101:8081\n\n\nvim conf/slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n 4. 最后，当前的flink版本是一个纯净的版本，如果需要依赖其他系统（例如咱们当前flink的相关数据都存储到了hdfs），则需要添加相应的jar包 官网有提供：https://flink.apache.org/downloads.html#additional-components mv /soft/software/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar /soft/module/flink/lib/\n 5. 分发文件并修改环境变量\n\n\n# 3. 启动服务\n\n启动之前我们要确保我们的zookeeper集群已启动，并且hdfs集群是启动状态\n\n * 直接使用start-cluster.sh脚本启动\n * jps查看进程\n * 访问flink的web UI hadoop100:8081\n\n----------------------------------------\n\n当前flink虽然使用了hdfs系统，但是其运行模式还是Stand alone，就是独立集群 独立集群在执行任务时所有的资源分配管理都是flink自己安排的 我们尝试使用独立集群运行一个测试计算 Flink可以读取系统文件，也可以读取hdfs文件 我们以本地系统文件为例 我们使用现有的WordCount.jar去统计README.txt文件的内容并输出 这个输出结果被输出到taskmanager机器，是随机的 所以我们最好还是使用hdfs系统\n\n * 测试 flink run ./examples/batch/WordCount.jar --input hdfs://mycluster/datas/wordcounttest.txt --output hdfs://mycluster/datas/wordcountresult.txt\n\n\n# 二. flink on yarn(Yarn cluster HA )\n\n在上面的基础上 参考链接: https://www.jianshu.com/p/8f1e650ebcad\n\n\n# 0. yarn高可用？\n\n\n# 1. 修改配置文件\n\n 1. 配置yarn-site.xml\n\n * 修改环境变量 vim /etc/profile 加上(用于flink寻找yarn的配置信息 ): export HADOOP_CONF_DIR=/soft/module/hadoop-2.9.2/etc/hadoop/ source /etc/profile\n * 修改文件: vim yarn-site.xml\n\n<property>\n    \x3c!--配置yarn最大重试次数--\x3e\n  <name>yarn.resourcemanager.am.max-attempts</name>\n  <value>4</value>\n</property>\n\n\n 2. 配置flink-conf.yaml\n\n# 配置Yarn重试次数\nyarn.application-attempts: 10\n\n## 配置Zookeeper\n high-availability: zookeeper\n high-availability.storageDir: hdfs:///flink/ha/\n high-availability.zookeeper.quorum: 10.108.4.203:2181,10.108.4.204:2181,10.108.4.205:2181\n high-availability.zookeeper.path.root: /flink\n high-availability.cluster-id: /cluster_yarn\n\n\n 3. 同步配置文件\n\n\n# 2. 启动\n\n 1. 启动Flink Yarn Session有2种模式：分离模式、客户端模式\n 2. 分离模式 通过-d指定分离模式，即客户端在启动Flink Yarn Session后，就不再属于Yarn Cluster的一部分。如果想要停止Flink Yarn Application，需要通过yarn application -kill 命令来停止 yarn-session.sh -n 3 -jm 1024 -tm 1024 -s 3 -nm FlinkOnYarnSession -d -st\n\n\n# 错误\n\n2020-04-15 16:19:28,433 ERROR org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - Error while running the Flink Yarn session.\norg.apache.flink.client.deployment.ClusterDeploymentException: Couldn't deploy Yarn session cluster\n        at org.apache.flink.yarn.AbstractYarnClusterDescriptor.deploySessionCluster(AbstractYarnClusterDescriptor.java:387)\n        at org.apache.flink.yarn.cli.FlinkYarnSessionCli.run(FlinkYarnSessionCli.java:616)\n        at org.apache.flink.yarn.cli.FlinkYarnSessionCli.lambda$main$3(FlinkYarnSessionCli.java:844)\n        at java.security.AccessController.doPrivileged(Native Method)\n        at javax.security.auth.Subject.doAs(Subject.java:422)\n        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1836)\n        at org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41)\n        at org.apache.flink.yarn.cli.FlinkYarnSessionCli.main(FlinkYarnSessionCli.java:844)\nCaused by: org.apache.flink.yarn.AbstractYarnClusterDescriptor$YarnDeploymentException: The YARN application unexpectedly switched to state FAILED during deployment. \n\n\n在yarn-site.xml加上\n\n    <property> \n        <name>yarn.nodemanager.vmem-check-enabled</name> \n        <value>false</value> \n    </property> \n",normalizedContent:"# 集群规划\n\n主机          zookeeper   jobmanager   taskmanager\nhadoop100               是            \nhadoop101   是           是            是\nhadoop102   是                        是\nhadoop103   是                        是\n\n\n# 一. standalone cluster ha\n\n\n# 1. 安装\n\n 1. 下载安装包 flink-1.9.2-bin-scala_2.12.tgz\n 2. 上传解压 tar -zxvf flink-1.9.2-bin-scala_2.12.tgz -c /soft/module/ 重命名 mv flink-1.9.2/ flink\n 3. 配置环境变量 sudo vim /etc/profile\n\n# flink环境变量\nexport flink_home=/soft/module/flink\nexport path=$path:$flink_home/bin\n\n\nsource /etc/profile\n\n\n# 2.修改配置文件\n\n 1. 修改zoo.cfg文件 vim conf/zoo.cfg 和zookeeper配置相同\n\n# the port at which the clients will connect\nclientport=2181\n#######################cluster##########################\nserver.1=hadoop101:2888:3888\nserver.2=hadoop102:2888:3888\nserver.3=hadoop103:2888:3888\n\n\n 2. 修改flink-conf.yaml文件(需要注意的是 配置:后要有空格) vim conf/flink-conf.yaml\n\n# jobmanager服务主机名,这条配置只在单机模式下有用 用于taskmanager寻找jobmanager 及后续通信\n# 集群模式下这条会被忽略,集群模式下flink会寻找conf/master中的主机配置\njobmanager.rpc.address: hadoop100\n#jobmanager rpc 端口号\njobmanager.rpc.port: 6123\n#jobmanager内存\njobmanager.heap.size: 1024m\n#jobmanager内存\ntaskmanager.heap.size: 1024m\n# taskmanager服务中插槽个数,其实就是子任务task的个数\ntaskmanager.numberoftaskslots: 1\n# the parallelism used for programs that did not specify and other parallelism.\n# 程序默认并行度\nparallelism.default: 1\n\n# 开启集群模式\nhigh-availability: zookeeper\n# 开启hdfs存储目录\nhigh-availability.storagedir: hdfs:///flink/ha/\n# 指定zookeeper集群地址\nhigh-availability.zookeeper.quorum: hadoop101:2181,hadoop102:2181,hadoop103:2181\n\n# <class-name-of-factory>.\n# 启用检查点,存储于文件系统\nstate.backend: filesystem\n\n# directory for checkpoints filesystem, when using any of the default bundled\n# state backends.\n# 检查点的文件存储位置,这里我们指定的事hdfs集群地址\n# 这里的检查点是指程序运行过程中的检查点,以便快速恢复程序运行或恢复到某个正确运行的时刻\nstate.checkpoints.dir: hdfs://mycluster:9000/flink-checkpoints\n# default target directory for savepoints, optional.\n# 对应外部应用程序的检查点文件存储位置  记录数据的处理进度\n# 例如flink处理到30% 重启了 启动之后在30%的位置继续处理\nstate.savepoints.dir: hdfs://mycluster:9000/flink-checkpoints\n\n# full模式是一个任务失败了,结束所有任务,然后重启所有任务  简单粗暴但是龙一直造成内存溢出\n# region模式是查出具体出错的任务,然后单独重启这一任务\njobmanager.execution.failover-strategy: region\n\n\n 3. 修改masters和slaves文件 vim conf/masters\n\nhadoop100:8081\nhadoop101:8081\n\n\nvim conf/slaves\n\nhadoop101\nhadoop102\nhadoop103\n\n\n 4. 最后，当前的flink版本是一个纯净的版本，如果需要依赖其他系统（例如咱们当前flink的相关数据都存储到了hdfs），则需要添加相应的jar包 官网有提供：https://flink.apache.org/downloads.html#additional-components mv /soft/software/flink-shaded-hadoop-2-uber-2.8.3-10.0.jar /soft/module/flink/lib/\n 5. 分发文件并修改环境变量\n\n\n# 3. 启动服务\n\n启动之前我们要确保我们的zookeeper集群已启动，并且hdfs集群是启动状态\n\n * 直接使用start-cluster.sh脚本启动\n * jps查看进程\n * 访问flink的web ui hadoop100:8081\n\n----------------------------------------\n\n当前flink虽然使用了hdfs系统，但是其运行模式还是stand alone，就是独立集群 独立集群在执行任务时所有的资源分配管理都是flink自己安排的 我们尝试使用独立集群运行一个测试计算 flink可以读取系统文件，也可以读取hdfs文件 我们以本地系统文件为例 我们使用现有的wordcount.jar去统计readme.txt文件的内容并输出 这个输出结果被输出到taskmanager机器，是随机的 所以我们最好还是使用hdfs系统\n\n * 测试 flink run ./examples/batch/wordcount.jar --input hdfs://mycluster/datas/wordcounttest.txt --output hdfs://mycluster/datas/wordcountresult.txt\n\n\n# 二. flink on yarn(yarn cluster ha )\n\n在上面的基础上 参考链接: https://www.jianshu.com/p/8f1e650ebcad\n\n\n# 0. yarn高可用？\n\n\n# 1. 修改配置文件\n\n 1. 配置yarn-site.xml\n\n * 修改环境变量 vim /etc/profile 加上(用于flink寻找yarn的配置信息 ): export hadoop_conf_dir=/soft/module/hadoop-2.9.2/etc/hadoop/ source /etc/profile\n * 修改文件: vim yarn-site.xml\n\n<property>\n    \x3c!--配置yarn最大重试次数--\x3e\n  <name>yarn.resourcemanager.am.max-attempts</name>\n  <value>4</value>\n</property>\n\n\n 2. 配置flink-conf.yaml\n\n# 配置yarn重试次数\nyarn.application-attempts: 10\n\n## 配置zookeeper\n high-availability: zookeeper\n high-availability.storagedir: hdfs:///flink/ha/\n high-availability.zookeeper.quorum: 10.108.4.203:2181,10.108.4.204:2181,10.108.4.205:2181\n high-availability.zookeeper.path.root: /flink\n high-availability.cluster-id: /cluster_yarn\n\n\n 3. 同步配置文件\n\n\n# 2. 启动\n\n 1. 启动flink yarn session有2种模式：分离模式、客户端模式\n 2. 分离模式 通过-d指定分离模式，即客户端在启动flink yarn session后，就不再属于yarn cluster的一部分。如果想要停止flink yarn application，需要通过yarn application -kill 命令来停止 yarn-session.sh -n 3 -jm 1024 -tm 1024 -s 3 -nm flinkonyarnsession -d -st\n\n\n# 错误\n\n2020-04-15 16:19:28,433 error org.apache.flink.yarn.cli.flinkyarnsessioncli                 - error while running the flink yarn session.\norg.apache.flink.client.deployment.clusterdeploymentexception: couldn't deploy yarn session cluster\n        at org.apache.flink.yarn.abstractyarnclusterdescriptor.deploysessioncluster(abstractyarnclusterdescriptor.java:387)\n        at org.apache.flink.yarn.cli.flinkyarnsessioncli.run(flinkyarnsessioncli.java:616)\n        at org.apache.flink.yarn.cli.flinkyarnsessioncli.lambda$main$3(flinkyarnsessioncli.java:844)\n        at java.security.accesscontroller.doprivileged(native method)\n        at javax.security.auth.subject.doas(subject.java:422)\n        at org.apache.hadoop.security.usergroupinformation.doas(usergroupinformation.java:1836)\n        at org.apache.flink.runtime.security.hadoopsecuritycontext.runsecured(hadoopsecuritycontext.java:41)\n        at org.apache.flink.yarn.cli.flinkyarnsessioncli.main(flinkyarnsessioncli.java:844)\ncaused by: org.apache.flink.yarn.abstractyarnclusterdescriptor$yarndeploymentexception: the yarn application unexpectedly switched to state failed during deployment. \n\n\n在yarn-site.xml加上\n\n    <property> \n        <name>yarn.nodemanager.vmem-check-enabled</name> \n        <value>false</value> \n    </property> \n",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Spark内核学习",frontmatter:{title:"Spark内核学习",date:"2022-03-10T20:22:35.000Z",permalink:"/pages/70f03f/",categories:["大数据","Spark"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/06.Spark/10.Spark%E5%86%85%E6%A0%B8%E5%AD%A6%E4%B9%A0.html",relativePath:"02.大数据/06.Spark/10.Spark内核学习.md",key:"v-0221b7b2",path:"/pages/70f03f/",headers:[{level:2,title:"1. Spark内核架构(运行流程) 20200525",slug:"_1-spark内核架构-运行流程-20200525",normalizedTitle:"1. spark内核架构(运行流程) 20200525",charIndex:2},{level:2,title:"2.宽依赖和窄依赖 20200226",slug:"_2-宽依赖和窄依赖-20200226",normalizedTitle:"2.宽依赖和窄依赖 20200226",charIndex:36},{level:2,title:"3.基于yarn两种提交模式深度剖析  20200527",slug:"_3-基于yarn两种提交模式深度剖析-20200527",normalizedTitle:"3.基于yarn两种提交模式深度剖析  20200527",charIndex:null},{level:2,title:"4.Spark Context原理",slug:"_4-spark-context原理",normalizedTitle:"4.spark context原理",charIndex:95}],headersStr:"1. Spark内核架构(运行流程) 20200525 2.宽依赖和窄依赖 20200226 3.基于yarn两种提交模式深度剖析  20200527 4.Spark Context原理",content:"# 1. Spark内核架构(运行流程) 20200525\n\n\n\n\n# 2.宽依赖和窄依赖 20200226\n\n\n\n\n# 3.基于yarn两种提交模式深度剖析 20200527\n\n\n\n\n# 4.Spark Context原理\n\n\n\n课程跟随 北风网视频 学习",normalizedContent:"# 1. spark内核架构(运行流程) 20200525\n\n\n\n\n# 2.宽依赖和窄依赖 20200226\n\n\n\n\n# 3.基于yarn两种提交模式深度剖析 20200527\n\n\n\n\n# 4.spark context原理\n\n\n\n课程跟随 北风网视频 学习",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Flink学习",frontmatter:{title:"Flink学习",date:"2022-02-28T08:55:04.000Z",permalink:"/pages/415097/",categories:["大数据","Flink"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/07.Flink/02.Flink%E5%AD%A6%E4%B9%A0.html",relativePath:"02.大数据/07.Flink/02.Flink学习.md",key:"v-356e286c",path:"/pages/415097/",headers:[{level:2,title:"学习",slug:"学习",normalizedTitle:"学习",charIndex:10},{level:3,title:"1. WordCount示例",slug:"_1-wordcount示例",normalizedTitle:"1. wordcount示例",charIndex:17},{level:3,title:"2. 验证Flink高可用",slug:"_2-验证flink高可用",normalizedTitle:"2. 验证flink高可用",charIndex:180},{level:3,title:"3. 高可用",slug:"_3-高可用",normalizedTitle:"3. 高可用",charIndex:401},{level:3,title:"4. flink on yarn",slug:"_4-flink-on-yarn",normalizedTitle:"4. flink on yarn",charIndex:702},{level:3,title:"5. Flink 的 Watermark(水位线  水印)(迟到数据的处理)",slug:"_5-flink-的-watermark-水位线-水印-迟到数据的处理",normalizedTitle:"5. flink 的 watermark(水位线  水印)(迟到数据的处理)",charIndex:null},{level:3,title:"代码学习",slug:"代码学习",normalizedTitle:"代码学习",charIndex:2111},{level:3,title:"demo案例",slug:"demo案例",normalizedTitle:"demo案例",charIndex:4195}],headersStr:"学习 1. WordCount示例 2. 验证Flink高可用 3. 高可用 4. flink on yarn 5. Flink 的 Watermark(水位线  水印)(迟到数据的处理) 代码学习 demo案例",content:'中文版官网\n\n\n# 学习\n\n\n# 1. WordCount示例\n\nflink run ./examples/batch/WordCount.jar --input hdfs://mycluster/datas/wordcounttest.txt --output hdfs://mycluster/datas/wordcountresult.txt\n\n\n\n# 2. 验证Flink高可用\n\n参考链接\n\n 1. 手动将JobManager / TaskManager实例添加到群集(单点启动)\n\njobmanager.sh start hadoop100\njobmanager.sh start cluster hadoop100\n\n\n 2. 在hadoop101上 kill -9 10155(StandaloneSessionClusterEntrypoint), 查看另一个节点是否可用。\n\n\n# 3. 高可用\n\n独立集群的JobManager的机制是，一个leader JobManager和多个standby JobManager，当leader JobManager崩溃后，多个standby JobManager选举后产生新的leader JobManager。\n\nleader JobManager和standby JobManager之间没有区别，任何JobManager都可以承担leader或standby角色。\n\n借助ZK的临时节点机制，Flink实现了Job Manager独立集群的高可用性。但是由于ZK是CP，并不保证每次可用性，实际使用中应当予以考虑。\n\n原文链接\n\n\n# 4. flink on yarn\n\n修改etc/hadoop/yarn-site.xml\n<property> \n    <name>yarn.nodemanager.vmem-check-enabled</name> \n    <value>false</value> \n</property>\n\n\nstop-cluster.sh 后再启动 flink on yarn (1. namenode死掉) yarn-session.sh -n 3 -jm 1024 -tm 1024 -s 3 -nm FlinkOnYarnSession -d -st\n\n\n# 5. Flink 的 Watermark(水位线 水印)(迟到数据的处理)\n\n\n 每隔3秒统计前3秒的元素个数，那么flink系统会事先在系统中划分好20（60/3）个window\n制定watermark的策略: 周期性提取watermark，默认时间为200ms，我们可以认为在1号数据被分配到window之后的200ms，flink系统就开始计算水位线了\n假设允许数据乱序的最大时间为10秒 数据开始流入flink系统\n1号数据  01:01:22---hello\n2号数据  01:01:35---flink\n在此之后 又来一条数据(迟到) 3号数据  01:01:23---later\n\n\n    第一条数据流入 01:01:22---hello\n这条数据的event time是01:01:22, 那么它将会被放置到[00:00:21-00:00:24)窗口内\n(100ms后)此时水位线(Watermark)为 12 (22-10)\nWatermark(12) &lt; WindowEndTime(24)  所以 不会触发该window的计算\n\n\n    第二条数据流入 01:01:35---flink\n这条数据的event time是01:01:35, 那么它会被放置在[00:00:33-00:00:36)窗口内\n(100ms后)此时水位线(Watermark)为 25 (35-10)\n由于Watermark(25) >= WindowEndTime(24), 所以 会触发水位线(25)之前window的计算, ([21, 24))\n计算后窗口直接销毁\n\n\n    第三条数据流入 01:01:23---later\n正常情况下数据应放到[00:00:21-00:00:24)窗口, 由于此窗口被销毁,所以数据被丢弃\n\n为保证数据完整性,修改 AllowedLateness 为2s  也就是窗口触发计算后2s再销毁\n(35-37流入)这条数据的event time是01:01:23, \n那么它将会被放置到[00:00:21-00:00:24)窗口(此窗口在37时会被销毁)内\n(100ms后)此时计算水位线: 23-10=13 &lt; Watermark=25, 所以水位线不变仍为25\n由于 Watermark(25) &lt; WindowEndTime(24) + AllowedLateness(2),\n所以 [00:00:21-00:00:24)窗口会再次(多次)触发\n\n此时, 窗口销毁时机 Watermark >= WindowEndTime + AllowedLateness            \n\n\n\n\n# 代码学习\n\nword count\n\npackage hrbu\n\nimport org.apache.flink.api.java.utils.ParameterTool\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.api.windowing.time.Time\n\nobject StreamingJob {\n  def main(args: Array[String]) {\n\n    //参数--host localhost --port 7777\n    val params = ParameterTool.fromArgs(args)\n    val host:String = params.get("host")\n    val port:Int = params.getInt("port")\n\n    // set up the streaming execution environment\n    //创建流处理的执行环境\n    val env = StreamExecutionEnvironment.getExecutionEnvironment\n\n    //接收socket数据流\n    val textDataSet = env.socketTextStream(host, port)\n\n    //逐一读取数据,搭散之后进行WordCount\n    val wordCountData = textDataSet\n      .flatMap(_.split("\\\\s"))\n      .filter(_.nonEmpty)\n      .map( (_,1) )\n      .keyBy(0)\n      //.timeWindow(Time.seconds(10))\n      .sum(1)\n\n    //打印输出\n    wordCountData.print()\n      .setParallelism(2)    //设置并行度 1\n    //wordCountData.writeAsText("datas\\\\flink_Stream_result").setParallelism(2)\n    //执行任务\n    env.execute("stream word count job")\n  }\n}\n\n\n消费kafka\n\npackage hrbu.StreamingJob\n\nimport java.util.Properties\n\nimport org.apache.flink.api.common.serialization.SimpleStringSchema\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer\n\nobject StreamingJob_Kafka {\n  def main(args: Array[String]): Unit = {\n    val env = StreamExecutionEnvironment.getExecutionEnvironment\n    // kafka读取数据\n    val properties = new Properties()\n    properties.setProperty("bootstrap.servers", "192.168.1.100:9092")\n    properties.setProperty("group.id", "consumer-group")\n    properties.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")\n    properties.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer")\n    properties.setProperty("auto.offset.reset", "latest")\n\n    val stream3 = env.addSource(new FlinkKafkaConsumer[String]("", new SimpleStringSchema(), properties))\n    stream3.print("stream3").setParallelism(1)\n\n    env.execute("source test")\n  }\n}\n\n\n\n# demo案例\n\n> 需求：在当今数字时代，信用卡欺诈行为越来越被重视。 罪犯可以通过诈骗或者入侵安全级别较低系统来盗窃信用卡卡号。 用盗得的信用卡进行很小额度的例如一美元或者更小额度的消费进行测试。 如果测试消费成功，那么他们就会用这个信用卡进行大笔消费，来购买一些他们希望得到的，或者可以倒卖的财物 为了方便编码，我们直接下载flink官网提供的项目模板，因为内置的walkthrough包只有最新的flink1.10版本才有，所以我们下载完项目后就不要再改动相关版本号了\n\nmvn archetype:generate \\\n    -DarchetypeGroupId=org.apache.flink \\\n    -DarchetypeArtifactId=flink-walkthrough-datastream-scala \\\n    -DarchetypeVersion=1.10.0 \\\n    -DgroupId=frauddetection \\\n    -DartifactId=frauddetection \\\n    -Dversion=0.1 \\\n    -Dpackage=spendreport \\\n    -DinteractiveMode=false\n\n\n下载完成后，将项目导入到IDEA FraudDetectionJob\n\npackage spendreport\n\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.walkthrough.common.sink.AlertSink\nimport org.apache.flink.walkthrough.common.entity.Alert\nimport org.apache.flink.walkthrough.common.entity.Transaction\nimport org.apache.flink.walkthrough.common.source.TransactionSource\n\n/**\n  * Skeleton code for the DataStream code walkthrough\n  */\nobject FraudDetectionJob {\n\n  @throws[Exception]\n  def main(args: Array[String]): Unit = {\n    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment\n    /**\n     * TransactionSource就是walkthrough包的交易数据生成类\n     * Transaction类结构非常简单，类似于: Transaction {accountId=2, timestamp=154627760000. amount=412.91]\n     */\n    val transactions: DataStream[Transaction] = env\n      .addSource(new TransactionSource)\n      .name("transactions")\n    /**\n     * 此处为了方便检测结果的输出，我们在最终结果DataStream中存放的是wa1kthrough的Alert类\n     * 该类很简单，主要为了输出欺诈账户的id\n     */\n    /**\n     * DataStrean的process方法支持传入一个继承KeyedProcessFunction的自定义类\n     * KeyedProcessFunction主要是解决同一个key对应集合数据的处理\n     * 内部实现的方法为processElement, 该方法能够保证在处理元素数据时，属于同一个key的元素被放置到同一个context (上下文)中\n     */\n    val alerts: DataStream[Alert] = transactions\n      .keyBy(transaction => transaction.getAccountId)\n      .process(new FraudDetector)\n      .name("fraud-detector")\n\n    alerts\n      .addSink(new AlertSink)\n      .name("send-alerts")\n    //上面的所有过程都设置了nne属性，没有实际业务意义，仅仅是方便我们查看日志，定位问题\n    env.execute("Fraud Detection")\n  }\n}\n\n\nFraudDetector\n\npackage spendreport\n\nimport org.apache.flink.api.common.state.{ValueState, ValueStateDescriptor}\nimport org.apache.flink.api.common.typeinfo.Types\nimport org.apache.flink.configuration.Configuration\nimport org.apache.flink.streaming.api.functions.KeyedProcessFunction\nimport org.apache.flink.util.Collector\nimport org.apache.flink.walkthrough.common.entity.Alert\nimport org.apache.flink.walkthrough.common.entity.Transaction\n\n/**\n  * Skeleton code for implementing a fraud detector.\n  */\n//该类的派生对象，我们可以理解为java中的静态代码块\nobject FraudDetector {\n  //以下常量在我们正式实现欺诈检测时会用到\n  //定义常量小型交易金额\n  val SMALL_AMOUNT: Double = 1.00\n  //定义常量大型交易金额\n  val LARGE_AMOUNT: Double = 500.00\n  //定义常量一分钟是多少毫秒\n  val ONE_MINUTE: Long     = 60 * 1000L\n}\n\n/**\n * KeyedProcessFunction需要指定3个对象类型，K I 0\n * 第一个参数key指的是被处理的key是什么类型，这里是账户id是一个长整型\n * 第二个参数是传入的被处理对象，这里是Transaction交易数据类\n * 第三个参数指的是输出数据类型，这里我们使用Alert类\n */\n@SerialVersionUID(1L)\nclass FraudDetector extends KeyedProcessFunction[Long, Transaction, Alert] {\n  /**\n   *  @ transient注解表示该属性不用被序列化，此处生命一个私有变量ValueState,并赋值默认值\n   *  此处顺便说明下ValueState\n   *  ValueState是一个包装类， 类似于Java标准库里边的AtomicReference 和Atomiclongo\n   *  它提供了三个用于交互的方法。update 用于更新状态，value 用于获取状态值，还有clear 用于清空状态。\n   *  如果一个key 还没有状态，例如当程序刚启动或者调用过Va lueState#clear方法时，ValueState#value 将会返回nullo\n   *  如果需要更新状态，需要调用Va lueState#update方法，直接更改ValueState#value 的返回值可能不会被系统识别。\n   *  容错处理将在Flink 后台自动管理，你可以像与常规变量那样与状态变量进行交互\n   */\n  @transient private var flagState:ValueState[java.lang.Boolean] = _\n  //新增一个时间状态\n  @transient private var timerState:ValueState[java.lang.Long] = _\n\n\n  /**\n   * 正如我们ppt中所讲，Va lueState在使用之前需要先调用open方法注册\n   * 我们先生成Va lueStateDescriptor实例\n   * 然后使用上下文对象获取ValueState对象\n   * 此处顺便说明下\n   */\n  @throws[Exception]\n  override def open(parameters: Configuration): Unit = {\n    val flagDescriptor = new ValueStateDescriptor("flag", Types.BOOLEAN)\n    flagState = getRuntimeContext.getState(flagDescriptor)\n    //注册时,一起将时间状态注册了\n    val timeDescriptor = new ValueStateDescriptor("time-state", Types.LONG)\n    timerState = getRuntimeContext.getState(timeDescriptor)\n  }\n  /**\n   * 处理对象为Transaction交易数据对象\n   * 上下文为KeyedProcessFunction的Context\n   * 显示报警的数据我们使用Collector收集\n   */\n  @throws[Exception]\n  def processElement(transaction: Transaction, context: KeyedProcessFunction[Long, Transaction, Alert]#Context, collector: Collector[Alert]): Unit = {\n    //先获取flagState的value值,第一次肯定是空\n    val lastTransactionWasSmall = flagState.value\n    //我们顺便打印下transaction数据， 方便观察\n    println("transaction=============" + transaction)\n\n    /**\n     * 首次处理element,肯定不进入此if，往后可能进入\n     * 基于第111行代码，如果不为nu1l其实lastTransactionWasSmall的值就是true\n     * 代表了上次的交易金额为小型交易\n     */\n    if(lastTransactionWasSmall != null) {\n      //如果上次是小型交易,并且此次是大型交易,就报警\n      if(transaction.getAmount > FraudDetector.LARGE_AMOUNT) {\n        val alert = new Alert\n        alert.setId(transaction.getAccountId)\n        collector.collect(alert)\n      }\n\n      /**\n       * 在检查之后，不论是什么状态，都需要被清空。\n       * 不管是当前交易触发了欺诈报警而造成模式的结束，还是当前交易没有触发报警而造成模式的中断，都需要重新开始新的模式检测\n       * 因为我们的需求规定小额紧跟大额才算欺诈，如果现在有3笔交易: 1:$0.5; 2:$505; 3:$605,那么第3笔就不应该被认定为欺诈\n       */\n      //flagState.clear()\n      clearUp(context)\n    }\n\n    /**\n     * 无论是否进入上面if,只要当前的交易金额小于我们预定的小型金额，那么flagState就应该被更新为true\n     * 否则什么都不做\n     */\n    if(transaction.getAmount < FraudDetector.SMALL_AMOUNT) {\n      flagState.update(true)\n\n      /**\n       * KeyedProcessFunction#processElement需要使用提供了定时器服务的Context 来调用。\n       * 定时器服务可以用于查询当前时间、注册定时器和删除定时器。\n       * 我们首先定义了一个1分钟后触发的定时器，时间到达后会调用onIimer方法\n       * 同时我们更新了timerState状态\n       */\n      val timer = context.timerService().currentProcessingTime() + FraudDetector.ONE_MINUTE\n      context.timerService().registerProcessingTimeTimer(timer)\n      timerState.update(timer)\n    }\n  }\n\n  /**\n   * 定时器回调: 1分钟之内如果没有小额+大额交易我们就重置已有小额交易的状态，防止检测到正常交易\n   */\n  override def onTimer(timestamp: Long, ctx: KeyedProcessFunction[Long, Transaction, Alert]#OnTimerContext, out: Collector[Alert]): Unit = {\n    timerState.clear()\n    flagState.clear()\n  }\n\n  /**\n   * 在成功捕获欺诈交易后我们同样需要清空所有状态与定时器\n   * 我们可以把这些逻辑封装到一个私有函数中，而不是直接调用flagState. clear()\n   */\n  private def clearUp(ctx: KeyedProcessFunction[Long, Transaction, Alert]#Context): Unit = {\n    val timer = timerState.value()\n    //删除定时器\n    ctx.timerService().deleteProcessingTimeTimer(timer)\n    //清空所有状态\n    timerState.clear()\n    flagState.clear()\n  }\n}\n',normalizedContent:'中文版官网\n\n\n# 学习\n\n\n# 1. wordcount示例\n\nflink run ./examples/batch/wordcount.jar --input hdfs://mycluster/datas/wordcounttest.txt --output hdfs://mycluster/datas/wordcountresult.txt\n\n\n\n# 2. 验证flink高可用\n\n参考链接\n\n 1. 手动将jobmanager / taskmanager实例添加到群集(单点启动)\n\njobmanager.sh start hadoop100\njobmanager.sh start cluster hadoop100\n\n\n 2. 在hadoop101上 kill -9 10155(standalonesessionclusterentrypoint), 查看另一个节点是否可用。\n\n\n# 3. 高可用\n\n独立集群的jobmanager的机制是，一个leader jobmanager和多个standby jobmanager，当leader jobmanager崩溃后，多个standby jobmanager选举后产生新的leader jobmanager。\n\nleader jobmanager和standby jobmanager之间没有区别，任何jobmanager都可以承担leader或standby角色。\n\n借助zk的临时节点机制，flink实现了job manager独立集群的高可用性。但是由于zk是cp，并不保证每次可用性，实际使用中应当予以考虑。\n\n原文链接\n\n\n# 4. flink on yarn\n\n修改etc/hadoop/yarn-site.xml\n<property> \n    <name>yarn.nodemanager.vmem-check-enabled</name> \n    <value>false</value> \n</property>\n\n\nstop-cluster.sh 后再启动 flink on yarn (1. namenode死掉) yarn-session.sh -n 3 -jm 1024 -tm 1024 -s 3 -nm flinkonyarnsession -d -st\n\n\n# 5. flink 的 watermark(水位线 水印)(迟到数据的处理)\n\n\n 每隔3秒统计前3秒的元素个数，那么flink系统会事先在系统中划分好20（60/3）个window\n制定watermark的策略: 周期性提取watermark，默认时间为200ms，我们可以认为在1号数据被分配到window之后的200ms，flink系统就开始计算水位线了\n假设允许数据乱序的最大时间为10秒 数据开始流入flink系统\n1号数据  01:01:22---hello\n2号数据  01:01:35---flink\n在此之后 又来一条数据(迟到) 3号数据  01:01:23---later\n\n\n    第一条数据流入 01:01:22---hello\n这条数据的event time是01:01:22, 那么它将会被放置到[00:00:21-00:00:24)窗口内\n(100ms后)此时水位线(watermark)为 12 (22-10)\nwatermark(12) &lt; windowendtime(24)  所以 不会触发该window的计算\n\n\n    第二条数据流入 01:01:35---flink\n这条数据的event time是01:01:35, 那么它会被放置在[00:00:33-00:00:36)窗口内\n(100ms后)此时水位线(watermark)为 25 (35-10)\n由于watermark(25) >= windowendtime(24), 所以 会触发水位线(25)之前window的计算, ([21, 24))\n计算后窗口直接销毁\n\n\n    第三条数据流入 01:01:23---later\n正常情况下数据应放到[00:00:21-00:00:24)窗口, 由于此窗口被销毁,所以数据被丢弃\n\n为保证数据完整性,修改 allowedlateness 为2s  也就是窗口触发计算后2s再销毁\n(35-37流入)这条数据的event time是01:01:23, \n那么它将会被放置到[00:00:21-00:00:24)窗口(此窗口在37时会被销毁)内\n(100ms后)此时计算水位线: 23-10=13 &lt; watermark=25, 所以水位线不变仍为25\n由于 watermark(25) &lt; windowendtime(24) + allowedlateness(2),\n所以 [00:00:21-00:00:24)窗口会再次(多次)触发\n\n此时, 窗口销毁时机 watermark >= windowendtime + allowedlateness            \n\n\n\n\n# 代码学习\n\nword count\n\npackage hrbu\n\nimport org.apache.flink.api.java.utils.parametertool\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.api.windowing.time.time\n\nobject streamingjob {\n  def main(args: array[string]) {\n\n    //参数--host localhost --port 7777\n    val params = parametertool.fromargs(args)\n    val host:string = params.get("host")\n    val port:int = params.getint("port")\n\n    // set up the streaming execution environment\n    //创建流处理的执行环境\n    val env = streamexecutionenvironment.getexecutionenvironment\n\n    //接收socket数据流\n    val textdataset = env.sockettextstream(host, port)\n\n    //逐一读取数据,搭散之后进行wordcount\n    val wordcountdata = textdataset\n      .flatmap(_.split("\\\\s"))\n      .filter(_.nonempty)\n      .map( (_,1) )\n      .keyby(0)\n      //.timewindow(time.seconds(10))\n      .sum(1)\n\n    //打印输出\n    wordcountdata.print()\n      .setparallelism(2)    //设置并行度 1\n    //wordcountdata.writeastext("datas\\\\flink_stream_result").setparallelism(2)\n    //执行任务\n    env.execute("stream word count job")\n  }\n}\n\n\n消费kafka\n\npackage hrbu.streamingjob\n\nimport java.util.properties\n\nimport org.apache.flink.api.common.serialization.simplestringschema\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.streaming.connectors.kafka.flinkkafkaconsumer\n\nobject streamingjob_kafka {\n  def main(args: array[string]): unit = {\n    val env = streamexecutionenvironment.getexecutionenvironment\n    // kafka读取数据\n    val properties = new properties()\n    properties.setproperty("bootstrap.servers", "192.168.1.100:9092")\n    properties.setproperty("group.id", "consumer-group")\n    properties.setproperty("key.deserializer", "org.apache.kafka.common.serialization.stringdeserializer")\n    properties.setproperty("value.deserializer", "org.apache.kafka.common.serialization.stringdeserializer")\n    properties.setproperty("auto.offset.reset", "latest")\n\n    val stream3 = env.addsource(new flinkkafkaconsumer[string]("", new simplestringschema(), properties))\n    stream3.print("stream3").setparallelism(1)\n\n    env.execute("source test")\n  }\n}\n\n\n\n# demo案例\n\n> 需求：在当今数字时代，信用卡欺诈行为越来越被重视。 罪犯可以通过诈骗或者入侵安全级别较低系统来盗窃信用卡卡号。 用盗得的信用卡进行很小额度的例如一美元或者更小额度的消费进行测试。 如果测试消费成功，那么他们就会用这个信用卡进行大笔消费，来购买一些他们希望得到的，或者可以倒卖的财物 为了方便编码，我们直接下载flink官网提供的项目模板，因为内置的walkthrough包只有最新的flink1.10版本才有，所以我们下载完项目后就不要再改动相关版本号了\n\nmvn archetype:generate \\\n    -darchetypegroupid=org.apache.flink \\\n    -darchetypeartifactid=flink-walkthrough-datastream-scala \\\n    -darchetypeversion=1.10.0 \\\n    -dgroupid=frauddetection \\\n    -dartifactid=frauddetection \\\n    -dversion=0.1 \\\n    -dpackage=spendreport \\\n    -dinteractivemode=false\n\n\n下载完成后，将项目导入到idea frauddetectionjob\n\npackage spendreport\n\nimport org.apache.flink.streaming.api.scala._\nimport org.apache.flink.walkthrough.common.sink.alertsink\nimport org.apache.flink.walkthrough.common.entity.alert\nimport org.apache.flink.walkthrough.common.entity.transaction\nimport org.apache.flink.walkthrough.common.source.transactionsource\n\n/**\n  * skeleton code for the datastream code walkthrough\n  */\nobject frauddetectionjob {\n\n  @throws[exception]\n  def main(args: array[string]): unit = {\n    val env: streamexecutionenvironment = streamexecutionenvironment.getexecutionenvironment\n    /**\n     * transactionsource就是walkthrough包的交易数据生成类\n     * transaction类结构非常简单，类似于: transaction {accountid=2, timestamp=154627760000. amount=412.91]\n     */\n    val transactions: datastream[transaction] = env\n      .addsource(new transactionsource)\n      .name("transactions")\n    /**\n     * 此处为了方便检测结果的输出，我们在最终结果datastream中存放的是wa1kthrough的alert类\n     * 该类很简单，主要为了输出欺诈账户的id\n     */\n    /**\n     * datastrean的process方法支持传入一个继承keyedprocessfunction的自定义类\n     * keyedprocessfunction主要是解决同一个key对应集合数据的处理\n     * 内部实现的方法为processelement, 该方法能够保证在处理元素数据时，属于同一个key的元素被放置到同一个context (上下文)中\n     */\n    val alerts: datastream[alert] = transactions\n      .keyby(transaction => transaction.getaccountid)\n      .process(new frauddetector)\n      .name("fraud-detector")\n\n    alerts\n      .addsink(new alertsink)\n      .name("send-alerts")\n    //上面的所有过程都设置了nne属性，没有实际业务意义，仅仅是方便我们查看日志，定位问题\n    env.execute("fraud detection")\n  }\n}\n\n\nfrauddetector\n\npackage spendreport\n\nimport org.apache.flink.api.common.state.{valuestate, valuestatedescriptor}\nimport org.apache.flink.api.common.typeinfo.types\nimport org.apache.flink.configuration.configuration\nimport org.apache.flink.streaming.api.functions.keyedprocessfunction\nimport org.apache.flink.util.collector\nimport org.apache.flink.walkthrough.common.entity.alert\nimport org.apache.flink.walkthrough.common.entity.transaction\n\n/**\n  * skeleton code for implementing a fraud detector.\n  */\n//该类的派生对象，我们可以理解为java中的静态代码块\nobject frauddetector {\n  //以下常量在我们正式实现欺诈检测时会用到\n  //定义常量小型交易金额\n  val small_amount: double = 1.00\n  //定义常量大型交易金额\n  val large_amount: double = 500.00\n  //定义常量一分钟是多少毫秒\n  val one_minute: long     = 60 * 1000l\n}\n\n/**\n * keyedprocessfunction需要指定3个对象类型，k i 0\n * 第一个参数key指的是被处理的key是什么类型，这里是账户id是一个长整型\n * 第二个参数是传入的被处理对象，这里是transaction交易数据类\n * 第三个参数指的是输出数据类型，这里我们使用alert类\n */\n@serialversionuid(1l)\nclass frauddetector extends keyedprocessfunction[long, transaction, alert] {\n  /**\n   *  @ transient注解表示该属性不用被序列化，此处生命一个私有变量valuestate,并赋值默认值\n   *  此处顺便说明下valuestate\n   *  valuestate是一个包装类， 类似于java标准库里边的atomicreference 和atomiclongo\n   *  它提供了三个用于交互的方法。update 用于更新状态，value 用于获取状态值，还有clear 用于清空状态。\n   *  如果一个key 还没有状态，例如当程序刚启动或者调用过va luestate#clear方法时，valuestate#value 将会返回nullo\n   *  如果需要更新状态，需要调用va luestate#update方法，直接更改valuestate#value 的返回值可能不会被系统识别。\n   *  容错处理将在flink 后台自动管理，你可以像与常规变量那样与状态变量进行交互\n   */\n  @transient private var flagstate:valuestate[java.lang.boolean] = _\n  //新增一个时间状态\n  @transient private var timerstate:valuestate[java.lang.long] = _\n\n\n  /**\n   * 正如我们ppt中所讲，va luestate在使用之前需要先调用open方法注册\n   * 我们先生成va luestatedescriptor实例\n   * 然后使用上下文对象获取valuestate对象\n   * 此处顺便说明下\n   */\n  @throws[exception]\n  override def open(parameters: configuration): unit = {\n    val flagdescriptor = new valuestatedescriptor("flag", types.boolean)\n    flagstate = getruntimecontext.getstate(flagdescriptor)\n    //注册时,一起将时间状态注册了\n    val timedescriptor = new valuestatedescriptor("time-state", types.long)\n    timerstate = getruntimecontext.getstate(timedescriptor)\n  }\n  /**\n   * 处理对象为transaction交易数据对象\n   * 上下文为keyedprocessfunction的context\n   * 显示报警的数据我们使用collector收集\n   */\n  @throws[exception]\n  def processelement(transaction: transaction, context: keyedprocessfunction[long, transaction, alert]#context, collector: collector[alert]): unit = {\n    //先获取flagstate的value值,第一次肯定是空\n    val lasttransactionwassmall = flagstate.value\n    //我们顺便打印下transaction数据， 方便观察\n    println("transaction=============" + transaction)\n\n    /**\n     * 首次处理element,肯定不进入此if，往后可能进入\n     * 基于第111行代码，如果不为nu1l其实lasttransactionwassmall的值就是true\n     * 代表了上次的交易金额为小型交易\n     */\n    if(lasttransactionwassmall != null) {\n      //如果上次是小型交易,并且此次是大型交易,就报警\n      if(transaction.getamount > frauddetector.large_amount) {\n        val alert = new alert\n        alert.setid(transaction.getaccountid)\n        collector.collect(alert)\n      }\n\n      /**\n       * 在检查之后，不论是什么状态，都需要被清空。\n       * 不管是当前交易触发了欺诈报警而造成模式的结束，还是当前交易没有触发报警而造成模式的中断，都需要重新开始新的模式检测\n       * 因为我们的需求规定小额紧跟大额才算欺诈，如果现在有3笔交易: 1:$0.5; 2:$505; 3:$605,那么第3笔就不应该被认定为欺诈\n       */\n      //flagstate.clear()\n      clearup(context)\n    }\n\n    /**\n     * 无论是否进入上面if,只要当前的交易金额小于我们预定的小型金额，那么flagstate就应该被更新为true\n     * 否则什么都不做\n     */\n    if(transaction.getamount < frauddetector.small_amount) {\n      flagstate.update(true)\n\n      /**\n       * keyedprocessfunction#processelement需要使用提供了定时器服务的context 来调用。\n       * 定时器服务可以用于查询当前时间、注册定时器和删除定时器。\n       * 我们首先定义了一个1分钟后触发的定时器，时间到达后会调用oniimer方法\n       * 同时我们更新了timerstate状态\n       */\n      val timer = context.timerservice().currentprocessingtime() + frauddetector.one_minute\n      context.timerservice().registerprocessingtimetimer(timer)\n      timerstate.update(timer)\n    }\n  }\n\n  /**\n   * 定时器回调: 1分钟之内如果没有小额+大额交易我们就重置已有小额交易的状态，防止检测到正常交易\n   */\n  override def ontimer(timestamp: long, ctx: keyedprocessfunction[long, transaction, alert]#ontimercontext, out: collector[alert]): unit = {\n    timerstate.clear()\n    flagstate.clear()\n  }\n\n  /**\n   * 在成功捕获欺诈交易后我们同样需要清空所有状态与定时器\n   * 我们可以把这些逻辑封装到一个私有函数中，而不是直接调用flagstate. clear()\n   */\n  private def clearup(ctx: keyedprocessfunction[long, transaction, alert]#context): unit = {\n    val timer = timerstate.value()\n    //删除定时器\n    ctx.timerservice().deleteprocessingtimetimer(timer)\n    //清空所有状态\n    timerstate.clear()\n    flagstate.clear()\n  }\n}\n',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Flume安装配置",frontmatter:{title:"Flume安装配置",date:"2022-03-02T20:43:23.000Z",permalink:"/pages/e4166e/",categories:["大数据","Flume"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/10.Flume/01.Flume%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html",relativePath:"02.大数据/10.Flume/01.Flume安装配置.md",key:"v-e9baf2c8",path:"/pages/e4166e/",headers:[{level:3,title:"一. 安装(flume-ng)",slug:"一-安装-flume-ng",normalizedTitle:"一. 安装(flume-ng)",charIndex:2},{level:3,title:"安装 netcat 工具",slug:"安装-netcat-工具",normalizedTitle:"安装 netcat 工具",charIndex:277},{level:3,title:"二. 修改配置文件",slug:"二-修改配置文件",normalizedTitle:"二. 修改配置文件",charIndex:371},{level:3,title:"三. 数据采集",slug:"三-数据采集",normalizedTitle:"三. 数据采集",charIndex:2374},{level:3,title:"四. 数据导入到hbase中",slug:"四-数据导入到hbase中",normalizedTitle:"四. 数据导入到hbase中",charIndex:2598},{level:3,title:"五. 数据导入到hive中",slug:"五-数据导入到hive中",normalizedTitle:"五. 数据导入到hive中",charIndex:3409}],headersStr:"一. 安装(flume-ng) 安装 netcat 工具 二. 修改配置文件 三. 数据采集 四. 数据导入到hbase中 五. 数据导入到hive中",content:"# 一. 安装(flume-ng)\n\n 1. 下载安装包 apache-flume-1.9.0-bin.tar.gz\n 2. 上传 解压安装 tar -zxvf apache-flume-1.9.0-bin.tar.gz\n 3. 重命名 mv apache-flume-1.9.0-bin/ flume\n 4. 配置环境变量 vim ~/.bashrc\n\n# flume环境变量\nexport FLUME_HOME=/soft/flume\nexport PATH=$PATH:$FLUME_HOME/bin\n\n\nsource ~/.bashrc\n\n\n# 安装 netcat 工具\n\n安装:sudo yum install -y nc 判断 44444 端口是否被占用 sudo netstat -tunlp | grep 44444\n\n\n# 二. 修改配置文件\n\n 1. flume-env.sh文件配置\n\n * 到${FLUME_HOME}/conf下，复制一份flume-env.sh文件 cp flume-env.sh.template flume-env.sh\n * 编辑vim flume-env.sh\n\nexport JAVA_HOME=/soft/jdk1.8.0_161\n\n\n * 测试下flume是否能够正常运行 flume-ng version\n\n 2. Flume服务启动\n\n * 创建文件夹 mkdir logstodfs\n * 我们在conf文件夹下，创建一个vim flume_hdfs.conf 添加内容\n\n#source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#先配置单通道，定义source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#agent1 是该agent的名字，在启动的时候需要指定agent的名字\nagent1.sources=source1\nagent1.channels=channel1\nagent1.sinks=sink1\n\n##############配置source###################\n#source的类型\nagent1.sources.source1.type=spooldir\n#spooldir类型的source监控的目录\nagent1.sources.source1.spoolDir=/soft/flume/logstodfs\nagent1.sources.source1.fileHeader=false\nagent1.sources.source1.channels=channel1\nagent1.sources.source1.interceptors=i1\nagent1.sources.source1.interceptors.i1.type=timestamp\n#0.0.0.0表示本机\n#agent1.sources.source1.bind=0.0.0.0\n#使用的端口\n#agent1.sources.source1.port=44445\n#指定channel类型\nagent1.channels.channel1.type=file\n#file channle checkpoint文件的路径\nagent1.channels.channel1.checkpointDir=/soft/flume/tmp/point\n# file channel data文件的路径\nagent1.channels.channel1.dataDirs=/soft/flume/tmp\n\n#指定sink类型\nagent1.sinks.sink1.type=hdfs\nagent1.sinks.sink1.hdfs.path=hdfs://hadoop1:9000/flume\nagent1.sinks.sink1.hdfs.fileType=DataStream\nagent1.sinks.sink1.hdfs.writeFormat=TEXT\n#多久生成新的文件\nagent1.sinks.sink1.hdfs.rollInterval=5\nagent1.sinks.sink1.hdfs.rollSize=1000\nagent1.sinks.sink1.hdfs.rollCount=0\nagent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d\nagent1.sinks.sink1.hdfs.fileSuffix=.txt\n\nagent1.sinks.sink1.channel = channel1\n\n\n * 启动服务 flume-ng agent -c /soft/flume/conf -f /soft/flume/conf/flume_hdfs.conf -n agent1 -Dflume.root.logger=INFO,console 同\n\nflume-ng agent -c $FLUME_HOME/conf/\n -f  $FLUME_HOME/conf/flume_hdfs.conf \n-n agent1\n-Dflume.root.logger=INFO,console\n\n\n其中flume-ng agent为固定写法 -c指定flume-env.sh文件所在目录 -f指定flume-hdfs.conf文件所在位置 -n指定要启动的agent名称，我们在配置文件中配置的名称为agent1 -Dflume.root.logger代表日志打印到控制台 当然我们也可以使用nohup命令后台挂起程序\n\n\n# 三. 数据采集\n\n * 打开另一个终端\n * 将某个文件（实验阶段建议不要太大）移动或复制到${FLUME_HOME}/logstohdfs目录下，那么flume就会自动读取该文件的数据并上传到hdfs cp /soft/datas/short-student-utf8_classNO1.txt /soft/flume/logstodfs/\n * 查看第一个终端窗口(显示信息)\n * 最后我们可以去hdfs系统查看我们采集到的数据文件\n\n\n# 四. 数据导入到hbase中\n\n * 把jar包复制替换到/opt/flume/lib目录下面\n\n/soft/hive/lib\nhbase-protocol-1.1.1.jar\nhbase-client-1.1.1.jar\nhbase-common-1.1.1.jar \nhbase-server-1.1.1.jar\nhbase-hadoop2-compat-1.1.1.jar \nhbase-hadoop-compat-1.1.1.jar\nhtrace-core-3.1.0-incubating.jar\n\n\n命令: cp /soft/hive/lib/{hbase-protocol-1.1.1.jar,hbase-client-1.1.1.jar,hbase-common-1.1.1.jar,hbase-server-1.1.1.jar,hbase-hadoop2-compat-1.1.1.jar,hbase-hadoop-compat-1.1.1.jar,htrace-core-3.1.0-incubating.jar} /soft/flume/lib\n\n * 启动hbase,创建表 hbase shell 创建表 create \"flume_hbase\",\"info\"\n * 写配置文件 flume_hbase.conf\n * 启动服务 flume-ng agent --conf-file /soft/flume/conf/flume-hbase.conf -n agent2 -Dflume.root.logger=INFO,console\n * 生成数据: echo \"hello flume\">>/soft/flume/tmp/datas/flume_hbase.txt echo \"hello hbase\">>/soft/flume/tmp/datas/flume_hbase.txt\n\n\n# 五. 数据导入到hive中\n\n 1. 写配置文件 flume_hive.conf\n 2. Flume 端服务器 hosts 配置文件修改(不整可否???)\n\nvim /etc/hosts\n\n# myCluster 是你的集群名称，hdfs://myCluster/hellowold 通常用于 HDFS NameNode HA 模式下会用到这个地址\n192.168.1.1 node1.hadoop.com myCluster\n192.168.1.2 ndoe2.hadoop.com myCluster\n192.168.1.3 node3.hadoop.com\n\n\n 3. Hive 建表\n\n * 需要开启的策略 - ORC 格式存储 - 分桶 - 支持事务性 - 显式声明 transtions(也可以修改配置文件hive-site.xml) 实测建表的时候不需要分桶。分桶会将文件分散,一个桶编号一个文件。日志收集写到 Hive 中就是为了实现数据聚合，解决小文件问题。\n\n-- 是否支持并发\nSET hive.support.concurrency = true;\n-- 分桶是否被强制执行\nSET hive.enforce.bucketing = true;\n-- 非严格模式\nSET hive.exec.dynamic.partition.mode = nonstrict;\nSET hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;\n-- 是否开启事务性\nSET hive.compactor.initiator.on = true;\n\n-- 工作线程\nSET hive.compactor.worker.threads = 1;\n\n-- 建表\nCREATE TABLE <MY_HIVE_DB>.<MY_HIVE_TABLE>(\n  name string comment '姓名'\n  age string comment '年龄'\n  role string comment '角色'\n)\n-- 表明备注 \nCOMMENT '你好,中国'\n-- 创建分区\nPARTITIONED BY (\n    country STRING comment '国家',\n    month STRING comment '月份'\n)\n-- ORC 支持\nSTORED AS ORC TBLPROPERTIES ('transactional'='true');\n\nCREATE TABLE flume_hive.flume_hive(name string comment '姓名',age string comment '年龄',role string comment '角色')\nCOMMENT '你好,中国'\nPARTITIONED BY (country STRING comment '国家',month STRING comment '月份')\nSTORED AS ORC;\n\n\n 4. HDFS 目录权限修改 hadoop fs -chmod 777 -R /usr(未测试)\n 5. Flume 写 Hive 依赖包(一说/soft/hive/hcatalog/share/hcatalog/下所有包)\n\ncalcite-core-1.16.0.3.0.0.0-1634.jar\nlibfb303-0.9.3.jar\nhive-hcatalog-core-3.1.0.3.0.0.0-1634.jar\nhadoop-mapreduce-client-core-3.1.0.3.0.0.0-1634.jar\nhive-exec-3.1.0.3.0.0.0-1634.jar\nhive-standalone-metastore-3.1.0.3.0.0.0-1634.jar\nhive-hcatalog-streaming-3.1.0.3.0.0.0-1634.jar\n\n\n 6. 启动 Flume 服务 flume-ng agent -c conf/ -f /soft/flume/conf/flume_hive.conf -n agent3 -Dflume.root.logger=INFO,console\n 7. 趁热打铁：记录自己查错的思考方向\n\n * 输入文件格式必须为csv 或json\n * 输出格式必须为orc格式\n * 看日志文件(呃 暂时没找到)\n * 修改hive-site配置文件(永久参数)\n * 建表时必须分桶 分区 orc (挖坑记得加上)\n * flume配置文件sink的配置(端口号9083 必须有分区(partation)？) 最好参考官方文档\n * channel配置(连接 内存) source监控文件夹\n * MySQL下hive元数据(metastore)插入值 然后 commit;？\n * 启动时hive (hive --service metastore -p 9083) hive --service hiveserver2\n * hive命令行设置临时参数",normalizedContent:"# 一. 安装(flume-ng)\n\n 1. 下载安装包 apache-flume-1.9.0-bin.tar.gz\n 2. 上传 解压安装 tar -zxvf apache-flume-1.9.0-bin.tar.gz\n 3. 重命名 mv apache-flume-1.9.0-bin/ flume\n 4. 配置环境变量 vim ~/.bashrc\n\n# flume环境变量\nexport flume_home=/soft/flume\nexport path=$path:$flume_home/bin\n\n\nsource ~/.bashrc\n\n\n# 安装 netcat 工具\n\n安装:sudo yum install -y nc 判断 44444 端口是否被占用 sudo netstat -tunlp | grep 44444\n\n\n# 二. 修改配置文件\n\n 1. flume-env.sh文件配置\n\n * 到${flume_home}/conf下，复制一份flume-env.sh文件 cp flume-env.sh.template flume-env.sh\n * 编辑vim flume-env.sh\n\nexport java_home=/soft/jdk1.8.0_161\n\n\n * 测试下flume是否能够正常运行 flume-ng version\n\n 2. flume服务启动\n\n * 创建文件夹 mkdir logstodfs\n * 我们在conf文件夹下，创建一个vim flume_hdfs.conf 添加内容\n\n#source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#先配置单通道，定义source,channel,sink，它们分别都可以配置多份，比如n个channel和n个sink\n#agent1 是该agent的名字，在启动的时候需要指定agent的名字\nagent1.sources=source1\nagent1.channels=channel1\nagent1.sinks=sink1\n\n##############配置source###################\n#source的类型\nagent1.sources.source1.type=spooldir\n#spooldir类型的source监控的目录\nagent1.sources.source1.spooldir=/soft/flume/logstodfs\nagent1.sources.source1.fileheader=false\nagent1.sources.source1.channels=channel1\nagent1.sources.source1.interceptors=i1\nagent1.sources.source1.interceptors.i1.type=timestamp\n#0.0.0.0表示本机\n#agent1.sources.source1.bind=0.0.0.0\n#使用的端口\n#agent1.sources.source1.port=44445\n#指定channel类型\nagent1.channels.channel1.type=file\n#file channle checkpoint文件的路径\nagent1.channels.channel1.checkpointdir=/soft/flume/tmp/point\n# file channel data文件的路径\nagent1.channels.channel1.datadirs=/soft/flume/tmp\n\n#指定sink类型\nagent1.sinks.sink1.type=hdfs\nagent1.sinks.sink1.hdfs.path=hdfs://hadoop1:9000/flume\nagent1.sinks.sink1.hdfs.filetype=datastream\nagent1.sinks.sink1.hdfs.writeformat=text\n#多久生成新的文件\nagent1.sinks.sink1.hdfs.rollinterval=5\nagent1.sinks.sink1.hdfs.rollsize=1000\nagent1.sinks.sink1.hdfs.rollcount=0\nagent1.sinks.sink1.hdfs.fileprefix=%y-%m-%d\nagent1.sinks.sink1.hdfs.filesuffix=.txt\n\nagent1.sinks.sink1.channel = channel1\n\n\n * 启动服务 flume-ng agent -c /soft/flume/conf -f /soft/flume/conf/flume_hdfs.conf -n agent1 -dflume.root.logger=info,console 同\n\nflume-ng agent -c $flume_home/conf/\n -f  $flume_home/conf/flume_hdfs.conf \n-n agent1\n-dflume.root.logger=info,console\n\n\n其中flume-ng agent为固定写法 -c指定flume-env.sh文件所在目录 -f指定flume-hdfs.conf文件所在位置 -n指定要启动的agent名称，我们在配置文件中配置的名称为agent1 -dflume.root.logger代表日志打印到控制台 当然我们也可以使用nohup命令后台挂起程序\n\n\n# 三. 数据采集\n\n * 打开另一个终端\n * 将某个文件（实验阶段建议不要太大）移动或复制到${flume_home}/logstohdfs目录下，那么flume就会自动读取该文件的数据并上传到hdfs cp /soft/datas/short-student-utf8_classno1.txt /soft/flume/logstodfs/\n * 查看第一个终端窗口(显示信息)\n * 最后我们可以去hdfs系统查看我们采集到的数据文件\n\n\n# 四. 数据导入到hbase中\n\n * 把jar包复制替换到/opt/flume/lib目录下面\n\n/soft/hive/lib\nhbase-protocol-1.1.1.jar\nhbase-client-1.1.1.jar\nhbase-common-1.1.1.jar \nhbase-server-1.1.1.jar\nhbase-hadoop2-compat-1.1.1.jar \nhbase-hadoop-compat-1.1.1.jar\nhtrace-core-3.1.0-incubating.jar\n\n\n命令: cp /soft/hive/lib/{hbase-protocol-1.1.1.jar,hbase-client-1.1.1.jar,hbase-common-1.1.1.jar,hbase-server-1.1.1.jar,hbase-hadoop2-compat-1.1.1.jar,hbase-hadoop-compat-1.1.1.jar,htrace-core-3.1.0-incubating.jar} /soft/flume/lib\n\n * 启动hbase,创建表 hbase shell 创建表 create \"flume_hbase\",\"info\"\n * 写配置文件 flume_hbase.conf\n * 启动服务 flume-ng agent --conf-file /soft/flume/conf/flume-hbase.conf -n agent2 -dflume.root.logger=info,console\n * 生成数据: echo \"hello flume\">>/soft/flume/tmp/datas/flume_hbase.txt echo \"hello hbase\">>/soft/flume/tmp/datas/flume_hbase.txt\n\n\n# 五. 数据导入到hive中\n\n 1. 写配置文件 flume_hive.conf\n 2. flume 端服务器 hosts 配置文件修改(不整可否???)\n\nvim /etc/hosts\n\n# mycluster 是你的集群名称，hdfs://mycluster/hellowold 通常用于 hdfs namenode ha 模式下会用到这个地址\n192.168.1.1 node1.hadoop.com mycluster\n192.168.1.2 ndoe2.hadoop.com mycluster\n192.168.1.3 node3.hadoop.com\n\n\n 3. hive 建表\n\n * 需要开启的策略 - orc 格式存储 - 分桶 - 支持事务性 - 显式声明 transtions(也可以修改配置文件hive-site.xml) 实测建表的时候不需要分桶。分桶会将文件分散,一个桶编号一个文件。日志收集写到 hive 中就是为了实现数据聚合，解决小文件问题。\n\n-- 是否支持并发\nset hive.support.concurrency = true;\n-- 分桶是否被强制执行\nset hive.enforce.bucketing = true;\n-- 非严格模式\nset hive.exec.dynamic.partition.mode = nonstrict;\nset hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.dbtxnmanager;\n-- 是否开启事务性\nset hive.compactor.initiator.on = true;\n\n-- 工作线程\nset hive.compactor.worker.threads = 1;\n\n-- 建表\ncreate table <my_hive_db>.<my_hive_table>(\n  name string comment '姓名'\n  age string comment '年龄'\n  role string comment '角色'\n)\n-- 表明备注 \ncomment '你好,中国'\n-- 创建分区\npartitioned by (\n    country string comment '国家',\n    month string comment '月份'\n)\n-- orc 支持\nstored as orc tblproperties ('transactional'='true');\n\ncreate table flume_hive.flume_hive(name string comment '姓名',age string comment '年龄',role string comment '角色')\ncomment '你好,中国'\npartitioned by (country string comment '国家',month string comment '月份')\nstored as orc;\n\n\n 4. hdfs 目录权限修改 hadoop fs -chmod 777 -r /usr(未测试)\n 5. flume 写 hive 依赖包(一说/soft/hive/hcatalog/share/hcatalog/下所有包)\n\ncalcite-core-1.16.0.3.0.0.0-1634.jar\nlibfb303-0.9.3.jar\nhive-hcatalog-core-3.1.0.3.0.0.0-1634.jar\nhadoop-mapreduce-client-core-3.1.0.3.0.0.0-1634.jar\nhive-exec-3.1.0.3.0.0.0-1634.jar\nhive-standalone-metastore-3.1.0.3.0.0.0-1634.jar\nhive-hcatalog-streaming-3.1.0.3.0.0.0-1634.jar\n\n\n 6. 启动 flume 服务 flume-ng agent -c conf/ -f /soft/flume/conf/flume_hive.conf -n agent3 -dflume.root.logger=info,console\n 7. 趁热打铁：记录自己查错的思考方向\n\n * 输入文件格式必须为csv 或json\n * 输出格式必须为orc格式\n * 看日志文件(呃 暂时没找到)\n * 修改hive-site配置文件(永久参数)\n * 建表时必须分桶 分区 orc (挖坑记得加上)\n * flume配置文件sink的配置(端口号9083 必须有分区(partation)？) 最好参考官方文档\n * channel配置(连接 内存) source监控文件夹\n * mysql下hive元数据(metastore)插入值 然后 commit;？\n * 启动时hive (hive --service metastore -p 9083) hive --service hiveserver2\n * hive命令行设置临时参数",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Flume高可用集群安装",frontmatter:{title:"Flume高可用集群安装",date:"2022-03-02T20:44:13.000Z",permalink:"/pages/0376ec/",categories:["大数据","Flume"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/10.Flume/02.Flume%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85.html",relativePath:"02.大数据/10.Flume/02.Flume高可用集群安装.md",key:"v-db83fd4c",path:"/pages/0376ec/",headers:[{level:3,title:"1. agent配置",slug:"_1-agent配置",normalizedTitle:"1. agent配置",charIndex:271},{level:3,title:"2. collector配置",slug:"_2-collector配置",normalizedTitle:"2. collector配置",charIndex:1613},{level:3,title:"3. 先启动所有server，再启动所有client，否则会报错。",slug:"_3-先启动所有server-再启动所有client-否则会报错。",normalizedTitle:"3. 先启动所有server，再启动所有client，否则会报错。",charIndex:2923},{level:3,title:"4. 测试高可用功能",slug:"_4-测试高可用功能",normalizedTitle:"4. 测试高可用功能",charIndex:3614},{level:3,title:"错误: 配置文件没写对",slug:"错误-配置文件没写对",normalizedTitle:"错误: 配置文件没写对",charIndex:3822}],headersStr:"1. agent配置 2. collector配置 3. 先启动所有server，再启动所有client，否则会报错。 4. 测试高可用功能 错误: 配置文件没写对",content:'Flume NG: Flume next generation, 即flume 1.x版本 多个agent连接到一个agent,此agent也就相当于collector,支持负载均衡\n\n集群架构\n\n角色           主机名         IP\ncollector1   hadoop100   8.8.8.100\ncollector2   hadoop101   8.8.8.101\nagent        hadoop102   8.8.8.102\nagent        hadoop103   8.8.8.103\n\n\n# 1. agent配置\n\n两台agent上所有配置相同\n\n#agent1 name\nagent1.channels = channel1\nagent1.sources = source1\nagent1.sinks = sink1 sink2\n#set gruop\nagent1.sinkgroups = sinkgroup1\n#set channel\nagent1.channels.channel1.type = memory\nagent1.channels.channel1.capacity = 1000\nagent1.channels.channel1.transactionCapacity = 100\nagent1.sources.source1.channels = channel1\nagent1.sources.source1.type = exec\nagent1.sources.source1.command = tail -F /soft/module/flume/logstestfile/test.txt\nagent1.sources.source1.interceptors = i1 i2\nagent1.sources.source1.interceptors.i1.type = static\nagent1.sources.source1.interceptors.i1.key = Type\nagent1.sources.source1.interceptors.i1.value = LOGIN\nagent1.sources.source1.interceptors.i2.type = timestamp\n# set sink1\nagent1.sinks.sink1.channel = channel1\nagent1.sinks.sink1.type = avro\nagent1.sinks.sink1.hostname = hadoop100\nagent1.sinks.sink1.port = 52020\n# set sink2\nagent1.sinks.sink2.channel = channel1\nagent1.sinks.sink2.type = avro\nagent1.sinks.sink2.hostname = hadoop101\nagent1.sinks.sink2.port = 52020\n#set sink group\nagent1.sinkgroups.sinkgroup1.sinks = sink1 sink2\n#set failover\nagent1.sinkgroups.sinkgroup1.processor.type = failover\nagent1.sinkgroups.sinkgroup1.processor.priority.sink1 = 10\nagent1.sinkgroups.sinkgroup1.processor.priority.sink2 = 1\nagent1.sinkgroups.sinkgroup1.processor.maxpenalty = 10000\n\n\n\n# 2. collector配置\n\n在两台collector上操作，除了修改hostname，其他配置项相同\n\n#set Agent name\nagent2.sources = source1\nagent2.channels = channel1\nagent2.sinks = sink1\n\n#set channel\nagent2.channels.channel1.type = memory\nagent2.channels.channel1.capacity = 1000\nagent2.channels.channel1.transactionCapacity = 100\n\n# other node,nna to nns\nagent2.sources.source1.type = avro\nagent2.sources.source1.bind = hadoop100   #此处修改\nagent2.sources.source1.port = 52020\n#增加拦截器 所有events,增加头,类似json格式里的"headers":{" key":" value"}\nagent2.sources.source1.interceptors = i1\nagent2.sources.source1.interceptors.i1.type = static\nagent2.sources.source1.interceptors.i1.key = Collector\nagent2.sources.source1.interceptors.i1.value = hadoop100  #此处修改\nagent2.sources.source1.channels = channel1\n#set sink to hdfs\n#agent2.sinks.sink1.type=logger\n#指定sink类型\nagent2.sinks.sink1.type=hdfs\nagent2.sinks.sink1.hdfs.path=hdfs://mycluster/flume\nagent2.sinks.sink1.hdfs.fileType=DataStream\nagent2.sinks.sink1.hdfs.writeFormat=TEXT\n#多久生成新的文件\nagent2.sinks.sink1.hdfs.rollInterval=5\nagent2.sinks.sink1.hdfs.rollSize=1000\nagent2.sinks.sink1.hdfs.rollCount=0\n#agent2.sinks.sink1.hdfs.rollCount=1\nagent2.sinks.sink1.hdfs.filePrefix=%Y-%m-%d\n#agent2.sinks.sink1.hdfs.filePrefix=%Y-%m-%d/%H%M/%S\nagent2.sinks.sink1.hdfs.fileSuffix=.txt\nagent2.sinks.sink1.channel=channel1\n\n\n\n# 3. 先启动所有server，再启动所有client，否则会报错。\n\n[root@slave1] /usr/local/flume/conf$ ../bin/flume-ng agent -n agent1 -c ../conf -f flume-client.conf -Dflume.root.logger=DEBUG,console flume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeHA_server.conf --name agent1 -Dflume.root.logger=INFO,console > /soft/module/flume/logs/flumeHA_server.log 2>&1 &\n\n[root@slave3] /usr/local/flume/conf$ ../bin/flume-ng agent --conf ../conf --conf-file flume-server.conf --name agent2 -Dflume.root.logger=INFO,console flume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeHA_client.conf --name agent2 -Dflume.root.logger=DEBUG,console > /soft/module/flume/logs/flumeHA_client.log 2>&1 &\n\n\n# 4. 测试高可用功能\n\n 1. agent1上创建源消息 echo "hello failover" >> test.txt\n 2. 由于collector1的priority高，所以会收到，而collector2不会，查看控制台信息\n 3. 停止collector1，在agent1上创建源消息 echo "hello failover1" >> test.txt\n 4. 查看collector2控制台\n\n\n# 错误: 配置文件没写对\n\nerror1: 因为网上的配置文件不全,所以sink部分是从之前的配置文件拷的, agent的名字忘记改了,所以引起了异常,修改之后重启了几次服务,就好使了',normalizedContent:'flume ng: flume next generation, 即flume 1.x版本 多个agent连接到一个agent,此agent也就相当于collector,支持负载均衡\n\n集群架构\n\n角色           主机名         ip\ncollector1   hadoop100   8.8.8.100\ncollector2   hadoop101   8.8.8.101\nagent        hadoop102   8.8.8.102\nagent        hadoop103   8.8.8.103\n\n\n# 1. agent配置\n\n两台agent上所有配置相同\n\n#agent1 name\nagent1.channels = channel1\nagent1.sources = source1\nagent1.sinks = sink1 sink2\n#set gruop\nagent1.sinkgroups = sinkgroup1\n#set channel\nagent1.channels.channel1.type = memory\nagent1.channels.channel1.capacity = 1000\nagent1.channels.channel1.transactioncapacity = 100\nagent1.sources.source1.channels = channel1\nagent1.sources.source1.type = exec\nagent1.sources.source1.command = tail -f /soft/module/flume/logstestfile/test.txt\nagent1.sources.source1.interceptors = i1 i2\nagent1.sources.source1.interceptors.i1.type = static\nagent1.sources.source1.interceptors.i1.key = type\nagent1.sources.source1.interceptors.i1.value = login\nagent1.sources.source1.interceptors.i2.type = timestamp\n# set sink1\nagent1.sinks.sink1.channel = channel1\nagent1.sinks.sink1.type = avro\nagent1.sinks.sink1.hostname = hadoop100\nagent1.sinks.sink1.port = 52020\n# set sink2\nagent1.sinks.sink2.channel = channel1\nagent1.sinks.sink2.type = avro\nagent1.sinks.sink2.hostname = hadoop101\nagent1.sinks.sink2.port = 52020\n#set sink group\nagent1.sinkgroups.sinkgroup1.sinks = sink1 sink2\n#set failover\nagent1.sinkgroups.sinkgroup1.processor.type = failover\nagent1.sinkgroups.sinkgroup1.processor.priority.sink1 = 10\nagent1.sinkgroups.sinkgroup1.processor.priority.sink2 = 1\nagent1.sinkgroups.sinkgroup1.processor.maxpenalty = 10000\n\n\n\n# 2. collector配置\n\n在两台collector上操作，除了修改hostname，其他配置项相同\n\n#set agent name\nagent2.sources = source1\nagent2.channels = channel1\nagent2.sinks = sink1\n\n#set channel\nagent2.channels.channel1.type = memory\nagent2.channels.channel1.capacity = 1000\nagent2.channels.channel1.transactioncapacity = 100\n\n# other node,nna to nns\nagent2.sources.source1.type = avro\nagent2.sources.source1.bind = hadoop100   #此处修改\nagent2.sources.source1.port = 52020\n#增加拦截器 所有events,增加头,类似json格式里的"headers":{" key":" value"}\nagent2.sources.source1.interceptors = i1\nagent2.sources.source1.interceptors.i1.type = static\nagent2.sources.source1.interceptors.i1.key = collector\nagent2.sources.source1.interceptors.i1.value = hadoop100  #此处修改\nagent2.sources.source1.channels = channel1\n#set sink to hdfs\n#agent2.sinks.sink1.type=logger\n#指定sink类型\nagent2.sinks.sink1.type=hdfs\nagent2.sinks.sink1.hdfs.path=hdfs://mycluster/flume\nagent2.sinks.sink1.hdfs.filetype=datastream\nagent2.sinks.sink1.hdfs.writeformat=text\n#多久生成新的文件\nagent2.sinks.sink1.hdfs.rollinterval=5\nagent2.sinks.sink1.hdfs.rollsize=1000\nagent2.sinks.sink1.hdfs.rollcount=0\n#agent2.sinks.sink1.hdfs.rollcount=1\nagent2.sinks.sink1.hdfs.fileprefix=%y-%m-%d\n#agent2.sinks.sink1.hdfs.fileprefix=%y-%m-%d/%h%m/%s\nagent2.sinks.sink1.hdfs.filesuffix=.txt\nagent2.sinks.sink1.channel=channel1\n\n\n\n# 3. 先启动所有server，再启动所有client，否则会报错。\n\n[root@slave1] /usr/local/flume/conf$ ../bin/flume-ng agent -n agent1 -c ../conf -f flume-client.conf -dflume.root.logger=debug,console flume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeha_server.conf --name agent1 -dflume.root.logger=info,console > /soft/module/flume/logs/flumeha_server.log 2>&1 &\n\n[root@slave3] /usr/local/flume/conf$ ../bin/flume-ng agent --conf ../conf --conf-file flume-server.conf --name agent2 -dflume.root.logger=info,console flume-ng agent --conf conf --conf-file /soft/module/flume/conf/flumeha_client.conf --name agent2 -dflume.root.logger=debug,console > /soft/module/flume/logs/flumeha_client.log 2>&1 &\n\n\n# 4. 测试高可用功能\n\n 1. agent1上创建源消息 echo "hello failover" >> test.txt\n 2. 由于collector1的priority高，所以会收到，而collector2不会，查看控制台信息\n 3. 停止collector1，在agent1上创建源消息 echo "hello failover1" >> test.txt\n 4. 查看collector2控制台\n\n\n# 错误: 配置文件没写对\n\nerror1: 因为网上的配置文件不全,所以sink部分是从之前的配置文件拷的, agent的名字忘记改了,所以引起了异常,修改之后重启了几次服务,就好使了',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Flume把数据导入hive（文件方式）",frontmatter:{title:"Flume把数据导入hive（文件方式）",date:"2022-03-11T13:37:13.000Z",permalink:"/pages/eeda49/",categories:["大数据","Flume"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/10.Flume/04.Flume%E6%8A%8A%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5hive%EF%BC%88%E6%96%87%E4%BB%B6%E6%96%B9%E5%BC%8F%EF%BC%89.html",relativePath:"02.大数据/10.Flume/04.Flume把数据导入hive（文件方式）.md",key:"v-51040124",path:"/pages/eeda49/",headers:[{level:2,title:"1. 配置表支持事务",slug:"_1-配置表支持事务",normalizedTitle:"1. 配置表支持事务",charIndex:2},{level:2,title:"2. 版本问题导jar包",slug:"_2-版本问题导jar包",normalizedTitle:"2. 版本问题导jar包",charIndex:747},{level:2,title:"3. copyhive文件(这步好像不必要的??)",slug:"_3-copyhive文件-这步好像不必要的",normalizedTitle:"3. copyhive文件(这步好像不必要的??)",charIndex:829},{level:2,title:"4. 修改hdfs目录权限(这步不知道是不是必要的)",slug:"_4-修改hdfs目录权限-这步不知道是不是必要的",normalizedTitle:"4. 修改hdfs目录权限(这步不知道是不是必要的)",charIndex:902},{level:2,title:"5.建表",slug:"_5-建表",normalizedTitle:"5.建表",charIndex:984},{level:2,title:"6.配置flume的配置文件",slug:"_6-配置flume的配置文件",normalizedTitle:"6.配置flume的配置文件",charIndex:1233},{level:2,title:"7.启动",slug:"_7-启动",normalizedTitle:"7.启动",charIndex:2587},{level:2,title:"数据内容",slug:"数据内容",normalizedTitle:"数据内容",charIndex:2723}],headersStr:"1. 配置表支持事务 2. 版本问题导jar包 3. copyhive文件(这步好像不必要的??) 4. 修改hdfs目录权限(这步不知道是不是必要的) 5.建表 6.配置flume的配置文件 7.启动 数据内容",content:"# 1. 配置表支持事务\n\n * (1)改配置文件hive-site.xml 或者 临时设置参数 命令行\n\n<property>\n    <name>hive.support.concurrency</name>\n    <value>true</value>\n</property>\n<property>\n    <name>hive.exec.dynamic.partition.mode</name>\n    <value>nonstrict</value>\n</property>\n<property>\n    <name>hive.txn.manager</name>\n    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>\n</property>\n<property>\n    <name>hive.compactor.initiator.on</name>\n    <value>true</value>\n</property>\n<property>\n    <name>hive.compactor.worker.threads</name>\n    <value>1</value>\n    \x3c!--这里的线程数必须大于0 :理想状态和分桶数一致--\x3e\n</property>\n<property>\n    <name>hive.enforce.bucketing</name>\n    <value>true</value>\n</property>\n\n\n * (2)建表时 分区 分桶 stored as orc tblproperties('transactional'='true')\n\n\n# 2. 版本问题导jar包\n\n把${HIVE_HOME}/hcatalog/share/hcatalog下的所有包，拷贝入${FLUME_HOME}/lib\n\n\n# 3. copyhive文件(这步好像不必要的??)\n\n将hive.xml和hive-env.sh放到${HIVE_HOME}/conf下\n\n\n# 4. 修改hdfs目录权限(这步不知道是不是必要的)\n\nhadoop fs -chmod 777/tmp/hive chmod 777 /tmp/hive\n\n\n# 5.建表\n\n正确的建表实例\n\ncreate table flume_hive.flume_hive(nid int,name string,phone string)\npartitioned by(time string)\nclustered by(nid) into 3 buckets\nrow format delimited fields terminated by ','\nstored as orc tblproperties('transactional'='true');\n\n\n\n# 6.配置flume的配置文件\n\n配置文件flume_hive.cnof\n\n#定义agent名， source、channel、sink的名称\nagent3.sources = source3\nagent3.channels = channel3\nagent3.sinks = sink3\n#具体定义source\nagent3.sources.source3.type = spooldir\nagent3.sources.source3.spoolDir = /soft/flume/logstohive\nagent3.sources.source3.fileHeader=false\n#定义拦截器，为消息添加时间戳\nagent3.sources.source3.interceptors = i1\nagent3.sources.source3.interceptors.i1.type=timestamp\n\n#设置channel类型为磁盘\nagent3.channels.channel3.type = file\n#file channle checkpoint文件的路径\nagent3.channels.channel3.checkpointDir=/soft/flume/tmp/point\n# file channel data文件的路径\nagent3.channels.channel3.dataDirs=/soft/flume/tmp\n\n#具体定义sink\nagent3.sinks.sink3.type = hive\nagent3.sinks.sink3.hive.metastore = thrift://hadoop1:9083\nagent3.sinks.sink3.hive.database = flume_hive\nagent3.sinks.sink3.hive.table = flume_hive\nagent3.sinks.sink3.hive.partition = %y-%m-%d-%H-%M\nagent3.sinks.sink3.useLocalTimeStamp = false\nagent3.sinks.sink3.round = true\nagent3.sinks.sink3.roundValue = 10\nagent3.sinks.sink3.roundUnit = minute\nagent3.sinks.sink3.serializer = DELIMITED\nagent3.sinks.sink3.serializer.delimiter = \",\"\nagent3.sinks.sink3.serializer.serdeSeparator = ','\nagent3.sinks.sink3.serializer.fieldnames = nid,name,phone\nagent3.sinks.sink3.batchSize = 90\n\n#组装source、channel、sink\nagent3.sources.source3.channels = channel3\nagent3.sinks.sink3.channel = channel3\n\n\n\n# 7.启动\n\n * 先启动hive hive hive --service metastore -p 9083(这个端口号要配置到flume文件中,可用netstat -tulpn | grep 9083查看端口是否监听)\n * 然后启动flume\n * 拷贝文件\n\n\n# 数据内容\n\n[root@hadoop1 flume]# cat flume_hive.csv \n1001,aaa,12312453359,\n1002,bbb,12678723873,\n1003,ccc,12736732989,\n1004,ddd,12327836839,\n1005,eee,23728179728,\n1006,fff,12387623878,\n[root@hadoop1 flume]# cat flume_hive1.csv \n1007,aaa,12312453359,\n1008,bbb,12678723873,\n1009,ccc,12736732989,\n1010,ddd,12327836839,\n1011,eee,23728179728,\n1012,fff,12387623878,\n",normalizedContent:"# 1. 配置表支持事务\n\n * (1)改配置文件hive-site.xml 或者 临时设置参数 命令行\n\n<property>\n    <name>hive.support.concurrency</name>\n    <value>true</value>\n</property>\n<property>\n    <name>hive.exec.dynamic.partition.mode</name>\n    <value>nonstrict</value>\n</property>\n<property>\n    <name>hive.txn.manager</name>\n    <value>org.apache.hadoop.hive.ql.lockmgr.dbtxnmanager</value>\n</property>\n<property>\n    <name>hive.compactor.initiator.on</name>\n    <value>true</value>\n</property>\n<property>\n    <name>hive.compactor.worker.threads</name>\n    <value>1</value>\n    \x3c!--这里的线程数必须大于0 :理想状态和分桶数一致--\x3e\n</property>\n<property>\n    <name>hive.enforce.bucketing</name>\n    <value>true</value>\n</property>\n\n\n * (2)建表时 分区 分桶 stored as orc tblproperties('transactional'='true')\n\n\n# 2. 版本问题导jar包\n\n把${hive_home}/hcatalog/share/hcatalog下的所有包，拷贝入${flume_home}/lib\n\n\n# 3. copyhive文件(这步好像不必要的??)\n\n将hive.xml和hive-env.sh放到${hive_home}/conf下\n\n\n# 4. 修改hdfs目录权限(这步不知道是不是必要的)\n\nhadoop fs -chmod 777/tmp/hive chmod 777 /tmp/hive\n\n\n# 5.建表\n\n正确的建表实例\n\ncreate table flume_hive.flume_hive(nid int,name string,phone string)\npartitioned by(time string)\nclustered by(nid) into 3 buckets\nrow format delimited fields terminated by ','\nstored as orc tblproperties('transactional'='true');\n\n\n\n# 6.配置flume的配置文件\n\n配置文件flume_hive.cnof\n\n#定义agent名， source、channel、sink的名称\nagent3.sources = source3\nagent3.channels = channel3\nagent3.sinks = sink3\n#具体定义source\nagent3.sources.source3.type = spooldir\nagent3.sources.source3.spooldir = /soft/flume/logstohive\nagent3.sources.source3.fileheader=false\n#定义拦截器，为消息添加时间戳\nagent3.sources.source3.interceptors = i1\nagent3.sources.source3.interceptors.i1.type=timestamp\n\n#设置channel类型为磁盘\nagent3.channels.channel3.type = file\n#file channle checkpoint文件的路径\nagent3.channels.channel3.checkpointdir=/soft/flume/tmp/point\n# file channel data文件的路径\nagent3.channels.channel3.datadirs=/soft/flume/tmp\n\n#具体定义sink\nagent3.sinks.sink3.type = hive\nagent3.sinks.sink3.hive.metastore = thrift://hadoop1:9083\nagent3.sinks.sink3.hive.database = flume_hive\nagent3.sinks.sink3.hive.table = flume_hive\nagent3.sinks.sink3.hive.partition = %y-%m-%d-%h-%m\nagent3.sinks.sink3.uselocaltimestamp = false\nagent3.sinks.sink3.round = true\nagent3.sinks.sink3.roundvalue = 10\nagent3.sinks.sink3.roundunit = minute\nagent3.sinks.sink3.serializer = delimited\nagent3.sinks.sink3.serializer.delimiter = \",\"\nagent3.sinks.sink3.serializer.serdeseparator = ','\nagent3.sinks.sink3.serializer.fieldnames = nid,name,phone\nagent3.sinks.sink3.batchsize = 90\n\n#组装source、channel、sink\nagent3.sources.source3.channels = channel3\nagent3.sinks.sink3.channel = channel3\n\n\n\n# 7.启动\n\n * 先启动hive hive hive --service metastore -p 9083(这个端口号要配置到flume文件中,可用netstat -tulpn | grep 9083查看端口是否监听)\n * 然后启动flume\n * 拷贝文件\n\n\n# 数据内容\n\n[root@hadoop1 flume]# cat flume_hive.csv \n1001,aaa,12312453359,\n1002,bbb,12678723873,\n1003,ccc,12736732989,\n1004,ddd,12327836839,\n1005,eee,23728179728,\n1006,fff,12387623878,\n[root@hadoop1 flume]# cat flume_hive1.csv \n1007,aaa,12312453359,\n1008,bbb,12678723873,\n1009,ccc,12736732989,\n1010,ddd,12327836839,\n1011,eee,23728179728,\n1012,fff,12387623878,\n",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Sqoop安装配置",frontmatter:{title:"Sqoop安装配置",date:"2022-03-02T20:52:32.000Z",permalink:"/pages/60b3d7/",categories:["大数据","数据集成工具"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/11.%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%B7%A5%E5%85%B7/01.Sqoop%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE.html",relativePath:"02.大数据/11.数据集成工具/01.Sqoop安装配置.md",key:"v-d4ddf460",path:"/pages/60b3d7/",headers:[{level:3,title:"1. 下载解压",slug:"_1-下载解压",normalizedTitle:"1. 下载解压",charIndex:44},{level:3,title:"2.修改配置文件",slug:"_2-修改配置文件",normalizedTitle:"2.修改配置文件",charIndex:220},{level:3,title:"3.验证及使用",slug:"_3-验证及使用",normalizedTitle:"3.验证及使用",charIndex:978},{level:3,title:"错误:sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driver",slug:"错误-sqoop-sqoop-got-exception-running-sqoop-java-lang-runtimeexception-could-not-load-db-driver-class-com-mysql-jdbc-driver",normalizedTitle:"错误:sqoop.sqoop: got exception running sqoop: java.lang.runtimeexception: could not load db driver class: com.mysql.jdbc.driver",charIndex:2043},{level:3,title:"注释掉没有使用的组件(解决启动时的警告)",slug:"注释掉没有使用的组件-解决启动时的警告",normalizedTitle:"注释掉没有使用的组件(解决启动时的警告)",charIndex:2204}],headersStr:"1. 下载解压 2.修改配置文件 3.验证及使用 错误:sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driver 注释掉没有使用的组件(解决启动时的警告)",content:'注：sqoop只需要在namenode下安装即可 版本:Sqoop-1.4.7\n\n\n# 1. 下载解压\n\n * 上官网下载:sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz\n * 上传. 解压tar -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -C /soft/module\n * 重命名mv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop\n\n\n# 2.修改配置文件\n\n * 进入目录cd /soft/module/sqoop/conf/ 拷贝配置文件cp sqoop-env-template.sh sqoop-env.sh 修改配置文件vim sqoop-env.sh\n\n#Set path to where bin/hadoop is available\nexport HADOOP_COMMON_HOME=/soft/module/hadoop-2.9.2\n\n#Set path to where hadoop-*-core.jar is available\nexport HADOOP_MAPRED_HOME=/soft/module/hadoop-2.9.2\n\n#set the path to where bin/hbase is available\nexport HBASE_HOME=/soft/module/hbase\n\n#Set the path to where bin/hive is available\nexport HIVE_HOME=/soft/module/hive\n\n#Set the path for where zookeper config dir is\nexport ZOOCFGDIR=/soft/module/zookeeper\nexport ZOOKEEPER_HOME=/soft/module/zookeeper\n\n\n * 拷贝jdbc驱动 cp /soft/mysql-connector-java-5.1.48.jar /soft/sqoop/bin/ cp /soft/software/mysql-connector-java-5.1.48.jar /soft/module/sqoop/lib\n\n\n# 3.验证及使用\n\n * 验证配置:./bin/sqoop help 出现以下\n\nAvailable commands:\n  codegen            Generate code to interact with database records\n  create-hive-table  Import a table definition into Hive\n  eval               Evaluate a SQL statement and display the results\n  export             Export an HDFS directory to a database table\n  help               List available commands\n  import             Import a table from a database to HDFS\n  import-all-tables  Import tables from a database to HDFS\n  import-mainframe   Import datasets from a mainframe server to HDFS\n  job                Work with saved jobs\n  list-databases     List available databases on a server\n  list-tables        List available tables in a database\n  merge              Merge results of incremental imports\n  metastore          Run a standalone Sqoop metastore\n  version            Display version information\n\n\n * 测试Sqoop是否能够成功连接数据库 bin/sqoop list-databases --connect jdbc:mysql://hadoop1:3306/ --username root --password 123456789 出现以下\n\ninformation_schema\nmetastore\nmysql\nperformance_schema\nsys\n\n\n\n# 错误:sqoop.Sqoop: Got exception running Sqoop: java.lang.RuntimeException: Could not load db driver class: com.mysql.jdbc.Driver\n\n[SQOOP_HOME]/lib/下缺少mysql驱动包\n\n\n# 注释掉没有使用的组件(解决启动时的警告)\n\nbin/config-sqoop\n\n#if [ ! -d "${HBASE_HOME}" ]; then\n#  echo "Warning: $HBASE_HOME does not exist! HBase imports will fail."\n#  echo \'Please set $HBASE_HOME to the root of your HBase installation.\'\n#fi\n\n# Moved to be a runtime check in sqoop.\n#if [ ! -d "${HCAT_HOME}" ]; then\n#  echo "Warning: $HCAT_HOME does not exist! HCatalog jobs will fail."\n#  echo \'Please set $HCAT_HOME to the root of your HCatalog installation.\'\n#fi\n\n#if [ ! -d "${ACCUMULO_HOME}" ]; then\n#  echo "Warning: $ACCUMULO_HOME does not exist! Accumulo imports will fail."\n#  echo \'Please set $ACCUMULO_HOME to the root of your Accumulo installation.\'\n#fi\n#if [ ! -d "${ZOOKEEPER_HOME}" ]; then\n#  echo "Warning: $ZOOKEEPER_HOME does not exist! Accumulo imports will fail."\n#  echo \'Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.\'\n#fi\n',normalizedContent:'注：sqoop只需要在namenode下安装即可 版本:sqoop-1.4.7\n\n\n# 1. 下载解压\n\n * 上官网下载:sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz\n * 上传. 解压tar -zxvf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz -c /soft/module\n * 重命名mv sqoop-1.4.7.bin__hadoop-2.6.0 sqoop\n\n\n# 2.修改配置文件\n\n * 进入目录cd /soft/module/sqoop/conf/ 拷贝配置文件cp sqoop-env-template.sh sqoop-env.sh 修改配置文件vim sqoop-env.sh\n\n#set path to where bin/hadoop is available\nexport hadoop_common_home=/soft/module/hadoop-2.9.2\n\n#set path to where hadoop-*-core.jar is available\nexport hadoop_mapred_home=/soft/module/hadoop-2.9.2\n\n#set the path to where bin/hbase is available\nexport hbase_home=/soft/module/hbase\n\n#set the path to where bin/hive is available\nexport hive_home=/soft/module/hive\n\n#set the path for where zookeper config dir is\nexport zoocfgdir=/soft/module/zookeeper\nexport zookeeper_home=/soft/module/zookeeper\n\n\n * 拷贝jdbc驱动 cp /soft/mysql-connector-java-5.1.48.jar /soft/sqoop/bin/ cp /soft/software/mysql-connector-java-5.1.48.jar /soft/module/sqoop/lib\n\n\n# 3.验证及使用\n\n * 验证配置:./bin/sqoop help 出现以下\n\navailable commands:\n  codegen            generate code to interact with database records\n  create-hive-table  import a table definition into hive\n  eval               evaluate a sql statement and display the results\n  export             export an hdfs directory to a database table\n  help               list available commands\n  import             import a table from a database to hdfs\n  import-all-tables  import tables from a database to hdfs\n  import-mainframe   import datasets from a mainframe server to hdfs\n  job                work with saved jobs\n  list-databases     list available databases on a server\n  list-tables        list available tables in a database\n  merge              merge results of incremental imports\n  metastore          run a standalone sqoop metastore\n  version            display version information\n\n\n * 测试sqoop是否能够成功连接数据库 bin/sqoop list-databases --connect jdbc:mysql://hadoop1:3306/ --username root --password 123456789 出现以下\n\ninformation_schema\nmetastore\nmysql\nperformance_schema\nsys\n\n\n\n# 错误:sqoop.sqoop: got exception running sqoop: java.lang.runtimeexception: could not load db driver class: com.mysql.jdbc.driver\n\n[sqoop_home]/lib/下缺少mysql驱动包\n\n\n# 注释掉没有使用的组件(解决启动时的警告)\n\nbin/config-sqoop\n\n#if [ ! -d "${hbase_home}" ]; then\n#  echo "warning: $hbase_home does not exist! hbase imports will fail."\n#  echo \'please set $hbase_home to the root of your hbase installation.\'\n#fi\n\n# moved to be a runtime check in sqoop.\n#if [ ! -d "${hcat_home}" ]; then\n#  echo "warning: $hcat_home does not exist! hcatalog jobs will fail."\n#  echo \'please set $hcat_home to the root of your hcatalog installation.\'\n#fi\n\n#if [ ! -d "${accumulo_home}" ]; then\n#  echo "warning: $accumulo_home does not exist! accumulo imports will fail."\n#  echo \'please set $accumulo_home to the root of your accumulo installation.\'\n#fi\n#if [ ! -d "${zookeeper_home}" ]; then\n#  echo "warning: $zookeeper_home does not exist! accumulo imports will fail."\n#  echo \'please set $zookeeper_home to the root of your zookeeper installation.\'\n#fi\n',charsets:{cjk:!0},lastUpdated:"2022/07/25, 17:21:50",lastUpdatedTimestamp:165874091e4},{title:"Sqoop使用",frontmatter:{title:"Sqoop使用",date:"2022-03-02T20:53:35.000Z",permalink:"/pages/40f7a3/",categories:["大数据","数据集成工具"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/11.%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%B7%A5%E5%85%B7/02.Sqoop%E4%BD%BF%E7%94%A8.html",relativePath:"02.大数据/11.数据集成工具/02.Sqoop使用.md",key:"v-2c5956be",path:"/pages/40f7a3/",headers:[{level:2,title:"sql to hadoop",slug:"sql-to-hadoop",normalizedTitle:"sql to hadoop",charIndex:2},{level:2,title:"1.导入数据",slug:"_1-导入数据",normalizedTitle:"1.导入数据",charIndex:1485},{level:3,title:"关系型数据库(RDBMS)导入到HDFS",slug:"关系型数据库-rdbms-导入到hdfs",normalizedTitle:"关系型数据库(rdbms)导入到hdfs",charIndex:1618},{level:3,title:"关系型数据库(RDBMS)到Hive",slug:"关系型数据库-rdbms-到hive",normalizedTitle:"关系型数据库(rdbms)到hive",charIndex:4057},{level:3,title:"RDBMS到Hbase",slug:"rdbms到hbase",normalizedTitle:"rdbms到hbase",charIndex:5576},{level:2,title:"2.导出数据",slug:"_2-导出数据",normalizedTitle:"2.导出数据",charIndex:6328},{level:3,title:"HIVE/HDFS到RDBMS",slug:"hive-hdfs到rdbms",normalizedTitle:"hive/hdfs到rdbms",charIndex:6381},{level:2,title:"sqoop job",slug:"sqoop-job",normalizedTitle:"sqoop job",charIndex:6685},{level:2,title:"Sqoop job安全配置",slug:"sqoop-job安全配置",normalizedTitle:"sqoop job安全配置",charIndex:7137},{level:2,title:"脚本打包",slug:"脚本打包",normalizedTitle:"脚本打包",charIndex:8940}],headersStr:"sql to hadoop 1.导入数据 关系型数据库(RDBMS)导入到HDFS 关系型数据库(RDBMS)到Hive RDBMS到Hbase 2.导出数据 HIVE/HDFS到RDBMS sqoop job Sqoop job安全配置 脚本打包",content:'# sql to hadoop\n\n----------------------------------------\n\n导出数据：从Hadoop 的文件系统中导出数据到关系数据库mysql 等 Sqoop的本质还是一个命令行工具，和HDFS，Hive 相比，并没有什么高深的理论。\n\n测试连接\nsqoop list-databases --connect jdbc:mysql://hadoop100 --username root --password 123456789\n把数据导入hdfs\nsqoop import --connect jdbc:mysql://8.8.8.100/test --username root --password 123456789 --table emp --delete-target-dir\n\nsqoop import \\\n--connect jdbc:mysql://8.8.8.100/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--delete-target-dir\n\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--target-dir /user/test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n数据导入到hive\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--num-mappers 1 \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table emp_hive\n数据导入hbase(手动建表)\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--columns "id,name,degree,salary,dept" \\\n--column-family "info" \\\n--hbase-create-table \\\n--hbase-row-key "id" \\\n--hbase-table "hbase_emp" \\\n--num-mappers 1 \\\n--split-by id\n\nhdfs数据导出\n先建表\nsqoop export --connect "jdbc:mysql://192.168.94.137/test?useUnicode=true&characterEncoding=utf-8"  --username root -password lishy2019 --export-dir /user/root/emp1/part-m-00000 --table EMP  --fields-terminated-by \',\'\nsqoop作业\n\n\n\n# 1.导入数据\n\n----------------------------------------\n\n在Sqoop中，“导入”概念指：从非大数据集群（RDBMS）向大数据集群（HDFS，HIVE，HBASE）中传输数据，叫做：导入，即使用import关键字。\n\n\n# 关系型数据库(RDBMS)导入到HDFS\n\n在mysql新建一张表并插入数据\nmysql -uroot -p123456789\ncreate database company;\ncreate table company.staff(\n    id int(4) primary key not null auto_increment, \n    name varchar(255), \n    sex varchar(255));\ninsert into company.staff(name, sex) values(\'Thomas\', \'Male\');\ninsert into company.staff(name, sex) values(\'Catalina\', \'FeMale\');\n\n\n关系型数据库到HDFS\n全部导入\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\n查询导入\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--query \'select name,sex from staff where id <=1 and $CONDITIONS;\'\n如果query后使用的是双引号，则$CONDITIONS前必须加转移符，防止shell识别为自己的变量。\n\n导入指定列\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--columns id,sex \\\n--table staff\n\n使用sqoop关键字筛选查询导入数据\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--table staff \\\n--where "id=1"\n\n\n> [banana@hadoop100 ~]$ sqoop import --connect jdbc:mysql://8.8.8.100/test --username root --password 123456789 --table emp --delete-target-dir 省略一万字 20/03/30 15:27:08 ERROR tool.ImportTool: Import failed: No primary key could be found for table emp. Please specify one with --split-by or perform a sequential import with \'-m 1\'. 原因:未加参数--num-mappers 提示可以看出，在我们从mysql中导出的表没有设定主键，提示我们使用把--split-by或者把参数-m设置为1，这里大家会不会问到，这倒是是为什么呢？ Sqoop通可以过–split-by指定切分的字段，–m设置mapper的数量。通过这两个参数分解生成m个where子句，进行分段查询。 split-by 根据不同的参数类型有不同的切分方法，如表共有100条数据其中id为int类型，并且我们指定–split-by id，我们不设置map数量使用默认的为四个，首先Sqoop会取获取切分字段的MIN()和MAX()即（–split -by），再根据map数量进行划分，这是字段值就会分为四个map：（1-25）（26-50）（51-75）（75-100）。 根据MIN和MAX不同的类型采用不同的切分方式支持有Date,Text,Float,Integer， Boolean,NText,BigDecimal等等。 所以，若导入的表中没有主键，将-m 设置称1或者设置split-by，即只有一个map运行，缺点是不能并行map录入数据。（注意，当-m 设置的值大于1时，split-by必须设置字段） 。 split-by即便是int型，若不是连续有规律递增的话，各个map分配的数据是不均衡的，可能会有些map很忙，有些map几乎没有数据处理的情况。 ———————————————— 原文链接(错误集锦)：https://blog.csdn.net/yu0_zhang0/article/details/79069251\n\n\n# 关系型数据库(RDBMS)到Hive\n\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--num-mappers 1 \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table staff_hive\n\n该过程分为两步，第一步将数据导入到HDFS，第二步将导入到HDFS的数据迁移到Hive仓库，第一步默认的临时目录是/user/用户名/表名\n\n\n> ERROR hive.HiveConfig: Could not load org.apache.hadoop.hive.conf.HiveConf. Make sure HIVE_CONF_DIR is set correctly 原因: 未设置HIVE_CONF_DIR vim ~/.bashrc hive环境变量配置 export HIVE_HOME=/soft/hive export HIVE_CONF_DIR=$HIVE_HOME/conf export PATH=$PATH:$HIVE_HOME/bin\n\n> 20/03/29 20:40:06 INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS) Caused by: java.net.ConnectException: Your endpoint configuration is wrong; 原因:主机10020端口连接不上，应该是hadoop集群中datanode访问namenode的10020端口的问题，使用10020端口是jobhistory服务，在检查配置文件mapred-site.xml未发现错误 mapreduce.jobhistory.address 主机名:10020 mapreduce.jobhistory.webapp.address 主机名:19888 执行$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver 主机10020端口开放\n\n> Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf 原因：缺少了hive-common-2.3.3.jar包，在hive的lib目录下，拷贝到sqoop的lib目录下即可。 cp /soft/hive/lib/hive-common-2.3.6.jar /soft/sqoop/lib/ hbase环境变量配置配置 export HBASE_HOME=/soft/hbase export PATH=$PATH:$HBASE_HOME/bin Zookeeper环境变量配置 export ZOOKEEPER_HOME=/soft/zookeeper export PATH=$ZOOKEEPER_HOME/bin:$PATH\n\n\n# RDBMS到Hbase\n\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--columns "id,name,sex" \\\n--column-family "info" \\\n--hbase-create-table \\\n--hbase-row-key "id" \\\n--hbase-table "hbase_company" \\\n--num-mappers 1 \\\n--split-by id\n\n若没有自动创建 需手动创建\n\n\n> Exception in thread "main" java.lang.NoSuchMethodError: org.apache.hadoop.hbase.client.HBaseAdmin.(Lorg/apache/hadoop/conf/Configuration;) 我已经将以下提到的jar手动添加到SQOOP_HOME/lib中- 1: hbase-client-1.2.0.jar 2: hbase-common-1.2.0.jar 3: hbase-mapreduce-2.2.0.jar 4: hbase-protocol-1.2.0.jar 5: hbase-server-1.2.0.jar 6: hbase-zookeeper-2.2.0.jar 7: protobuf-java-2.5.0.jar\n\n> 版本不兼容???(sqoop1.4.7手动创建都不好使???) sqoop1.4.6只支持hbase1.0.1之前的版本自动创建表\n\n\n# 2.导出数据\n\n----------------------------------------\n\n\n# HIVE/HDFS到RDBMS\n\nbin/sqoop export \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff1 \\\n--num-mappers 1 \\\n--export-dir /user/hive/warehouse/staff_hive \\\n--input-fields-terminated-by "\\t"\n\nMySQL表如果不存在 不会自动创建?useUnicode=true&characterEncoding=utf-8\n\n\n\n# sqoop job\n\n----------------------------------------\n\nsqoop job命令的基本用法：\n\n * 创建job：--create\n * 删除job：--delete\n * 执行job：--exec\n * 显示job：--show\n * 列出job：--list\n\n创建一个job(注意-- import中间有个空格,切勿忽视)\n\nsqoop job --create firstjob \\\n-- import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--target-dir /user/test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\nsqoop job --list\n\n\n\n# Sqoop job安全配置\n\n----------------------------------------\n\n默认情况下，创建的每个job在运行的时候都不会进行安全的认证。如果我们希望限制指定的sqoop job的执行，只有经过认证以后才能执行，这时候可以使用sqoop job的安全选项。Sqoop安装目录下，通过修改配置文件conf/sqoop-site.xml可以对job进行更高级的配置。实际上，我们使用了Sqoop的metastore工具，它能够对Sqoop进行细粒度的配置。 我们要将MySQL数据库中的数据同步到Hive表，每次执行sqoop job都需要输入访问MySQL数据库的连接账号信息，可以设置sqoop.metastore.client.record.password的值为true。如果在conf/sqoop-site.xml中增加如下配置，会将连接账号信息存储到Sqoop的metastore中：\n\n<property>\n    <name>sqoop.metastore.client.record.password</name>\n    <value>true</value>\n    <description>If true, allow saved passwords in the metastore. </description>\n</property>\n\n\n如果想要限制从外部调用执行Sqoop job，如将Sqoop job提交给Oozie调度程序，也会通过上面Sqoop的metastore配置的内容来进行验证。 另外，Sqoop的metastore工具，可以允许我们指定为外部，例如使用外部主机上的MySQL数据库来存储元数据，可以在conf/sqoop-site.xml配置如下：\n\n<property>\n    <name>sqoop.metastore.client.autoconnect.url</name>\n    <value>jdbc:mysql://10.95.3.49:3306/sqoop_metastore</value>\n    <description>The connect string to use when connecting to a\n        job-management metastore. If unspecified, uses ~/.sqoop/.\n        You can specify a different path here.\n    </description>\n</property>\n<property>\n    <name>sqoop.metastore.client.autoconnect.username</name>\n    <value>shirdrn</value>\n    <description>The username to bind to the metastore.\n    </description>\n</property>\n<property>\n    <name>sqoop.metastore.client.autoconnect.password</name>\n    <value>108loIOL</value>\n    <description>The password to bind to the metastore.\n    </description>\n</property>\n\n\n还有一个可与选择的配置项是，可以设置是否自动连接到外部metastore数据库，通过如下配置指定：\n\n<property>\n     <name>sqoop.metastore.client.enable.autoconnect</name>\n     <value>false</value>\n     <description>If true, Sqoop will connect to a local metastore for job management when no other metastore arguments are provided.\n     </description>\n</property>\n\n\n\n# 脚本打包\n\n----------------------------------------\n\n编写脚本\nvim job_HDFS_RDBMS.opt\n脚本内容(导出数据到mysql)\nexport\n--connect\njdbc:mysql://hadoop1:3306/company\n--username\nroot\n--password\n123456789\n--table\nstaff\n--num-mappers\n1\n--export-dir\n/user/hive/warehouse/staff_hive\n--input-fields-terminated-by\n"\\t"\n\n执行脚本\nbin/sqoop --options-file opt/job_HDFS2RDBMS.opt\n',normalizedContent:'# sql to hadoop\n\n----------------------------------------\n\n导出数据：从hadoop 的文件系统中导出数据到关系数据库mysql 等 sqoop的本质还是一个命令行工具，和hdfs，hive 相比，并没有什么高深的理论。\n\n测试连接\nsqoop list-databases --connect jdbc:mysql://hadoop100 --username root --password 123456789\n把数据导入hdfs\nsqoop import --connect jdbc:mysql://8.8.8.100/test --username root --password 123456789 --table emp --delete-target-dir\n\nsqoop import \\\n--connect jdbc:mysql://8.8.8.100/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--delete-target-dir\n\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--target-dir /user/test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n数据导入到hive\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--num-mappers 1 \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table emp_hive\n数据导入hbase(手动建表)\nsqoop import \\\n--connect jdbc:mysql://hadoop100:3306/test \\\n--username root \\\n--password 123456789 \\\n--table emp \\\n--columns "id,name,degree,salary,dept" \\\n--column-family "info" \\\n--hbase-create-table \\\n--hbase-row-key "id" \\\n--hbase-table "hbase_emp" \\\n--num-mappers 1 \\\n--split-by id\n\nhdfs数据导出\n先建表\nsqoop export --connect "jdbc:mysql://192.168.94.137/test?useunicode=true&characterencoding=utf-8"  --username root -password lishy2019 --export-dir /user/root/emp1/part-m-00000 --table emp  --fields-terminated-by \',\'\nsqoop作业\n\n\n\n# 1.导入数据\n\n----------------------------------------\n\n在sqoop中，“导入”概念指：从非大数据集群（rdbms）向大数据集群（hdfs，hive，hbase）中传输数据，叫做：导入，即使用import关键字。\n\n\n# 关系型数据库(rdbms)导入到hdfs\n\n在mysql新建一张表并插入数据\nmysql -uroot -p123456789\ncreate database company;\ncreate table company.staff(\n    id int(4) primary key not null auto_increment, \n    name varchar(255), \n    sex varchar(255));\ninsert into company.staff(name, sex) values(\'thomas\', \'male\');\ninsert into company.staff(name, sex) values(\'catalina\', \'female\');\n\n\n关系型数据库到hdfs\n全部导入\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\n查询导入\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--query \'select name,sex from staff where id <=1 and $conditions;\'\n如果query后使用的是双引号，则$conditions前必须加转移符，防止shell识别为自己的变量。\n\n导入指定列\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--columns id,sex \\\n--table staff\n\n使用sqoop关键字筛选查询导入数据\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--table staff \\\n--where "id=1"\n\n\n> [banana@hadoop100 ~]$ sqoop import --connect jdbc:mysql://8.8.8.100/test --username root --password 123456789 --table emp --delete-target-dir 省略一万字 20/03/30 15:27:08 error tool.importtool: import failed: no primary key could be found for table emp. please specify one with --split-by or perform a sequential import with \'-m 1\'. 原因:未加参数--num-mappers 提示可以看出，在我们从mysql中导出的表没有设定主键，提示我们使用把--split-by或者把参数-m设置为1，这里大家会不会问到，这倒是是为什么呢？ sqoop通可以过–split-by指定切分的字段，–m设置mapper的数量。通过这两个参数分解生成m个where子句，进行分段查询。 split-by 根据不同的参数类型有不同的切分方法，如表共有100条数据其中id为int类型，并且我们指定–split-by id，我们不设置map数量使用默认的为四个，首先sqoop会取获取切分字段的min()和max()即（–split -by），再根据map数量进行划分，这是字段值就会分为四个map：（1-25）（26-50）（51-75）（75-100）。 根据min和max不同的类型采用不同的切分方式支持有date,text,float,integer， boolean,ntext,bigdecimal等等。 所以，若导入的表中没有主键，将-m 设置称1或者设置split-by，即只有一个map运行，缺点是不能并行map录入数据。（注意，当-m 设置的值大于1时，split-by必须设置字段） 。 split-by即便是int型，若不是连续有规律递增的话，各个map分配的数据是不均衡的，可能会有些map很忙，有些map几乎没有数据处理的情况。 ———————————————— 原文链接(错误集锦)：https://blog.csdn.net/yu0_zhang0/article/details/79069251\n\n\n# 关系型数据库(rdbms)到hive\n\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--num-mappers 1 \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table staff_hive\n\n该过程分为两步，第一步将数据导入到hdfs，第二步将导入到hdfs的数据迁移到hive仓库，第一步默认的临时目录是/user/用户名/表名\n\n\n> error hive.hiveconfig: could not load org.apache.hadoop.hive.conf.hiveconf. make sure hive_conf_dir is set correctly 原因: 未设置hive_conf_dir vim ~/.bashrc hive环境变量配置 export hive_home=/soft/hive export hive_conf_dir=$hive_home/conf export path=$path:$hive_home/bin\n\n> 20/03/29 20:40:06 info ipc.client: retrying connect to server: 0.0.0.0/0.0.0.0:10020. already tried 0 time(s); retry policy is retryuptomaximumcountwithfixedsleep(maxretries=10, sleeptime=1000 milliseconds) caused by: java.net.connectexception: your endpoint configuration is wrong; 原因:主机10020端口连接不上，应该是hadoop集群中datanode访问namenode的10020端口的问题，使用10020端口是jobhistory服务，在检查配置文件mapred-site.xml未发现错误 mapreduce.jobhistory.address 主机名:10020 mapreduce.jobhistory.webapp.address 主机名:19888 执行$hadoop_home/sbin/mr-jobhistory-daemon.sh start historyserver 主机10020端口开放\n\n> caused by: java.lang.classnotfoundexception: org.apache.hadoop.hive.conf.hiveconf 原因：缺少了hive-common-2.3.3.jar包，在hive的lib目录下，拷贝到sqoop的lib目录下即可。 cp /soft/hive/lib/hive-common-2.3.6.jar /soft/sqoop/lib/ hbase环境变量配置配置 export hbase_home=/soft/hbase export path=$path:$hbase_home/bin zookeeper环境变量配置 export zookeeper_home=/soft/zookeeper export path=$zookeeper_home/bin:$path\n\n\n# rdbms到hbase\n\nbin/sqoop import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--columns "id,name,sex" \\\n--column-family "info" \\\n--hbase-create-table \\\n--hbase-row-key "id" \\\n--hbase-table "hbase_company" \\\n--num-mappers 1 \\\n--split-by id\n\n若没有自动创建 需手动创建\n\n\n> exception in thread "main" java.lang.nosuchmethoderror: org.apache.hadoop.hbase.client.hbaseadmin.(lorg/apache/hadoop/conf/configuration;) 我已经将以下提到的jar手动添加到sqoop_home/lib中- 1: hbase-client-1.2.0.jar 2: hbase-common-1.2.0.jar 3: hbase-mapreduce-2.2.0.jar 4: hbase-protocol-1.2.0.jar 5: hbase-server-1.2.0.jar 6: hbase-zookeeper-2.2.0.jar 7: protobuf-java-2.5.0.jar\n\n> 版本不兼容???(sqoop1.4.7手动创建都不好使???) sqoop1.4.6只支持hbase1.0.1之前的版本自动创建表\n\n\n# 2.导出数据\n\n----------------------------------------\n\n\n# hive/hdfs到rdbms\n\nbin/sqoop export \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff1 \\\n--num-mappers 1 \\\n--export-dir /user/hive/warehouse/staff_hive \\\n--input-fields-terminated-by "\\t"\n\nmysql表如果不存在 不会自动创建?useunicode=true&characterencoding=utf-8\n\n\n\n# sqoop job\n\n----------------------------------------\n\nsqoop job命令的基本用法：\n\n * 创建job：--create\n * 删除job：--delete\n * 执行job：--exec\n * 显示job：--show\n * 列出job：--list\n\n创建一个job(注意-- import中间有个空格,切勿忽视)\n\nsqoop job --create firstjob \\\n-- import \\\n--connect jdbc:mysql://hadoop1:3306/company \\\n--username root \\\n--password 123456789 \\\n--table staff \\\n--target-dir /user/test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\nsqoop job --list\n\n\n\n# sqoop job安全配置\n\n----------------------------------------\n\n默认情况下，创建的每个job在运行的时候都不会进行安全的认证。如果我们希望限制指定的sqoop job的执行，只有经过认证以后才能执行，这时候可以使用sqoop job的安全选项。sqoop安装目录下，通过修改配置文件conf/sqoop-site.xml可以对job进行更高级的配置。实际上，我们使用了sqoop的metastore工具，它能够对sqoop进行细粒度的配置。 我们要将mysql数据库中的数据同步到hive表，每次执行sqoop job都需要输入访问mysql数据库的连接账号信息，可以设置sqoop.metastore.client.record.password的值为true。如果在conf/sqoop-site.xml中增加如下配置，会将连接账号信息存储到sqoop的metastore中：\n\n<property>\n    <name>sqoop.metastore.client.record.password</name>\n    <value>true</value>\n    <description>if true, allow saved passwords in the metastore. </description>\n</property>\n\n\n如果想要限制从外部调用执行sqoop job，如将sqoop job提交给oozie调度程序，也会通过上面sqoop的metastore配置的内容来进行验证。 另外，sqoop的metastore工具，可以允许我们指定为外部，例如使用外部主机上的mysql数据库来存储元数据，可以在conf/sqoop-site.xml配置如下：\n\n<property>\n    <name>sqoop.metastore.client.autoconnect.url</name>\n    <value>jdbc:mysql://10.95.3.49:3306/sqoop_metastore</value>\n    <description>the connect string to use when connecting to a\n        job-management metastore. if unspecified, uses ~/.sqoop/.\n        you can specify a different path here.\n    </description>\n</property>\n<property>\n    <name>sqoop.metastore.client.autoconnect.username</name>\n    <value>shirdrn</value>\n    <description>the username to bind to the metastore.\n    </description>\n</property>\n<property>\n    <name>sqoop.metastore.client.autoconnect.password</name>\n    <value>108loiol</value>\n    <description>the password to bind to the metastore.\n    </description>\n</property>\n\n\n还有一个可与选择的配置项是，可以设置是否自动连接到外部metastore数据库，通过如下配置指定：\n\n<property>\n     <name>sqoop.metastore.client.enable.autoconnect</name>\n     <value>false</value>\n     <description>if true, sqoop will connect to a local metastore for job management when no other metastore arguments are provided.\n     </description>\n</property>\n\n\n\n# 脚本打包\n\n----------------------------------------\n\n编写脚本\nvim job_hdfs_rdbms.opt\n脚本内容(导出数据到mysql)\nexport\n--connect\njdbc:mysql://hadoop1:3306/company\n--username\nroot\n--password\n123456789\n--table\nstaff\n--num-mappers\n1\n--export-dir\n/user/hive/warehouse/staff_hive\n--input-fields-terminated-by\n"\\t"\n\n执行脚本\nbin/sqoop --options-file opt/job_hdfs2rdbms.opt\n',charsets:{cjk:!0},lastUpdated:"2022/07/25, 17:21:50",lastUpdatedTimestamp:165874091e4},{title:"Flume相关学习",frontmatter:{title:"Flume相关学习",date:"2022-03-02T20:48:15.000Z",permalink:"/pages/3408a8/",categories:["大数据","Flume"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/10.Flume/03.Flume%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0.html",relativePath:"02.大数据/10.Flume/03.Flume相关学习.md",key:"v-1fd37798",path:"/pages/3408a8/",headers:[{level:2,title:"自定义Sink到MySQL",slug:"自定义sink到mysql",normalizedTitle:"自定义sink到mysql",charIndex:2},{level:2,title:"拦截器",slug:"拦截器",normalizedTitle:"拦截器",charIndex:6518}],headersStr:"自定义Sink到MySQL 拦截器",content:'# 自定义Sink到MySQL\n\n----------------------------------------\n\npackage org.flume.mysql.sink;\n/**\n * create by yong 2016-6-16\n */\nimport com.google.common.base.Preconditions;\nimport com.google.common.base.Throwables;\nimport com.google.common.collect.Lists;\nimport org.apache.flume.*;\nimport org.apache.flume.conf.Configurable;\nimport org.apache.flume.sink.AbstractSink;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n \nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.SQLException;\nimport java.util.List;\n \npublic class MysqlSink extends AbstractSink implements Configurable {\n \n    private Logger LOG = LoggerFactory.getLogger(MysqlSink.class);\n    private String hostname;\n    private String port;\n    private String databaseName;\n    private String tableName;\n    private String user;\n    private String password;\n    private PreparedStatement preparedStatement;\n    private Connection conn;\n    private int batchSize;\n \n    public MysqlSink() {\n        LOG.info("MysqlSink start...");\n    }\n \n    public void configure(Context context) {\n        hostname = context.getString("hostname");\n        Preconditions.checkNotNull(hostname, "hostname must be set!!");\n        port = context.getString("port");\n        Preconditions.checkNotNull(port, "port must be set!!");\n        databaseName = context.getString("databaseName");\n        Preconditions.checkNotNull(databaseName, "databaseName must be set!!");\n        tableName = context.getString("tableName");\n        Preconditions.checkNotNull(tableName, "tableName must be set!!");\n        user = context.getString("user");\n        Preconditions.checkNotNull(user, "user must be set!!");\n        password = context.getString("password");\n        Preconditions.checkNotNull(password, "password must be set!!");\n        batchSize = context.getInteger("batchSize", 100);\n        Preconditions.checkNotNull(batchSize > 0, "batchSize must be a positive number!!");\n    }\n \n    @Override\n    public void start() {\n        super.start();\n        try {\n            //调用Class.forName()方法加载驱动程序\n            Class.forName("com.mysql.jdbc.Driver");\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace();\n        }\n \n        String url = "jdbc:mysql://" + hostname + ":" + port + "/" + databaseName; \n        //调用DriverManager对象的getConnection()方法，获得一个Connection对象\n \n        try {\n            conn = DriverManager.getConnection(url, user, password);\n            conn.setAutoCommit(false);\n            //创建一个Statement对象\n            preparedStatement = conn.prepareStatement("insert into " + tableName + \n                                               " (content) values (?)");\n \n        } catch (SQLException e) {\n            e.printStackTrace();\n            System.exit(1);\n        }\n \n    }\n \n    @Override\n    public void stop() {\n        super.stop();\n        if (preparedStatement != null) {\n            try {\n                preparedStatement.close();\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        }\n \n        if (conn != null) {\n            try {\n                conn.close();\n            } catch (SQLException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n \n    public Status process() throws EventDeliveryException {\n        Status result = Status.READY;\n        Channel channel = getChannel();\n        Transaction transaction = channel.getTransaction();\n        Event event;\n        String content;\n \n        List<String> actions = Lists.newArrayList();\n        transaction.begin();\n        try {\n            for (int i = 0; i < batchSize; i++) {\n                event = channel.take();\n                if (event != null) {\n                    content = new String(event.getBody());\n                    actions.add(content);\n                } else {\n                    result = Status.BACKOFF;\n                    break;\n                }\n            }\n \n            if (actions.size() > 0) {\n                preparedStatement.clearBatch();\n                for (String temp : actions) {\n                    preparedStatement.setString(1, temp);\n                    preparedStatement.addBatch();\n                }\n                preparedStatement.executeBatch();\n \n                conn.commit();\n            }\n            transaction.commit();\n        } catch (Throwable e) {\n            try {\n                transaction.rollback();\n            } catch (Exception e2) {\n                LOG.error("Exception in rollback. Rollback might not have been" +\n                        "successful.", e2);\n            }\n            LOG.error("Failed to commit transaction." +\n                    "Transaction rolled back.", e);\n            Throwables.propagate(e);\n        } finally {\n            transaction.close();\n        }\n \n        return result;\n    }\n}\n\n\n依赖\n\n<dependencies>\n        <dependency>\n            <groupId>org.apache.flume</groupId>\n            <artifactId>flume-ng-core</artifactId>\n        </dependency>\n \n        <dependency>\n            <groupId>org.apache.flume</groupId>\n            <artifactId>flume-ng-configuration</artifactId>\n        </dependency>\n \n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n            <version>5.1.25</version>\n        </dependency>\n \n        <dependency>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-api</artifactId>\n        </dependency>\n \n        <dependency>\n            <groupId>org.slf4j</groupId>\n            <artifactId>slf4j-log4j12</artifactId>\n            <scope>test</scope>\n        </dependency>\n</dependencies>\n\n\nflume配置\n\nagent1.sources = source1\nagent1.sinks = mysqlSink\nagent1.channels = channel1\n \n \n \n# Describe/configure source1\nagent1.sources.source1.type  =  exec\nagent1.sources.source1.command  = tail -F /home/yong/Work/flum-1.6/tail_log_exec\nagent1.sources.source1.channels = channel1\n \n \n# Describe mysqlSink\nagent1.sinks.mysqlSink.type  = org.flume.mysql.sink.MysqlSink\nagent1.sinks.mysqlSink.hostname =localhost\nagent1.sinks.mysqlSink.port=3306\nagent1.sinks.mysqlSink.databaseName=sinktest\nagent1.sinks.mysqlSink.tableName=mysqltest\nagent1.sinks.mysqlSink.user=root\nagent1.sinks.mysqlSink.password=root\nagent1.sinks.mysqlSink.channel = channel1\n  \n# Use a channel which buffers events in memory\nagent1.channels.channel1.type = memory\nagent1.channels.channel1.capacity = 1000\nagent1.channels.channel1.transactionCapactiy = 100\n\n\n原文链接\n\n\n# 拦截器\n\n----------------------------------------\n\n\n',normalizedContent:'# 自定义sink到mysql\n\n----------------------------------------\n\npackage org.flume.mysql.sink;\n/**\n * create by yong 2016-6-16\n */\nimport com.google.common.base.preconditions;\nimport com.google.common.base.throwables;\nimport com.google.common.collect.lists;\nimport org.apache.flume.*;\nimport org.apache.flume.conf.configurable;\nimport org.apache.flume.sink.abstractsink;\nimport org.slf4j.logger;\nimport org.slf4j.loggerfactory;\n \nimport java.sql.connection;\nimport java.sql.drivermanager;\nimport java.sql.preparedstatement;\nimport java.sql.sqlexception;\nimport java.util.list;\n \npublic class mysqlsink extends abstractsink implements configurable {\n \n    private logger log = loggerfactory.getlogger(mysqlsink.class);\n    private string hostname;\n    private string port;\n    private string databasename;\n    private string tablename;\n    private string user;\n    private string password;\n    private preparedstatement preparedstatement;\n    private connection conn;\n    private int batchsize;\n \n    public mysqlsink() {\n        log.info("mysqlsink start...");\n    }\n \n    public void configure(context context) {\n        hostname = context.getstring("hostname");\n        preconditions.checknotnull(hostname, "hostname must be set!!");\n        port = context.getstring("port");\n        preconditions.checknotnull(port, "port must be set!!");\n        databasename = context.getstring("databasename");\n        preconditions.checknotnull(databasename, "databasename must be set!!");\n        tablename = context.getstring("tablename");\n        preconditions.checknotnull(tablename, "tablename must be set!!");\n        user = context.getstring("user");\n        preconditions.checknotnull(user, "user must be set!!");\n        password = context.getstring("password");\n        preconditions.checknotnull(password, "password must be set!!");\n        batchsize = context.getinteger("batchsize", 100);\n        preconditions.checknotnull(batchsize > 0, "batchsize must be a positive number!!");\n    }\n \n    @override\n    public void start() {\n        super.start();\n        try {\n            //调用class.forname()方法加载驱动程序\n            class.forname("com.mysql.jdbc.driver");\n        } catch (classnotfoundexception e) {\n            e.printstacktrace();\n        }\n \n        string url = "jdbc:mysql://" + hostname + ":" + port + "/" + databasename; \n        //调用drivermanager对象的getconnection()方法，获得一个connection对象\n \n        try {\n            conn = drivermanager.getconnection(url, user, password);\n            conn.setautocommit(false);\n            //创建一个statement对象\n            preparedstatement = conn.preparestatement("insert into " + tablename + \n                                               " (content) values (?)");\n \n        } catch (sqlexception e) {\n            e.printstacktrace();\n            system.exit(1);\n        }\n \n    }\n \n    @override\n    public void stop() {\n        super.stop();\n        if (preparedstatement != null) {\n            try {\n                preparedstatement.close();\n            } catch (sqlexception e) {\n                e.printstacktrace();\n            }\n        }\n \n        if (conn != null) {\n            try {\n                conn.close();\n            } catch (sqlexception e) {\n                e.printstacktrace();\n            }\n        }\n    }\n \n    public status process() throws eventdeliveryexception {\n        status result = status.ready;\n        channel channel = getchannel();\n        transaction transaction = channel.gettransaction();\n        event event;\n        string content;\n \n        list<string> actions = lists.newarraylist();\n        transaction.begin();\n        try {\n            for (int i = 0; i < batchsize; i++) {\n                event = channel.take();\n                if (event != null) {\n                    content = new string(event.getbody());\n                    actions.add(content);\n                } else {\n                    result = status.backoff;\n                    break;\n                }\n            }\n \n            if (actions.size() > 0) {\n                preparedstatement.clearbatch();\n                for (string temp : actions) {\n                    preparedstatement.setstring(1, temp);\n                    preparedstatement.addbatch();\n                }\n                preparedstatement.executebatch();\n \n                conn.commit();\n            }\n            transaction.commit();\n        } catch (throwable e) {\n            try {\n                transaction.rollback();\n            } catch (exception e2) {\n                log.error("exception in rollback. rollback might not have been" +\n                        "successful.", e2);\n            }\n            log.error("failed to commit transaction." +\n                    "transaction rolled back.", e);\n            throwables.propagate(e);\n        } finally {\n            transaction.close();\n        }\n \n        return result;\n    }\n}\n\n\n依赖\n\n<dependencies>\n        <dependency>\n            <groupid>org.apache.flume</groupid>\n            <artifactid>flume-ng-core</artifactid>\n        </dependency>\n \n        <dependency>\n            <groupid>org.apache.flume</groupid>\n            <artifactid>flume-ng-configuration</artifactid>\n        </dependency>\n \n        <dependency>\n            <groupid>mysql</groupid>\n            <artifactid>mysql-connector-java</artifactid>\n            <version>5.1.25</version>\n        </dependency>\n \n        <dependency>\n            <groupid>org.slf4j</groupid>\n            <artifactid>slf4j-api</artifactid>\n        </dependency>\n \n        <dependency>\n            <groupid>org.slf4j</groupid>\n            <artifactid>slf4j-log4j12</artifactid>\n            <scope>test</scope>\n        </dependency>\n</dependencies>\n\n\nflume配置\n\nagent1.sources = source1\nagent1.sinks = mysqlsink\nagent1.channels = channel1\n \n \n \n# describe/configure source1\nagent1.sources.source1.type  =  exec\nagent1.sources.source1.command  = tail -f /home/yong/work/flum-1.6/tail_log_exec\nagent1.sources.source1.channels = channel1\n \n \n# describe mysqlsink\nagent1.sinks.mysqlsink.type  = org.flume.mysql.sink.mysqlsink\nagent1.sinks.mysqlsink.hostname =localhost\nagent1.sinks.mysqlsink.port=3306\nagent1.sinks.mysqlsink.databasename=sinktest\nagent1.sinks.mysqlsink.tablename=mysqltest\nagent1.sinks.mysqlsink.user=root\nagent1.sinks.mysqlsink.password=root\nagent1.sinks.mysqlsink.channel = channel1\n  \n# use a channel which buffers events in memory\nagent1.channels.channel1.type = memory\nagent1.channels.channel1.capacity = 1000\nagent1.channels.channel1.transactioncapactiy = 100\n\n\n原文链接\n\n\n# 拦截器\n\n----------------------------------------\n\n\n',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"其他ETL工具",frontmatter:{title:"其他ETL工具",date:"2022-03-29T13:03:59.000Z",permalink:"/pages/b76fc1/",categories:["大数据","数据集成工具"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/11.%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%B7%A5%E5%85%B7/09.%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E6%A1%86%E6%9E%B6.html",relativePath:"02.大数据/11.数据集成工具/09.数据集成框架.md",key:"v-63f04fc0",path:"/pages/b76fc1/",headers:[{level:2,title:"工具",slug:"工具",normalizedTitle:"工具",charIndex:2},{level:3,title:"Kettle",slug:"kettle",normalizedTitle:"kettle",charIndex:445},{level:4,title:"多表数据迁移",slug:"多表数据迁移",normalizedTitle:"多表数据迁移",charIndex:632},{level:4,title:"表名变量导出指定表",slug:"表名变量导出指定表",normalizedTitle:"表名变量导出指定表",charIndex:833},{level:3,title:"Sqoop",slug:"sqoop",normalizedTitle:"sqoop",charIndex:576},{level:3,title:"Datax",slug:"datax",normalizedTitle:"datax",charIndex:2515},{level:4,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:2524},{level:4,title:"字段对应",slug:"字段对应",normalizedTitle:"字段对应",charIndex:3231},{level:4,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:549},{level:4,title:"datax-web 安装",slug:"datax-web-安装",normalizedTitle:"datax-web 安装",charIndex:7871},{level:3,title:"达梦DTS工具",slug:"达梦dts工具",normalizedTitle:"达梦dts工具",charIndex:8433},{level:3,title:"SeaTunnel",slug:"seatunnel",normalizedTitle:"seatunnel",charIndex:8445},{level:2,title:"数据迁移方案（结构化数据）",slug:"数据迁移方案-结构化数据",normalizedTitle:"数据迁移方案（结构化数据）",charIndex:9004},{level:4,title:"选型",slug:"选型",normalizedTitle:"选型",charIndex:9021},{level:4,title:"调优",slug:"调优",normalizedTitle:"调优",charIndex:9184}],headersStr:"工具 Kettle 多表数据迁移 表名变量导出指定表 Sqoop Datax 安装 字段对应 使用 datax-web 安装 达梦DTS工具 SeaTunnel 数据迁移方案（结构化数据） 选型 调优",content:'# 工具\n\n维度      KETTLE   DATAX       达梦DTS          SQOOP      SEATUNNEL\n实时性     否        否           否              否          ✅（流批一体）\n图形化界面   ✅（强）     ❌（JSON配置）   ✅（向导式）         ❌（命令行）     ❌（YAML配置）\n性能      中等       高           中等             高          ✅（超高）\n扩展性     插件生态     插件架构        封闭生态           Hadoop生态   连接器丰富\n易用性     ✅（低门槛）   ❌（复杂）       ✅（国产化）         中等         中等\n适用场景    复杂ETL    离线迁移        与DM之间数据及对象迁移   Hadoop集成   实时数据管道\n\n\n# Kettle\n\n> ETL（Extract-Transform-Load的缩写，即数据抽取、转换、装载的过程），对于企业或行业应用来说，我们经常会遇到各种数据的处理，转换，迁移，所以了解并掌握一种ETL工具的使用，必不可少。\n\n市面上常用的ETL工具有很多，比如Sqoop，DataX，Kettle，Talend等，作为一个大数据工程师，我们最好要掌握其中的两到三种\n\n# 多表数据迁移\n\n 1. 创建数据源（源和目标）\n 2. 点击 工具 -> 向导 -> 复制多表向导\n 3. 选择 源数据库和目标数据库，选择需要迁移的表\n 4. 执行生成的job\n\n附：连接 Oracle 19c正常，但是读取元数据报错（不支持的字符集），在 Oracle官网 下载ojdbcx-full.tar.gz，取出其中的orai18n.jar，放入 Kettle 的 lib 目录下。\n\n# 表名变量导出指定表\n\n通过循环表名变量，导出指定表数据（导出到 excel 时速度较慢）\n\n原文链接\n\n\n# Sqoop\n\n导入\n\n# 全部导入\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\n# 导入指定列\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--columns id,sex \\\n--table staff\n\n# 查询导入\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--query \'select name,sex from staff where id <=1 and $CONDITIONS;\'\n\n# where关键字筛选\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--table staff \\\n--where "id=1"\n\n# 导入到hive：第一步将数据导入到HDFS，第二步将导入到HDFS的数据迁移到Hive仓库\nbin/sqoop import \\\n--connect jdbc:mysql://Faded103:3306/db_sqoop_test \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--target-dir /user/db_sqoop_test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table staff_hive\n\n\n导出\n\n# hdfs/hive到rdms\n$ bin/sqoop export \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--num-mappers 1 \\\n--export-dir /user/hive/warehouse/staff_hive \\\n--input-fields-terminated-by "\\t"\n\n\n\n# Datax\n\n# 安装\n\n * 下载 wget http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz\n * 解压 tar -zxvf datax.tar.gz -C /opt/module\n * 依赖\n   * 安装jdk\n   * python\n\nsudo apt install python\n(一定要是python2(2.7+?)\n因为后面执行datax.py的时候，里面的Python的print会执行不了，导致运行不成功，会提示你print语法要加括号，Python2中加不加都行，Python3中必须要加，否则报语法错。)\n\n\n* **Apache Maven 3.x**   \n\n\n下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.8.5/binaries/apache-maven-3.8.5-bin.tar.gz\n解压 tar -zxvf apache-maven-3.8.5-bin.tar.gz -C /opt/module/\n环境变量\nvim /etc/profile\n\nMAVEN_HOME=/opt/module/apache-maven-3.8.5\nPATH=${M2_HOME}/bin:${PATH}\n\nsource /etc/profile\n\n\n * Jdk、Python、Maven都安装成功了，datax解压缩成功了，开始自检，进入bin目录，开始自检\n\npython datax.py ../job/job.json\n\n\n# 字段对应\n\n各个数据库和datax字段映射\n\n# 使用\n\n> 最开始时报错，然后考虑是不支持MySQL8.0的原因，下载源码修改，由于依赖不全(下载jar包 安装到本地maven库也不行)，暂时搁置。\n> 然后考虑将mysqlwriter中MySQL驱动换成8.0的驱动。\n> 还报错，是因为date日期格式的问题，需制定格式。 （换jar包解决问题）暂未发现其他问题，待补充\n\n点击查看\n\nJson文件示例(csv文本到mysql)\n\n{\n    "job": {\n        "setting": {\n                "speed": {\n                        "channel": 3 \n                }\n        },\n        "content": [\n            {\n                "reader": {\n                    "name": "txtfilereader",\n                    "parameter": {\n                    "path": ["/home/banana/data/xxxxx.csv"],\n                    "encoding":"utf-8",\n                        "column": [\n                            { "index": 0, "type": "String" },\n                            { "index": 1, "type": "String" },\n                            { "index": 2, "type": "String" },\n                            { "index": 3, "type": "String" },\n                            { "index": 4, "type": "String" },\n                            { "index": 5, "type": "String" },\n                            { "index": 6, "type": "String" },\n                            { "index": 7, "type": "String" },\n                            { "index": 8, "type": "String" },\n                            { "index": 9, "type": "String" },\n                            { "index": 10, "type": "String" },\n                            { "index": 11, "type": "String" },\n                            { "index": 12, "type": "String" },\n                            { "index": 13, "type": "String" },\n                            { "index": 14, "type": "String" },\n                            { "index": 15, "type": "String" },\n                            { "index": 16, "type": "String" },\n                            { "index": 17, "type": "String" },\n                            { "index": 18, "type": "String" },\n                            { "index": 19, "type": "String" },\n                            { "index": 20, "type": "String" },\n                            { "index": 21, "type": "Date", "format": "yyyy/MM/dd" },\n                            { "index": 22, "type": "Date", "format": "yyyy/MM/dd" },\n                            { "index": 23, "type": "String" },\n                            { "index": 24, "type": "Date", "format": "yyyy/MM/dd HH:mm:ss" },\n                            { "index": 25, "type": "String" },\n                            { "index": 26, "type": "String" },\n                            { "index": 27, "type": "String" },\n                            { "index": 28, "type": "String" },\n                            { "index": 29, "type": "String" },\n                            { "index": 30, "type": "Date", "format": "yyyy/MM/dd HH:mm:ss" },\n                            { "index": 31, "type": "Date", "format": "yyyy/MM/dd" },\n                            { "index": 32, "type": "String" },\n                            { "index": 33, "type": "String" },\n                            { "index": 34, "type": "String" },\n                            { "index": 35, "type": "String" },\n                            { "index": 36, "type": "String" },\n                            { "index": 37, "type": "String" },\n                            { "index": 38, "type": "String" },\n                            { "index": 39, "type": "String" },\n                            { "index": 40, "type": "string" },\n                            { "index": 41, "type": "Long" },\n                            { "index": 42, "type": "Long" }\n                        ],\n                    "skipHeader": "true",\n                      "fileDelimiter":","\n                    }\n                },\n                "writer": {\n                    "name": "mysqlwriter",\n                    "parameter": {\n                        "column": ["字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名"\n                        ],\n                        "preSql": [\n                            "truncate table 表名;"\n                        ],\n                        "connection": [\n                            {\n                               "jdbcUrl": "jdbc:mysql://ip:port/book?&useSSL=false&serverTimezone=Asia/Shanghai",\n                               "table": ["表名"]\n                            }\n                        ],\n                        "password": "xxxx",\n                        "username": "banana",\n                        "writeMode":"insert"\n                    }\n                }\n            }\n        ]\n    }\n}\n\n\n# datax-web 安装\n\n官方地址\n\n 1. 下载官方编译 tar 包：datax-web-2.1.2.tar.gz\n 2. 解压：tar -zxvf datax-web-2.1.2.tar.gz -C ../module/\n 3. 进入目录：cd ../module/datax-web-2.1.2\n 4. 安装：手动安装 ./bin/install.sh 不询问安装 ./bin/install.sh --force\n 5. 第四步或输入MySQL连接相关信息，若没有输入需要手动初始化 vim datax-web-2.1.2/modules/datax-admin/conf/bootstrap.properties 执行 /bin/db/datax-web.sql 脚本\n 6. 配置\n    * /modules/datax-admin/bin/env.properties 配置邮件服务(可跳过)\n    * /modules/datax-execute/bin/env.properties 指定PYTHON_PATH的路径\n 7. 命令：启动 ./bin/start-all.sh 停止 ./bin/stop-all.sh 单模块停止 ./bin/stop.sh -m {module_name}\n\n\n# 达梦DTS工具\n\n\n# SeaTunnel\n\n * 应用集成: 数据接口形式\n * 数据集成: 数据库数据同步形式\n\n与DataX相比：DataX只能单节点，存在瓶颈限制。而SeaTunnel是将配置转换为Spark或Flink代码，能借助集群的能力，不存在瓶颈。且拥有丰富的连接器。\n\nSeaTunnel专注于数据集成和数据同步，主要旨在解决数据集成领域的常见问题：\n\n * 数据源多样：常用数据源有数百种，版本不兼容。 随着新技术的出现，更多的数据源不断出现。 用户很难找到一个能够全面、快速支持这些数据源的工具。\n * 同步场景复杂：数据同步需要支持离线全量同步、离线增量同步、CDC、实时同步、全库同步等多种同步场景。\n * 资源需求高：现有的数据集成和数据同步工具往往需要大量的计算资源或JDBC连接资源来完成海量小表的实时同步。 这增加了企业的负担。\n * 缺乏质量和监控：数据集成和同步过程经常会出现数据丢失或重复的情况。 同步过程缺乏监控，无法直观了解任务过程中数据的真实情况。\n * 技术栈复杂：企业使用的技术组件不同，用户需要针对不同组件开发相应的同步程序来完成数据集成。\n * 管理和维护困难：受限于底层技术组件（Flink/Spark）不同，离线同步和实时同步往往需要分开开发和管理，增加了管理和维护的难度。\n\n\n# 数据迁移方案（结构化数据）\n\n# 选型\n\n需要考虑的点\n\n 1. 是否能操作数据库、服务器\n 2. 是否网络畅通\n 3. 是否允许停机\n 4. 是否异构数据源\n 5. 是否增量迁移（迁移一次、每天迁移还是实时同步）\n 6. 若增量，是否有时间字段等增量字段且正常维护\n 7. 若增量，删除数据是否是逻辑删除（该怎么迁移）\n\n参考图片（不大对，简单看看）\n\n# 调优\n\n工具调优\n\n 1. 内存配置\n 2. 多线程配置\n 3. 并行数配置\n 4. 分批提交\n 5. 其他方式（配置参数、优化网络?）\n\n数据库方面\n\n 1. 目标库删除索引（非唯一索引；最好空表，数据导完之后再建索引）\n 2. 目标库停用触发器\n 3. 其他：若事务过大必要时调整redo log大小',normalizedContent:'# 工具\n\n维度      kettle   datax       达梦dts          sqoop      seatunnel\n实时性     否        否           否              否          ✅（流批一体）\n图形化界面   ✅（强）     ❌（json配置）   ✅（向导式）         ❌（命令行）     ❌（yaml配置）\n性能      中等       高           中等             高          ✅（超高）\n扩展性     插件生态     插件架构        封闭生态           hadoop生态   连接器丰富\n易用性     ✅（低门槛）   ❌（复杂）       ✅（国产化）         中等         中等\n适用场景    复杂etl    离线迁移        与dm之间数据及对象迁移   hadoop集成   实时数据管道\n\n\n# kettle\n\n> etl（extract-transform-load的缩写，即数据抽取、转换、装载的过程），对于企业或行业应用来说，我们经常会遇到各种数据的处理，转换，迁移，所以了解并掌握一种etl工具的使用，必不可少。\n\n市面上常用的etl工具有很多，比如sqoop，datax，kettle，talend等，作为一个大数据工程师，我们最好要掌握其中的两到三种\n\n# 多表数据迁移\n\n 1. 创建数据源（源和目标）\n 2. 点击 工具 -> 向导 -> 复制多表向导\n 3. 选择 源数据库和目标数据库，选择需要迁移的表\n 4. 执行生成的job\n\n附：连接 oracle 19c正常，但是读取元数据报错（不支持的字符集），在 oracle官网 下载ojdbcx-full.tar.gz，取出其中的orai18n.jar，放入 kettle 的 lib 目录下。\n\n# 表名变量导出指定表\n\n通过循环表名变量，导出指定表数据（导出到 excel 时速度较慢）\n\n原文链接\n\n\n# sqoop\n\n导入\n\n# 全部导入\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t"\n\n# 导入指定列\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--columns id,sex \\\n--table staff\n\n# 查询导入\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--query \'select name,sex from staff where id <=1 and $conditions;\'\n\n# where关键字筛选\n$ bin/sqoop import \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--target-dir /user/company \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--table staff \\\n--where "id=1"\n\n# 导入到hive：第一步将数据导入到hdfs，第二步将导入到hdfs的数据迁移到hive仓库\nbin/sqoop import \\\n--connect jdbc:mysql://faded103:3306/db_sqoop_test \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--target-dir /user/db_sqoop_test \\\n--delete-target-dir \\\n--num-mappers 1 \\\n--fields-terminated-by "\\t" \\\n--hive-import \\\n--fields-terminated-by "\\t" \\\n--hive-overwrite \\\n--hive-table staff_hive\n\n\n导出\n\n# hdfs/hive到rdms\n$ bin/sqoop export \\\n--connect jdbc:mysql://linux01:3306/company \\\n--username root \\\n--password 123456 \\\n--table staff \\\n--num-mappers 1 \\\n--export-dir /user/hive/warehouse/staff_hive \\\n--input-fields-terminated-by "\\t"\n\n\n\n# datax\n\n# 安装\n\n * 下载 wget http://datax-opensource.oss-cn-hangzhou.aliyuncs.com/datax.tar.gz\n * 解压 tar -zxvf datax.tar.gz -c /opt/module\n * 依赖\n   * 安装jdk\n   * python\n\nsudo apt install python\n(一定要是python2(2.7+?)\n因为后面执行datax.py的时候，里面的python的print会执行不了，导致运行不成功，会提示你print语法要加括号，python2中加不加都行，python3中必须要加，否则报语法错。)\n\n\n* **apache maven 3.x**   \n\n\n下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.8.5/binaries/apache-maven-3.8.5-bin.tar.gz\n解压 tar -zxvf apache-maven-3.8.5-bin.tar.gz -c /opt/module/\n环境变量\nvim /etc/profile\n\nmaven_home=/opt/module/apache-maven-3.8.5\npath=${m2_home}/bin:${path}\n\nsource /etc/profile\n\n\n * jdk、python、maven都安装成功了，datax解压缩成功了，开始自检，进入bin目录，开始自检\n\npython datax.py ../job/job.json\n\n\n# 字段对应\n\n各个数据库和datax字段映射\n\n# 使用\n\n> 最开始时报错，然后考虑是不支持mysql8.0的原因，下载源码修改，由于依赖不全(下载jar包 安装到本地maven库也不行)，暂时搁置。\n> 然后考虑将mysqlwriter中mysql驱动换成8.0的驱动。\n> 还报错，是因为date日期格式的问题，需制定格式。 （换jar包解决问题）暂未发现其他问题，待补充\n\n点击查看\n\njson文件示例(csv文本到mysql)\n\n{\n    "job": {\n        "setting": {\n                "speed": {\n                        "channel": 3 \n                }\n        },\n        "content": [\n            {\n                "reader": {\n                    "name": "txtfilereader",\n                    "parameter": {\n                    "path": ["/home/banana/data/xxxxx.csv"],\n                    "encoding":"utf-8",\n                        "column": [\n                            { "index": 0, "type": "string" },\n                            { "index": 1, "type": "string" },\n                            { "index": 2, "type": "string" },\n                            { "index": 3, "type": "string" },\n                            { "index": 4, "type": "string" },\n                            { "index": 5, "type": "string" },\n                            { "index": 6, "type": "string" },\n                            { "index": 7, "type": "string" },\n                            { "index": 8, "type": "string" },\n                            { "index": 9, "type": "string" },\n                            { "index": 10, "type": "string" },\n                            { "index": 11, "type": "string" },\n                            { "index": 12, "type": "string" },\n                            { "index": 13, "type": "string" },\n                            { "index": 14, "type": "string" },\n                            { "index": 15, "type": "string" },\n                            { "index": 16, "type": "string" },\n                            { "index": 17, "type": "string" },\n                            { "index": 18, "type": "string" },\n                            { "index": 19, "type": "string" },\n                            { "index": 20, "type": "string" },\n                            { "index": 21, "type": "date", "format": "yyyy/mm/dd" },\n                            { "index": 22, "type": "date", "format": "yyyy/mm/dd" },\n                            { "index": 23, "type": "string" },\n                            { "index": 24, "type": "date", "format": "yyyy/mm/dd hh:mm:ss" },\n                            { "index": 25, "type": "string" },\n                            { "index": 26, "type": "string" },\n                            { "index": 27, "type": "string" },\n                            { "index": 28, "type": "string" },\n                            { "index": 29, "type": "string" },\n                            { "index": 30, "type": "date", "format": "yyyy/mm/dd hh:mm:ss" },\n                            { "index": 31, "type": "date", "format": "yyyy/mm/dd" },\n                            { "index": 32, "type": "string" },\n                            { "index": 33, "type": "string" },\n                            { "index": 34, "type": "string" },\n                            { "index": 35, "type": "string" },\n                            { "index": 36, "type": "string" },\n                            { "index": 37, "type": "string" },\n                            { "index": 38, "type": "string" },\n                            { "index": 39, "type": "string" },\n                            { "index": 40, "type": "string" },\n                            { "index": 41, "type": "long" },\n                            { "index": 42, "type": "long" }\n                        ],\n                    "skipheader": "true",\n                      "filedelimiter":","\n                    }\n                },\n                "writer": {\n                    "name": "mysqlwriter",\n                    "parameter": {\n                        "column": ["字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名","字段名"\n                        ],\n                        "presql": [\n                            "truncate table 表名;"\n                        ],\n                        "connection": [\n                            {\n                               "jdbcurl": "jdbc:mysql://ip:port/book?&usessl=false&servertimezone=asia/shanghai",\n                               "table": ["表名"]\n                            }\n                        ],\n                        "password": "xxxx",\n                        "username": "banana",\n                        "writemode":"insert"\n                    }\n                }\n            }\n        ]\n    }\n}\n\n\n# datax-web 安装\n\n官方地址\n\n 1. 下载官方编译 tar 包：datax-web-2.1.2.tar.gz\n 2. 解压：tar -zxvf datax-web-2.1.2.tar.gz -c ../module/\n 3. 进入目录：cd ../module/datax-web-2.1.2\n 4. 安装：手动安装 ./bin/install.sh 不询问安装 ./bin/install.sh --force\n 5. 第四步或输入mysql连接相关信息，若没有输入需要手动初始化 vim datax-web-2.1.2/modules/datax-admin/conf/bootstrap.properties 执行 /bin/db/datax-web.sql 脚本\n 6. 配置\n    * /modules/datax-admin/bin/env.properties 配置邮件服务(可跳过)\n    * /modules/datax-execute/bin/env.properties 指定python_path的路径\n 7. 命令：启动 ./bin/start-all.sh 停止 ./bin/stop-all.sh 单模块停止 ./bin/stop.sh -m {module_name}\n\n\n# 达梦dts工具\n\n\n# seatunnel\n\n * 应用集成: 数据接口形式\n * 数据集成: 数据库数据同步形式\n\n与datax相比：datax只能单节点，存在瓶颈限制。而seatunnel是将配置转换为spark或flink代码，能借助集群的能力，不存在瓶颈。且拥有丰富的连接器。\n\nseatunnel专注于数据集成和数据同步，主要旨在解决数据集成领域的常见问题：\n\n * 数据源多样：常用数据源有数百种，版本不兼容。 随着新技术的出现，更多的数据源不断出现。 用户很难找到一个能够全面、快速支持这些数据源的工具。\n * 同步场景复杂：数据同步需要支持离线全量同步、离线增量同步、cdc、实时同步、全库同步等多种同步场景。\n * 资源需求高：现有的数据集成和数据同步工具往往需要大量的计算资源或jdbc连接资源来完成海量小表的实时同步。 这增加了企业的负担。\n * 缺乏质量和监控：数据集成和同步过程经常会出现数据丢失或重复的情况。 同步过程缺乏监控，无法直观了解任务过程中数据的真实情况。\n * 技术栈复杂：企业使用的技术组件不同，用户需要针对不同组件开发相应的同步程序来完成数据集成。\n * 管理和维护困难：受限于底层技术组件（flink/spark）不同，离线同步和实时同步往往需要分开开发和管理，增加了管理和维护的难度。\n\n\n# 数据迁移方案（结构化数据）\n\n# 选型\n\n需要考虑的点\n\n 1. 是否能操作数据库、服务器\n 2. 是否网络畅通\n 3. 是否允许停机\n 4. 是否异构数据源\n 5. 是否增量迁移（迁移一次、每天迁移还是实时同步）\n 6. 若增量，是否有时间字段等增量字段且正常维护\n 7. 若增量，删除数据是否是逻辑删除（该怎么迁移）\n\n参考图片（不大对，简单看看）\n\n# 调优\n\n工具调优\n\n 1. 内存配置\n 2. 多线程配置\n 3. 并行数配置\n 4. 分批提交\n 5. 其他方式（配置参数、优化网络?）\n\n数据库方面\n\n 1. 目标库删除索引（非唯一索引；最好空表，数据导完之后再建索引）\n 2. 目标库停用触发器\n 3. 其他：若事务过大必要时调整redo log大小',charsets:{cjk:!0},lastUpdated:"2025/05/18, 02:30:32",lastUpdatedTimestamp:1747506632e3},{title:"Impala",frontmatter:{title:"Impala",date:"2024-07-27T23:52:53.000Z",permalink:"/pages/4d39ac/"},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/12.%20Impala/01.Impala.html",relativePath:"02.大数据/12. Impala/01.Impala.md",key:"v-599d1974",path:"/pages/4d39ac/",headers:[{level:2,title:"Impala",slug:"impala",normalizedTitle:"impala",charIndex:2},{level:3,title:"Impala 语句",slug:"impala-语句",normalizedTitle:"impala 语句",charIndex:13},{level:4,title:"Impala 基础语句",slug:"impala-基础语句",normalizedTitle:"impala 基础语句",charIndex:26},{level:4,title:"Impala 统计信息",slug:"impala-统计信息",normalizedTitle:"impala 统计信息",charIndex:281},{level:4,title:"Impala 元数据",slug:"impala-元数据",normalizedTitle:"impala 元数据",charIndex:660},{level:4,title:"Impala-Shell 传入参数",slug:"impala-shell-传入参数",normalizedTitle:"impala-shell 传入参数",charIndex:975},{level:3,title:"Impala 执行计划",slug:"impala-执行计划",normalizedTitle:"impala 执行计划",charIndex:1124},{level:4,title:"explain（执行前）",slug:"explain-执行前",normalizedTitle:"explain（执行前）",charIndex:1139},{level:4,title:"Summary（执行后）",slug:"summary-执行后",normalizedTitle:"summary（执行后）",charIndex:1308},{level:4,title:"Profile（执行后-更详细）",slug:"profile-执行后-更详细",normalizedTitle:"profile（执行后-更详细）",charIndex:1478}],headersStr:"Impala Impala 语句 Impala 基础语句 Impala 统计信息 Impala 元数据 Impala-Shell 传入参数 Impala 执行计划 explain（执行前） Summary（执行后） Profile（执行后-更详细）",content:"# Impala\n\n\n# Impala 语句\n\n# Impala 基础语句\n\n与 Hive 基本通用，包括建表语句、动态分区等\n\n-- 查看建表语句\nSHOW CREATE TABLE table_name;\n\n-- 分区信息\nshow partitions table_name;\n\n-- 查看表详细信息\ndescribe extended table_name;\nDESCRIBE FORMATTED table_name;\n\n-- 删除分区\nalter table table_name drop partition (ny='201901');\n\n\n# Impala 统计信息\n\n官网链接：impala统计信息\n\n-- 查看表统计信息\nshow table[COLUMN] stats table_name;\n\n-- 收集统计信息（不能对同一个表执行两种统计信息收集，若要混用，需先删除统计信息，重新收集）\nCOMPUTE STATS table_name;  -- 全表统计信息计算（不带分区的表）\nCOMPUTE INCREMENTAL STATS table_name;  -- 全表统计信息计算（带分区的表，若表实际未分区则实际执行 COMPUTE STATS）\nCOMPUTE INCREMENTAL STATS table_name PARTITION(year=2009, month>1);  -- 分区统计信息计算\n\n-- 删除表统计信息\nDROP STATS table_name;\n\n\n# Impala 元数据\n\n加载元数据参数\n\n-- 直接把元数据重置回未加载状态，下次使用时重新加载\nINVALIDATE METADATA table_name;\n\n-- 让 Impala 增量更新指定表的元数据\nREFRESH table_name;\n\n-- 让 impala 感知到在 Hive 创建的函数\nREFRESH FUNCTIONS db_name;\n\n-- 启动参数：控制 Impala 在何时进行 metadata 的 load（为 true 时在后台自动加载元数据：缺点是元数据常驻内存，比较占用内存，优点是不用在查询时加载元数据）\nload_catalog_in_background = true;\n\n\n# Impala-Shell 传入参数\n\n# impala 执行 SQL 文件中语句，可传入参数\nny=`date -d \"$(date +%Y-%m-01) -1 month\" +%Y%m`\nimpala-shell --var=NY=${ny} -f impala_insert.sql\n\n\n\n# Impala 执行计划\n\n# explain（执行前）\n\n 1. 使用 explain 语句生成的执行计划，实际并未执行 sql 语句（根据统计信息生成，统计信息准确与否会生成不同的执行计划，尤其影响带关联的 SQL 执行效率）\n 2. 预计使用内存情况、是否缺少表统计信息（）、扫描分区数、扫描文件数、扫描文件大小、关联方式（广播小表、混洗哈希）、排序等信息\n\n# Summary（执行后）\n\n 1. 执行后生成\n 2. 可以看到每个步骤资源使用情况，比如：\n    * 使用了几个节点\n    * 计划读取大小和实际读取文件大小\n    * 计划读取行数（为 -1 时缺乏表统计信息）和实际读取行数\n    * 平均时间和最大时间：若有一个节点耗时比较长，说明可能出现数据倾斜或节点资源不足等情况\n\n# Profile（执行后-更详细）\n\n 1. 执行后生成，包含 Expalin、Summary 等信息且更详细\n 2. Query Compilation 为编译阶段耗时，Query Timeline 为查询阶段耗时\n 3. 查看各个节点的详细信息：使用字符串“id=0”来搜索Profile文件，“0”是Summary部分“00:SCAN HDFS”中每一行开头的操作编号。",normalizedContent:"# impala\n\n\n# impala 语句\n\n# impala 基础语句\n\n与 hive 基本通用，包括建表语句、动态分区等\n\n-- 查看建表语句\nshow create table table_name;\n\n-- 分区信息\nshow partitions table_name;\n\n-- 查看表详细信息\ndescribe extended table_name;\ndescribe formatted table_name;\n\n-- 删除分区\nalter table table_name drop partition (ny='201901');\n\n\n# impala 统计信息\n\n官网链接：impala统计信息\n\n-- 查看表统计信息\nshow table[column] stats table_name;\n\n-- 收集统计信息（不能对同一个表执行两种统计信息收集，若要混用，需先删除统计信息，重新收集）\ncompute stats table_name;  -- 全表统计信息计算（不带分区的表）\ncompute incremental stats table_name;  -- 全表统计信息计算（带分区的表，若表实际未分区则实际执行 compute stats）\ncompute incremental stats table_name partition(year=2009, month>1);  -- 分区统计信息计算\n\n-- 删除表统计信息\ndrop stats table_name;\n\n\n# impala 元数据\n\n加载元数据参数\n\n-- 直接把元数据重置回未加载状态，下次使用时重新加载\ninvalidate metadata table_name;\n\n-- 让 impala 增量更新指定表的元数据\nrefresh table_name;\n\n-- 让 impala 感知到在 hive 创建的函数\nrefresh functions db_name;\n\n-- 启动参数：控制 impala 在何时进行 metadata 的 load（为 true 时在后台自动加载元数据：缺点是元数据常驻内存，比较占用内存，优点是不用在查询时加载元数据）\nload_catalog_in_background = true;\n\n\n# impala-shell 传入参数\n\n# impala 执行 sql 文件中语句，可传入参数\nny=`date -d \"$(date +%y-%m-01) -1 month\" +%y%m`\nimpala-shell --var=ny=${ny} -f impala_insert.sql\n\n\n\n# impala 执行计划\n\n# explain（执行前）\n\n 1. 使用 explain 语句生成的执行计划，实际并未执行 sql 语句（根据统计信息生成，统计信息准确与否会生成不同的执行计划，尤其影响带关联的 sql 执行效率）\n 2. 预计使用内存情况、是否缺少表统计信息（）、扫描分区数、扫描文件数、扫描文件大小、关联方式（广播小表、混洗哈希）、排序等信息\n\n# summary（执行后）\n\n 1. 执行后生成\n 2. 可以看到每个步骤资源使用情况，比如：\n    * 使用了几个节点\n    * 计划读取大小和实际读取文件大小\n    * 计划读取行数（为 -1 时缺乏表统计信息）和实际读取行数\n    * 平均时间和最大时间：若有一个节点耗时比较长，说明可能出现数据倾斜或节点资源不足等情况\n\n# profile（执行后-更详细）\n\n 1. 执行后生成，包含 expalin、summary 等信息且更详细\n 2. query compilation 为编译阶段耗时，query timeline 为查询阶段耗时\n 3. 查看各个节点的详细信息：使用字符串“id=0”来搜索profile文件，“0”是summary部分“00:scan hdfs”中每一行开头的操作编号。",charsets:{cjk:!0},lastUpdated:"2024/07/28, 01:18:14",lastUpdatedTimestamp:1722100694e3},{title:"docker",frontmatter:{title:"docker",date:"2022-03-02T21:08:40.000Z",permalink:"/pages/d89b45/",categories:["大数据","其他"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/20.%E5%85%B6%E4%BB%96/01.docker.html",relativePath:"02.大数据/20.其他/01.docker.md",key:"v-0c3bcc96",path:"/pages/d89b45/",headers:[{level:2,title:"概述",slug:"概述",normalizedTitle:"概述",charIndex:2},{level:2,title:"docker 命令",slug:"docker-命令",normalizedTitle:"docker 命令",charIndex:367},{level:2,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:2697},{level:2,title:"安装docker（阿里云）",slug:"安装docker-阿里云",normalizedTitle:"安装docker（阿里云）",charIndex:3105},{level:3,title:"卸载原来安装的Docker",slug:"卸载原来安装的docker",normalizedTitle:"卸载原来安装的docker",charIndex:3165},{level:3,title:"安装DockerCE",slug:"安装dockerce",normalizedTitle:"安装dockerce",charIndex:3430},{level:3,title:"配置镜像",slug:"配置镜像",normalizedTitle:"配置镜像",charIndex:3813},{level:3,title:"使用Docker安装Nginx服务",slug:"使用docker安装nginx服务",normalizedTitle:"使用docker安装nginx服务",charIndex:4203},{level:3,title:"搭建Hadoop",slug:"搭建hadoop",normalizedTitle:"搭建hadoop",charIndex:4547}],headersStr:"概述 docker 命令 其他 安装docker（阿里云） 卸载原来安装的Docker 安装DockerCE 配置镜像 使用Docker安装Nginx服务 搭建Hadoop",content:'# 概述\n\n>  传说 go 语言天生支持高并发（执行速度接近C,网络服务接近Nginx）。\n>  Golang实现了 CSP 并发模型做为并发基础，底层使用goroutine做为并发实体，goroutine非常轻量级可以创建几十万个实体。实体间通过 channel 继续匿名消息传递使之解耦，在语言层面实现了自动调度，这样屏蔽了很多内部细节，对外提供简单的语法关键字，大大简化了并发编程的思维转换和管理线程的复杂性。\n>  一句话总结：go语言在设计的时候从关键字层面实现了多协程开发，好像语言天生支持高并发一样。\n\n原文链接\n\nDocker采用的是Go语言编写的，该语言一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，常用于Web程序开发，并且具有成熟的Web开发框架，如Beego、Gin、Iris等等。\n\n\n# docker 命令\n\nDocker仓库\n\ndocker 命令可以通过 --help 进行查看，比如docker --help、docker run --help等\n\n 1.  docker version 查看docker版本信息\n\n 2.  docker info 查看系统信息，包括当前系统 docker 镜像和容器的数量\n\n 3.  docker images 查看已下载镜像\n\n 4.  docker search <镜像名> 从中央仓库搜索镜像\n\n 5.  docker pull 镜像名<:tags> 从仓库拉取。比如下载Tomcat 8.0 镜像：docker pull tomcat:8.0\n\n 6.  删除镜像\n     \n     * docker rmi repository<:tag> # 根据名称和版本删除，如果不指定tag，默认是lastest\n     * docker rmi IMAGE_ID # 根据镜像id删除\n     * docker rmi IMAGE_ID1 IMAGE_ID2 ... # 批量删除\n\n 7.  docker run <参数> 镜像id|镜像名称 运行（从镜像到容器）\n     参数：\n     \n     * --name: 为启动容器指定一个名字，注意有两个 --。\n     * -d：表示以后台方式运行,并返回容器ID。\n     * -i：以交互模式运行容器。\n     * -t：为容器重新分配一个伪输入终端。\n     * -p：主机端口:容器端口 | 容器端口 | ip:主机端口:容器端口。\n     * -P：随机端口映射，容器内部端口随机映射到主机端口。\n     * --link=[]：添加链接到另一个容器。\n     \n     比如：docker run -itd --name MyCentos7 centos:7、docker run --rm -it --cap-add SYS_ADMIN MyCentos7 sh、docker run -d -p 8888:8888 sqlflow/sqlflow:latest\n\n 8.  进入容器\n     \n     * docker run -it [镜像id|镜像名] /bin/bash 使用run方式在创建时进入\n     * docker attach --sig-proxy=false 容器名称|容器ID 使用 attach 命令，进入已启动的容器\n     \n     > 直接进入 容器启动命令的终端，不会启动新进程，多个attach连接共享容器屏幕，参数：--sig-proxy=false 确保CTRL-D或CTRL-C不会关闭容器\n     \n     * docker exec -it 容器名称|容器ID /bin/bash 使用 exec 命令，进入已启动的容器（进入容器后开启一个新的终端，可以在里面进行操作）\n\n 9.  查看所有运行的容器\n     \n     * docker ps 查看正在运行的容器\n     * docker ps -q 查看正在运行的容器的ID\n     * docker ps -a 查看正在运行+历史运行过的容器\n     * docker ps -s 显示运行容器总文件大小\n\n 10. 停止与删除容器\n     \n     * docker stop【start、restart】 容器名|容器id 停止一个运行中的容器\n     * docker kill 容器名|容器id 杀掉一个运行中的容器\n     * docker rm 容器名|容器id 删除一个已停止的容器\n     * docker rm -f 容器名|容器id 删除一个运行中的容器\n\n 11. docker logs <参数>容器名|容器id 查看容器日志\n     参数：\n     \n     * -f 跟踪日志输出\n     * -t：显示时间戳\n     * --tail N：仅列出最后N条日志\n\n 12. docker top 容器ID|容器名 查看容器内进程\n\n 13. docker inspect 容器ID|容器名 查看容器信息\n\n 14. 主机和容器之间数据复制\n     \n     * docker cp 容器名|容器ID:/[container_path] [local_path] 将容器中的文件copy至本地路径\n     * docker cp [local_path] 容器名|容器ID:/[container_path] 将主机文件copy至容器\n     * docker cp [local_path] rabbitmq:/[container_path] 将主机文件copy至容器，目录重命名为[container_path]（注意与非重命名copy的区别）\n\n 15. 容器打包镜像，提交仓库\n     \n     * docker commit -a "作者" -m "简要说明" 容器ID 想要打包成的镜像名称:版本号 将容器打包成镜像\n     * 去docker官网（https://hub.docker.com/）注册账号，并且建立仓库\n     * docker login 从Linux登录，输入用户名密码\n     * docker tag 本地的镜像名 docker用户名/远程仓库名 设置镜像标签\n     * docker push docker用户名/远程仓库名 推送（上传）镜像\n\n原文链接\n\n\n# 其他\n\n * Docker-Compose 学习\n * DockerFile 学习\n * 网络隔离、独立IP设置（使Docker容器拥有可被宿主机以外的机器直接访问的独立IP）、网桥命名空间、创建网桥\n * pipework 网络工具使用（打通容器间的网络）\n\n点击查看\n\n#停止docker\nsystemctl stop docker\n#docker0\nip link set dev docker0 down\n#删除docker0网桥\nbrctl delbr docker0\n#新增一个docker0网桥\nbrctl addbr docker0\n#增加网卡(这里ip也完全使用这个)\nip addr add 172.16.10.0/24 dev docker0\n#启用网卡\nip link set dev docker0 up\n#重启docker服务\nsystemctl restart docker\n\n\n\n# 安装docker（阿里云）\n\n----------------------------------------\n\n\n# 卸载原来安装的Docker\n\n查看当前docker状态\nsystemctl status docker\n\n如果是运行状态则停掉\nsystemctl stop docker\n\n查看yum安装的docker文件包\nyum list installed |grep docker\n\n查看docker相关的rpm源文件\nrpm -qa |grep docker\n\n删除所有安装的docker文件包\nyum -y remove docker.x86_64\n\n删除docker的镜像文件，默认在/var/lib/docker目录下\n\n\n\n# 安装DockerCE\n\nDocker有两个分支版本：Docker CE和Docker EE，即社区版和企业版。本教程基于CentOS 7安装Docker CE。\n\n 1. 安装Docker的依赖库。 yum install -y yum-utils device-mapper-persistent-data lvm2\n\n 2. 添加Docker CE的软件源信息 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n 3. 安装Docker CE\n\nyum makecache fast\nyum -y install docker-ce\n\n\n 4. 启动Docker服务 systemctl start docker\n\n\n# 配置镜像\n\nDocker的默认官方远程仓库是hub.docker.com，由于网络原因，下载一个Docker官方镜像可能会需要很长的时间，甚至下载失败。为此，阿里云容器镜像服务ACR提供了官方的镜像站点，从而加速官方镜像的下载。下面介绍如何使用阿里云镜像仓库。\n\n将下面命令中的镜像仓库地址https://kqh8****.mirror.aliyuncs.com替换为阿里云为您提供的专属镜像加速地址。\n\ntee /etc/docker/daemon.json <<-\'EOF\'\n{\n  "registry-mirrors": ["https://kqh8****.mirror.aliyuncs.com"]\n}\nEOF\n\n\n重新加载服务配置文件。 systemctl daemon-reload\n\n重启Docker服务 systemctl restart docker\n\n\n# 使用Docker安装Nginx服务\n\n 1. 查看Docker镜像仓库中Nginx的可用版本。 docker search nginx\n 2. 拉取最新版的Nginx镜像。 docker pull nginx:latest\n 3. 查看本地镜像 docker images\n 4. 运行容器 docker run --name nginx-test -p 8080:80 -d nginx\n\n命令参数说明：\n\n--name nginx-test：容器名称。\n-p 8080:80： 端口进行映射，将本地8080端口映射到容器内部的80端口。\n-d nginx： 设置容器在后台一直运行。\n\n\n 5. 在浏览器地址栏输入http://<ECS公网地址>:8080访问Nginx服务\n\n\n# 搭建Hadoop\n\n下载centos镜像\ndocker pull centos\n\n后创建一个容器准备安装jdk、hadoop作为基础版本\ndocker run -it --name hadoop101 -h hadoop 5d0da3dc9764 bash\n\n安装一下vim（好像安装了其他基础东西）\nyum install vim\nFailed to set locale, defaulting to C.UTF-8\nCentOS Linux 8 - AppStream                                                                                                               2.6 MB/s | 8.1 MB     00:03    \nCentOS Linux 8 - BaseOS                                                                                                                  115 kB/s | 3.5 MB     00:31    \nCentOS Linux 8 - Extras\n\nyum install openssh-server\n     yum install rsync\n      yum install iputils-ping\n              yum install net-tools             ifconfig\n[root@hadoop opt]# mkdir /opt/modules\n[root@hadoop opt]# mkdir /opt/softwares\n重启已停止的容器\n[root@banana software]# docker ps -a\n[root@banana software]# docker start hadoop101\n拷贝进容器\n docker cp ./env.tar.gz hadoop101:/opt/softwares\n 进入容器\n docker exec -it hadoop101 /bin/bash\n 容器内解压\n[root@hadoop softwares]# tar -zxvf env.tar.gz -C /opt/modules/\n[root@hadoop modules]# vim /root/.bashrc\n[root@hadoop modules]# source /root/.bashrc\n[root@hadoop modules]# echo $JAVA_HOME\n容器转为镜像\n\n复制镜像\ndocker export hadoop_base > hadoop_base.tar导出容器\ndocker import hadoop_base.tar hadoop导入容器为新的hadoop镜像\ndocker images查看一下现在有的镜像\n\n启动三个容器作为hadoop集群\ndocker run -it -p 50070:50070 --name hadoop102 -h hadoop102 hadoop101 bash\ndocker run -it -p 8088:8088 --name hadoop103 -h hadoop103 hadoop101 bash\ndocker run -it --name hadoop104 -h hadoop104 hadoop101 bash\n\nvim /etc/hosts\n172.17.0.2 hadoop102\n172.17.0.3 hadoop103\n172.17.0.4 hadoop104\n修改完主机映射 互相ping一下查看是否网络互通\n\n配置免密登录\nssh-keygen -t rsa  # 生成密钥公钥\n公钥发送到免密登录的机器上 之前ssh没安装上？（yum -y install openssh-clients）\n    ssh-copy-id hadoop102 \nssh-copy-id hadoop103\nssh-copy-id hadoop104\n',normalizedContent:'# 概述\n\n>  传说 go 语言天生支持高并发（执行速度接近c,网络服务接近nginx）。\n>  golang实现了 csp 并发模型做为并发基础，底层使用goroutine做为并发实体，goroutine非常轻量级可以创建几十万个实体。实体间通过 channel 继续匿名消息传递使之解耦，在语言层面实现了自动调度，这样屏蔽了很多内部细节，对外提供简单的语法关键字，大大简化了并发编程的思维转换和管理线程的复杂性。\n>  一句话总结：go语言在设计的时候从关键字层面实现了多协程开发，好像语言天生支持高并发一样。\n\n原文链接\n\ndocker采用的是go语言编写的，该语言一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言，常用于web程序开发，并且具有成熟的web开发框架，如beego、gin、iris等等。\n\n\n# docker 命令\n\ndocker仓库\n\ndocker 命令可以通过 --help 进行查看，比如docker --help、docker run --help等\n\n 1.  docker version 查看docker版本信息\n\n 2.  docker info 查看系统信息，包括当前系统 docker 镜像和容器的数量\n\n 3.  docker images 查看已下载镜像\n\n 4.  docker search <镜像名> 从中央仓库搜索镜像\n\n 5.  docker pull 镜像名<:tags> 从仓库拉取。比如下载tomcat 8.0 镜像：docker pull tomcat:8.0\n\n 6.  删除镜像\n     \n     * docker rmi repository<:tag> # 根据名称和版本删除，如果不指定tag，默认是lastest\n     * docker rmi image_id # 根据镜像id删除\n     * docker rmi image_id1 image_id2 ... # 批量删除\n\n 7.  docker run <参数> 镜像id|镜像名称 运行（从镜像到容器）\n     参数：\n     \n     * --name: 为启动容器指定一个名字，注意有两个 --。\n     * -d：表示以后台方式运行,并返回容器id。\n     * -i：以交互模式运行容器。\n     * -t：为容器重新分配一个伪输入终端。\n     * -p：主机端口:容器端口 | 容器端口 | ip:主机端口:容器端口。\n     * -p：随机端口映射，容器内部端口随机映射到主机端口。\n     * --link=[]：添加链接到另一个容器。\n     \n     比如：docker run -itd --name mycentos7 centos:7、docker run --rm -it --cap-add sys_admin mycentos7 sh、docker run -d -p 8888:8888 sqlflow/sqlflow:latest\n\n 8.  进入容器\n     \n     * docker run -it [镜像id|镜像名] /bin/bash 使用run方式在创建时进入\n     * docker attach --sig-proxy=false 容器名称|容器id 使用 attach 命令，进入已启动的容器\n     \n     > 直接进入 容器启动命令的终端，不会启动新进程，多个attach连接共享容器屏幕，参数：--sig-proxy=false 确保ctrl-d或ctrl-c不会关闭容器\n     \n     * docker exec -it 容器名称|容器id /bin/bash 使用 exec 命令，进入已启动的容器（进入容器后开启一个新的终端，可以在里面进行操作）\n\n 9.  查看所有运行的容器\n     \n     * docker ps 查看正在运行的容器\n     * docker ps -q 查看正在运行的容器的id\n     * docker ps -a 查看正在运行+历史运行过的容器\n     * docker ps -s 显示运行容器总文件大小\n\n 10. 停止与删除容器\n     \n     * docker stop【start、restart】 容器名|容器id 停止一个运行中的容器\n     * docker kill 容器名|容器id 杀掉一个运行中的容器\n     * docker rm 容器名|容器id 删除一个已停止的容器\n     * docker rm -f 容器名|容器id 删除一个运行中的容器\n\n 11. docker logs <参数>容器名|容器id 查看容器日志\n     参数：\n     \n     * -f 跟踪日志输出\n     * -t：显示时间戳\n     * --tail n：仅列出最后n条日志\n\n 12. docker top 容器id|容器名 查看容器内进程\n\n 13. docker inspect 容器id|容器名 查看容器信息\n\n 14. 主机和容器之间数据复制\n     \n     * docker cp 容器名|容器id:/[container_path] [local_path] 将容器中的文件copy至本地路径\n     * docker cp [local_path] 容器名|容器id:/[container_path] 将主机文件copy至容器\n     * docker cp [local_path] rabbitmq:/[container_path] 将主机文件copy至容器，目录重命名为[container_path]（注意与非重命名copy的区别）\n\n 15. 容器打包镜像，提交仓库\n     \n     * docker commit -a "作者" -m "简要说明" 容器id 想要打包成的镜像名称:版本号 将容器打包成镜像\n     * 去docker官网（https://hub.docker.com/）注册账号，并且建立仓库\n     * docker login 从linux登录，输入用户名密码\n     * docker tag 本地的镜像名 docker用户名/远程仓库名 设置镜像标签\n     * docker push docker用户名/远程仓库名 推送（上传）镜像\n\n原文链接\n\n\n# 其他\n\n * docker-compose 学习\n * dockerfile 学习\n * 网络隔离、独立ip设置（使docker容器拥有可被宿主机以外的机器直接访问的独立ip）、网桥命名空间、创建网桥\n * pipework 网络工具使用（打通容器间的网络）\n\n点击查看\n\n#停止docker\nsystemctl stop docker\n#docker0\nip link set dev docker0 down\n#删除docker0网桥\nbrctl delbr docker0\n#新增一个docker0网桥\nbrctl addbr docker0\n#增加网卡(这里ip也完全使用这个)\nip addr add 172.16.10.0/24 dev docker0\n#启用网卡\nip link set dev docker0 up\n#重启docker服务\nsystemctl restart docker\n\n\n\n# 安装docker（阿里云）\n\n----------------------------------------\n\n\n# 卸载原来安装的docker\n\n查看当前docker状态\nsystemctl status docker\n\n如果是运行状态则停掉\nsystemctl stop docker\n\n查看yum安装的docker文件包\nyum list installed |grep docker\n\n查看docker相关的rpm源文件\nrpm -qa |grep docker\n\n删除所有安装的docker文件包\nyum -y remove docker.x86_64\n\n删除docker的镜像文件，默认在/var/lib/docker目录下\n\n\n\n# 安装dockerce\n\ndocker有两个分支版本：docker ce和docker ee，即社区版和企业版。本教程基于centos 7安装docker ce。\n\n 1. 安装docker的依赖库。 yum install -y yum-utils device-mapper-persistent-data lvm2\n\n 2. 添加docker ce的软件源信息 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n\n 3. 安装docker ce\n\nyum makecache fast\nyum -y install docker-ce\n\n\n 4. 启动docker服务 systemctl start docker\n\n\n# 配置镜像\n\ndocker的默认官方远程仓库是hub.docker.com，由于网络原因，下载一个docker官方镜像可能会需要很长的时间，甚至下载失败。为此，阿里云容器镜像服务acr提供了官方的镜像站点，从而加速官方镜像的下载。下面介绍如何使用阿里云镜像仓库。\n\n将下面命令中的镜像仓库地址https://kqh8****.mirror.aliyuncs.com替换为阿里云为您提供的专属镜像加速地址。\n\ntee /etc/docker/daemon.json <<-\'eof\'\n{\n  "registry-mirrors": ["https://kqh8****.mirror.aliyuncs.com"]\n}\neof\n\n\n重新加载服务配置文件。 systemctl daemon-reload\n\n重启docker服务 systemctl restart docker\n\n\n# 使用docker安装nginx服务\n\n 1. 查看docker镜像仓库中nginx的可用版本。 docker search nginx\n 2. 拉取最新版的nginx镜像。 docker pull nginx:latest\n 3. 查看本地镜像 docker images\n 4. 运行容器 docker run --name nginx-test -p 8080:80 -d nginx\n\n命令参数说明：\n\n--name nginx-test：容器名称。\n-p 8080:80： 端口进行映射，将本地8080端口映射到容器内部的80端口。\n-d nginx： 设置容器在后台一直运行。\n\n\n 5. 在浏览器地址栏输入http://<ecs公网地址>:8080访问nginx服务\n\n\n# 搭建hadoop\n\n下载centos镜像\ndocker pull centos\n\n后创建一个容器准备安装jdk、hadoop作为基础版本\ndocker run -it --name hadoop101 -h hadoop 5d0da3dc9764 bash\n\n安装一下vim（好像安装了其他基础东西）\nyum install vim\nfailed to set locale, defaulting to c.utf-8\ncentos linux 8 - appstream                                                                                                               2.6 mb/s | 8.1 mb     00:03    \ncentos linux 8 - baseos                                                                                                                  115 kb/s | 3.5 mb     00:31    \ncentos linux 8 - extras\n\nyum install openssh-server\n     yum install rsync\n      yum install iputils-ping\n              yum install net-tools             ifconfig\n[root@hadoop opt]# mkdir /opt/modules\n[root@hadoop opt]# mkdir /opt/softwares\n重启已停止的容器\n[root@banana software]# docker ps -a\n[root@banana software]# docker start hadoop101\n拷贝进容器\n docker cp ./env.tar.gz hadoop101:/opt/softwares\n 进入容器\n docker exec -it hadoop101 /bin/bash\n 容器内解压\n[root@hadoop softwares]# tar -zxvf env.tar.gz -c /opt/modules/\n[root@hadoop modules]# vim /root/.bashrc\n[root@hadoop modules]# source /root/.bashrc\n[root@hadoop modules]# echo $java_home\n容器转为镜像\n\n复制镜像\ndocker export hadoop_base > hadoop_base.tar导出容器\ndocker import hadoop_base.tar hadoop导入容器为新的hadoop镜像\ndocker images查看一下现在有的镜像\n\n启动三个容器作为hadoop集群\ndocker run -it -p 50070:50070 --name hadoop102 -h hadoop102 hadoop101 bash\ndocker run -it -p 8088:8088 --name hadoop103 -h hadoop103 hadoop101 bash\ndocker run -it --name hadoop104 -h hadoop104 hadoop101 bash\n\nvim /etc/hosts\n172.17.0.2 hadoop102\n172.17.0.3 hadoop103\n172.17.0.4 hadoop104\n修改完主机映射 互相ping一下查看是否网络互通\n\n配置免密登录\nssh-keygen -t rsa  # 生成密钥公钥\n公钥发送到免密登录的机器上 之前ssh没安装上？（yum -y install openssh-clients）\n    ssh-copy-id hadoop102 \nssh-copy-id hadoop103\nssh-copy-id hadoop104\n',charsets:{cjk:!0},lastUpdated:"2025/05/12, 13:54:05",lastUpdatedTimestamp:1747029245e3},{title:"调度工具",frontmatter:{title:"调度工具",date:"2022-02-28T10:14:49.000Z",permalink:"/pages/a04438/",categories:["大数据","调度"],tags:[null]},regularPath:"/02.%E5%A4%A7%E6%95%B0%E6%8D%AE/16.%E8%B0%83%E5%BA%A6/01.%E8%B0%83%E5%BA%A6%E5%B7%A5%E5%85%B7.html",relativePath:"02.大数据/16.调度/01.调度工具.md",key:"v-a5e93828",path:"/pages/a04438/",headers:[{level:3,title:"crontab",slug:"crontab",normalizedTitle:"crontab",charIndex:2},{level:3,title:"oozie",slug:"oozie",normalizedTitle:"oozie",charIndex:56},{level:3,title:"Azkaban",slug:"azkaban",normalizedTitle:"azkaban",charIndex:102},{level:3,title:"dolphin scheduler",slug:"dolphin-scheduler",normalizedTitle:"dolphin scheduler",charIndex:266},{level:3,title:"XXL-JOB",slug:"xxl-job",normalizedTitle:"xxl-job",charIndex:288},{level:3,title:"airflow",slug:"airflow",normalizedTitle:"airflow",charIndex:300}],headersStr:"crontab oozie Azkaban dolphin scheduler XXL-JOB airflow",content:"# crontab\n\nLinux 自带命令，使用方式简单，适合不是非常复杂的场景，比如只按照时间来调度\n\n\n# oozie\n\nHadoop 自带的开源调度系统，使用方式比较复杂，适合大型项目场景\n\n\n# Azkaban\n\n一个开源调度系统，使用方式比较简单，适合中小型项目场景\n\n> Azkaban是由Linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。\n\n\n# dolphin scheduler\n\n\n# XXL-JOB\n\n\n# airflow",normalizedContent:"# crontab\n\nlinux 自带命令，使用方式简单，适合不是非常复杂的场景，比如只按照时间来调度\n\n\n# oozie\n\nhadoop 自带的开源调度系统，使用方式比较复杂，适合大型项目场景\n\n\n# azkaban\n\n一个开源调度系统，使用方式比较简单，适合中小型项目场景\n\n> azkaban是由linkedin开源的一个批量工作流任务调度器。用于在一个工作流内以一个特定的顺序运行一组工作和流程。azkaban定义了一种kv文件格式来建立任务之间的依赖关系，并提供一个易于使用的web用户界面维护和跟踪你的工作流。\n\n\n# dolphin scheduler\n\n\n# xxl-job\n\n\n# airflow",charsets:{cjk:!0},lastUpdated:"2024/06/18, 17:45:10",lastUpdatedTimestamp:171870391e4},{title:"系统函数篇",frontmatter:{title:"系统函数篇",date:"2022-03-02T17:21:38.000Z",permalink:"/pages/b5c27a/",categories:["数据库","Oracle"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/01.Oracle/02.%E7%B3%BB%E7%BB%9F%E5%87%BD%E6%95%B0%E7%AF%87.html",relativePath:"03.数据库/01.Oracle/02.系统函数篇.md",key:"v-f125018c",path:"/pages/b5c27a/",headers:[{level:2,title:"Oracle",slug:"oracle",normalizedTitle:"oracle",charIndex:2},{level:3,title:"正则替换函数REGEXP_REPLACE（不规则日期修改）",slug:"正则替换函数regexp-replace-不规则日期修改",normalizedTitle:"正则替换函数regexp_replace（不规则日期修改）",charIndex:55},{level:3,title:"聚合函数lag/lead",slug:"聚合函数lag-lead",normalizedTitle:"聚合函数lag/lead",charIndex:1618},{level:3,title:"聚合函数wm_concat",slug:"聚合函数wm-concat",normalizedTitle:"聚合函数wm_concat",charIndex:1903},{level:3,title:"单行函数L[R]PAD",slug:"单行函数l-r-pad",normalizedTitle:"单行函数l[r]pad",charIndex:2455},{level:3,title:"单行函数MD5加密",slug:"单行函数md5加密",normalizedTitle:"单行函数md5加密",charIndex:2693},{level:3,title:"SYS.UTLMATCH.editdistance_similarity 文本相似度计算",slug:"sys-utl-match-edit-distance-similarity-文本相似度计算",normalizedTitle:"sys.utlmatch.editdistance_similarity 文本相似度计算",charIndex:null},{level:3,title:"oracle实现数据炸裂效果",slug:"oracle实现数据炸裂效果",normalizedTitle:"oracle实现数据炸裂效果",charIndex:3454},{level:3,title:"oracle行列转换",slug:"oracle行列转换",normalizedTitle:"oracle行列转换",charIndex:3937},{level:4,title:"行转列",slug:"行转列",normalizedTitle:"行转列",charIndex:3951},{level:4,title:"列转行",slug:"列转行",normalizedTitle:"列转行",charIndex:4136},{level:3,title:"自定义函数(存储过程)",slug:"自定义函数-存储过程",normalizedTitle:"自定义函数(存储过程)",charIndex:4239},{level:3,title:"MERGE INTO 语法",slug:"merge-into-语法",normalizedTitle:"merge into 语法",charIndex:4764},{level:3,title:"不常用语法",slug:"不常用语法",normalizedTitle:"不常用语法",charIndex:5242},{level:4,title:"触发器",slug:"触发器",normalizedTitle:"触发器",charIndex:5251},{level:4,title:"出包含 CLOB 字段的脚本",slug:"出包含-clob-字段的脚本",normalizedTitle:"出包含 clob 字段的脚本",charIndex:5756}],headersStr:"Oracle 正则替换函数REGEXP_REPLACE（不规则日期修改） 聚合函数lag/lead 聚合函数wm_concat 单行函数L[R]PAD 单行函数MD5加密 SYS.UTLMATCH.editdistance_similarity 文本相似度计算 oracle实现数据炸裂效果 oracle行列转换 行转列 列转行 自定义函数(存储过程) MERGE INTO 语法 不常用语法 触发器 出包含 CLOB 字段的脚本",content:"# Oracle\n\n----------------------------------------\n\n\n# 正则替换函数REGEXP_REPLACE（不规则日期修改）\n\n日期格式检查\n\n-- 检查大致格式\n-- ^\\d{4}([-/])\\d{2}([-/])\\d{2}(\\s+\\d{2}:\\d{2}:\\d{2}){0,1}$'\n\n-- 检查部分值（部分月份、日期、时分秒）\n-- ^\\d{4}[-/.](0[1-9]|1[0-2])[-/.]([012][0-9]|3[0-1])\\s+([01][0-9]|2[0-3]):[0-5]\\d:[0-5]\\d$\n\n\n01-1月 -19\n\n-- 查看NLS_TIMESTAMP_FORMAT和NLS_DATE_LANGUAGE参数和SYSTIMESTAMP 数据格式\nselect * from v$nls_parameters; \nSELECT SYSTIMESTAMP FROM DUAL;\n-- 确定NLS_TIMESTAMP_FORMAT格式\n-- alter session set NLS_TIMESTAMP_FORMAT = 'YYYY-MM-DD HH.MI.SS.FF8 AM';  -- 如果参数NLS_TIMESTAMP_FORMAT格式不是DD-MON-RR HH.MI.SSXFF AM首先要调整该参数\n-- 查看NLS_DATE_LANGUAGE是SIMPLIFIED CHINESE还是AMERICA，如果是AMERICA需要修改成SIMPLIFIED CHINESE，\nALTER SESSION SET nls_date_language='SIMPLIFIED CHINESE';\n\nSELECT TO_DATE('01-1月 -19', 'DD-MON -RR') FROM DUAL;\n\n\n2021-1-02\n\n-- 1. 可以直接转日期 \nSELECT to_date('2021-1-02', 'yyyy-MM-dd hh24:mi:ss') FROM dual;\n\n-- 2. 当字符串处理\nselect CASE WHEN REGEXP_LIKE('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{1})$') THEN REGEXP_REPLACE('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{1})$', '\\1-0\\2-0\\3') \n            WHEN REGEXP_LIKE('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{2})$') THEN REGEXP_REPLACE('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{2})$', '\\1-0\\2-\\3')\n            WHEN REGEXP_LIKE('2021-1-02', '^(\\d{4})[-|/](\\d{2})[-|/](\\d{1})$') THEN REGEXP_REPLACE('2021-1-02', '^(\\d{4})[-|/](\\d{2})[-|/](\\d{1})$', '\\1-\\2-0\\3')\n            ELSE '2021-1-02' END\nfrom dual;\n\n-- 转为日期格式，抽取出年、月、日，左补全 位数\nselect extract(YEAR from date'2022-8-11') || LPAD(extract(MONTH from date'2022-8-11'), 2, '0') || LPAD(extract(DAY from date'2022-8-11'), 2, '0') year from dual;\n\n\n\n# 聚合函数lag/lead\n\nlead(value_expr [,offset][,default]) over([query_partition_clause] order by Order_by_clause)\n\nlag(exp_str,offset,defval) over()\nexp_str 是要做对比的字段\noffset 是exp_str字段的偏移量 比如说 offset 为2 则 拿exp_str的第一行和第三行对比，第二行和第四行，依次类推，offset的默认值为1！\ndefval是当该函数无值可用的情况下返回的值。Lead函数的用法类似。\n\n\n\n# 聚合函数wm_concat\n\n> 注：Oracle 19c中，wm_concat失效。wm_concat函数是oracle的非公开函数，在新版的oracle中不支持该函数。\n> 解决方法：\n> \n>  1. 创建 wm_concat 函数， 参考连接：https://blog.csdn.net/sun2012930/article/details/111712882\n>  2. 使用 listagg(多行转单行的列,分隔符) within group(order by 排序字段) 写法替换（返回类型为字符串，长度最大为4000）\n>  3. 使用 xmlagg(xmlparse( content(多行转单行的列) ) order by 排序字段).getclobval() 写法替换\n\n多行变一行\n\n * 类似于 MySQL 中的 GROUP_CONCAT GROUP_CONCAT( [distinct] 要连接的字段 [ORDER BY 排序字段 ASC/DESC ] [separator '分隔符'] )\n * 类似于 Hive 中的 concat_ws + collect_list（collect_set）效果 concat_ws('_', collect_set(id))\n\n\n# 单行函数L[R]PAD\n\n语法\nLPAD(string,padded_length,[ pad_string]) :从左开始填充,L:left 左,PAD:pad 填充\nRPAD(string,padded_length,[ pad_string]) :从右开始填充,R:right 右,PAD:pad 填充\n\n解释\nstring：原数据，即要被填充的数据；\npadded_length：填充后的长度；\npad_string：填充字符串 可选填，如果不填就粘贴空格\n\n\n\n# 单行函数MD5加密\n\nselect utl_raw.cast_to_raw(DBMS_OBFUSCATION_TOOLKIT.MD5(INPUT_STRING => 'test')) from dual\n\n\n\n# SYS.UTL_MATCH.edit_distance_similarity 文本相似度计算\n\n点击查看\n\n过程梳理：\n\n由于有两个数据量过万的表数据进行对比，且编码不一致不能进行比对，只能通过同一区划，相似名称进行比对，确认一对一关系。\n\n确定思路是把数据分成多部分，能确认一对一关系的先插入结果表中。\n\n先能想到的是通过等值关联取能关联上的先插入到结果表。\n\n后通过instr(str1, str2) > 0关联，将此部分数据插入到结果表。\n\n后由于instr只能找出连续子串，非连续的简称一类并不能解决，采用自定义函数通过遍历短字符串的每个字符，到长字符串中查找如果有找不到的字符，返回-1；若全能找到返回短串的长度。\n\n后由于有些名称有错别字或其他问题，上面的自定义函数并不能解决，故考虑判断字符串的相似度，Oracle自带判断文本相似度函数，故用其作为关联条件。\n\n\nSELECT  A.AGENCY_ID,A.AGENCY_CODE,A.AGENCY_NAME,A.MOF_DIV_CODE,A.MOF_DIV_NAME,B.GUID,B.NAME,B.CODE,PROVINCE \n FROM  YTHDWXX A\n JOIN  DZXTDWXX B\n   ON  SYS.UTL_MATCH.edit_distance_similarity(a.agency_name,b.name) > 80\n  AND  MOF_DIV_CODE = rpad(PROVINCE, 9, 0)\n\n\n\n# oracle实现数据炸裂效果\n\n--oracle根据分隔符将一行拆分为多行\nwith tmp as --临时数据集\n(select '1,2,3' val\n    from dual\n  union all\n  select '4,5,6' val\n    from dual)\nselect regexp_substr(t.val, '[^,]+', 1, t2.lv)--截取对应行数的数据\n  from tmp t,\n      (select level lv--生成行数序列数据 1到最大行数\n          from (select max(regexp_count(a.val, '[^,]+', 1)) r_count--计算数据集中拆分后最大的行数\n                  from tmp a) b\n        connect by level <= b.r_count) t2\nwhere regexp_substr(t.val, '[^,]+', 1, t2.lv) is not null-- 排除掉空的数据\n\n\n\n# oracle行列转换\n\n# 行转列\n\n 1. PIVOT\n\nSELECT * FROM （数据查询集）\nPIVOT\n(\n SUM(Score/*行转列后 列的值*/) FOR \n coursename/*需要行转列的列*/ IN (转换后列的值)\n)\n\n-- 通俗理解就是把一列拆成了多列，被拆的列不能再被select？\n\n\n 2. 通过 group by + case when 判断实现\n\n# 列转行\n\n 1. unpivot\n\nselect 字段 from 数据集\nunpivot（自定义列名/*列的值*/ for 自定义列名 in（列名））\n\n\n 2. 利用union all 进行拼接\n\n\n# 自定义函数(存储过程)\n\n用于匹配简称\n\n-- 一个字符串包含另一个字符串中的所有字符\ncreate or replace function checks(v_a varchar2,v_b varchar)\nreturn number\nas\n  num number;\n  cou number;\n  j number;\n  index1 number;\nbegin\n  num := -1;\n  cou:=0;\n  j := 0;\n  index1 := 1;\n  for i in 1..length(v_b) loop\n     j := instr( substr(v_a,index1,length(v_a)), substr(v_b,i,1) );\n     if j > 0 then\n      cou:=cou+1;\n      index1 := index1 + j;\n     else\n      return num;\n     end if;\n  end loop;\n  return cou;\n  --dbms_output.put_line(cou||'    '||length(v_b));\nend;\n\n\n\n# MERGE INTO 语法\n\nMERGE INTO是Oracle SQL中用于将一个表中的数据合并到另一个表中的命令。该命令可以根据指定的条件来确定在目标表中是插入还是更新记录。\n\nMERGE INTO target_table\nUSING source_table\nON (condition)\nWHEN MATCHED THEN\n  UPDATE SET target_column = source_column\nWHEN NOT MATCHED THEN\n  INSERT (target_column1, target_column2, ...) VALUES (source_column1, source_column2, ...)\n\n\n其中\n\n * target_table是要合并到的目标表；\n * source_table是要从中获取数据的源表；\n * condition是用于匹配目标表和源表的条件；\n * UPDATE SET语句用于更新目标表中已有的记录；\n * INSERT语句用于将源表中不存在的记录插入到目标表中。\n\n\n# 不常用语法\n\n# 触发器\n\n-- 向另一个数据库同步表数据\nCREATE OR REPLACE TRIGGER \"触发器名\"\n  after insert or update or delete on 表名\n    for each row\nbegin\n  if inserting then\n    insert into 表名@INNERDB\n      (ID,\n       CODE,\n       NAME)\n    values\n      (:new.ID,\n       :new.CODE,\n       :new.NAME);\n  elsif updating then\n    delete 表名@INNERDB where ID = :old.ID;\ninsert into 表名@INNERDB\n(ID,\n CODE,\n NAME)\nvalues\n    (:new.ID,\n     :new.CODE,\n     :new.NAME);\nelsif deleting then\n    delete 表名@INNERDB where ID = :old.ID;\nend if;\nend;\n\n\n# 出包含 CLOB 字段的脚本\n\n条件允许的话还是用 Kettle、DataX等迁移工具，没有这个麻烦事\n\n-- 1. 使用 plsql 工具查询该脚本（适用于一定长度的）\n\tSELECT q_id,\n         q_code,\n         q_title,\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 1, 3000)) <> 0 THEN 'TO_CLOB(''' || SUBSTR(Q_TABLE, 1, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 3001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 3001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 6001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 6001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 9001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 9001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 12001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 12001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 15001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 15001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 18001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 18001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 21001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 21001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 24001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 24001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 27001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 27001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 30001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 30001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 33001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 33001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 36001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 36001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 39001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 39001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 42001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 42001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 45001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 45001, 3000) || ''')' ELSE NULL END ||\n         CASE WHEN LENGTH(SUBSTR(Q_TABLE, 48001, 3000)) <> 0 THEN '||TO_CLOB(''' || SUBSTR(Q_TABLE, 48001, 3000) || ''')' ELSE NULL END\n  FROM table_name t \n  order by sort_index;\n-- 2. 使用导出功能导出SQL脚本\n-- 3. 替换 SQL 脚本中的内容\n-- 3.1 将'TO_CLOB(''替换为TO_CLOB('\n-- 3.2 将'')||TO_CLOB(''替换为')||TO_CLOB('\n-- 3.3 将'')',替换为'),\n-- 4 替换特殊字符& 为 ' || chr(38) || '\n",normalizedContent:"# oracle\n\n----------------------------------------\n\n\n# 正则替换函数regexp_replace（不规则日期修改）\n\n日期格式检查\n\n-- 检查大致格式\n-- ^\\d{4}([-/])\\d{2}([-/])\\d{2}(\\s+\\d{2}:\\d{2}:\\d{2}){0,1}$'\n\n-- 检查部分值（部分月份、日期、时分秒）\n-- ^\\d{4}[-/.](0[1-9]|1[0-2])[-/.]([012][0-9]|3[0-1])\\s+([01][0-9]|2[0-3]):[0-5]\\d:[0-5]\\d$\n\n\n01-1月 -19\n\n-- 查看nls_timestamp_format和nls_date_language参数和systimestamp 数据格式\nselect * from v$nls_parameters; \nselect systimestamp from dual;\n-- 确定nls_timestamp_format格式\n-- alter session set nls_timestamp_format = 'yyyy-mm-dd hh.mi.ss.ff8 am';  -- 如果参数nls_timestamp_format格式不是dd-mon-rr hh.mi.ssxff am首先要调整该参数\n-- 查看nls_date_language是simplified chinese还是america，如果是america需要修改成simplified chinese，\nalter session set nls_date_language='simplified chinese';\n\nselect to_date('01-1月 -19', 'dd-mon -rr') from dual;\n\n\n2021-1-02\n\n-- 1. 可以直接转日期 \nselect to_date('2021-1-02', 'yyyy-mm-dd hh24:mi:ss') from dual;\n\n-- 2. 当字符串处理\nselect case when regexp_like('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{1})$') then regexp_replace('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{1})$', '\\1-0\\2-0\\3') \n            when regexp_like('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{2})$') then regexp_replace('2021-1-02', '^(\\d{4})[-|/](\\d{1})[-|/](\\d{2})$', '\\1-0\\2-\\3')\n            when regexp_like('2021-1-02', '^(\\d{4})[-|/](\\d{2})[-|/](\\d{1})$') then regexp_replace('2021-1-02', '^(\\d{4})[-|/](\\d{2})[-|/](\\d{1})$', '\\1-\\2-0\\3')\n            else '2021-1-02' end\nfrom dual;\n\n-- 转为日期格式，抽取出年、月、日，左补全 位数\nselect extract(year from date'2022-8-11') || lpad(extract(month from date'2022-8-11'), 2, '0') || lpad(extract(day from date'2022-8-11'), 2, '0') year from dual;\n\n\n\n# 聚合函数lag/lead\n\nlead(value_expr [,offset][,default]) over([query_partition_clause] order by order_by_clause)\n\nlag(exp_str,offset,defval) over()\nexp_str 是要做对比的字段\noffset 是exp_str字段的偏移量 比如说 offset 为2 则 拿exp_str的第一行和第三行对比，第二行和第四行，依次类推，offset的默认值为1！\ndefval是当该函数无值可用的情况下返回的值。lead函数的用法类似。\n\n\n\n# 聚合函数wm_concat\n\n> 注：oracle 19c中，wm_concat失效。wm_concat函数是oracle的非公开函数，在新版的oracle中不支持该函数。\n> 解决方法：\n> \n>  1. 创建 wm_concat 函数， 参考连接：https://blog.csdn.net/sun2012930/article/details/111712882\n>  2. 使用 listagg(多行转单行的列,分隔符) within group(order by 排序字段) 写法替换（返回类型为字符串，长度最大为4000）\n>  3. 使用 xmlagg(xmlparse( content(多行转单行的列) ) order by 排序字段).getclobval() 写法替换\n\n多行变一行\n\n * 类似于 mysql 中的 group_concat group_concat( [distinct] 要连接的字段 [order by 排序字段 asc/desc ] [separator '分隔符'] )\n * 类似于 hive 中的 concat_ws + collect_list（collect_set）效果 concat_ws('_', collect_set(id))\n\n\n# 单行函数l[r]pad\n\n语法\nlpad(string,padded_length,[ pad_string]) :从左开始填充,l:left 左,pad:pad 填充\nrpad(string,padded_length,[ pad_string]) :从右开始填充,r:right 右,pad:pad 填充\n\n解释\nstring：原数据，即要被填充的数据；\npadded_length：填充后的长度；\npad_string：填充字符串 可选填，如果不填就粘贴空格\n\n\n\n# 单行函数md5加密\n\nselect utl_raw.cast_to_raw(dbms_obfuscation_toolkit.md5(input_string => 'test')) from dual\n\n\n\n# sys.utl_match.edit_distance_similarity 文本相似度计算\n\n点击查看\n\n过程梳理：\n\n由于有两个数据量过万的表数据进行对比，且编码不一致不能进行比对，只能通过同一区划，相似名称进行比对，确认一对一关系。\n\n确定思路是把数据分成多部分，能确认一对一关系的先插入结果表中。\n\n先能想到的是通过等值关联取能关联上的先插入到结果表。\n\n后通过instr(str1, str2) > 0关联，将此部分数据插入到结果表。\n\n后由于instr只能找出连续子串，非连续的简称一类并不能解决，采用自定义函数通过遍历短字符串的每个字符，到长字符串中查找如果有找不到的字符，返回-1；若全能找到返回短串的长度。\n\n后由于有些名称有错别字或其他问题，上面的自定义函数并不能解决，故考虑判断字符串的相似度，oracle自带判断文本相似度函数，故用其作为关联条件。\n\n\nselect  a.agency_id,a.agency_code,a.agency_name,a.mof_div_code,a.mof_div_name,b.guid,b.name,b.code,province \n from  ythdwxx a\n join  dzxtdwxx b\n   on  sys.utl_match.edit_distance_similarity(a.agency_name,b.name) > 80\n  and  mof_div_code = rpad(province, 9, 0)\n\n\n\n# oracle实现数据炸裂效果\n\n--oracle根据分隔符将一行拆分为多行\nwith tmp as --临时数据集\n(select '1,2,3' val\n    from dual\n  union all\n  select '4,5,6' val\n    from dual)\nselect regexp_substr(t.val, '[^,]+', 1, t2.lv)--截取对应行数的数据\n  from tmp t,\n      (select level lv--生成行数序列数据 1到最大行数\n          from (select max(regexp_count(a.val, '[^,]+', 1)) r_count--计算数据集中拆分后最大的行数\n                  from tmp a) b\n        connect by level <= b.r_count) t2\nwhere regexp_substr(t.val, '[^,]+', 1, t2.lv) is not null-- 排除掉空的数据\n\n\n\n# oracle行列转换\n\n# 行转列\n\n 1. pivot\n\nselect * from （数据查询集）\npivot\n(\n sum(score/*行转列后 列的值*/) for \n coursename/*需要行转列的列*/ in (转换后列的值)\n)\n\n-- 通俗理解就是把一列拆成了多列，被拆的列不能再被select？\n\n\n 2. 通过 group by + case when 判断实现\n\n# 列转行\n\n 1. unpivot\n\nselect 字段 from 数据集\nunpivot（自定义列名/*列的值*/ for 自定义列名 in（列名））\n\n\n 2. 利用union all 进行拼接\n\n\n# 自定义函数(存储过程)\n\n用于匹配简称\n\n-- 一个字符串包含另一个字符串中的所有字符\ncreate or replace function checks(v_a varchar2,v_b varchar)\nreturn number\nas\n  num number;\n  cou number;\n  j number;\n  index1 number;\nbegin\n  num := -1;\n  cou:=0;\n  j := 0;\n  index1 := 1;\n  for i in 1..length(v_b) loop\n     j := instr( substr(v_a,index1,length(v_a)), substr(v_b,i,1) );\n     if j > 0 then\n      cou:=cou+1;\n      index1 := index1 + j;\n     else\n      return num;\n     end if;\n  end loop;\n  return cou;\n  --dbms_output.put_line(cou||'    '||length(v_b));\nend;\n\n\n\n# merge into 语法\n\nmerge into是oracle sql中用于将一个表中的数据合并到另一个表中的命令。该命令可以根据指定的条件来确定在目标表中是插入还是更新记录。\n\nmerge into target_table\nusing source_table\non (condition)\nwhen matched then\n  update set target_column = source_column\nwhen not matched then\n  insert (target_column1, target_column2, ...) values (source_column1, source_column2, ...)\n\n\n其中\n\n * target_table是要合并到的目标表；\n * source_table是要从中获取数据的源表；\n * condition是用于匹配目标表和源表的条件；\n * update set语句用于更新目标表中已有的记录；\n * insert语句用于将源表中不存在的记录插入到目标表中。\n\n\n# 不常用语法\n\n# 触发器\n\n-- 向另一个数据库同步表数据\ncreate or replace trigger \"触发器名\"\n  after insert or update or delete on 表名\n    for each row\nbegin\n  if inserting then\n    insert into 表名@innerdb\n      (id,\n       code,\n       name)\n    values\n      (:new.id,\n       :new.code,\n       :new.name);\n  elsif updating then\n    delete 表名@innerdb where id = :old.id;\ninsert into 表名@innerdb\n(id,\n code,\n name)\nvalues\n    (:new.id,\n     :new.code,\n     :new.name);\nelsif deleting then\n    delete 表名@innerdb where id = :old.id;\nend if;\nend;\n\n\n# 出包含 clob 字段的脚本\n\n条件允许的话还是用 kettle、datax等迁移工具，没有这个麻烦事\n\n-- 1. 使用 plsql 工具查询该脚本（适用于一定长度的）\n\tselect q_id,\n         q_code,\n         q_title,\n         case when length(substr(q_table, 1, 3000)) <> 0 then 'to_clob(''' || substr(q_table, 1, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 3001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 3001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 6001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 6001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 9001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 9001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 12001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 12001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 15001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 15001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 18001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 18001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 21001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 21001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 24001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 24001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 27001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 27001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 30001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 30001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 33001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 33001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 36001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 36001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 39001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 39001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 42001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 42001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 45001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 45001, 3000) || ''')' else null end ||\n         case when length(substr(q_table, 48001, 3000)) <> 0 then '||to_clob(''' || substr(q_table, 48001, 3000) || ''')' else null end\n  from table_name t \n  order by sort_index;\n-- 2. 使用导出功能导出sql脚本\n-- 3. 替换 sql 脚本中的内容\n-- 3.1 将'to_clob(''替换为to_clob('\n-- 3.2 将'')||to_clob(''替换为')||to_clob('\n-- 3.3 将'')',替换为'),\n-- 4 替换特殊字符& 为 ' || chr(38) || '\n",charsets:{cjk:!0},lastUpdated:"2025/05/12, 13:54:05",lastUpdatedTimestamp:1747029245e3},{title:"与MySQL语法区别",frontmatter:{title:"与MySQL语法区别",date:"2022-03-31T14:19:35.000Z",permalink:"/pages/c2df29/",categories:["数据库","Oracle"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/01.Oracle/06.%E4%B8%8EMySQL%E8%AF%AD%E6%B3%95%E5%8C%BA%E5%88%AB.html",relativePath:"03.数据库/01.Oracle/06.与MySQL语法区别.md",key:"v-01457896",path:"/pages/c2df29/",headers:[{level:4,title:"1. 数据类型",slug:"_1-数据类型",normalizedTitle:"1. 数据类型",charIndex:2},{level:4,title:"2. 函数",slug:"_2-函数",normalizedTitle:"2. 函数",charIndex:420},{level:4,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:2201}],headersStr:"1. 数据类型 2. 函数 其他",content:"# 1. 数据类型\n\n * Number类型\n\n  MySQL中是没有Number类型的，但有int/decimal 类型，Oracle中的Number(5,1)对应MySQL中的decimal(5,1)，Number(5) 对应 int(5)。MySQL中的数字型类型比较多，分的也比较细，还有tinyint、smallint、mediumint、bigint等类型\n\n * varchar2(n)类型\n\n  MySQL中对应Oracle Varchar2(n)类型的替代类型是varchar(n)类型。\n\n * Date 类型\n\n  MySQL 中的日期时间类型有Date、Time、Datetime等类型，MySQL中Date类型仅表示日期(年-月-日)，Time类型仅表示时间（时:分:秒），而Datetime类型表示日期时间(年-月-日 时:分:秒)，Oracle中的Date类型和MySQL中的Datetime类型一致。\n\n# 2. 函数\n\n * length(str)函数\n\n  Oracle中的length(str)是获取字符串长度的函数，MySQL 中对应的函数为char_length(str)。\n\n * sys_guid()函数\n\n  Oracle中可通过sys_guid()函数是生成随机序列，MySQL通过UUID()生成随机序列。\n\n * 时间格式化函数\n   \n   * 时间转换为字符串 MySQL: date_format(NOW(),'%Y-%m-%d')   Oracle: to_char(sysdate, 'YYYY-MM-DD')\n   * 字符串转换为时间 MySQL: str_to_date('2019-01-01','%Y-%m-%d')   Oracle: to_date('2019-01-01', 'YYYY-MM-DD');\n   * 时分秒的函数转换 DATE_FORMAT(NOW(),'%Y-%m-%d %H:%i:%s')   str_to_date('2019-01-01','%Y-%m-%d %H:%i:%s')\n   \n   注意: MySQL不能直接两个日期用减号相减, 它会去掉连接符转成数字进行计算, 结果没有任何意义\n\n * 条件函数 nvl()、nvl2()、decode()\n   \n   * nvl(col, 0)   Oralce函数: col为空，则返回值取0，否则取col   MySQL: ifnull(col, 0)\n   * nvl2(expr1,expr2,expr3)   Oralce函数: 如果expr1不为null，则返回expr2，否则返回expr3   MySQL: if(expr1,expr2,expr3)\n   * DECODE(value, val1, val2, val3)   Oralce函数: 如果value等于val1，则返回val2，否则返回val3   MySQL: if(value=val1, val2, val3)\n   * DECODE(value, if1, val1, if2,val2,...,ifn, valn, val)   如果value等于if1，则返回val1，如果value等于if2，则返回value2...如果value等于ifn，则返回valn，否则返回val   MySQL: case when value=if1 then val1 when value=if2 then val2,,,when value=ifn then valn else val end\n\n * trunc()函数\n   \n   * TRUNC(12.123)   Oracle: 返回整数(12)   MySQL: truncate(12.123, 0)\n   * TRUNC(12.123, 2)   Oracle: 返回值保留2为小数(12.12)   MySQL: truncate(12.123, 2)\n   * TRUNC(SYSDATE)   Oracle: 返回值为(2019-07-26 00:00:00)   MySQL: cast(now() as datetime)：返回值为(2019-07-26 14:11:38)\n\n> MySQL的cast函数语法为：CAST(xxx AS 类型) （可用类型为：二进制,同带binary前缀的效果:BINARY；字符型,可带参数:CHAR()；日期:DATE；时间:TIME；日期时间型: DATETIME；浮点数: DECIMAL；整数:SIGNED；无符号整数:UNSIGNED）\n\n * to_char() / to_number()\n   \n   * to_char(123)   Oracle: 数字123转为字符串123   MySQL: CAST(123 AS CHAR(3))\n   * to_number('123')   Oracle: 字符串123转换为数字类型   MySQL: 对应的函数为cast('123' as SIGNED)；\n\n * sysdate\n\n  sysdate   Oracle: 返回当前日期+时间   MySQL: now()\n\n# 其他\n\n * 引号\n\n  MySQL可识别双引号和单引号（反引号`为字段名），Oracle只能识别单引号（双引号为字段名）。\n\n * 字符串连接符\n\n  Oracle: 可用'||'来连接多个字符串（concat只能连接两个字符串）  MySQL: concat()函数可连接多个字符串\n\n * ROWNUM\n\n  Oracle可通过rownum获取前n条记录，MySQL通过limit来获取前n条记录（Oracle中rownum作为where条件的一部分，而MySQL中limit不是where条件的一部分）\n\n * 空数据排序(nulls first 和nulls last)\n\n-- null值排在最前\nSELECT * FROM FW_DEPARTMENT A ORDER BY A.REMARK DESC NULLS FIRST\n-- null值排在最后\nSELECT * FROM FW_DEPARTMENT A ORDER BY A.REMARK DESC NULLS LAST\n \n-- MySQL 可通过IF和ISNULL函数达到相同的效果\n-- null值排在最后\nselect * from FW_DEPARTMENT A order by IF(ISNULL(A.REMARK),1,0),A.REMARK desc\n-- null值排在最前\nselect * from FW_DEPARTMENT A order by IF(ISNULL(A.REMARK),0,1),A.REMARK desc\n\n\n * 全关联\n\nMySQL不支持full join （需通过join + union方式实现）\n\n * 递归查询(start with connect by prior)\n\nMySQL不支持(start with connect by prior)的这种递归查询，但可以通过自定义函数来实现。\n\n-- Oracle 递归查询 查询部门ID为‘1111’的所有子部门（包含自身）\nSELECT *\nFROM FW_DEPARTMENT\nSTART WITH DEPID='1111'\nCONNECT BY PRIOR DEPID = PARENTDEPID;\n-- Oracle 递归查询 查询部门ID为‘1111’的所有父部门（包含自身）\nSELECT *\nFROM FW_DEPARTMENT\nSTART WITH DEPID='1111'\nCONNECT BY PRIOR PARENTDEPID = DEPID;\n \n-- MySQL 先创建fun_getDepIDList函数，用于查询部门ID字符串\nCREATE FUNCTION fun_getDepIDList(rootId VARCHAR(32))\nRETURNS VARCHAR(6000)\nBEGIN \n\tDECLARE pTemp VARCHAR(6000);\n\tDECLARE cTemp VARCHAR(6000);\n\tSET pTemp='$';\n\tSET cTemp=rootId;\n\tWHILE cTemp is not null DO\n\t\tset pTemp=CONCAT(pTemp,',',cTemp);\n\t\tSELECT GROUP_CONCAT(depid) INTO cTemp from fw_department\n\t\tWHERE FIND_IN_SET(PARENTDEPID,cTemp)>0;\n\tEND WHILE;\n\tRETURN pTemp;\nEND;\n \n-- 查询部门ID为‘1111’的所有子部门（包含自己）\nselect * from fw_department\nwhere FIND_IN_SET(DEPID, fun_getDepIDList('1111'));\n \n-- 查询部门ID为‘1111’的所有父部门(包含自己)\nselect * from fw_department\nwhere FIND_IN_SET('1111', fun_getDepIDList(DEPID));\n\n\n * merge into\n\nMySQL不支持（merge into），但提供的replace into 和on duplicate key update可实现相似的功能。\n\n-- Oracle merge into (有则修改，无则新增)\nMERGE INTO TMPDEPTAB A\nUSING (SELECT '1111' DEPID, '哈哈' DEPNAME FROM DUAL) B\nON (A.DEPID = B.DEPID)\nWHEN MATCHED THEN \n\tUPDATE SET A.DEPNAME = B.DEPNAME\nWHEN NOT MATCHED THEN \n\tINSERT(DEPID, DEPNAME) VALUES(B.DEPID, B.DEPNAME);\n \n-- MySQL replace into (特点：1、先删后增； 2、插入/更新的表必须有主键或唯一索引；\n-- 3、未修改/新增的数据项，如果必填，则必须有默认值)\n-- 1、由于是先删后增，所以需要满足以下2个条件之一：\n--      1.要么必填项有默认值； \n--      2.要么插入/更新时为没有默认值的必填项赋值， 否则新增时会报错。\n-- 2、表中需要有主键或唯一索引，否则下面语句如果执行多次，表中会出现重复数据。\nreplace into fw_department(DEPID,PARENTDEPID,DEPNO,DEPNAME) \nvalues('1111111', '1234','123', '哈哈');\n \n-- MySQL on duplicate key update (特点：1、插入/更新的表必须有主键或唯一索引；\n-- 2、未修改/新增的数据项，如果必填，则必须有默认值)\ninsert into fw_department(depid,parentdepid,depno,depname)\nselect '1111111' depid, '123' parentdepid, 'e12' depno, '哈哈哈哈' depname\nfrom fw_department\non duplicate key \nupdate parentdepid = values(parentdepid),\n\tdepno=values(depno),\n\tdepname=values(depname);\n\n\n * with\n\nOracle 中可用with来构建一个临时表，MySQL8.0+也支持\n\n源地址",normalizedContent:"# 1. 数据类型\n\n * number类型\n\n  mysql中是没有number类型的，但有int/decimal 类型，oracle中的number(5,1)对应mysql中的decimal(5,1)，number(5) 对应 int(5)。mysql中的数字型类型比较多，分的也比较细，还有tinyint、smallint、mediumint、bigint等类型\n\n * varchar2(n)类型\n\n  mysql中对应oracle varchar2(n)类型的替代类型是varchar(n)类型。\n\n * date 类型\n\n  mysql 中的日期时间类型有date、time、datetime等类型，mysql中date类型仅表示日期(年-月-日)，time类型仅表示时间（时:分:秒），而datetime类型表示日期时间(年-月-日 时:分:秒)，oracle中的date类型和mysql中的datetime类型一致。\n\n# 2. 函数\n\n * length(str)函数\n\n  oracle中的length(str)是获取字符串长度的函数，mysql 中对应的函数为char_length(str)。\n\n * sys_guid()函数\n\n  oracle中可通过sys_guid()函数是生成随机序列，mysql通过uuid()生成随机序列。\n\n * 时间格式化函数\n   \n   * 时间转换为字符串 mysql: date_format(now(),'%y-%m-%d')   oracle: to_char(sysdate, 'yyyy-mm-dd')\n   * 字符串转换为时间 mysql: str_to_date('2019-01-01','%y-%m-%d')   oracle: to_date('2019-01-01', 'yyyy-mm-dd');\n   * 时分秒的函数转换 date_format(now(),'%y-%m-%d %h:%i:%s')   str_to_date('2019-01-01','%y-%m-%d %h:%i:%s')\n   \n   注意: mysql不能直接两个日期用减号相减, 它会去掉连接符转成数字进行计算, 结果没有任何意义\n\n * 条件函数 nvl()、nvl2()、decode()\n   \n   * nvl(col, 0)   oralce函数: col为空，则返回值取0，否则取col   mysql: ifnull(col, 0)\n   * nvl2(expr1,expr2,expr3)   oralce函数: 如果expr1不为null，则返回expr2，否则返回expr3   mysql: if(expr1,expr2,expr3)\n   * decode(value, val1, val2, val3)   oralce函数: 如果value等于val1，则返回val2，否则返回val3   mysql: if(value=val1, val2, val3)\n   * decode(value, if1, val1, if2,val2,...,ifn, valn, val)   如果value等于if1，则返回val1，如果value等于if2，则返回value2...如果value等于ifn，则返回valn，否则返回val   mysql: case when value=if1 then val1 when value=if2 then val2,,,when value=ifn then valn else val end\n\n * trunc()函数\n   \n   * trunc(12.123)   oracle: 返回整数(12)   mysql: truncate(12.123, 0)\n   * trunc(12.123, 2)   oracle: 返回值保留2为小数(12.12)   mysql: truncate(12.123, 2)\n   * trunc(sysdate)   oracle: 返回值为(2019-07-26 00:00:00)   mysql: cast(now() as datetime)：返回值为(2019-07-26 14:11:38)\n\n> mysql的cast函数语法为：cast(xxx as 类型) （可用类型为：二进制,同带binary前缀的效果:binary；字符型,可带参数:char()；日期:date；时间:time；日期时间型: datetime；浮点数: decimal；整数:signed；无符号整数:unsigned）\n\n * to_char() / to_number()\n   \n   * to_char(123)   oracle: 数字123转为字符串123   mysql: cast(123 as char(3))\n   * to_number('123')   oracle: 字符串123转换为数字类型   mysql: 对应的函数为cast('123' as signed)；\n\n * sysdate\n\n  sysdate   oracle: 返回当前日期+时间   mysql: now()\n\n# 其他\n\n * 引号\n\n  mysql可识别双引号和单引号（反引号`为字段名），oracle只能识别单引号（双引号为字段名）。\n\n * 字符串连接符\n\n  oracle: 可用'||'来连接多个字符串（concat只能连接两个字符串）  mysql: concat()函数可连接多个字符串\n\n * rownum\n\n  oracle可通过rownum获取前n条记录，mysql通过limit来获取前n条记录（oracle中rownum作为where条件的一部分，而mysql中limit不是where条件的一部分）\n\n * 空数据排序(nulls first 和nulls last)\n\n-- null值排在最前\nselect * from fw_department a order by a.remark desc nulls first\n-- null值排在最后\nselect * from fw_department a order by a.remark desc nulls last\n \n-- mysql 可通过if和isnull函数达到相同的效果\n-- null值排在最后\nselect * from fw_department a order by if(isnull(a.remark),1,0),a.remark desc\n-- null值排在最前\nselect * from fw_department a order by if(isnull(a.remark),0,1),a.remark desc\n\n\n * 全关联\n\nmysql不支持full join （需通过join + union方式实现）\n\n * 递归查询(start with connect by prior)\n\nmysql不支持(start with connect by prior)的这种递归查询，但可以通过自定义函数来实现。\n\n-- oracle 递归查询 查询部门id为‘1111’的所有子部门（包含自身）\nselect *\nfrom fw_department\nstart with depid='1111'\nconnect by prior depid = parentdepid;\n-- oracle 递归查询 查询部门id为‘1111’的所有父部门（包含自身）\nselect *\nfrom fw_department\nstart with depid='1111'\nconnect by prior parentdepid = depid;\n \n-- mysql 先创建fun_getdepidlist函数，用于查询部门id字符串\ncreate function fun_getdepidlist(rootid varchar(32))\nreturns varchar(6000)\nbegin \n\tdeclare ptemp varchar(6000);\n\tdeclare ctemp varchar(6000);\n\tset ptemp='$';\n\tset ctemp=rootid;\n\twhile ctemp is not null do\n\t\tset ptemp=concat(ptemp,',',ctemp);\n\t\tselect group_concat(depid) into ctemp from fw_department\n\t\twhere find_in_set(parentdepid,ctemp)>0;\n\tend while;\n\treturn ptemp;\nend;\n \n-- 查询部门id为‘1111’的所有子部门（包含自己）\nselect * from fw_department\nwhere find_in_set(depid, fun_getdepidlist('1111'));\n \n-- 查询部门id为‘1111’的所有父部门(包含自己)\nselect * from fw_department\nwhere find_in_set('1111', fun_getdepidlist(depid));\n\n\n * merge into\n\nmysql不支持（merge into），但提供的replace into 和on duplicate key update可实现相似的功能。\n\n-- oracle merge into (有则修改，无则新增)\nmerge into tmpdeptab a\nusing (select '1111' depid, '哈哈' depname from dual) b\non (a.depid = b.depid)\nwhen matched then \n\tupdate set a.depname = b.depname\nwhen not matched then \n\tinsert(depid, depname) values(b.depid, b.depname);\n \n-- mysql replace into (特点：1、先删后增； 2、插入/更新的表必须有主键或唯一索引；\n-- 3、未修改/新增的数据项，如果必填，则必须有默认值)\n-- 1、由于是先删后增，所以需要满足以下2个条件之一：\n--      1.要么必填项有默认值； \n--      2.要么插入/更新时为没有默认值的必填项赋值， 否则新增时会报错。\n-- 2、表中需要有主键或唯一索引，否则下面语句如果执行多次，表中会出现重复数据。\nreplace into fw_department(depid,parentdepid,depno,depname) \nvalues('1111111', '1234','123', '哈哈');\n \n-- mysql on duplicate key update (特点：1、插入/更新的表必须有主键或唯一索引；\n-- 2、未修改/新增的数据项，如果必填，则必须有默认值)\ninsert into fw_department(depid,parentdepid,depno,depname)\nselect '1111111' depid, '123' parentdepid, 'e12' depno, '哈哈哈哈' depname\nfrom fw_department\non duplicate key \nupdate parentdepid = values(parentdepid),\n\tdepno=values(depno),\n\tdepname=values(depname);\n\n\n * with\n\noracle 中可用with来构建一个临时表，mysql8.0+也支持\n\n源地址",charsets:{cjk:!0},lastUpdated:"2022/04/14, 13:35:50",lastUpdatedTimestamp:164991455e4},{title:"Oracle相关知识杂记",frontmatter:{title:"Oracle相关知识杂记",date:"2022-02-23T12:58:51.000Z",permalink:"/pages/7e6951/",categories:["数据库","Oracle"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/01.Oracle/01.Oracle%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%9D%82%E8%AE%B0.html",relativePath:"03.数据库/01.Oracle/01.Oracle相关知识杂记.md",key:"v-7ea7fc0c",path:"/pages/7e6951/",headers:[{level:2,title:"Oracle 常用性能排查语句",slug:"oracle-常用性能排查语句",normalizedTitle:"oracle 常用性能排查语句",charIndex:2},{level:4,title:"查看表空间大小",slug:"查看表空间大小",normalizedTitle:"查看表空间大小",charIndex:21},{level:4,title:"查看锁表及解决",slug:"查看锁表及解决",normalizedTitle:"查看锁表及解决",charIndex:1108},{level:4,title:"查询行锁并解决",slug:"查询行锁并解决",normalizedTitle:"查询行锁并解决",charIndex:2754},{level:4,title:"刷新表统计信息（做表分析）",slug:"刷新表统计信息-做表分析",normalizedTitle:"刷新表统计信息（做表分析）",charIndex:4608},{level:4,title:"查询正在执行的SQL",slug:"查询正在执行的sql",normalizedTitle:"查询正在执行的sql",charIndex:7257},{level:4,title:"查询SQL平均耗时",slug:"查询sql平均耗时",normalizedTitle:"查询sql平均耗时",charIndex:7734},{level:4,title:"慢查询耗时",slug:"慢查询耗时",normalizedTitle:"慢查询耗时",charIndex:8298},{level:4,title:"找到正在运行的存储过程并杀死",slug:"找到正在运行的存储过程并杀死",normalizedTitle:"找到正在运行的存储过程并杀死",charIndex:8818},{level:4,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:9362},{level:2,title:"SCN",slug:"scn",normalizedTitle:"scn",charIndex:10651},{level:3,title:"Oracle 表闪回",slug:"oracle-表闪回",normalizedTitle:"oracle 表闪回",charIndex:11908},{level:4,title:"查询历史版本数据（闪回查询）",slug:"查询历史版本数据-闪回查询",normalizedTitle:"查询历史版本数据（闪回查询）",charIndex:11971},{level:4,title:"恢复已删除的表",slug:"恢复已删除的表",normalizedTitle:"恢复已删除的表",charIndex:12354},{level:4,title:"恢复表到某个时间点",slug:"恢复表到某个时间点",normalizedTitle:"恢复表到某个时间点",charIndex:13214},{level:2,title:"LogMiner",slug:"logminer",normalizedTitle:"logminer",charIndex:13686},{level:2,title:"动态性能视图(x$,v$,gv$,v$,gv$)",slug:"动态性能视图-x-v-gv-v-gv",normalizedTitle:"动态性能视图(x$,v$,gv$,v$,gv$)",charIndex:null},{level:2,title:"常用系统表",slug:"常用系统表",normalizedTitle:"常用系统表",charIndex:15480},{level:3,title:"实例",slug:"实例",normalizedTitle:"实例",charIndex:14183},{level:4,title:"查看视图中用到的表和视图",slug:"查看视图中用到的表和视图",normalizedTitle:"查看视图中用到的表和视图",charIndex:16692},{level:4,title:"用到 某个表 的视图",slug:"用到-某个表-的视图",normalizedTitle:"用到 某个表 的视图",charIndex:17027},{level:4,title:"查看视图或表创建语句",slug:"查看视图或表创建语句",normalizedTitle:"查看视图或表创建语句",charIndex:17317},{level:4,title:"查询建表语句（不含注释）",slug:"查询建表语句-不含注释",normalizedTitle:"查询建表语句（不含注释）",charIndex:17407},{level:4,title:"查看函数、存储过程、触发器、包等创建语句",slug:"查看函数、存储过程、触发器、包等创建语句",normalizedTitle:"查看函数、存储过程、触发器、包等创建语句",charIndex:17493},{level:4,title:"迁移数据（大批量操作数据）前禁用索引！！！",slug:"迁移数据-大批量操作数据-前禁用索引",normalizedTitle:"迁移数据（大批量操作数据）前禁用索引！！！",charIndex:17696},{level:4,title:"查询数据表自上次统计信息收集以来数据变化量",slug:"查询数据表自上次统计信息收集以来数据变化量",normalizedTitle:"查询数据表自上次统计信息收集以来数据变化量",charIndex:18579},{level:2,title:"与MySQL区别",slug:"与mysql区别",normalizedTitle:"与mysql区别",charIndex:19506},{level:2,title:"Shell跑oracle脚本",slug:"shell跑oracle脚本",normalizedTitle:"shell跑oracle脚本",charIndex:19997},{level:2,title:"Oracle关联方式（执行计划）",slug:"oracle关联方式-执行计划",normalizedTitle:"oracle关联方式（执行计划）",charIndex:20759},{level:2,title:"点状知识",slug:"点状知识",normalizedTitle:"点状知识",charIndex:23198},{level:3,title:"匹配中文",slug:"匹配中文",normalizedTitle:"匹配中文",charIndex:23207},{level:3,title:"创建DBLink",slug:"创建dblink",normalizedTitle:"创建dblink",charIndex:23354},{level:3,title:"SQL并行",slug:"sql并行",normalizedTitle:"sql并行",charIndex:23735},{level:3,title:"中文排序方式",slug:"中文排序方式",normalizedTitle:"中文排序方式",charIndex:24970},{level:3,title:"数据中包含特殊符号需要转义",slug:"数据中包含特殊符号需要转义",normalizedTitle:"数据中包含特殊符号需要转义",charIndex:25449},{level:3,title:"数据泵导入导出（待完善）",slug:"数据泵导入导出-待完善",normalizedTitle:"数据泵导入导出（待完善）",charIndex:25677},{level:3,title:"Oracle 高版本导出，低版本导入，修改版本号",slug:"oracle-高版本导出-低版本导入-修改版本号",normalizedTitle:"oracle 高版本导出，低版本导入，修改版本号",charIndex:31004},{level:3,title:"REDOLOG（导库、大批量、长事务是不是需要调整？）",slug:"redolog-导库、大批量、长事务是不是需要调整",normalizedTitle:"redolog（导库、大批量、长事务是不是需要调整？）",charIndex:31087},{level:3,title:"解决本地Oracle服务内存占用过高",slug:"解决本地oracle服务内存占用过高",normalizedTitle:"解决本地oracle服务内存占用过高",charIndex:33541},{level:3,title:"数据插入慢的问题",slug:"数据插入慢的问题",normalizedTitle:"数据插入慢的问题",charIndex:34565}],headersStr:"Oracle 常用性能排查语句 查看表空间大小 查看锁表及解决 查询行锁并解决 刷新表统计信息（做表分析） 查询正在执行的SQL 查询SQL平均耗时 慢查询耗时 找到正在运行的存储过程并杀死 其他 SCN Oracle 表闪回 查询历史版本数据（闪回查询） 恢复已删除的表 恢复表到某个时间点 LogMiner 动态性能视图(x$,v$,gv$,v$,gv$) 常用系统表 实例 查看视图中用到的表和视图 用到 某个表 的视图 查看视图或表创建语句 查询建表语句（不含注释） 查看函数、存储过程、触发器、包等创建语句 迁移数据（大批量操作数据）前禁用索引！！！ 查询数据表自上次统计信息收集以来数据变化量 与MySQL区别 Shell跑oracle脚本 Oracle关联方式（执行计划） 点状知识 匹配中文 创建DBLink SQL并行 中文排序方式 数据中包含特殊符号需要转义 数据泵导入导出（待完善） Oracle 高版本导出，低版本导入，修改版本号 REDOLOG（导库、大批量、长事务是不是需要调整？） 解决本地Oracle服务内存占用过高 数据插入慢的问题",content:"# Oracle 常用性能排查语句\n\n# 查看表空间大小\n\n----------------------------------------\n\n--oracle表空间大小\nSELECT a.tablespace_name \"表空间名\",\n       total \"表空间大小\",\n       free \"表空间剩余大小\",\n       (total - free) \"表空间使用大小\",\n       round(total / (1024 * 1024 * 1024),2) \"表空间大小(G)\",\n       round(free / (1024 * 1024 * 1024),2) \"表空间剩余大小(G)\",\n       round((total - free) / (1024 * 1024 * 1024),2) \"表空间使用大小(G)\",\n       round((total - free) / total, 4) * 100 \"使用率 %\"\n  FROM (SELECT tablespace_name, SUM(bytes) free\n          FROM dba_free_space\n         GROUP BY tablespace_name) a,\n       (SELECT tablespace_name, SUM(bytes) total\n          FROM dba_data_files\n         GROUP BY tablespace_name) b\n WHERE a.tablespace_name = b.tablespace_name\n\n\n查看单表占用磁盘空间\n\nSELECT *\n  FROM (SELECT T.TABLESPACE_NAME,\n               T.OWNER,\n               T.SEGMENT_NAME,\n               T.SEGMENT_TYPE,\n               SUM(T.BYTES / 1024 / 1024) MB\n          FROM DBA_SEGMENTS T\n         WHERE T.SEGMENT_TYPE = 'TABLE' AND T.SEGMENT_NAME = 'TABLE_NAME'\n         GROUP BY T.TABLESPACE_NAME, T.OWNER, T.SEGMENT_NAME, T.SEGMENT_TYPE) T\n ORDER BY T.MB DESC;\n\n\n# 查看锁表及解决\n\n----------------------------------------\n\n1.下面的语句用来查询哪些对象被锁：\nselect object_name,machine,s.sid,s.serial#,l.ORACLE_USERNAME\nfrom v$locked_object l,dba_objects o ,v$session s\nwhere l.object_id　=　o.object_id and l.session_id=s.sid;\n2.下面的语句用来杀死一个进程：\nalter system kill session '24,111'; (其中24,111分别是上面查询出的sid,serial#);\n3.批量删除\nselect 'alter system kill session ''' || s.sid || ',' || s.serial# || '''' || ';'\n  from v$locked_object l, dba_objects o, v$session s\n where l.object_id　 = 　o.object_id\n   and l.session_id = s.sid;\n\nselect object_name,a.SQL_TEXT,machine,s.sid,s.serial#,s.status,lockwait,machine,program\nfrom v$locked_object l,dba_objects o ,v$session s,v$sql a\nwhere l.object_id　=　o.object_id and l.session_id=s.sid and a.HASH_VALUE = s.SQL_HASH_VALUE;\nUsername：死锁语句所用的数据库用户；\nLockwait：死锁的状态，如果有内容表示被死锁。\nStatus： 状态，active表示被死锁\nMachine： 死锁语句所在的机器。\nProgram： 产生死锁的语句主要来自哪个应用程序。\n\n\n\n   select b.file_id　　文件ID,\n　　      b.tablespace_name　　表空间,\n　　      b.file_name　　　　　物理文件名,\n　　      b.bytes　　　　　　　总字节数,\n　　      (b.bytes-sum(nvl(a.bytes,0)))　　　已使用,\n　　      sum(nvl(a.bytes,0))　　　　　　　　剩余,\n　　      sum(nvl(a.bytes,0))/(b.bytes)*100　剩余百分比\n　　 from dba_free_space a,dba_data_files b\n　　where a.file_id=b.file_id\n group by b.tablespace_name,b.file_name,b.file_id,b.bytes\n order by b.tablespace_name\n\n\n\n--最新\nselect object_name,a.SQL_TEXT,machine,s.sid,s.serial#,s.status,lockwait,machine,program,l.ORACLE_USERNAME\n  from v$locked_object l,dba_objects o ,v$session s,v$sql a\n where l.object_id　=　o.object_id and l.session_id=s.sid and a.HASH_VALUE = s.SQL_HASH_VALUE;\n\nalter system kill session '1902,24317'; \n\n\ngrant alter system to ysgl_guanli\n\n\n# 查询行锁并解决\n\n--------------------------------- 方案1\n--行锁查看\nselect s.SID,s.SERIAL#,s.MACHINE,s.TYPE,l.TYPE,l.CTIME,l.BLOCK,l.REQUEST,l.LMODE,\n       decode(l.lmode, 0, 'None', 1, 'Null', 2, 'Row-S (SS)', 3, 'Row-X (SX)', 4, 'Share', 5, 'S/Row-X (SSX)', 6, 'Exclusive', substr(to_char(l.lmode), 1, 13)) as \"Locked Mode\",\n       DECODE(L.TYPE,'MR','File_ID:' || L.ID1,'TM',t.NAME,'TX','USN:' || to_char(TRUNC(L.ID1 / 65536)) || 'RWO:' ||nvl(r.NAME, 'None'), L.ID1) as LOCK_ID1,\n       'alter system kill session ''' || s.SID || ',' || s.SERIAL# || '''immediate;' as \"Kill\"\n  from gv$process p\n inner join gv$session s\n    on s.PADDR = p.ADDR\n inner join v$lock l\n    on l.SID = s.SID\n  left join sys.obj$ t\n    on l.ID1 = t.obj#\n  left join sys.obj$ r\n    on s.ROW_WAIT_OBJ# = r.obj#\n where 1 = 1\n   and l.TYPE != 'MR' \n and l.TYPE  = 'TM'\n   and l.lmode = 3\n order by s.SID;\n\n-- 查看原因?\nWITH sessions AS\n(SELECT  /*+materialize*/\n         sid\n        ,sql_id\n        ,event\n        ,blocking_session\n        ,row_wait_obj#\nFROM gv$session)\nSELECT LPAD(' ', LEVEL ) || sid sid\n      ,sql_id\n      ,event\n      ,owner||decode(owner,null,null,'.')||object_name object_name\n      ,substr(sql_text,1,40) sql_text\nFROM sessions s\nLEFT OUTER JOIN dba_objects ON (object_id = row_wait_obj#)\nLEFT OUTER JOIN v$sql USING (sql_id)\nWHERE sid IN (SELECT blocking_session FROM sessions)\nOR blocking_session IS NOT NULL\nCONNECT BY PRIOR sid = blocking_session\n   START WITH blocking_session IS NULL;\n\n--------------------------------- 方案2\n   select 'alter system kill session ''' || ss.sid || '' || ',' || ss.serial# || ',@' ||\n       ss.inst_id || ''' immediate;' db_kill_session\n  from gv$session s, \n  gv$session ss\n where s.final_blocking_session is not null\n   and s.final_blocking_instance = ss.inst_id\n   and s.final_blocking_session = ss.sid\n   and s.sid <> ss.sid;\n\n\n# 刷新表统计信息（做表分析）\n\n  统计信息主要是描述数据库中表，索引的大小，规模，数据分布状况等的一类信息。例如，表的行数，块数，平均每行的大小，索引的leaf blocks，索引字段的行数，不同值的大小等，都属于统计信息。CBO正是根据这些统计信息数据，计算出不同访问路径下，不同join 方式下，各种计划的成本，最后选择出成本最小的计划。\n\n  统计信息是存放在数据字典表中的，如tab$，一般可通过察看某些视图来获取统计信息状况，如DBA_TABLES，DBA_INDEXES，DBA_TAB_COL_STATISTICS， DBA_TAB_HISTOGRAMS等。在这些视图中包含表示统计信息的一些字段，这些字段只有搜集过统计信息之后才有值，否则是空的。例如：last_analyzed 字段表示上次统计信息搜集的时间，可以根据这个字段，快速的了解最近一次统计信息搜集的时间。\n\n博客： 有关Oracle统计信息的知识点\n博客： Oracle 11g新特性之统计信息收集\n\n--当表没有做分析的时候，Oracle 会使用动态采样来收集统计信息。获取准确的段对象（表，表分区，索引等）的分析数据，是CBO存在的基石，\n--CBO的机制就是收集尽可能多的对象信息和系统信息，通过对这些信息进行计算，分析，评估，最终得出一个成本最低的执行计划。\n--所以对于CBO，数据段的分析就非常重要。\n\n解锁单个用户schema\nexec dbms_stats.unlock_schema_stats('用户名');\n\n单个表统计数据的统计数据更新\nEXEC dbms_stats.gather_table_stats('【username】','【tablename】', estimate_percent => dbms_stats.auto_sample_size, cascade=>true);\n-- EXEC dbms_stats.gather_table_stats('【username】','【tablename】',cascade=>true);\n-- analyze table tablename compute statistics 等同于 analyze table tablename compute statistics for table for all indexes for all columns\n\n-- 更新整个用户所有表的统计数据更新\n-- EXEC dbms_stats.gather_schema_stats('【username】',estimate_percent=>100,cascade=> TRUE);\n\n\n参数说明: (https://www.cnblogs.com/tingxin/p/12663682.html)\nownname:要分析表的拥有者\ntabname:要分析的表名.\npartname:分区的名字,只对分区表或分区索引有用.\nestimate_percent:采样行的百分比,取值范围[0.000001,100],null为全部分析,不采样. 常量:DBMS_STATS.AUTO_SAMPLE_SIZE是默认值,由oracle决定最佳取采样值.\nblock_sapmple:是否用块采样代替行采样.\nmethod_opt:决定histograms信息是怎样被统计的.method_opt的取值如下(默认值为FOR ALL COLUMNS SIZE AUTO):\nfor all columns:统计所有列的histograms.\nfor all indexed columns:统计所有indexed列的histograms.\nfor all hidden columns:统计你看不到列的histograms\nfor columns <list> SIZE <N> | REPEAT | AUTO | SKEWONLY:统计指定列的histograms.N的取值范围[1,254]; REPEAT上次统计过的histograms;AUTO由oracle决定N的大小;SKEWONLY multiple end-points with the same value which is what we define by \"there is skew in thedata\ndegree:决定并行度.默认值为null.\ngranularity:Granularity of statistics to collect ,only pertinent if the table is partitioned.\ncascade:是收集索引的信息.默认为FALSE.\nstattab:指定要存储统计信息的表,statid如果多个表的统计信息存储在同一个stattab中用于进行区分.statown存储统计信息表的拥有者.以上三个参数若不指定,统计信息会直接更新到数据字典.\nno_invalidate: Does not invalidate the dependent cursors if set to TRUE. The procedure invalidates the dependent cursors immediately if set to FALSE.\nforce:即使表锁住了也收集统计信息.\n\n\n这是对命令与工具包的一些总结\n1、对于分区表，建议使用DBMS_STATS，而不是使用Analyze语句。\na) 可以并行进行，对多个用户，多个Table\nb) 可以得到整个分区表的数据和单个分区的数据。\nc) 可以在不同级别上Compute Statistics：单个分区，子分区，全表，所有分区\nd) 可以倒出统计信息\ne) 可以用户自动收集统计信息\n2、DBMS_STATS的缺点\na) 不能Validate Structure\nb) 不能收集CHAINED ROWS, 不能收集CLUSTER TABLE的信息，这两个仍旧需要使用Analyze语句。\nc) DBMS_STATS 默认不对索引进行Analyze，因为默认Cascade是False，需要手工指定为True\n3、对于oracle 9里面的External Table，Analyze不能使用，只能使用DBMS_STATS来收集信息。\n\n\n\n# 查询正在执行的SQL\n\nSELECT b.inst_id,b.sid oracleID,\n       b.username 登录Oracle用户名,\n       b.serial#,\n       spid 操作系统ID,\n       paddr,\n       sql_text 正在执行的SQL,\n       sql_fulltext,\n       b.machine 计算机名,\n       b.EVENT,\n       'alter system kill session '''||b.sid||','||b.serial#||''';'\nFROM gv$process a, gv$session b, gv$sql c\nWHERE a.addr = b.paddr\n   AND b.sql_hash_value = c.hash_value\n   and a.inst_id=1\n   and b.inst_id=1\n   and c.inst_id=1\n   and b.status='ACTIVE'\n   ;\n\n\n# 查询SQL平均耗时\n\n--根据平均耗时大小排序\nSELECT a.SQL_TEXT,\n       a.SQL_ID,\n       a.EXECUTIONS \"总执行次数\",\n       nvl(a.ELAPSED_TIME, 0) / 1000 / 1000 \"总耗时(秒)\",\n       (nvl(a.ELAPSED_TIME, 0) /\n       nvl(decode(a.EXECUTIONS, 0, 1, a.EXECUTIONS), 1)) / 1000 / 1000 \"平均耗时（秒）\",\n       a.PARSE_CALLS \"硬解析次数\",\n       a.DISK_READS \"物理读次数\",\n       a.BUFFER_GETS \"读缓存区次数\",\n       a.FIRST_LOAD_TIME \"sql开始执行时间\"\n  FROM v$SQL a\n WHERE a.first_load_time like '2022-07-13%'\n order by (nvl(a.ELAPSED_TIME, 0) /\n          nvl(decode(a.EXECUTIONS, 0, 1, a.EXECUTIONS), 1)) / 1000 / 1000 desc;\n\n\n# 慢查询耗时\n\n-- 慢查询耗时\nselect *\n from (select sa.SQL_TEXT \"执行 SQL\",\n        sa.EXECUTIONS \"执行次数\",\n        round(sa.ELAPSED_TIME / 1000000, 2) \"总执行时间\",\n        round(sa.ELAPSED_TIME / 1000000 / sa.EXECUTIONS, 2) \"平均执行时间\",\n        sa.COMMAND_TYPE,\n        sa.PARSING_USER_ID \"用户ID\",\n        u.username \"用户名\",\n        sa.HASH_VALUE\n     from v$sqlarea sa\n     left join all_users u\n      on sa.PARSING_USER_ID = u.user_id\n     where sa.EXECUTIONS > 0\n     order by (sa.ELAPSED_TIME / sa.EXECUTIONS) desc)\n where rownum <= 50;\n\n\n# 找到正在运行的存储过程并杀死\n\n-- ddl锁 dba_ddl_locks\n1.查询正在运行的存储过程（包、函数等）\nselect name from v$db_object_cache where type IN ('PROCEDURE', 'PACKAGE BODY', 'PACKAGE') and locks > 0 and pins > 0;\n-- 获取ddl锁的信息\nselect * from dba_ddl_locks where owner = 'XXX' AND name='XXX';\n\n2.找到对应存储过程的sid\nselect/*+rule */ sid from v$access o where OWNER='过程的所属用户' AND o.OBJECT = '存储过程'   --（参数是存储过程名称）\n\n3.根据sid找到对应的serial#\nselect sid,serial# from v$session a WHERE A.SID='sid'\n\n4.终止运行存储过程\nalter system kill session 'sid,serial#'  (例如：alter system kill session 'sid,serial#')\n\n\n# 其他\n\n--查询当前用户使用了多少还原表空间\nselect d.username,c.name,b.writes\nfrom v$transaction a,v$rollstat b,v$rollname c,v$session d\nwhere d.taddr=a.addr\n  and a.xidusn=b.usn\n  and b.usn=c.usn\norder by d.username;\n\n-- 查看临时表空间的使用情况\nselect ts.name,ts.phyrds \"reads\",ts.phywrts \"writes\",ts.phyblkrd,ts.phyblkwrt,ts.readtim \"rtime\",ts.writetim \"wtime\"\n  from v$tablespace ts,v$tempfile tf ,v$tempstat ts\n where ts.ts#=tf.ts#\n   and tf.file#=ts.file#;\n\n-- 查看数据文件的i/o分布情况\nselect name,phyrds,phywrts,readtim,writetim\n  from v$filestat a,v$datafile b\n where a.file#=b.file#\n order by readtim desc;\n\n-- 查看连接oracle的所有机器的连接数和状态\nselect machine,status,count(*) from v$session group by machine,status order by status;\n\n/*\nSGA(System Global Area)：由所有服务进程和后台进程共享；\nPGA(Program Global Area)：由每个服务进程、后台进程专有；每个进程都有一个PGA。\n*/\n-- oracle的PGA、SGA和process count\nselect 'SGA' AS NAME,ROUND(sum(value)/1024/1024,2)||'M' AS \"SIZE(M)\" from v$sga\nUNION\nselect 'PGA' AS NAME,ROUND(value/1024/1024,2)||'M' AS \"SIZE(M)\" from v$pgastat where name='total PGA allocated'\nUNION\nselect 'TOTAL' AS NAME,((SELECT ROUND(sum(value)/1024/1024,2) from v$sga)+(select ROUND(value/1024/1024,2) from v$pgastat where name='total PGA allocated'))||'M' AS \"SIZE(M)\" FROM DUAL\nUNION\nSELECT NAME,TO_CHAR(VALUE) FROM V$PGASTAT WHERE NAME='process count';\n\n\n\n# SCN\n\n----------------------------------------\n\nSCN（System Change Number），也就是通常所说的系统改变号，是数据库中非常重要的一个数据结构。\nSCN用以标识数据库在某个确切时刻提交的版本。在事务提交时，它被赋予一个唯一的标识事务的SCN。SCN同时被作为Oracle数据库的内部时钟机制，可被看做逻辑时钟，每个数据库都有一个全局的SCN生成器。\n作为数据库内部的逻辑时钟，数据库事务依SCN而排序，Oracle也依据SCN来实现一致性读（Read Consistency）等重要数据库功能。另外对于分布式事务（Distributed Transactions），SCN也极为重要，这里不做更多介绍。\nSCN在数据库中是唯一的，并随时间而增加，但是可能并不连贯。除非重建数据库，SCN的值永远不会被重置为0.\n一直以来，对于SCN有很多争议，很多人认为SCN是指System Commit Number，而通常SCN在提交时才变化，所以很多时候，这两个名词经常在文档中反复出现。即使在Oracle的官方文档中，SCN也常以System Change/Commit Number两种形式出现。\n到底是哪个词其实不是很重要，重要的是需要知道SCN是Oracle内部的时钟机制，Oracle通过SCN来维护数据库的一致性，并通过SCN实施Oracle至关重要的恢复机制。\nSCN在数据库中是无处不在，常见的事务表、控制文件、数据文件头、日志文件、数据块头等都记录有SCN值。\n冠以不同前缀，SCN也有了不同的名称，如检查点SCN（Checkpint SCN）、Resetlogs SCN等。\n\n-- 当前scn号和时间的对应关系：\nselect dbms_flashback.get_system_change_number,SCN_TO_TIMESTAMP(dbms_flashback.get_system_change_number) from dual;\n\n-- 查询当前scn：\nselect CURRENT_SCN from v$database;\nselect dbms_flashback.get_system_change_number from dual;\n\n-- SCN与时间的相互转换\n将SCN转换成时间戳: SCN_TO_TIMESTAMP(scn_number)\n将时间戳转换成SCN: TIMESTAMP_TO_SCN(timestamp)\n\n-- 数据行伪列保存数据最后更新时间  select ora_rowscn from table_name;\n-- 系统表保存scn与时间戳对应关系（保留5天）   SELECT * FROM sys.smon_scn_time\n\n了解更多请核查看博客：https://blog.csdn.net/fuwencaho/article/details/21256973\n\n\n\n\n# Oracle 表闪回\n\n查看是否开启闪回功能：SELECT flashback_on FROM V$DATABASE;\n\n# 查询历史版本数据（闪回查询）\n\n-- 查询出类似拉链表的数据（包含历史版本）\nSELECT \n       字段名,\n       TO_CHAR(VERSIONS_STARTTIME, 'yyyy-MM-dd hh24:mi:ss') AS VERSIONS_STARTTIME,\n       TO_CHAR(VERSIONS_ENDTIME, 'yyyy-MM-dd hh24:mi:ss') AS VERSIONS_ENDTIME,\n       VERSIONS_OPERATION\n  FROM 表名 VERSIONS BETWEEN TIMESTAMP MINVALUE AND MAXVALUE\n WHERE VERSIONS_STARTTIME IS NOT NULL\n ORDER BY VERSIONS_STARTTIME DESC;\n\n\n# 恢复已删除的表\n\n-- 恢复已删除的表\nflashback table table_name to before drop;\n\n-- 若删除后已经创建了同名的表（ORA-38312）\n-- 如果表名重复，则闪回时遵循后入先出的原则。\nflashback table test to before drop rename to test1;\n\n\n扩展：\n\n-- 闪回时可指明被恢复的回收站对象\nflashback table \"BIN$AyId7ZbBjWngUKjADQIIuA==$0\" to before drop;\n\n-- 闪回删表的工作原理是：当“drop table”命令执行时，表及其索引并没有被真正删除，其所占空间只是分配给了另一个数据库对象：回收站对象，本质上相当于重命名。注意：表空间在自动增长的压力下会按照先入先出的规则将回收站对象的空间分配给需要空间的段，在将回收站对象耗尽之前数据文件是不会自动增长的。\n-- Oracle启用回收站功能后，使用drop table ...语句删除一张表时，并不会将表给删除，而是以一定的格式重新对表重命名，然后将该表放到数据字典表中，在遇到表空间不足的情况下自动清理这些表，释放被占用的空间，让其它对象能够使用这些空间。\n\n-- 可禁用回收站功能\nalter system set recyclebin='OFF' scope=spfile;\n\n-- 清理指定用户的表空间中的回收站对象\nPURGE TABLESPACE USERS user user_name;\n-- 删除当前用户回收站的所有对象\npurge recyclebin;\n    \n-- dbms_flashback包\n-- 利用dbms_flashback包的enable_at_time或enable_at_scn存储过程锁定一个会话级别的闪回时间目标，即进入闪回模式，随后的查询命令可以省略“as of”，直到调用dbms_flashback_disable存储过程将其关闭为止。\n\n\n# 恢复表到某个时间点\n\n-- 确定要恢复的表的时间点\nSELECT * FROM table_name AS OF TIMESTAMP(to_timestamp('2024-08-29 19:00:00', 'yyyy-MM-dd hh24:mi:ss'));\n\n-- 将表恢复到指定时间点\nFLASHBACK TABLE table_name TO TIMESTAMP(to_timestamp('2024-08-29 19:00:00', 'yyyy-MM-dd hh24:mi:ss'));\n-- 1. \"FLASHBACK TABLE\"命令的执行者必须有\"FLASHBACK ANY TABLE\"系统权限或者在被闪回的表上具有\"FLASHBACK\"对象权限。\n-- 2. 需启用行移动  alter table DEBT_T_FILE_INFO_FABZ_BAK enable row movement;\n-- 3. \"FLASHBACK TABLE\"属于DDL命令，隐式提交。\n-- 4. SYS用户的任何表无法使用此功能。\n\n\n\n# LogMiner\n\n----------------------------------------\n\n众所周知，所有对用户数据和数据字典的改变都记录在Oracle的Redo Log中，因此，Redo Log包含了所有进行恢复操作所需要的信息。但是，原始的Redo Log文件无法看懂，所以，Oracle从8i以后提供了一个非常有用的分析工具，称为LogMiner。使用该工具可以轻松获得Redo Log文件（包含归档日志文件）中的具体内容。特别是该工具可以分析出所有对于数据库的DML操作（INSERT、UPDATE、DELETE等）语句。Oracle 9i后可以分析DDL语句，另外还可分析得到一些必要的回滚SQL语句。LogMiner一个最重要的用途就是不用全部恢复数据库就可以恢复数据库的某个变化。该工具特别适用于调试、审计或者回退某个特定的事务。 LogMiner工具既可以用来分析在线日志，也可以用来分析离线日志文件，既可以分析本身自己数据库的重作日志文件，也可以用来分析其它数据库的重作日志文件。当分析其它数据库的重作日志文件时，需要注意的是，LogMiner必须使用被分析数据库实例产生的字典文件，而不是安装LogMiner的数据库产生的字典文件，另外，必须保证安装LogMiner数据库的字符集和被分析数据库的字符集相同。源数据库（Source Database）平台必须和分析数据库（Mining Database）平台一样。 Oracle通过LogMiner工具对Redo Log进行挖掘，显示出一系列可读的信息，该过程称为日志挖掘。LogMiner通过V$LOGMNR_CONTENTS视图显示Redo Log中的信息。\n\n总的说来，LogMiner工具的主要用途有：\n\n 1. 跟踪数据库的变化：可以离线地跟踪数据库的变化，而不会影响在线系统的性能\n 2. 回退数据库的变化：回退特定的变化数据，减少Point-In-Time Recovery的执行\n 3. 优化和扩容计划：可通过分析日志文件中的数据以分析数据的增长模式\n 4. 确定数据库的逻辑损坏时间：准确定位操作执行的时间和SCN\n 5. 确定事务级要执行的精细逻辑恢复操作，可以取得相应的UNDO操作\n 6. 执行后续审计\n\n了解更多请查看博客： https://blog.csdn.net/yes_is_ok/article/details/79296614\n\n\n# 动态性能视图(x$,v$,gv$,v_$,gv_$)\n\n----------------------------------------\n\n官方文档12.2\n\nv$database 数据库信息\nv$datafile 数据文件信息\nv$controlfile 控制文件信息\nv$logfile 重做日志信息\nv$instance 数据库实例信息\nv$log 日志组信息\nv$loghist 日志历史信息\nv$sga 数据库SGA信息\nv$parameter 初始化参数信息\nv$process 数据库服务器进程信息\nv$bgprocess 数据库后台进程信息\nv$controlfile_record_section 控制文件记载的各部分信息\nv$thread 线程信息\nv$datafile_header 数据文件头所记载的信息\nv$archived_log归档日志信息\nv$archive_dest 归档日志的设置信息\nv$logmnr_contents 归档日志分析的DML DDL结果信息\nv$logmnr_dictionary 日志分析的字典文件信息\nv$logmnr_logs 日志分析的日志列表信息\nv$tablespace 表空间信息\nv$tempfile 临时文件信息\nv$filestat 数据文件的I/O统计信息\nv$undostat Undo数据信息\nv$rollname 在线回滚段信息\nv$session 会话信息\nv$transaction 事务信息\nv$rollstat 回滚段统计信息\nv$pwfile_users 特权用户信息\nv$sqlarea 当前查询过的sql语句访问过的资源及相关的信息\nv$sql 与v$sqlarea基本相同的相关信息\nv$sysstat 数据库系统状态信息\n\n\n\n# 常用系统表\n\n原文链接\n\ndba_开头\n\n\ndba_users 数据库用户信息\ndba_segments 表段信息\ndba_extents 数据区信息\ndba_objects 数据库对象信息\ndba_tablespaces 数据库表空间信息\ndba_data_files 数据文件设置信息\ndba_temp_files 临时数据文件信息\ndba_rollback_segs 回滚段信息\ndba_ts_quotas 用户表空间配额信息\ndba_free_space 数据库空闲空间信息\ndba_profiles 数据库用户资源限制信息\ndba_sys_privs 用户的系统权限信息\ndba_tab_privs 用户具有的对象权限信息\ndba_col_privs 用户具有的列对象权限信息\ndba_role_privs 用户具有的角色信息\ndba_audit_trail 审计跟踪记录信息\ndba_stmt_audit_opts 审计设置信息\ndba_audit_object 对象审计结果信息\ndba_audit_session 会话审计结果信息\ndba_indexes 用户模式的索引信息\n\n\nuser_开头\n\nuser_objects 用户对象信息\nuser_source 数据库用户的所有资源对象信息\nuser_segments 用户的表段信息\nuser_tables 用户的表对象信息\nuser_tab_columns 用户的表列信息\nuser_col_comments 用户的表列注释信息\nuser_constraints 用户的对象约束信息\nuser_sys_privs 当前用户的系统权限信息\nuser_tab_privs 当前用户的对象权限信息\nuser_col_privs 当前用户的表列权限信息\nuser_role_privs 当前用户的角色权限信息\nuser_indexes 用户的索引信息\nuser_ind_columns 用户的索引对应的表列信息\nuser_cons_columns 用户的约束对应的表列信息\nuser_clusters 用户的所有簇信息\nuser_clu_columns 用户的簇所包含的内容信息\nuser_cluster_hash_expressions 散列簇的信息\n\n\n\nall_开头\n\nall_users 数据库所有用户的信息\nall_objects 数据库所有的对象的信息\nall_def_audit_opts 所有默认的审计设置信息\nall_tables 所有的表对象信息\nall_indexes 所有的数据库对象索引的信息\n\nsession_开头\nsession_roles 会话的角色信息\nsession_privs 会话的权限信息\n\nindex_开头\nindex_stats 索引的设置和存储信息\n\n**伪表**\ndual 系统伪列表信息\n\n\n\n# 实例\n\n# 查看视图中用到的表和视图\n\n   SELECT NAME, REFERENCED_TYPE, REPLACE(TO_CHAR(WM_CONCAT(DISTINCT REFERENCED_NAME)), ',', chr(13))\n     FROM SYS.ALL_DEPENDENCIES\n    WHERE TYPE = 'VIEW'\n      AND NAME = UPPER('视图名')\n      AND REFERENCED_TYPE IN ('TABLE', 'VIEW')\n      AND OWNER = '用户名'\n GROUP BY NAME, REFERENCED_TYPE\n ORDER BY REFERENCED_TYPE\n;\n\n\n# 用到 某个表 的视图\n\n\n   SELECT NAME, REFERENCED_TYPE, REPLACE(TO_CHAR(WM_CONCAT(DISTINCT REFERENCED_NAME)), ',', chr(13))\n     FROM SYS.ALL_DEPENDENCIES\n    WHERE TYPE = 'VIEW'\n      AND REFERENCED_NAME = '表名'\n      AND OWNER = '用户名'\n GROUP BY NAME, REFERENCED_TYPE\n ORDER BY REFERENCED_TYPE\n;\n\n\n# 查看视图或表创建语句\n\nSELECT * FROM all_views where VIEW_NAME = UPPER('视图名') AND OWNER = '用户名';\n\n\n# 查询建表语句（不含注释）\n\nselect dbms_metadata.get_ddl('TABLE',upper('tablename')) from dual;\n\n\n# 查看函数、存储过程、触发器、包等创建语句\n\nSELECT OWNER, NAME, TYPE, listagg(TEXT) WITHIN GROUP(ORDER BY line) AS TEXT\n  FROM ALL_SOURCE\n WHERE NAME = 'OBJECT_NAME'\n   AND owner = 'USER_NAME'\n GROUP BY OWNER, NAME, TYPE\n\n\n# 迁移数据（大批量操作数据）前禁用索引！！！\n\nSELECT 'ALTER INDEX ' || idx.index_name || ' UNUSABLE;',\n       'ALTER INDEX ' || idx.index_name || ' REBUILD;'\n  FROM user_indexes idx\n  LEFT JOIN USER_IND_COLUMNS IDXC\n    ON IDX.table_name = IDXC.TABLE_NAME\n   AND IDX.INDEX_NAME = IDXC.INDEX_NAME\n WHERE IDX.UNIQUENESS <> 'UNIQUE'\n   AND IDX.table_name IN (SELECT UPPER(DATA_TARGET)\n                            FROM DEBT_T_EXC_CONFIG_PARAM\n                           WHERE EXC_TYPE = 'QY_IN')  /*指定表清单*/\n   AND NOT EXISTS\n (SELECT 1\n          FROM (SELECT ucc.table_name, ucc.COLUMN_NAME\n                  FROM USER_CONS_COLUMNS ucc\n                  JOIN USER_CONSTRAINTS uc\n                    ON ucc.CONSTRAINT_NAME = uc.CONSTRAINT_NAME\n                 WHERE uc.CONSTRAINT_TYPE = 'P') t\n         WHERE idx.TABLE_NAME = t.table_name\n           AND IDXC.COLUMN_NAME = T.COLUMN_NAME)  /*过滤掉主键列上的索引*/\n;\n\n\n# 查询数据表自上次统计信息收集以来数据变化量\n\nDBA_TAB_MODIFICATIONS记录自上次统计信息收集以来表上的DML操作（INSERT、UPDATE、DELETE）及TRUNCATE操作的历史数据；该视图依赖于后台作业MMON（15min执行一次），手动执行 exec DBMS_STATS.FLUSH_DATABASE_MONITORING_INFO;\n\n-- 需要启用表监控（激活表修改跟踪）（10g之后，10g之前需手动开启表监控alter table MODIFI_TEST nomonitoring/MONITORING）\n-- 1. 设置设置统计级别\nshow parameter statistics_level;   -- 查看参数值\n--alter system set statistics_level=TYPICAL;   -- 参数设为TYPICAL或ALL\n--alter session set statistics_level=TYPICAL; \n\n\n-- 查询\nSELECT MODIF.TABLE_OWNER,\n       MODIF.TABLE_NAME,\n       MODIF.INSERTS,\n       MODIF.UPDATES,\n       MODIF.DELETES,\n       MODIF.TIMESTAMP,\n       TABS.LAST_ANALYZED  -- 最后分析时间\n  FROM DBA_TAB_MODIFICATIONS MODIF\n INNER JOIN DBA_TABLES TABS\n    ON MODIF.TABLE_OWNER = TABS.OWNER\n   AND MODIF.TABLE_NAME = TABS.TABLE_NAME\n WHERE MODIF.TABLE_OWNER = 'QY_CZB_RZPT_OUT'\n   AND MODIF.TIMESTAMP >= SYSDATE - INTERVAL '30' DAY -- 查询最近 1 天内变动的表\n ORDER BY MODIF.TIMESTAMP DESC\n;\n\n\n\n# 与MySQL区别\n\n1、oracle是大型数据库，mysql是小型数据库；\n2、mysql是主键是支持自动增长类型的（在创建表的时候指定表的主键为auto_increment）,在插入记录时，不需要再指定该记录的主键值，mysql将自动增长；\n3、oracle没有自动增长类型主键一般使用序列，在插入记录时，将序列号的下一个值付给该字段即可；\n4、mysql可以用双引号包起字符串，而oracle只能用单引号包起。\n5、处理分页逻辑不一样，mysql使用limit处理分页；而oracle使用rownum字段标明位置，并且只能用rowNum&lt;100,不能用rowNum>80;\n6、mysql定义的空字段里面可以有空的内容，但是oracle种非空字段不能有空的内；\n7、两者都能使用like “%字符串%”,但是oracle中使用模糊查询后不能使用索引，速度不快；\n8、两者给字段添加注释的方式不一样，\n\n————————————————\n原文链接：https://blog.csdn.net/z19950712/article/details/115478505\n\n\n\n# Shell跑oracle脚本\n\n----------------------------------------\n\n#! /bin/sh\nlogpath=\"log\"\nfilepath=\"/home/ap/user\"\n#输入Oracle数据库的用户名密码等信息\nDBINFO=\"username/password@ip:port/orcl\"\nif  ! -d ${logpath} ]\nthen\n mkdir log\nfi\necho \"`date +'%Y%m%d %H:%M:%S'`] Info: Begin to execute init sql!\"\nlogfile=\"${logpath}/init_table_data_info.log\"\n#“${logfile} 2>&1”这里的意思就是把标准输出信息和错误输出信息都记录在init_table_data_info.log文件中\nsqlplus -s ${DBINFO} << ! > ${logfile} 2>&1\nwhenever oserror exit 1;\nwhenever sqlerror exit 1;\n@${filepath}/initTable.sql\n@${filepath}/initTable2.sql\nquit\n!\nif  $? -ne 0 ]\nthen\n    echo \"`date +'%Y%m%d %H:%M:%S'`] Error: Initialize initTable failed!\"  >> ${logpath}\n    exit 1\nfi\necho \"`date +'%Y%m%d %H:%M:%S'`] Initialize initTable  successed.\"  >> ${logpath}\n\n\n\n# Oracle关联方式（执行计划）\n\n为啥有说只有三种的（待完善！！！）\n\n> 不同数据库支持情况不同：PGSQL支持 nested-loop join 、hash join 、merge join；MySQL只支持 nested-loop join\n\nOracle的SQL优化器（Optimizer）在执行多表连接查询时，通常采用的连接算法有以下几种方式：\n1、嵌套循环连接（NESTED LOOPS JOIN）\n2、哈希连接（HASH JOIN）\n3、排序合并连接（SORT MERGE JOIN）\n4、笛卡尔连接（CARTESIAN JOIN）\n5、群集连接（CLUSTER JOIN）\n6、索引连接（INDEX JOIN）\n\n\n多表之间的连接有三种方式：Nested Loops，Hash Join 和 Sort Merge Join. 下面来介绍三种不同连接的不同：\n\nNESTED LOOP\n\n> 对于被连接的数据子集较小的情况，嵌套循环连接是个较好的选择。在嵌套循环中，内表被外表驱动，外表返回的每一行都要在内表中检索找到与它匹配的行，因此整个查询返回的结果集不能太大（大于1 万不适合），要把返回子集较小表的作为外表（CBO 默认外表是驱动表），而且在内表的连接字段上一定要有索引。当然也可以用ORDERED 提示来改变CBO默认的驱动表，使用USE_NL(table_name1 table_name2)可是强制CBO 执行嵌套循环连接。\n\n> Nested loop一般用在连接的表中有索引，并且索引选择性较好的时候.\n\n> 步骤：确定一个驱动表(outer table)，另一个表为inner table，驱动表中的每一行与inner表中的相应记录JOIN。类似一个嵌套的循环。适用于驱动表的记录集比较小（<10000）而且inner表需要有有效的访问方法（Index）。需要注意的是：JOIN的顺序很重要，驱动表的记录集一定要小，返回结果集的响应时间是最快的。\n\nHASH JOIN\n\n> 散列连接是CBO 做大数据集连接时的常用方式，优化器使用两个表中较小的表（或数据源）利用连接键在内存中建立散列表，然后扫描较大的表并探测散列表，找出与散列表匹配的行。 这种方式适用于较小的表完全可以放于内存中的情况，这样总成本就是访问两个表的成本之和。但是在表很大的情况下并不能完全放入内存，这时优化器会将它分割成若干不同的分区，不能放入内存的部分就把该分区写入磁盘的临时段，此时要有较大的临时段从而尽量提高I/O 的性能。 也可以用USE_HASH(table_name1 table_name2)提示来强制使用散列连接。如果使用散列连接HASH_AREA_SIZE 初始化参数必须足够的大，如果是9i，Oracle建议使用SQL工作区自动管理，设置WORKAREA_SIZE_POLICY 为AUTO，然后调整PGA_AGGREGATE_TARGET 即可。\n\n> Hash join在两个表的数据量差别很大的时候.\n\n> 步骤：将两个表中较小的一个在内存中构造一个HASH表（对JOIN KEY），扫描另一个表，同样对JOIN KEY进行HASH后探测是否可以JOIN。适用于记录集比较大的情况。需要注意的是：如果HASH表太大，无法一次构造在内存中，则分成若干个partition，写入磁盘的temporary segment，则会多一个写的代价，会降低效率。\n\nSORT MERGE JOIN\n\n> 通常情况下散列连接的效果都比排序合并连接要好，然而如果行源已经被排过序，在执行排序合并连接时不需要再排序了，这时排序合并连接的性能会优于散列连接。可以使用USE_MERGE(table_name1 table_name2)来强制使用排序合并连接. Sort Merge join 用在没有索引，并且数据已经排序的情况. cost = (outer access cost * # of hash partitions) + inner access cost\n\n> 步骤：将两个表排序，然后将两个表合并。通常情况下，只有在以下情况发生时，才会使用此种JOIN方式：\n> \n> > 1.RBO模式\n> > 2.不等价关联(>,<,>=,<=,<>)\n> > 3.HASH_JOIN_ENABLED=false\n> > 4.数据源已排序\n\n三种连接工作方式比较\n\n> Hash join的工作方式是将一个表（通常是小一点的那个表）做hash运算，将列数据存储到hash列表中，从另一个表中抽取记录，做hash运算，到hash 列表中找到相应的值，做匹配。\n\n> Nested loops 工作方式是从一张表中读取数据，访问另一张表（通常是索引）来做匹配，nested loops适用的场合是当一个关联表比较小的时候，效率会更高。\n\n> Merge Join 是先将关联表的关联列各自做排序，然后从各自的排序表中抽取数据，到另一个排序表中做匹配，因为merge join需要做更多的排序，所以消耗的资源更多。 通常来讲，能够使用merge join的地方，hash join都可以发挥更好的性能。\n\n强制使用关联方式\n\nselect /*+use_hash(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\nselect /*+use_nl(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\nselect /*+use_merge(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\n\n\n原文链接\n\n\n# 点状知识\n\n\n# 匹配中文\n\n使用正则匹配不太好使\n\n替换方案：chr(128) - chr(255) 可以匹配双字节字符（同样不够准确）\nselect regexp_replace('', '['||chr(128)|| '-' || chr(255) ||']', '-') from dual;\n\n\n\n# 创建DBLink\n\n> 注：由于 dblink 跨库查询是把一个数据库数据通过网络发送到另一数据库关联查询， 可以通过指定 hint /*+ driving_site(t)*/ 指定驱动表（t 一般是大表），从而减少网络传输。 当然，最终效率还是要综合磁盘IO、网络IO和计算能力等综合考虑\n\n-- Create database link \ncreate public database link <dblink名>\n  connect to <用户名>\n  IDENTIFIED BY <\"密码\">\n  using '(DESCRIPTION =(ADDRESS_LIST =(ADDRESS =(PROTOCOL=TCP)(HOST=<ip>)(PORT=<端口>)))(CONNECT_DATA=(SERVICE_NAME=orcl)))';\n\n\n\n# SQL并行\n\n官方文档\n\n原文地址\n\n * 1.查询开启并行（Parallel query）\n\nselect /*+parallel(a, 16)*/ count(1) from dual a;     -- 第一种方式（Hist方式）\nalter table tab1 parallel n;                          -- 第二种方式\nalter session force parallel query parallel n;        -- 第三种方式\n\n\n * 2.修改数据开启并行（Parallel DML (INSERT, UPDATE, DELETE, and MERGE) ）\n\n-- 第一种方式（Hist方式）\nUPDATE /*+ PARALLEL(tab1,4) */ tbl_2 SET c1=c1+1;\nINSERT /*+ PARALLEL(tbl_ins,2) */ INTO tbl_ins\nSELECT /*+ PARALLEL(tbl_sel,4) */ * FROM tbl_sel;\nDELETE /*+ PARALLEL (t1, 2) */ FROM t1\n\n-- 第二种方式\nalter session force parallel DML parallel n;\n\n-- 第三种方式\nalter table tab1 parallel n;\n\n\n * 3.Parallel DDL\n\n-- 第一种方式（Hist方式）\nALTER SESSION FORCE PARALLEL DDL parallel n;\n\n-- 第二种方式\nCREATE INDEX ….parallel 10;\nALTER INDEX ... REBUILD parallel 10;\nALTER INDEX ... MOVE PARTITION parallel 10;\nALTER INDEX ...SPLIT PARTITION parallel 10;\n\n\n * 附：存储过程中开启并行\n\ndeclare\n...\nbegin\n execute immediate 'alter session force parallel dml parallel  8';\n --更新操作\n ...\n commit; --必须先commit,否则会报 ora-12841\n execute immediate 'alter session disable parallel dml ';\n\nexception\n when others then\n   rollback;\n   execute immediate 'alter session disable parallel dml '; \nend;\n\n\n注：使用临时表with as时不能使用并行（比如：在存储过程中开启session并行），否则会导致结果不一致\n\n\n# 中文排序方式\n\nOracle9i之前，中文是按照二进制编码进行排序的。\n在oracle9i中新增了按照拼音、部首、笔画排序功能。设置NLS_SORT值\n\nSCHINESE_RADICAL_M 按照部首(第一顺序)、笔划(第二顺序)排序\nSCHINESE_STROKE_M 按照笔划(第一顺序)、部首(第二顺序)排序\nSCHINESE_PINYIN_M 按照拼音排序\n\n修改ORACLE字段的默认排序方式：\n按拼音(默认)：\nalter session set nls_sort = SCHINESE_PINYIN_M;\n按笔画：\nalter session set nls_sort = SCHINESE_STROKE_M;\n按偏旁：\nalter session set nls_sort = NLS_SORT=SCHINESE_RADICAL_M;\n\nNLSSORT()，用来进行语言排序\n\n示例:\nSELECT * FROM TEAM ORDER BY NLSSORT(排序字段名,'NLS_SORT =SCHINESE_PINYIN_M')\n\n\n\n# 数据中包含特殊符号需要转义\n\n 1. 执行语句前先执行 set define off; （去掉oracle自定义的字符含义，还原它本来的意思）\n 2. 使用ASCII编码对 & 进行转义 chr(38) select 'xxx?xxx=11' || chr(38) || 'xxx=33' from dual\n 3. 不转义，直接字符串的形式写进去 select 'xxx?xxx=11' || '&' || 'xxx=33' from dual\n\n\n# 数据泵导入导出（待完善）\n\n导入：首先我们需要知道导出用户和表空间的名字\n\n注意：1. 如果表空间不是只有一个，需要使用remap_tablespace指定到我们创建的表空间 2. 单个表空间文件最大32G\n\n> 所以拿到导出log文件是非常有必要的\n\n-- 创建表空间  UNLIMITED指定不限制最大表空间\ncreate TABLESPACE BANANA datafile 'E:\\OracleData\\tablespace\\DATAS.dbf' size 50m autoextend on next 50m MAXSIZE UNLIMITED extent management local; \n-- 删除表空间\ndrop TABLESPACE BANANA including contents and datafiles cascade constraints;\n-- 查询表空间\nselect * from dba_tablespaces;\n\n\n-- 管理员登录，创建新用户，分配已创建好的表空间\ncreate user banana identified BY banana default TABLESPACE BANANA;\n-- 删除用户带级联\ndrop user banana cascade;\n\n\n-- 授权\nGrant dba to banana with admin option;\n\n\n-- 查询dup存放目录目录    注意：后面的E盘下面的dpdump 必须把你要导入的xxx.dmp文件放进该文件夹  DATA_PUMP_DIR\nselect * from dba_directories;\n-- 数据泵导入数据 (CMD命令行   DATA_PUMP_DIR为上面查出的目录名  如果有其他表空间的，需要使用remap_tablespace指定到我们创建的表空间)\nimpdp banana remap_tablespace=MOF:BANANA,TEST:BANANA directory=DATA_PUMP_DIR dumpfile=XXX.DMP logfile=impdp.log -- FULL=YES parallel=16\n\n\n-- 增加指定表空间文件（单个表空间文件最大32G，需要扩充）\nALTER TABLESPACE BANANA ADD DATAFILE 'E:\\OracleData\\tablespace\\DATAS01.dbf' SIZE 100M AUTOEXTEND ON NEXT 50M  ;\n\n\n导入导出实操过程命令保存\n\n-- 导出命令\nexpdp username/passwd@ip:port/lgfv directory=DATA_PUMP_DIR dumpfile=xxx.dmp logfile=xxx.log schemas=username\n-- 导出后对数据包进行压缩（WinRAR工具分卷压缩）！！！减少网络传输\n\n-- 表空间创建（确定表空间足够，一个文件最大32G）\n-- create TABLESPACE RZPT datafile 'D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\RZPT01.dbf' size 100m autoextend on next 100m MAXSIZE UNLIMITED extent management local; \n-- ALTER TABLESPACE RZPT ADD DATAFILE 'D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\RZPT02.dbf' SIZE 100M AUTOEXTEND ON NEXT 100M  ;\n\n-- 创建用户并授权\ncreate user username2 identified BY passwd2 default TABLESPACE RZPT;\nGrant dba to username2 with admin option;\n\n-- 查询原库用到的表空间\nSELECT DISTINCT TABLESPACE_NAME\nFROM DBA_SEGMENTS\nWHERE OWNER = 'username';\n\n-- 导入命令\nimpdp username2/passwd2@localhost/orcl DIRECTORY=DATA_PUMP_DIR DUMPFILE=xxx.DMP remap_schema=username:username2 remap_tablespace=DSY:RZPT,CS_CZB_RZPT:RZPT LOGFILE=xxx.log parallel=4\n\n-- 附：删除用户报有连接  查询会话并杀死\nSELECT s.sid, s.serial#, s.username, s.status, p.spid\nFROM v$session s, v$process p\nWHERE s.paddr = p.addr AND s.username = 'username';\n-- ALTER SYSTEM KILL SESSION '143,46649' ;\n\n-- 附：若导入卡在 处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX 不动；\n-- 查看日志\nshow parameter dump -- 命令行执行，查看日志位置\n-- 查看 alert_orcl.log 若日志有相关提示\nselect group#,sequence#,bytes,members,status from v$log;   \nalter database add logfile group 4 ('D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\REDO04.LOG') size 200M;\nalter database add logfile group 5 ('D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\REDO05.LOG') size 1G;\nalter system switch logfile;\n-- ALTER DATABASE DROP LOGFILE GROUP 4;   -- 删除旧组\n\n\n报错处理\n\n 1. ORA-39083: ORA-14460: 只能指定一个 COMPRESS 或 NOCOMPRESS 子句，导入命令加参数 transform=segment_attributes:n （未实测）\n\n命令保存\n\n-- 创建目录\ncreate directory my_dir as '/home/oracle/tmp';\ngrant read,write on directory my_dir to username;\n\n-- 环境变量(若没配置好，需先执行)   若不搞好容易表注释乱码！！！\nexport ORACLE_HOME=/xxx/oracle/product/11.2.0/dbhome_1\nexport ORACLE_SID=orcl\nexport PATH=$ORACLE_HOME/bin:$PATH\nexport NLS_LANG=AMERICAN_AMERICA.ZHS16GBK\n\n-- exp/imp 导入导出指定表\nexp 导出用户名/'密码'@orcl file=/home/oracle/xxx.dmp tables=\\(tablename1, tablename2\\) log=/home/oracle/xxx.log schemas=scott\nimp 导入用户名/'密码'@orcl file=/home/oracle/xxx.dmp tables=\\(tablename1, tablename2\\) log=/home/oracle/xxx.log statistics=none schemas=scott\n\n\n-- expdp/impdp 导入导出 \nexpdp $USERNAME/$PASSWD DUMPFILE=xxx.dmp(据说可以为任意后缀名) DIRECTORY=DATA_PUMP_DIR(Oracle内变量) FULL=y LOGFILE=xxx.log schemas=scott\nimpdp $USERNAME/$PASSWD directory=DATA_PUMP_DIR dumpfile=xxx.dmp logfile=xxx.log full=yes schemas=scott\nexpdp $USERNAME/$PASSWD DUMPFILE=xxx.dmp DIRECTORY=DATA_PUMP_DIR LOGFILE=xxx.log tables=\\(tablename1, tablename2\\) schemas=scott\nimpdp $USERNAME/$PASSWD directory=DATA_PUMP_DIR dumpfile=xxx.dmp logfile=xxx.log tables=\\(tablename1, tablename2\\) schemas=scott\n\n-- 参数\nparallel=5 -- 并行导出\ncontent=metadata_only -- 元数据(包含表定义、存储过程、函数等等)\ninclude=\\(procedure,function,view\\)\nexclude=index  -- 排除\n\n------------------------------------------ 导出 ------------------------------------------------\n##导出一张表，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log tables=scott.emp schemas=scott\n\n##导出多张表，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log tables=\\(scott.emp,scott.dept\\) schemas=scott\n\n##导出一个用户(导出这个用户的所有对象)，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log schemas=scott\n\n##导出多个用户，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log schemas=\\(scott,hr\\)\n\n##导出整个数据库（sys、ordsys、mdsys的用户数据不会被导出）例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log full=yes\n\n------------------------------------------ 导入 ------------------------------------------------\n##导入dmp文件中的所有数据，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log full=yes schemas=scott\n\n##导入一张表，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log tables=scott.emp schemas=scott\n\n##导入多张表，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log tables=\\(scott.emp,scott.dept\\) schemas=scott\n\n##导入一个用户，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log schemas=scott\n\n##导入多个用户，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log schemas=\\(scott,hr\\)\n\n\n\n# Oracle 高版本导出，低版本导入，修改版本号\n\n 1. 使用 AlexTools 工具\n 2. 导出时指定版本，增加参数（例：version=11.2）\n\n\n# REDOLOG（导库、大批量、长事务是不是需要调整？）\n\nshow parameter dump -- 命令行执行，查看日志位置\n\nselect group#,sequence#,bytes,members,status from v$log;   --查询日志组\nSELECT GROUP#, MEMBER FROM V$LOGFILE;  -- 查看成员文件路径。\n\n-- 增加日志文件\nalter database add logfile group 4 ('D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\REDO04.LOG') size 200M;\nalter database add logfile group 5 ('D:\\APP\\ADMINISTRATOR\\ORADATA\\ORCL\\REDO05.LOG') size 1G;\n-- ALTER DATABASE ADD LOGFILE GROUP 4 ('/u01/oradata/redo04a.log', '/u02/oradata/redo04b.log') SIZE 200M;\n\n\n-- 切换日志文件\nalter system switch logfile;\n\n-- ALTER DATABASE DROP LOGFILE GROUP 4;   -- 删除旧组 删除后需手动清理物理文件\n    \n-- 查询REDOLOG切换次数\nSELECT trunc(first_time) \"Date\",\n       to_char(first_time, 'Dy') \"Day\",\n       COUNT(1) \"Total\",\n       SUM(decode(to_char(first_time, 'hh24'), '00', 1, 0)) \"h0\",\n       SUM(decode(to_char(first_time, 'hh24'), '01', 1, 0)) \"h1\",\n       SUM(decode(to_char(first_time, 'hh24'), '02', 1, 0)) \"h2\",\n       SUM(decode(to_char(first_time, 'hh24'), '03', 1, 0)) \"h3\",\n       SUM(decode(to_char(first_time, 'hh24'), '04', 1, 0)) \"h4\",\n       SUM(decode(to_char(first_time, 'hh24'), '05', 1, 0)) \"h5\",\n       SUM(decode(to_char(first_time, 'hh24'), '06', 1, 0)) \"h6\",\n       SUM(decode(to_char(first_time, 'hh24'), '07', 1, 0)) \"h7\",\n       SUM(decode(to_char(first_time, 'hh24'), '08', 1, 0)) \"h8\",\n       SUM(decode(to_char(first_time, 'hh24'), '09', 1, 0)) \"h9\",\n       SUM(decode(to_char(first_time, 'hh24'), '10', 1, 0)) \"h10\",\n       SUM(decode(to_char(first_time, 'hh24'), '11', 1, 0)) \"h11\",\n       SUM(decode(to_char(first_time, 'hh24'), '12', 1, 0)) \"h12\",\n       SUM(decode(to_char(first_time, 'hh24'), '13', 1, 0)) \"h13\",\n       SUM(decode(to_char(first_time, 'hh24'), '14', 1, 0)) \"h14\",\n       SUM(decode(to_char(first_time, 'hh24'), '15', 1, 0)) \"h15\",\n       SUM(decode(to_char(first_time, 'hh24'), '16', 1, 0)) \"h16\",\n       SUM(decode(to_char(first_time, 'hh24'), '17', 1, 0)) \"h17\",\n       SUM(decode(to_char(first_time, 'hh24'), '18', 1, 0)) \"h18\",\n       SUM(decode(to_char(first_time, 'hh24'), '19', 1, 0)) \"h19\",\n       SUM(decode(to_char(first_time, 'hh24'), '20', 1, 0)) \"h20\",\n       SUM(decode(to_char(first_time, 'hh24'), '21', 1, 0)) \"h21\",\n       SUM(decode(to_char(first_time, 'hh24'), '22', 1, 0)) \"h22\",\n       SUM(decode(to_char(first_time, 'hh24'), '23', 1, 0)) \"h23\"\n  FROM V$log_history\n WHERE FIRST_TIME >= TRUNC(SYSDATE, 'MM')\n GROUP BY trunc(first_time), to_char(first_time, 'Dy')\n ORDER BY 1 DESC\n;\n\n\n\n# 解决本地Oracle服务内存占用过高\n\nOracle安装时，为均衡电脑性能和数据库性能，默认内存大小为物理内存的1/8\n\n 1. 用dba身份进入oracle\n 2. show parameter sga; --显示内存分配情况\n 3. alter system set sga_target=1024m scope=spfile;-修改target大小 //这个值必须小于等于sga_max_size ，否则库会起不来；\n 4. alter system set sga_max_size=1024m scope=spfile; --修改最大占用内存的大小\n 5. 修改后重启Oracle服务\n 6. 附：Oracle服务介绍 原文链接\n    * Oracle ORCL VSS Writer Service：Oracle卷映射拷贝写入服务，VSS（Volume Shadow Copy Service）能够让存储基础设备（比如磁盘，阵列等）创建高保真的时间点映像，即映射拷贝（shadow copy）。它可以在多卷或者单个卷上创建映射拷贝，同时不会影响到系统的系统能。（非必须启动）\n    * OracleDBConsoleorcl：Oracle数据库控制台服务，orcl是Oracle的实例标识，默认的实例为orcl。在运行Enterprise Manager（企业管理器OEM）的时候，需要启动这个服务。（非必须启动）\n    * OracleJobSchedulerORCL：Oracle作业调度（定时器）服务，ORCL是Oracle实例标识。（非必须启动）\n    * OracleMTSRecoveryService：服务端控制。该服务允许数据库充当一个微软事务服务器MTS、COM/COM+对象和分布式环境下的事务的资源管理器。（非必须启动）\n    * OracleOraDb11g_home1ClrAgent：Oracle数据库 .NET扩展服务的一部分。 （非必须启动）\n    * OracleOraDb11g_home1TNSListener：监听器服务，服务只有在数据库需要远程访问的时候才需要。（非必须启动但很常用）\n    * OracleServiceORCL：数据库服务(数据库实例)，是Oracle核心服务，该服务是数据库启动的基础， 只有该服务启动，Oracle数据库才能正常启动。(必须启动)\n\n\n# 数据插入慢的问题\n\n新增：晚上跑存储过程稍快（好几个表两千多万条数据4688s），为什么？因为磁盘读写速度慢T.T\n\n 1. 有个九百多万数据的表需要重新抽数（抽数速度极其慢，后发现是索引导致的，不清楚是索引有问题还是正常现象（索引增加查询速率但影响insert、update、delete效率），应该先删除索引再抽数）\n    \n    > 没删除索引前的效率： 【345430 条数据花费 1406s】【345430 条数据花费1301s】\n    > 删除后的效率：【345508条数据花费 64s】【345482 条数据花费 7.248s】【345508 条数据34.466s】【datax：1641410条数据465s】",normalizedContent:"# oracle 常用性能排查语句\n\n# 查看表空间大小\n\n----------------------------------------\n\n--oracle表空间大小\nselect a.tablespace_name \"表空间名\",\n       total \"表空间大小\",\n       free \"表空间剩余大小\",\n       (total - free) \"表空间使用大小\",\n       round(total / (1024 * 1024 * 1024),2) \"表空间大小(g)\",\n       round(free / (1024 * 1024 * 1024),2) \"表空间剩余大小(g)\",\n       round((total - free) / (1024 * 1024 * 1024),2) \"表空间使用大小(g)\",\n       round((total - free) / total, 4) * 100 \"使用率 %\"\n  from (select tablespace_name, sum(bytes) free\n          from dba_free_space\n         group by tablespace_name) a,\n       (select tablespace_name, sum(bytes) total\n          from dba_data_files\n         group by tablespace_name) b\n where a.tablespace_name = b.tablespace_name\n\n\n查看单表占用磁盘空间\n\nselect *\n  from (select t.tablespace_name,\n               t.owner,\n               t.segment_name,\n               t.segment_type,\n               sum(t.bytes / 1024 / 1024) mb\n          from dba_segments t\n         where t.segment_type = 'table' and t.segment_name = 'table_name'\n         group by t.tablespace_name, t.owner, t.segment_name, t.segment_type) t\n order by t.mb desc;\n\n\n# 查看锁表及解决\n\n----------------------------------------\n\n1.下面的语句用来查询哪些对象被锁：\nselect object_name,machine,s.sid,s.serial#,l.oracle_username\nfrom v$locked_object l,dba_objects o ,v$session s\nwhere l.object_id　=　o.object_id and l.session_id=s.sid;\n2.下面的语句用来杀死一个进程：\nalter system kill session '24,111'; (其中24,111分别是上面查询出的sid,serial#);\n3.批量删除\nselect 'alter system kill session ''' || s.sid || ',' || s.serial# || '''' || ';'\n  from v$locked_object l, dba_objects o, v$session s\n where l.object_id　 = 　o.object_id\n   and l.session_id = s.sid;\n\nselect object_name,a.sql_text,machine,s.sid,s.serial#,s.status,lockwait,machine,program\nfrom v$locked_object l,dba_objects o ,v$session s,v$sql a\nwhere l.object_id　=　o.object_id and l.session_id=s.sid and a.hash_value = s.sql_hash_value;\nusername：死锁语句所用的数据库用户；\nlockwait：死锁的状态，如果有内容表示被死锁。\nstatus： 状态，active表示被死锁\nmachine： 死锁语句所在的机器。\nprogram： 产生死锁的语句主要来自哪个应用程序。\n\n\n\n   select b.file_id　　文件id,\n　　      b.tablespace_name　　表空间,\n　　      b.file_name　　　　　物理文件名,\n　　      b.bytes　　　　　　　总字节数,\n　　      (b.bytes-sum(nvl(a.bytes,0)))　　　已使用,\n　　      sum(nvl(a.bytes,0))　　　　　　　　剩余,\n　　      sum(nvl(a.bytes,0))/(b.bytes)*100　剩余百分比\n　　 from dba_free_space a,dba_data_files b\n　　where a.file_id=b.file_id\n group by b.tablespace_name,b.file_name,b.file_id,b.bytes\n order by b.tablespace_name\n\n\n\n--最新\nselect object_name,a.sql_text,machine,s.sid,s.serial#,s.status,lockwait,machine,program,l.oracle_username\n  from v$locked_object l,dba_objects o ,v$session s,v$sql a\n where l.object_id　=　o.object_id and l.session_id=s.sid and a.hash_value = s.sql_hash_value;\n\nalter system kill session '1902,24317'; \n\n\ngrant alter system to ysgl_guanli\n\n\n# 查询行锁并解决\n\n--------------------------------- 方案1\n--行锁查看\nselect s.sid,s.serial#,s.machine,s.type,l.type,l.ctime,l.block,l.request,l.lmode,\n       decode(l.lmode, 0, 'none', 1, 'null', 2, 'row-s (ss)', 3, 'row-x (sx)', 4, 'share', 5, 's/row-x (ssx)', 6, 'exclusive', substr(to_char(l.lmode), 1, 13)) as \"locked mode\",\n       decode(l.type,'mr','file_id:' || l.id1,'tm',t.name,'tx','usn:' || to_char(trunc(l.id1 / 65536)) || 'rwo:' ||nvl(r.name, 'none'), l.id1) as lock_id1,\n       'alter system kill session ''' || s.sid || ',' || s.serial# || '''immediate;' as \"kill\"\n  from gv$process p\n inner join gv$session s\n    on s.paddr = p.addr\n inner join v$lock l\n    on l.sid = s.sid\n  left join sys.obj$ t\n    on l.id1 = t.obj#\n  left join sys.obj$ r\n    on s.row_wait_obj# = r.obj#\n where 1 = 1\n   and l.type != 'mr' \n and l.type  = 'tm'\n   and l.lmode = 3\n order by s.sid;\n\n-- 查看原因?\nwith sessions as\n(select  /*+materialize*/\n         sid\n        ,sql_id\n        ,event\n        ,blocking_session\n        ,row_wait_obj#\nfrom gv$session)\nselect lpad(' ', level ) || sid sid\n      ,sql_id\n      ,event\n      ,owner||decode(owner,null,null,'.')||object_name object_name\n      ,substr(sql_text,1,40) sql_text\nfrom sessions s\nleft outer join dba_objects on (object_id = row_wait_obj#)\nleft outer join v$sql using (sql_id)\nwhere sid in (select blocking_session from sessions)\nor blocking_session is not null\nconnect by prior sid = blocking_session\n   start with blocking_session is null;\n\n--------------------------------- 方案2\n   select 'alter system kill session ''' || ss.sid || '' || ',' || ss.serial# || ',@' ||\n       ss.inst_id || ''' immediate;' db_kill_session\n  from gv$session s, \n  gv$session ss\n where s.final_blocking_session is not null\n   and s.final_blocking_instance = ss.inst_id\n   and s.final_blocking_session = ss.sid\n   and s.sid <> ss.sid;\n\n\n# 刷新表统计信息（做表分析）\n\n  统计信息主要是描述数据库中表，索引的大小，规模，数据分布状况等的一类信息。例如，表的行数，块数，平均每行的大小，索引的leaf blocks，索引字段的行数，不同值的大小等，都属于统计信息。cbo正是根据这些统计信息数据，计算出不同访问路径下，不同join 方式下，各种计划的成本，最后选择出成本最小的计划。\n\n  统计信息是存放在数据字典表中的，如tab$，一般可通过察看某些视图来获取统计信息状况，如dba_tables，dba_indexes，dba_tab_col_statistics， dba_tab_histograms等。在这些视图中包含表示统计信息的一些字段，这些字段只有搜集过统计信息之后才有值，否则是空的。例如：last_analyzed 字段表示上次统计信息搜集的时间，可以根据这个字段，快速的了解最近一次统计信息搜集的时间。\n\n博客： 有关oracle统计信息的知识点\n博客： oracle 11g新特性之统计信息收集\n\n--当表没有做分析的时候，oracle 会使用动态采样来收集统计信息。获取准确的段对象（表，表分区，索引等）的分析数据，是cbo存在的基石，\n--cbo的机制就是收集尽可能多的对象信息和系统信息，通过对这些信息进行计算，分析，评估，最终得出一个成本最低的执行计划。\n--所以对于cbo，数据段的分析就非常重要。\n\n解锁单个用户schema\nexec dbms_stats.unlock_schema_stats('用户名');\n\n单个表统计数据的统计数据更新\nexec dbms_stats.gather_table_stats('【username】','【tablename】', estimate_percent => dbms_stats.auto_sample_size, cascade=>true);\n-- exec dbms_stats.gather_table_stats('【username】','【tablename】',cascade=>true);\n-- analyze table tablename compute statistics 等同于 analyze table tablename compute statistics for table for all indexes for all columns\n\n-- 更新整个用户所有表的统计数据更新\n-- exec dbms_stats.gather_schema_stats('【username】',estimate_percent=>100,cascade=> true);\n\n\n参数说明: (https://www.cnblogs.com/tingxin/p/12663682.html)\nownname:要分析表的拥有者\ntabname:要分析的表名.\npartname:分区的名字,只对分区表或分区索引有用.\nestimate_percent:采样行的百分比,取值范围[0.000001,100],null为全部分析,不采样. 常量:dbms_stats.auto_sample_size是默认值,由oracle决定最佳取采样值.\nblock_sapmple:是否用块采样代替行采样.\nmethod_opt:决定histograms信息是怎样被统计的.method_opt的取值如下(默认值为for all columns size auto):\nfor all columns:统计所有列的histograms.\nfor all indexed columns:统计所有indexed列的histograms.\nfor all hidden columns:统计你看不到列的histograms\nfor columns <list> size <n> | repeat | auto | skewonly:统计指定列的histograms.n的取值范围[1,254]; repeat上次统计过的histograms;auto由oracle决定n的大小;skewonly multiple end-points with the same value which is what we define by \"there is skew in thedata\ndegree:决定并行度.默认值为null.\ngranularity:granularity of statistics to collect ,only pertinent if the table is partitioned.\ncascade:是收集索引的信息.默认为false.\nstattab:指定要存储统计信息的表,statid如果多个表的统计信息存储在同一个stattab中用于进行区分.statown存储统计信息表的拥有者.以上三个参数若不指定,统计信息会直接更新到数据字典.\nno_invalidate: does not invalidate the dependent cursors if set to true. the procedure invalidates the dependent cursors immediately if set to false.\nforce:即使表锁住了也收集统计信息.\n\n\n这是对命令与工具包的一些总结\n1、对于分区表，建议使用dbms_stats，而不是使用analyze语句。\na) 可以并行进行，对多个用户，多个table\nb) 可以得到整个分区表的数据和单个分区的数据。\nc) 可以在不同级别上compute statistics：单个分区，子分区，全表，所有分区\nd) 可以倒出统计信息\ne) 可以用户自动收集统计信息\n2、dbms_stats的缺点\na) 不能validate structure\nb) 不能收集chained rows, 不能收集cluster table的信息，这两个仍旧需要使用analyze语句。\nc) dbms_stats 默认不对索引进行analyze，因为默认cascade是false，需要手工指定为true\n3、对于oracle 9里面的external table，analyze不能使用，只能使用dbms_stats来收集信息。\n\n\n\n# 查询正在执行的sql\n\nselect b.inst_id,b.sid oracleid,\n       b.username 登录oracle用户名,\n       b.serial#,\n       spid 操作系统id,\n       paddr,\n       sql_text 正在执行的sql,\n       sql_fulltext,\n       b.machine 计算机名,\n       b.event,\n       'alter system kill session '''||b.sid||','||b.serial#||''';'\nfrom gv$process a, gv$session b, gv$sql c\nwhere a.addr = b.paddr\n   and b.sql_hash_value = c.hash_value\n   and a.inst_id=1\n   and b.inst_id=1\n   and c.inst_id=1\n   and b.status='active'\n   ;\n\n\n# 查询sql平均耗时\n\n--根据平均耗时大小排序\nselect a.sql_text,\n       a.sql_id,\n       a.executions \"总执行次数\",\n       nvl(a.elapsed_time, 0) / 1000 / 1000 \"总耗时(秒)\",\n       (nvl(a.elapsed_time, 0) /\n       nvl(decode(a.executions, 0, 1, a.executions), 1)) / 1000 / 1000 \"平均耗时（秒）\",\n       a.parse_calls \"硬解析次数\",\n       a.disk_reads \"物理读次数\",\n       a.buffer_gets \"读缓存区次数\",\n       a.first_load_time \"sql开始执行时间\"\n  from v$sql a\n where a.first_load_time like '2022-07-13%'\n order by (nvl(a.elapsed_time, 0) /\n          nvl(decode(a.executions, 0, 1, a.executions), 1)) / 1000 / 1000 desc;\n\n\n# 慢查询耗时\n\n-- 慢查询耗时\nselect *\n from (select sa.sql_text \"执行 sql\",\n        sa.executions \"执行次数\",\n        round(sa.elapsed_time / 1000000, 2) \"总执行时间\",\n        round(sa.elapsed_time / 1000000 / sa.executions, 2) \"平均执行时间\",\n        sa.command_type,\n        sa.parsing_user_id \"用户id\",\n        u.username \"用户名\",\n        sa.hash_value\n     from v$sqlarea sa\n     left join all_users u\n      on sa.parsing_user_id = u.user_id\n     where sa.executions > 0\n     order by (sa.elapsed_time / sa.executions) desc)\n where rownum <= 50;\n\n\n# 找到正在运行的存储过程并杀死\n\n-- ddl锁 dba_ddl_locks\n1.查询正在运行的存储过程（包、函数等）\nselect name from v$db_object_cache where type in ('procedure', 'package body', 'package') and locks > 0 and pins > 0;\n-- 获取ddl锁的信息\nselect * from dba_ddl_locks where owner = 'xxx' and name='xxx';\n\n2.找到对应存储过程的sid\nselect/*+rule */ sid from v$access o where owner='过程的所属用户' and o.object = '存储过程'   --（参数是存储过程名称）\n\n3.根据sid找到对应的serial#\nselect sid,serial# from v$session a where a.sid='sid'\n\n4.终止运行存储过程\nalter system kill session 'sid,serial#'  (例如：alter system kill session 'sid,serial#')\n\n\n# 其他\n\n--查询当前用户使用了多少还原表空间\nselect d.username,c.name,b.writes\nfrom v$transaction a,v$rollstat b,v$rollname c,v$session d\nwhere d.taddr=a.addr\n  and a.xidusn=b.usn\n  and b.usn=c.usn\norder by d.username;\n\n-- 查看临时表空间的使用情况\nselect ts.name,ts.phyrds \"reads\",ts.phywrts \"writes\",ts.phyblkrd,ts.phyblkwrt,ts.readtim \"rtime\",ts.writetim \"wtime\"\n  from v$tablespace ts,v$tempfile tf ,v$tempstat ts\n where ts.ts#=tf.ts#\n   and tf.file#=ts.file#;\n\n-- 查看数据文件的i/o分布情况\nselect name,phyrds,phywrts,readtim,writetim\n  from v$filestat a,v$datafile b\n where a.file#=b.file#\n order by readtim desc;\n\n-- 查看连接oracle的所有机器的连接数和状态\nselect machine,status,count(*) from v$session group by machine,status order by status;\n\n/*\nsga(system global area)：由所有服务进程和后台进程共享；\npga(program global area)：由每个服务进程、后台进程专有；每个进程都有一个pga。\n*/\n-- oracle的pga、sga和process count\nselect 'sga' as name,round(sum(value)/1024/1024,2)||'m' as \"size(m)\" from v$sga\nunion\nselect 'pga' as name,round(value/1024/1024,2)||'m' as \"size(m)\" from v$pgastat where name='total pga allocated'\nunion\nselect 'total' as name,((select round(sum(value)/1024/1024,2) from v$sga)+(select round(value/1024/1024,2) from v$pgastat where name='total pga allocated'))||'m' as \"size(m)\" from dual\nunion\nselect name,to_char(value) from v$pgastat where name='process count';\n\n\n\n# scn\n\n----------------------------------------\n\nscn（system change number），也就是通常所说的系统改变号，是数据库中非常重要的一个数据结构。\nscn用以标识数据库在某个确切时刻提交的版本。在事务提交时，它被赋予一个唯一的标识事务的scn。scn同时被作为oracle数据库的内部时钟机制，可被看做逻辑时钟，每个数据库都有一个全局的scn生成器。\n作为数据库内部的逻辑时钟，数据库事务依scn而排序，oracle也依据scn来实现一致性读（read consistency）等重要数据库功能。另外对于分布式事务（distributed transactions），scn也极为重要，这里不做更多介绍。\nscn在数据库中是唯一的，并随时间而增加，但是可能并不连贯。除非重建数据库，scn的值永远不会被重置为0.\n一直以来，对于scn有很多争议，很多人认为scn是指system commit number，而通常scn在提交时才变化，所以很多时候，这两个名词经常在文档中反复出现。即使在oracle的官方文档中，scn也常以system change/commit number两种形式出现。\n到底是哪个词其实不是很重要，重要的是需要知道scn是oracle内部的时钟机制，oracle通过scn来维护数据库的一致性，并通过scn实施oracle至关重要的恢复机制。\nscn在数据库中是无处不在，常见的事务表、控制文件、数据文件头、日志文件、数据块头等都记录有scn值。\n冠以不同前缀，scn也有了不同的名称，如检查点scn（checkpint scn）、resetlogs scn等。\n\n-- 当前scn号和时间的对应关系：\nselect dbms_flashback.get_system_change_number,scn_to_timestamp(dbms_flashback.get_system_change_number) from dual;\n\n-- 查询当前scn：\nselect current_scn from v$database;\nselect dbms_flashback.get_system_change_number from dual;\n\n-- scn与时间的相互转换\n将scn转换成时间戳: scn_to_timestamp(scn_number)\n将时间戳转换成scn: timestamp_to_scn(timestamp)\n\n-- 数据行伪列保存数据最后更新时间  select ora_rowscn from table_name;\n-- 系统表保存scn与时间戳对应关系（保留5天）   select * from sys.smon_scn_time\n\n了解更多请核查看博客：https://blog.csdn.net/fuwencaho/article/details/21256973\n\n\n\n\n# oracle 表闪回\n\n查看是否开启闪回功能：select flashback_on from v$database;\n\n# 查询历史版本数据（闪回查询）\n\n-- 查询出类似拉链表的数据（包含历史版本）\nselect \n       字段名,\n       to_char(versions_starttime, 'yyyy-mm-dd hh24:mi:ss') as versions_starttime,\n       to_char(versions_endtime, 'yyyy-mm-dd hh24:mi:ss') as versions_endtime,\n       versions_operation\n  from 表名 versions between timestamp minvalue and maxvalue\n where versions_starttime is not null\n order by versions_starttime desc;\n\n\n# 恢复已删除的表\n\n-- 恢复已删除的表\nflashback table table_name to before drop;\n\n-- 若删除后已经创建了同名的表（ora-38312）\n-- 如果表名重复，则闪回时遵循后入先出的原则。\nflashback table test to before drop rename to test1;\n\n\n扩展：\n\n-- 闪回时可指明被恢复的回收站对象\nflashback table \"bin$ayid7zbbjwngukjadqiiua==$0\" to before drop;\n\n-- 闪回删表的工作原理是：当“drop table”命令执行时，表及其索引并没有被真正删除，其所占空间只是分配给了另一个数据库对象：回收站对象，本质上相当于重命名。注意：表空间在自动增长的压力下会按照先入先出的规则将回收站对象的空间分配给需要空间的段，在将回收站对象耗尽之前数据文件是不会自动增长的。\n-- oracle启用回收站功能后，使用drop table ...语句删除一张表时，并不会将表给删除，而是以一定的格式重新对表重命名，然后将该表放到数据字典表中，在遇到表空间不足的情况下自动清理这些表，释放被占用的空间，让其它对象能够使用这些空间。\n\n-- 可禁用回收站功能\nalter system set recyclebin='off' scope=spfile;\n\n-- 清理指定用户的表空间中的回收站对象\npurge tablespace users user user_name;\n-- 删除当前用户回收站的所有对象\npurge recyclebin;\n    \n-- dbms_flashback包\n-- 利用dbms_flashback包的enable_at_time或enable_at_scn存储过程锁定一个会话级别的闪回时间目标，即进入闪回模式，随后的查询命令可以省略“as of”，直到调用dbms_flashback_disable存储过程将其关闭为止。\n\n\n# 恢复表到某个时间点\n\n-- 确定要恢复的表的时间点\nselect * from table_name as of timestamp(to_timestamp('2024-08-29 19:00:00', 'yyyy-mm-dd hh24:mi:ss'));\n\n-- 将表恢复到指定时间点\nflashback table table_name to timestamp(to_timestamp('2024-08-29 19:00:00', 'yyyy-mm-dd hh24:mi:ss'));\n-- 1. \"flashback table\"命令的执行者必须有\"flashback any table\"系统权限或者在被闪回的表上具有\"flashback\"对象权限。\n-- 2. 需启用行移动  alter table debt_t_file_info_fabz_bak enable row movement;\n-- 3. \"flashback table\"属于ddl命令，隐式提交。\n-- 4. sys用户的任何表无法使用此功能。\n\n\n\n# logminer\n\n----------------------------------------\n\n众所周知，所有对用户数据和数据字典的改变都记录在oracle的redo log中，因此，redo log包含了所有进行恢复操作所需要的信息。但是，原始的redo log文件无法看懂，所以，oracle从8i以后提供了一个非常有用的分析工具，称为logminer。使用该工具可以轻松获得redo log文件（包含归档日志文件）中的具体内容。特别是该工具可以分析出所有对于数据库的dml操作（insert、update、delete等）语句。oracle 9i后可以分析ddl语句，另外还可分析得到一些必要的回滚sql语句。logminer一个最重要的用途就是不用全部恢复数据库就可以恢复数据库的某个变化。该工具特别适用于调试、审计或者回退某个特定的事务。 logminer工具既可以用来分析在线日志，也可以用来分析离线日志文件，既可以分析本身自己数据库的重作日志文件，也可以用来分析其它数据库的重作日志文件。当分析其它数据库的重作日志文件时，需要注意的是，logminer必须使用被分析数据库实例产生的字典文件，而不是安装logminer的数据库产生的字典文件，另外，必须保证安装logminer数据库的字符集和被分析数据库的字符集相同。源数据库（source database）平台必须和分析数据库（mining database）平台一样。 oracle通过logminer工具对redo log进行挖掘，显示出一系列可读的信息，该过程称为日志挖掘。logminer通过v$logmnr_contents视图显示redo log中的信息。\n\n总的说来，logminer工具的主要用途有：\n\n 1. 跟踪数据库的变化：可以离线地跟踪数据库的变化，而不会影响在线系统的性能\n 2. 回退数据库的变化：回退特定的变化数据，减少point-in-time recovery的执行\n 3. 优化和扩容计划：可通过分析日志文件中的数据以分析数据的增长模式\n 4. 确定数据库的逻辑损坏时间：准确定位操作执行的时间和scn\n 5. 确定事务级要执行的精细逻辑恢复操作，可以取得相应的undo操作\n 6. 执行后续审计\n\n了解更多请查看博客： https://blog.csdn.net/yes_is_ok/article/details/79296614\n\n\n# 动态性能视图(x$,v$,gv$,v_$,gv_$)\n\n----------------------------------------\n\n官方文档12.2\n\nv$database 数据库信息\nv$datafile 数据文件信息\nv$controlfile 控制文件信息\nv$logfile 重做日志信息\nv$instance 数据库实例信息\nv$log 日志组信息\nv$loghist 日志历史信息\nv$sga 数据库sga信息\nv$parameter 初始化参数信息\nv$process 数据库服务器进程信息\nv$bgprocess 数据库后台进程信息\nv$controlfile_record_section 控制文件记载的各部分信息\nv$thread 线程信息\nv$datafile_header 数据文件头所记载的信息\nv$archived_log归档日志信息\nv$archive_dest 归档日志的设置信息\nv$logmnr_contents 归档日志分析的dml ddl结果信息\nv$logmnr_dictionary 日志分析的字典文件信息\nv$logmnr_logs 日志分析的日志列表信息\nv$tablespace 表空间信息\nv$tempfile 临时文件信息\nv$filestat 数据文件的i/o统计信息\nv$undostat undo数据信息\nv$rollname 在线回滚段信息\nv$session 会话信息\nv$transaction 事务信息\nv$rollstat 回滚段统计信息\nv$pwfile_users 特权用户信息\nv$sqlarea 当前查询过的sql语句访问过的资源及相关的信息\nv$sql 与v$sqlarea基本相同的相关信息\nv$sysstat 数据库系统状态信息\n\n\n\n# 常用系统表\n\n原文链接\n\ndba_开头\n\n\ndba_users 数据库用户信息\ndba_segments 表段信息\ndba_extents 数据区信息\ndba_objects 数据库对象信息\ndba_tablespaces 数据库表空间信息\ndba_data_files 数据文件设置信息\ndba_temp_files 临时数据文件信息\ndba_rollback_segs 回滚段信息\ndba_ts_quotas 用户表空间配额信息\ndba_free_space 数据库空闲空间信息\ndba_profiles 数据库用户资源限制信息\ndba_sys_privs 用户的系统权限信息\ndba_tab_privs 用户具有的对象权限信息\ndba_col_privs 用户具有的列对象权限信息\ndba_role_privs 用户具有的角色信息\ndba_audit_trail 审计跟踪记录信息\ndba_stmt_audit_opts 审计设置信息\ndba_audit_object 对象审计结果信息\ndba_audit_session 会话审计结果信息\ndba_indexes 用户模式的索引信息\n\n\nuser_开头\n\nuser_objects 用户对象信息\nuser_source 数据库用户的所有资源对象信息\nuser_segments 用户的表段信息\nuser_tables 用户的表对象信息\nuser_tab_columns 用户的表列信息\nuser_col_comments 用户的表列注释信息\nuser_constraints 用户的对象约束信息\nuser_sys_privs 当前用户的系统权限信息\nuser_tab_privs 当前用户的对象权限信息\nuser_col_privs 当前用户的表列权限信息\nuser_role_privs 当前用户的角色权限信息\nuser_indexes 用户的索引信息\nuser_ind_columns 用户的索引对应的表列信息\nuser_cons_columns 用户的约束对应的表列信息\nuser_clusters 用户的所有簇信息\nuser_clu_columns 用户的簇所包含的内容信息\nuser_cluster_hash_expressions 散列簇的信息\n\n\n\nall_开头\n\nall_users 数据库所有用户的信息\nall_objects 数据库所有的对象的信息\nall_def_audit_opts 所有默认的审计设置信息\nall_tables 所有的表对象信息\nall_indexes 所有的数据库对象索引的信息\n\nsession_开头\nsession_roles 会话的角色信息\nsession_privs 会话的权限信息\n\nindex_开头\nindex_stats 索引的设置和存储信息\n\n**伪表**\ndual 系统伪列表信息\n\n\n\n# 实例\n\n# 查看视图中用到的表和视图\n\n   select name, referenced_type, replace(to_char(wm_concat(distinct referenced_name)), ',', chr(13))\n     from sys.all_dependencies\n    where type = 'view'\n      and name = upper('视图名')\n      and referenced_type in ('table', 'view')\n      and owner = '用户名'\n group by name, referenced_type\n order by referenced_type\n;\n\n\n# 用到 某个表 的视图\n\n\n   select name, referenced_type, replace(to_char(wm_concat(distinct referenced_name)), ',', chr(13))\n     from sys.all_dependencies\n    where type = 'view'\n      and referenced_name = '表名'\n      and owner = '用户名'\n group by name, referenced_type\n order by referenced_type\n;\n\n\n# 查看视图或表创建语句\n\nselect * from all_views where view_name = upper('视图名') and owner = '用户名';\n\n\n# 查询建表语句（不含注释）\n\nselect dbms_metadata.get_ddl('table',upper('tablename')) from dual;\n\n\n# 查看函数、存储过程、触发器、包等创建语句\n\nselect owner, name, type, listagg(text) within group(order by line) as text\n  from all_source\n where name = 'object_name'\n   and owner = 'user_name'\n group by owner, name, type\n\n\n# 迁移数据（大批量操作数据）前禁用索引！！！\n\nselect 'alter index ' || idx.index_name || ' unusable;',\n       'alter index ' || idx.index_name || ' rebuild;'\n  from user_indexes idx\n  left join user_ind_columns idxc\n    on idx.table_name = idxc.table_name\n   and idx.index_name = idxc.index_name\n where idx.uniqueness <> 'unique'\n   and idx.table_name in (select upper(data_target)\n                            from debt_t_exc_config_param\n                           where exc_type = 'qy_in')  /*指定表清单*/\n   and not exists\n (select 1\n          from (select ucc.table_name, ucc.column_name\n                  from user_cons_columns ucc\n                  join user_constraints uc\n                    on ucc.constraint_name = uc.constraint_name\n                 where uc.constraint_type = 'p') t\n         where idx.table_name = t.table_name\n           and idxc.column_name = t.column_name)  /*过滤掉主键列上的索引*/\n;\n\n\n# 查询数据表自上次统计信息收集以来数据变化量\n\ndba_tab_modifications记录自上次统计信息收集以来表上的dml操作（insert、update、delete）及truncate操作的历史数据；该视图依赖于后台作业mmon（15min执行一次），手动执行 exec dbms_stats.flush_database_monitoring_info;\n\n-- 需要启用表监控（激活表修改跟踪）（10g之后，10g之前需手动开启表监控alter table modifi_test nomonitoring/monitoring）\n-- 1. 设置设置统计级别\nshow parameter statistics_level;   -- 查看参数值\n--alter system set statistics_level=typical;   -- 参数设为typical或all\n--alter session set statistics_level=typical; \n\n\n-- 查询\nselect modif.table_owner,\n       modif.table_name,\n       modif.inserts,\n       modif.updates,\n       modif.deletes,\n       modif.timestamp,\n       tabs.last_analyzed  -- 最后分析时间\n  from dba_tab_modifications modif\n inner join dba_tables tabs\n    on modif.table_owner = tabs.owner\n   and modif.table_name = tabs.table_name\n where modif.table_owner = 'qy_czb_rzpt_out'\n   and modif.timestamp >= sysdate - interval '30' day -- 查询最近 1 天内变动的表\n order by modif.timestamp desc\n;\n\n\n\n# 与mysql区别\n\n1、oracle是大型数据库，mysql是小型数据库；\n2、mysql是主键是支持自动增长类型的（在创建表的时候指定表的主键为auto_increment）,在插入记录时，不需要再指定该记录的主键值，mysql将自动增长；\n3、oracle没有自动增长类型主键一般使用序列，在插入记录时，将序列号的下一个值付给该字段即可；\n4、mysql可以用双引号包起字符串，而oracle只能用单引号包起。\n5、处理分页逻辑不一样，mysql使用limit处理分页；而oracle使用rownum字段标明位置，并且只能用rownum&lt;100,不能用rownum>80;\n6、mysql定义的空字段里面可以有空的内容，但是oracle种非空字段不能有空的内；\n7、两者都能使用like “%字符串%”,但是oracle中使用模糊查询后不能使用索引，速度不快；\n8、两者给字段添加注释的方式不一样，\n\n————————————————\n原文链接：https://blog.csdn.net/z19950712/article/details/115478505\n\n\n\n# shell跑oracle脚本\n\n----------------------------------------\n\n#! /bin/sh\nlogpath=\"log\"\nfilepath=\"/home/ap/user\"\n#输入oracle数据库的用户名密码等信息\ndbinfo=\"username/password@ip:port/orcl\"\nif  ! -d ${logpath} ]\nthen\n mkdir log\nfi\necho \"`date +'%y%m%d %h:%m:%s'`] info: begin to execute init sql!\"\nlogfile=\"${logpath}/init_table_data_info.log\"\n#“${logfile} 2>&1”这里的意思就是把标准输出信息和错误输出信息都记录在init_table_data_info.log文件中\nsqlplus -s ${dbinfo} << ! > ${logfile} 2>&1\nwhenever oserror exit 1;\nwhenever sqlerror exit 1;\n@${filepath}/inittable.sql\n@${filepath}/inittable2.sql\nquit\n!\nif  $? -ne 0 ]\nthen\n    echo \"`date +'%y%m%d %h:%m:%s'`] error: initialize inittable failed!\"  >> ${logpath}\n    exit 1\nfi\necho \"`date +'%y%m%d %h:%m:%s'`] initialize inittable  successed.\"  >> ${logpath}\n\n\n\n# oracle关联方式（执行计划）\n\n为啥有说只有三种的（待完善！！！）\n\n> 不同数据库支持情况不同：pgsql支持 nested-loop join 、hash join 、merge join；mysql只支持 nested-loop join\n\noracle的sql优化器（optimizer）在执行多表连接查询时，通常采用的连接算法有以下几种方式：\n1、嵌套循环连接（nested loops join）\n2、哈希连接（hash join）\n3、排序合并连接（sort merge join）\n4、笛卡尔连接（cartesian join）\n5、群集连接（cluster join）\n6、索引连接（index join）\n\n\n多表之间的连接有三种方式：nested loops，hash join 和 sort merge join. 下面来介绍三种不同连接的不同：\n\nnested loop\n\n> 对于被连接的数据子集较小的情况，嵌套循环连接是个较好的选择。在嵌套循环中，内表被外表驱动，外表返回的每一行都要在内表中检索找到与它匹配的行，因此整个查询返回的结果集不能太大（大于1 万不适合），要把返回子集较小表的作为外表（cbo 默认外表是驱动表），而且在内表的连接字段上一定要有索引。当然也可以用ordered 提示来改变cbo默认的驱动表，使用use_nl(table_name1 table_name2)可是强制cbo 执行嵌套循环连接。\n\n> nested loop一般用在连接的表中有索引，并且索引选择性较好的时候.\n\n> 步骤：确定一个驱动表(outer table)，另一个表为inner table，驱动表中的每一行与inner表中的相应记录join。类似一个嵌套的循环。适用于驱动表的记录集比较小（<10000）而且inner表需要有有效的访问方法（index）。需要注意的是：join的顺序很重要，驱动表的记录集一定要小，返回结果集的响应时间是最快的。\n\nhash join\n\n> 散列连接是cbo 做大数据集连接时的常用方式，优化器使用两个表中较小的表（或数据源）利用连接键在内存中建立散列表，然后扫描较大的表并探测散列表，找出与散列表匹配的行。 这种方式适用于较小的表完全可以放于内存中的情况，这样总成本就是访问两个表的成本之和。但是在表很大的情况下并不能完全放入内存，这时优化器会将它分割成若干不同的分区，不能放入内存的部分就把该分区写入磁盘的临时段，此时要有较大的临时段从而尽量提高i/o 的性能。 也可以用use_hash(table_name1 table_name2)提示来强制使用散列连接。如果使用散列连接hash_area_size 初始化参数必须足够的大，如果是9i，oracle建议使用sql工作区自动管理，设置workarea_size_policy 为auto，然后调整pga_aggregate_target 即可。\n\n> hash join在两个表的数据量差别很大的时候.\n\n> 步骤：将两个表中较小的一个在内存中构造一个hash表（对join key），扫描另一个表，同样对join key进行hash后探测是否可以join。适用于记录集比较大的情况。需要注意的是：如果hash表太大，无法一次构造在内存中，则分成若干个partition，写入磁盘的temporary segment，则会多一个写的代价，会降低效率。\n\nsort merge join\n\n> 通常情况下散列连接的效果都比排序合并连接要好，然而如果行源已经被排过序，在执行排序合并连接时不需要再排序了，这时排序合并连接的性能会优于散列连接。可以使用use_merge(table_name1 table_name2)来强制使用排序合并连接. sort merge join 用在没有索引，并且数据已经排序的情况. cost = (outer access cost * # of hash partitions) + inner access cost\n\n> 步骤：将两个表排序，然后将两个表合并。通常情况下，只有在以下情况发生时，才会使用此种join方式：\n> \n> > 1.rbo模式\n> > 2.不等价关联(>,<,>=,<=,<>)\n> > 3.hash_join_enabled=false\n> > 4.数据源已排序\n\n三种连接工作方式比较\n\n> hash join的工作方式是将一个表（通常是小一点的那个表）做hash运算，将列数据存储到hash列表中，从另一个表中抽取记录，做hash运算，到hash 列表中找到相应的值，做匹配。\n\n> nested loops 工作方式是从一张表中读取数据，访问另一张表（通常是索引）来做匹配，nested loops适用的场合是当一个关联表比较小的时候，效率会更高。\n\n> merge join 是先将关联表的关联列各自做排序，然后从各自的排序表中抽取数据，到另一个排序表中做匹配，因为merge join需要做更多的排序，所以消耗的资源更多。 通常来讲，能够使用merge join的地方，hash join都可以发挥更好的性能。\n\n强制使用关联方式\n\nselect /*+use_hash(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\nselect /*+use_nl(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\nselect /*+use_merge(t,t1) */ * from scott.dept t,scott.emp t1 where t.deptno=t1.deptno;\n\n\n原文链接\n\n\n# 点状知识\n\n\n# 匹配中文\n\n使用正则匹配不太好使\n\n替换方案：chr(128) - chr(255) 可以匹配双字节字符（同样不够准确）\nselect regexp_replace('', '['||chr(128)|| '-' || chr(255) ||']', '-') from dual;\n\n\n\n# 创建dblink\n\n> 注：由于 dblink 跨库查询是把一个数据库数据通过网络发送到另一数据库关联查询， 可以通过指定 hint /*+ driving_site(t)*/ 指定驱动表（t 一般是大表），从而减少网络传输。 当然，最终效率还是要综合磁盘io、网络io和计算能力等综合考虑\n\n-- create database link \ncreate public database link <dblink名>\n  connect to <用户名>\n  identified by <\"密码\">\n  using '(description =(address_list =(address =(protocol=tcp)(host=<ip>)(port=<端口>)))(connect_data=(service_name=orcl)))';\n\n\n\n# sql并行\n\n官方文档\n\n原文地址\n\n * 1.查询开启并行（parallel query）\n\nselect /*+parallel(a, 16)*/ count(1) from dual a;     -- 第一种方式（hist方式）\nalter table tab1 parallel n;                          -- 第二种方式\nalter session force parallel query parallel n;        -- 第三种方式\n\n\n * 2.修改数据开启并行（parallel dml (insert, update, delete, and merge) ）\n\n-- 第一种方式（hist方式）\nupdate /*+ parallel(tab1,4) */ tbl_2 set c1=c1+1;\ninsert /*+ parallel(tbl_ins,2) */ into tbl_ins\nselect /*+ parallel(tbl_sel,4) */ * from tbl_sel;\ndelete /*+ parallel (t1, 2) */ from t1\n\n-- 第二种方式\nalter session force parallel dml parallel n;\n\n-- 第三种方式\nalter table tab1 parallel n;\n\n\n * 3.parallel ddl\n\n-- 第一种方式（hist方式）\nalter session force parallel ddl parallel n;\n\n-- 第二种方式\ncreate index ….parallel 10;\nalter index ... rebuild parallel 10;\nalter index ... move partition parallel 10;\nalter index ...split partition parallel 10;\n\n\n * 附：存储过程中开启并行\n\ndeclare\n...\nbegin\n execute immediate 'alter session force parallel dml parallel  8';\n --更新操作\n ...\n commit; --必须先commit,否则会报 ora-12841\n execute immediate 'alter session disable parallel dml ';\n\nexception\n when others then\n   rollback;\n   execute immediate 'alter session disable parallel dml '; \nend;\n\n\n注：使用临时表with as时不能使用并行（比如：在存储过程中开启session并行），否则会导致结果不一致\n\n\n# 中文排序方式\n\noracle9i之前，中文是按照二进制编码进行排序的。\n在oracle9i中新增了按照拼音、部首、笔画排序功能。设置nls_sort值\n\nschinese_radical_m 按照部首(第一顺序)、笔划(第二顺序)排序\nschinese_stroke_m 按照笔划(第一顺序)、部首(第二顺序)排序\nschinese_pinyin_m 按照拼音排序\n\n修改oracle字段的默认排序方式：\n按拼音(默认)：\nalter session set nls_sort = schinese_pinyin_m;\n按笔画：\nalter session set nls_sort = schinese_stroke_m;\n按偏旁：\nalter session set nls_sort = nls_sort=schinese_radical_m;\n\nnlssort()，用来进行语言排序\n\n示例:\nselect * from team order by nlssort(排序字段名,'nls_sort =schinese_pinyin_m')\n\n\n\n# 数据中包含特殊符号需要转义\n\n 1. 执行语句前先执行 set define off; （去掉oracle自定义的字符含义，还原它本来的意思）\n 2. 使用ascii编码对 & 进行转义 chr(38) select 'xxx?xxx=11' || chr(38) || 'xxx=33' from dual\n 3. 不转义，直接字符串的形式写进去 select 'xxx?xxx=11' || '&' || 'xxx=33' from dual\n\n\n# 数据泵导入导出（待完善）\n\n导入：首先我们需要知道导出用户和表空间的名字\n\n注意：1. 如果表空间不是只有一个，需要使用remap_tablespace指定到我们创建的表空间 2. 单个表空间文件最大32g\n\n> 所以拿到导出log文件是非常有必要的\n\n-- 创建表空间  unlimited指定不限制最大表空间\ncreate tablespace banana datafile 'e:\\oracledata\\tablespace\\datas.dbf' size 50m autoextend on next 50m maxsize unlimited extent management local; \n-- 删除表空间\ndrop tablespace banana including contents and datafiles cascade constraints;\n-- 查询表空间\nselect * from dba_tablespaces;\n\n\n-- 管理员登录，创建新用户，分配已创建好的表空间\ncreate user banana identified by banana default tablespace banana;\n-- 删除用户带级联\ndrop user banana cascade;\n\n\n-- 授权\ngrant dba to banana with admin option;\n\n\n-- 查询dup存放目录目录    注意：后面的e盘下面的dpdump 必须把你要导入的xxx.dmp文件放进该文件夹  data_pump_dir\nselect * from dba_directories;\n-- 数据泵导入数据 (cmd命令行   data_pump_dir为上面查出的目录名  如果有其他表空间的，需要使用remap_tablespace指定到我们创建的表空间)\nimpdp banana remap_tablespace=mof:banana,test:banana directory=data_pump_dir dumpfile=xxx.dmp logfile=impdp.log -- full=yes parallel=16\n\n\n-- 增加指定表空间文件（单个表空间文件最大32g，需要扩充）\nalter tablespace banana add datafile 'e:\\oracledata\\tablespace\\datas01.dbf' size 100m autoextend on next 50m  ;\n\n\n导入导出实操过程命令保存\n\n-- 导出命令\nexpdp username/passwd@ip:port/lgfv directory=data_pump_dir dumpfile=xxx.dmp logfile=xxx.log schemas=username\n-- 导出后对数据包进行压缩（winrar工具分卷压缩）！！！减少网络传输\n\n-- 表空间创建（确定表空间足够，一个文件最大32g）\n-- create tablespace rzpt datafile 'd:\\app\\administrator\\oradata\\orcl\\rzpt01.dbf' size 100m autoextend on next 100m maxsize unlimited extent management local; \n-- alter tablespace rzpt add datafile 'd:\\app\\administrator\\oradata\\orcl\\rzpt02.dbf' size 100m autoextend on next 100m  ;\n\n-- 创建用户并授权\ncreate user username2 identified by passwd2 default tablespace rzpt;\ngrant dba to username2 with admin option;\n\n-- 查询原库用到的表空间\nselect distinct tablespace_name\nfrom dba_segments\nwhere owner = 'username';\n\n-- 导入命令\nimpdp username2/passwd2@localhost/orcl directory=data_pump_dir dumpfile=xxx.dmp remap_schema=username:username2 remap_tablespace=dsy:rzpt,cs_czb_rzpt:rzpt logfile=xxx.log parallel=4\n\n-- 附：删除用户报有连接  查询会话并杀死\nselect s.sid, s.serial#, s.username, s.status, p.spid\nfrom v$session s, v$process p\nwhere s.paddr = p.addr and s.username = 'username';\n-- alter system kill session '143,46649' ;\n\n-- 附：若导入卡在 处理对象类型 schema_export/table/index/index 不动；\n-- 查看日志\nshow parameter dump -- 命令行执行，查看日志位置\n-- 查看 alert_orcl.log 若日志有相关提示\nselect group#,sequence#,bytes,members,status from v$log;   \nalter database add logfile group 4 ('d:\\app\\administrator\\oradata\\orcl\\redo04.log') size 200m;\nalter database add logfile group 5 ('d:\\app\\administrator\\oradata\\orcl\\redo05.log') size 1g;\nalter system switch logfile;\n-- alter database drop logfile group 4;   -- 删除旧组\n\n\n报错处理\n\n 1. ora-39083: ora-14460: 只能指定一个 compress 或 nocompress 子句，导入命令加参数 transform=segment_attributes:n （未实测）\n\n命令保存\n\n-- 创建目录\ncreate directory my_dir as '/home/oracle/tmp';\ngrant read,write on directory my_dir to username;\n\n-- 环境变量(若没配置好，需先执行)   若不搞好容易表注释乱码！！！\nexport oracle_home=/xxx/oracle/product/11.2.0/dbhome_1\nexport oracle_sid=orcl\nexport path=$oracle_home/bin:$path\nexport nls_lang=american_america.zhs16gbk\n\n-- exp/imp 导入导出指定表\nexp 导出用户名/'密码'@orcl file=/home/oracle/xxx.dmp tables=\\(tablename1, tablename2\\) log=/home/oracle/xxx.log schemas=scott\nimp 导入用户名/'密码'@orcl file=/home/oracle/xxx.dmp tables=\\(tablename1, tablename2\\) log=/home/oracle/xxx.log statistics=none schemas=scott\n\n\n-- expdp/impdp 导入导出 \nexpdp $username/$passwd dumpfile=xxx.dmp(据说可以为任意后缀名) directory=data_pump_dir(oracle内变量) full=y logfile=xxx.log schemas=scott\nimpdp $username/$passwd directory=data_pump_dir dumpfile=xxx.dmp logfile=xxx.log full=yes schemas=scott\nexpdp $username/$passwd dumpfile=xxx.dmp directory=data_pump_dir logfile=xxx.log tables=\\(tablename1, tablename2\\) schemas=scott\nimpdp $username/$passwd directory=data_pump_dir dumpfile=xxx.dmp logfile=xxx.log tables=\\(tablename1, tablename2\\) schemas=scott\n\n-- 参数\nparallel=5 -- 并行导出\ncontent=metadata_only -- 元数据(包含表定义、存储过程、函数等等)\ninclude=\\(procedure,function,view\\)\nexclude=index  -- 排除\n\n------------------------------------------ 导出 ------------------------------------------------\n##导出一张表，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log tables=scott.emp schemas=scott\n\n##导出多张表，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log tables=\\(scott.emp,scott.dept\\) schemas=scott\n\n##导出一个用户(导出这个用户的所有对象)，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log schemas=scott\n\n##导出多个用户，例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log schemas=\\(scott,hr\\)\n\n##导出整个数据库（sys、ordsys、mdsys的用户数据不会被导出）例：\nexpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=expdp.log full=yes\n\n------------------------------------------ 导入 ------------------------------------------------\n##导入dmp文件中的所有数据，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log full=yes schemas=scott\n\n##导入一张表，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log tables=scott.emp schemas=scott\n\n##导入多张表，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log tables=\\(scott.emp,scott.dept\\) schemas=scott\n\n##导入一个用户，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log schemas=scott\n\n##导入多个用户，例：\nimpdp system/oracle directory=my_dir dumpfile=expdp.dmp logfile=impdp.log schemas=\\(scott,hr\\)\n\n\n\n# oracle 高版本导出，低版本导入，修改版本号\n\n 1. 使用 alextools 工具\n 2. 导出时指定版本，增加参数（例：version=11.2）\n\n\n# redolog（导库、大批量、长事务是不是需要调整？）\n\nshow parameter dump -- 命令行执行，查看日志位置\n\nselect group#,sequence#,bytes,members,status from v$log;   --查询日志组\nselect group#, member from v$logfile;  -- 查看成员文件路径。\n\n-- 增加日志文件\nalter database add logfile group 4 ('d:\\app\\administrator\\oradata\\orcl\\redo04.log') size 200m;\nalter database add logfile group 5 ('d:\\app\\administrator\\oradata\\orcl\\redo05.log') size 1g;\n-- alter database add logfile group 4 ('/u01/oradata/redo04a.log', '/u02/oradata/redo04b.log') size 200m;\n\n\n-- 切换日志文件\nalter system switch logfile;\n\n-- alter database drop logfile group 4;   -- 删除旧组 删除后需手动清理物理文件\n    \n-- 查询redolog切换次数\nselect trunc(first_time) \"date\",\n       to_char(first_time, 'dy') \"day\",\n       count(1) \"total\",\n       sum(decode(to_char(first_time, 'hh24'), '00', 1, 0)) \"h0\",\n       sum(decode(to_char(first_time, 'hh24'), '01', 1, 0)) \"h1\",\n       sum(decode(to_char(first_time, 'hh24'), '02', 1, 0)) \"h2\",\n       sum(decode(to_char(first_time, 'hh24'), '03', 1, 0)) \"h3\",\n       sum(decode(to_char(first_time, 'hh24'), '04', 1, 0)) \"h4\",\n       sum(decode(to_char(first_time, 'hh24'), '05', 1, 0)) \"h5\",\n       sum(decode(to_char(first_time, 'hh24'), '06', 1, 0)) \"h6\",\n       sum(decode(to_char(first_time, 'hh24'), '07', 1, 0)) \"h7\",\n       sum(decode(to_char(first_time, 'hh24'), '08', 1, 0)) \"h8\",\n       sum(decode(to_char(first_time, 'hh24'), '09', 1, 0)) \"h9\",\n       sum(decode(to_char(first_time, 'hh24'), '10', 1, 0)) \"h10\",\n       sum(decode(to_char(first_time, 'hh24'), '11', 1, 0)) \"h11\",\n       sum(decode(to_char(first_time, 'hh24'), '12', 1, 0)) \"h12\",\n       sum(decode(to_char(first_time, 'hh24'), '13', 1, 0)) \"h13\",\n       sum(decode(to_char(first_time, 'hh24'), '14', 1, 0)) \"h14\",\n       sum(decode(to_char(first_time, 'hh24'), '15', 1, 0)) \"h15\",\n       sum(decode(to_char(first_time, 'hh24'), '16', 1, 0)) \"h16\",\n       sum(decode(to_char(first_time, 'hh24'), '17', 1, 0)) \"h17\",\n       sum(decode(to_char(first_time, 'hh24'), '18', 1, 0)) \"h18\",\n       sum(decode(to_char(first_time, 'hh24'), '19', 1, 0)) \"h19\",\n       sum(decode(to_char(first_time, 'hh24'), '20', 1, 0)) \"h20\",\n       sum(decode(to_char(first_time, 'hh24'), '21', 1, 0)) \"h21\",\n       sum(decode(to_char(first_time, 'hh24'), '22', 1, 0)) \"h22\",\n       sum(decode(to_char(first_time, 'hh24'), '23', 1, 0)) \"h23\"\n  from v$log_history\n where first_time >= trunc(sysdate, 'mm')\n group by trunc(first_time), to_char(first_time, 'dy')\n order by 1 desc\n;\n\n\n\n# 解决本地oracle服务内存占用过高\n\noracle安装时，为均衡电脑性能和数据库性能，默认内存大小为物理内存的1/8\n\n 1. 用dba身份进入oracle\n 2. show parameter sga; --显示内存分配情况\n 3. alter system set sga_target=1024m scope=spfile;-修改target大小 //这个值必须小于等于sga_max_size ，否则库会起不来；\n 4. alter system set sga_max_size=1024m scope=spfile; --修改最大占用内存的大小\n 5. 修改后重启oracle服务\n 6. 附：oracle服务介绍 原文链接\n    * oracle orcl vss writer service：oracle卷映射拷贝写入服务，vss（volume shadow copy service）能够让存储基础设备（比如磁盘，阵列等）创建高保真的时间点映像，即映射拷贝（shadow copy）。它可以在多卷或者单个卷上创建映射拷贝，同时不会影响到系统的系统能。（非必须启动）\n    * oracledbconsoleorcl：oracle数据库控制台服务，orcl是oracle的实例标识，默认的实例为orcl。在运行enterprise manager（企业管理器oem）的时候，需要启动这个服务。（非必须启动）\n    * oraclejobschedulerorcl：oracle作业调度（定时器）服务，orcl是oracle实例标识。（非必须启动）\n    * oraclemtsrecoveryservice：服务端控制。该服务允许数据库充当一个微软事务服务器mts、com/com+对象和分布式环境下的事务的资源管理器。（非必须启动）\n    * oracleoradb11g_home1clragent：oracle数据库 .net扩展服务的一部分。 （非必须启动）\n    * oracleoradb11g_home1tnslistener：监听器服务，服务只有在数据库需要远程访问的时候才需要。（非必须启动但很常用）\n    * oracleserviceorcl：数据库服务(数据库实例)，是oracle核心服务，该服务是数据库启动的基础， 只有该服务启动，oracle数据库才能正常启动。(必须启动)\n\n\n# 数据插入慢的问题\n\n新增：晚上跑存储过程稍快（好几个表两千多万条数据4688s），为什么？因为磁盘读写速度慢t.t\n\n 1. 有个九百多万数据的表需要重新抽数（抽数速度极其慢，后发现是索引导致的，不清楚是索引有问题还是正常现象（索引增加查询速率但影响insert、update、delete效率），应该先删除索引再抽数）\n    \n    > 没删除索引前的效率： 【345430 条数据花费 1406s】【345430 条数据花费1301s】\n    > 删除后的效率：【345508条数据花费 64s】【345482 条数据花费 7.248s】【345508 条数据34.466s】【datax：1641410条数据465s】",charsets:{cjk:!0},lastUpdated:"2025/04/22, 10:19:39",lastUpdatedTimestamp:1745288379e3},{title:"数据库",frontmatter:{title:"数据库",date:"2022-04-15T22:20:30.000Z",permalink:"/pages/e0cc49/",categories:["数据库"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/0101.%E6%95%B0%E6%8D%AE%E5%BA%93.html",relativePath:"03.数据库/0101.数据库.md",key:"v-4448404b",path:"/pages/e0cc49/",headers:[{level:3,title:"SQL标准",slug:"sql标准",normalizedTitle:"sql标准",charIndex:2},{level:4,title:"SQL发展简史",slug:"sql发展简史",normalizedTitle:"sql发展简史",charIndex:11},{level:4,title:"语法要素",slug:"语法要素",normalizedTitle:"语法要素",charIndex:1169},{level:4,title:"各标准语法",slug:"各标准语法",normalizedTitle:"各标准语法",charIndex:1503},{level:5,title:"MERGE",slug:"merge",normalizedTitle:"merge",charIndex:1512},{level:5,title:"表连接",slug:"表连接",normalizedTitle:"表连接",charIndex:2052},{level:3,title:"事务相关",slug:"事务相关",normalizedTitle:"事务相关",charIndex:3509},{level:4,title:"事务",slug:"事务",normalizedTitle:"事务",charIndex:1376},{level:3,title:"索引相关",slug:"索引相关",normalizedTitle:"索引相关",charIndex:4268},{level:4,title:"索引",slug:"索引",normalizedTitle:"索引",charIndex:4268},{level:4,title:"什么时候索引会失效",slug:"什么时候索引会失效",normalizedTitle:"什么时候索引会失效",charIndex:5006},{level:4,title:"需要避免的问题",slug:"需要避免的问题",normalizedTitle:"需要避免的问题",charIndex:5251},{level:5,title:"1. 视图",slug:"_1-视图",normalizedTitle:"1. 视图",charIndex:5262}],headersStr:"SQL标准 SQL发展简史 语法要素 各标准语法 MERGE 表连接 事务相关 事务 索引相关 索引 什么时候索引会失效 需要避免的问题 1. 视图",content:'# SQL标准\n\n# SQL发展简史\n\nSQL发展简史如下：\n\n * 1986年，ANSI X3.135-1986，ISO/IEC 9075:1986，SQL-86\n * 1989年，ANSI X3.135-1989，ISO/IEC 9075:1989，SQL-89\n * 1992年，ANSI X3.135-1992，ISO/IEC 9075:1992，SQL-92（SQL2）\n * 1999年，ISO/IEC 9075:1999，SQL:1999（SQL3）\n * 2003年，ISO/IEC 9075:2003，SQL:2003（SQL4）\n * 2011年，ISO/IEC 9075:200N，SQL:2011（SQL5）\n\n年份     名字         别名                 注释\n1986   SQL-86     SQL-87             ANSI首次标准化\n1989   SQL-89     FIPS 127-1         小修改，增加了integrity constraint\n1992   SQL-92     SQL2, FIPS 127-2   大修改，成为现代SQL的基础\n1999   SQL:1999   SQL3               增加了正则表达式匹配、递归查询（传递闭包）、数据库触发器、过程式与控制流语句、非标量类型(arrays)、面向对象特性。在Java中嵌入SQL(SQL/OLB)及其逆(SQL/JRT)\n2003   SQL:2003                      增加XML相关特性(SQL/XML)、window\n                                     functions、标准化sequences、自动产生值的列。对SQL:1999的新特性重新描述其内涵。\n2006   SQL:2006                      导入/导出XML数据与SQL数据库。XQuery\n2008   SQL:2008                      在cursor之外的ORDER BY语句。INSTEAD OF触发器。TRUNCATE语句。FETCH子句\n2011   SQL:2011                      增加时态数据(PERIOD FOR)。增强了window functions与FETCH子句\n2016   SQL:2016                      增加行模式匹配、多态表函数、JSON。\n2019   SQL:2019                      增加了第15部分，多维数组（MDarray类型和运算符）。\n\n# 语法要素\n\n * 子句 是语句和查询的组成成分。（在某些情况下，这些都是可选的。）\n * 表达式 可以产生任何标量值，或由列和行组成的数据库表\n * 谓词 给需要评估的SQL三值逻辑（3VL）（true/false/unknown）或布尔真值指定条件，并限制语句和查询的效果，或改变程序流程。\n * 查询 基于特定条件检索数据。这是SQL的一个重要组成部分。\n * 语句 可以持久地影响纲要和数据，也可以控制数据库事务、程序流程、连接、会话或诊断。\n * 语句终结符 SQL语句也包括分号（";"）语句终结符。尽管并不是每个平台都必需，但它是作为SQL语法的标准部分定义的。\n * 无意义的空白 在SQL语句和查询中一般会被忽略，更容易格式化SQL代码便于阅读\n\n# 各标准语法\n\n# MERGE\n\nMERGE用来合并多个表的数据。它结合了INSERT和UPDATE元素。它是在SQL:2003标准中定义的；在那之前，一些数据库也以不同的语法提供了相似的功能，又是叫做“upsert”。\n\nMERGE INTO table_name   --要处理的表\n USING table_reference ON (condition)   --参照的表\n -- 如果记录匹配，就更新目标表的匹配行\n WHEN MATCHED THEN\n UPDATE SET column1 = value1 [, column2 = value2 ...]\n -- 如果要处理表没有参照表上的记录，则插入\n WHEN NOT MATCHED THEN\n INSERT (column1 [, column2 ...]) VALUES (value1 [, value2 ...])\n -- 如果要处理表的记录在参照表上不存在，则删除\n WHEN NOT MATCHED BY SOURCE THEN DELETE\n -- 用OUTPUT输出刚刚变动过的数据  $action AS [ACTION]\n OUTPUT $action, Inserted.*, Deleted.*\n\n\n# 表连接\n\n 1. INNER JOIN\n\n-- 86标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a, b, c\n WHERE a.id = b.id\n   AND a.id = c.id\n\n\n-- 92标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a\n INNER JOIN b\n    ON a.id = b.id\n INNER JOIN c\n    ON a.id = c.id;\n\n\n 2. LEFT JOIN\n\n-- 86标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a, b, c\n WHERE a.id = b.id(+) /*b表和a表进行左连接，以a表为准，称为左连接。注意哦，(+)是放在右边的*/\n   AND a.id = c.id(+) /*c表和a表进行左连接，以a表为准*/\n\n--------------------------\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a, b, c\n WHERE a.id = b.id(+)\n   AND b.id = c.id(+)\n\n\n\n-- 92标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a\n\tLEFT JOIN b ON a.id = b.id\n\tLEFT JOIN c ON a.id = c.id;\n\n---------------------\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a\n  LEFT JOIN b ON a.id = b.id\n\tLEFT JOIN c ON b.id = c.id;\n\n\n 3. RIGHT JOIN\n\n-- 86标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a, b, c\n WHERE a.id(+) = b.id /*b表和a表进行左连接，以a表为准，称为左连接。注意哦，(+)是放在右边的*/\n   AND a.id(+) = c.id /*c表和a表进行左连接，以a表为准*/\n\n--------------------------\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a, b, c\n WHERE a.id(+) = b.id\n   AND b.id(+) = c.id\n\n\n\n-- 92标准\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a\n RIGHT JOIN b ON a.id = b.id\n RIGHT JOIN c ON a.id = c.id;\n\n---------------------\nSELECT a.id, a.name, b.id, b.name, c.id, c.name\n  FROM a\n RIGHT JOIN b ON a.id = b.id\n RIGHT JOIN c ON b.id = c.id;\n\n\n\n# 事务相关\n\n# 事务\n\n> 事务保证一组原子性的操作，要么全部成功，要么全部失败。一旦失败，回滚之前的所有操作。MySql采用自动提交，如果不是显式的开启一个事务，则每个查询都作为一个事务。\n\n事务的基本要素:\n\n 1. 原子性（Atomicity）：事务开始后所有操作，要么全部完成，要么全部不完成，不可能停滞在中间环节。事务执行过程中出错，会回滚（Rollback）到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体\n 2. 一致性（Consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如A向B转账，不可能A扣了钱，B却没收到\n 3. 隔离性（Isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账\n 4. 持久性（Durability）：事务完成后，该事务所对数据库所作的更改将被保存到数据库之中，不能回滚。即使系统出现故障，也能够保持。\n\n隔离级别控制了一个事务中的修改，哪些在事务内和事务间是可见的。四种常见的隔离级别：\n\n * 未提交读（Read UnCommitted），事务中的修改，即使没提交对其他事务也是可见的。事务可能读取未提交的数据，造成脏读。\n * 提交读（Read Committed），一个事务开始时，只能看见已提交的事务所做的修改。事务未提交之前，所做的修改对其他事务是不可见的。也叫不可重复读，同一个事务多次读取同样记录可能不同。\n * 可重复读（RepeatTable Read），同一个事务中多次读取同样的记录结果时结果相同。\n * 可串行化（Serializable），最高隔离级别，强制事务串行执行。\n\n\n# 索引相关\n\n# 索引\n\n索引包含一个或多个列的值。MySql只能高效的利用索引的最左前缀列。索引的优势：\n\n * 减少查询扫描的数据量\n * 避免排序和零时表\n * 将随机IO变为顺序IO （顺序IO的效率高于随机IO）\n\nB-Tree\n\n使用最多的索引类型。采用B-Tree数据结构来存储数据（每个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的遍历）。B-Tree索引适用于全键值，键值范围，键前缀查找，支持排序。\n\nB-Tree索引限制：\n\n * 如果不是按照索引的最左列开始查询，则无法使用索引。\n * 不能跳过索引中的列。如果使用第一列和第三列索引，则只能使用第一列索引。\n * 如果查询中有个范围查询，则其右边的所有列都无法使用索引优化查询。\n\n哈希索引\n\n只有精确匹配索引的所有列，查询才有效。存储引擎会对所有的索引列计算一个哈希码，哈希索引将所有的哈希码存储在索引中，并保存指向每个数据行的指针。\n\n哈希索引限制：\n\n * 无法用于排序\n * 不支持部分匹配\n * 只支持等值查询如=，IN（），不支持 <>\n\n优化建议点\n\n * 注意每种索引的适用范围和适用限制。\n * 索引的列如果是表达式的一部分或者是函数的参数，则失效。\n * 针对特别长的字符串，可以使用前缀索引，根据索引的选择性选择合适的前缀长度。\n * 使用多列索引的时候，可以通过 AND 和 OR 语法连接。\n * 重复索引没必要，如（A，B）和（A）重复。\n * 索引在where条件查询和group by语法查询的时候特别有效。\n * 将范围查询放在条件查询的最后，防止范围查询导致的右边索引失效的问题。\n * 索引最好不要选择过长的字符串，而且索引列也不宜为null。\n\n# 什么时候索引会失效\n\n> 在写SQL想到一个问题, 为什么会认为union all的效率比or的效率【原因可能是or会导致索引失效，假如此列非索引列，union all的效率是不是和or近似】\n\n索引失效的10种场景\n\n * 不满足最左匹配原则\n * 使用了select *\n * 索引列上有计算\n * 索引列用了函数\n * 字段类型不同\n * like左边包含%\n * 列对比\n * 使用or关键字\n * not in和not exists\n * order by的坑\n\n原文链接\n\n# 需要避免的问题\n\n# 1. 视图\n\n个人感觉：视图用不好会导致视图泛滥、重复关联，造成查询效率极低的情况。\n\n看到别人说的很有道理：原文链接\n\n>  1. 做个一般的业务系统，完全可以不用视图，如果你要用视图，只能说明你表没设计好，那就继续理解业务优化表设计去（有的人可能要喷这句，但实际情况就是要连表多表的SQL都是复杂的后台数据综合分析系统才需要，这样的SQL整个系统也要不了几句，再说现在不是有google的分析工具么，已经可以代替大部分自己要做的分析，只要网页嵌个js代码就行）。\n>  2. 视图一般都只有查询能力，和真正的表并不一样。而许多公司底层DAO都是BaseDao，然后各个表去继承的形式，这样就导致如果你有视图，肯定也要有dao，然而一继承这个BaseDao，就会暴露出视图根本就不支持的增删改能力。而为了DAO层统一性，很多情况下都是不允许你自己去写DAO的，你继承又暴露出你根本不支持的功能。你现在用的爽（因为你知道，所有只用了查），而后来者对此一无所知，他就按照公司的习惯，同时你也暴露出来增删改，他就去增删改，结果报错。\n>  3. 我们这次要改表，可我并不知道哪些视图依赖此表，好吧，我改表了，我的业务完成了；你的视图依赖了此表，但这是你很久前就做好的模块，你也不管。结果呢？大家都以为没事一切ok，当真的用到你做的模块时，却报错。你大吼“这是我以前做的，都上线3个月了，一直好好的。而这次谁都没改，怎么可能报错，反正不是我的错”，那谁的错？只是因为你的视图依赖的表结构改了，而你没有重新执行此视图的代码。',normalizedContent:'# sql标准\n\n# sql发展简史\n\nsql发展简史如下：\n\n * 1986年，ansi x3.135-1986，iso/iec 9075:1986，sql-86\n * 1989年，ansi x3.135-1989，iso/iec 9075:1989，sql-89\n * 1992年，ansi x3.135-1992，iso/iec 9075:1992，sql-92（sql2）\n * 1999年，iso/iec 9075:1999，sql:1999（sql3）\n * 2003年，iso/iec 9075:2003，sql:2003（sql4）\n * 2011年，iso/iec 9075:200n，sql:2011（sql5）\n\n年份     名字         别名                 注释\n1986   sql-86     sql-87             ansi首次标准化\n1989   sql-89     fips 127-1         小修改，增加了integrity constraint\n1992   sql-92     sql2, fips 127-2   大修改，成为现代sql的基础\n1999   sql:1999   sql3               增加了正则表达式匹配、递归查询（传递闭包）、数据库触发器、过程式与控制流语句、非标量类型(arrays)、面向对象特性。在java中嵌入sql(sql/olb)及其逆(sql/jrt)\n2003   sql:2003                      增加xml相关特性(sql/xml)、window\n                                     functions、标准化sequences、自动产生值的列。对sql:1999的新特性重新描述其内涵。\n2006   sql:2006                      导入/导出xml数据与sql数据库。xquery\n2008   sql:2008                      在cursor之外的order by语句。instead of触发器。truncate语句。fetch子句\n2011   sql:2011                      增加时态数据(period for)。增强了window functions与fetch子句\n2016   sql:2016                      增加行模式匹配、多态表函数、json。\n2019   sql:2019                      增加了第15部分，多维数组（mdarray类型和运算符）。\n\n# 语法要素\n\n * 子句 是语句和查询的组成成分。（在某些情况下，这些都是可选的。）\n * 表达式 可以产生任何标量值，或由列和行组成的数据库表\n * 谓词 给需要评估的sql三值逻辑（3vl）（true/false/unknown）或布尔真值指定条件，并限制语句和查询的效果，或改变程序流程。\n * 查询 基于特定条件检索数据。这是sql的一个重要组成部分。\n * 语句 可以持久地影响纲要和数据，也可以控制数据库事务、程序流程、连接、会话或诊断。\n * 语句终结符 sql语句也包括分号（";"）语句终结符。尽管并不是每个平台都必需，但它是作为sql语法的标准部分定义的。\n * 无意义的空白 在sql语句和查询中一般会被忽略，更容易格式化sql代码便于阅读\n\n# 各标准语法\n\n# merge\n\nmerge用来合并多个表的数据。它结合了insert和update元素。它是在sql:2003标准中定义的；在那之前，一些数据库也以不同的语法提供了相似的功能，又是叫做“upsert”。\n\nmerge into table_name   --要处理的表\n using table_reference on (condition)   --参照的表\n -- 如果记录匹配，就更新目标表的匹配行\n when matched then\n update set column1 = value1 [, column2 = value2 ...]\n -- 如果要处理表没有参照表上的记录，则插入\n when not matched then\n insert (column1 [, column2 ...]) values (value1 [, value2 ...])\n -- 如果要处理表的记录在参照表上不存在，则删除\n when not matched by source then delete\n -- 用output输出刚刚变动过的数据  $action as [action]\n output $action, inserted.*, deleted.*\n\n\n# 表连接\n\n 1. inner join\n\n-- 86标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a, b, c\n where a.id = b.id\n   and a.id = c.id\n\n\n-- 92标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a\n inner join b\n    on a.id = b.id\n inner join c\n    on a.id = c.id;\n\n\n 2. left join\n\n-- 86标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a, b, c\n where a.id = b.id(+) /*b表和a表进行左连接，以a表为准，称为左连接。注意哦，(+)是放在右边的*/\n   and a.id = c.id(+) /*c表和a表进行左连接，以a表为准*/\n\n--------------------------\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a, b, c\n where a.id = b.id(+)\n   and b.id = c.id(+)\n\n\n\n-- 92标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a\n\tleft join b on a.id = b.id\n\tleft join c on a.id = c.id;\n\n---------------------\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a\n  left join b on a.id = b.id\n\tleft join c on b.id = c.id;\n\n\n 3. right join\n\n-- 86标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a, b, c\n where a.id(+) = b.id /*b表和a表进行左连接，以a表为准，称为左连接。注意哦，(+)是放在右边的*/\n   and a.id(+) = c.id /*c表和a表进行左连接，以a表为准*/\n\n--------------------------\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a, b, c\n where a.id(+) = b.id\n   and b.id(+) = c.id\n\n\n\n-- 92标准\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a\n right join b on a.id = b.id\n right join c on a.id = c.id;\n\n---------------------\nselect a.id, a.name, b.id, b.name, c.id, c.name\n  from a\n right join b on a.id = b.id\n right join c on b.id = c.id;\n\n\n\n# 事务相关\n\n# 事务\n\n> 事务保证一组原子性的操作，要么全部成功，要么全部失败。一旦失败，回滚之前的所有操作。mysql采用自动提交，如果不是显式的开启一个事务，则每个查询都作为一个事务。\n\n事务的基本要素:\n\n 1. 原子性（atomicity）：事务开始后所有操作，要么全部完成，要么全部不完成，不可能停滞在中间环节。事务执行过程中出错，会回滚（rollback）到事务开始前的状态，所有的操作就像没有发生一样。也就是说事务是一个不可分割的整体\n 2. 一致性（consistency）：事务开始前和结束后，数据库的完整性约束没有被破坏 。比如a向b转账，不可能a扣了钱，b却没收到\n 3. 隔离性（isolation）：同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如a正在从一张银行卡中取钱，在a取钱的过程结束前，b不能向这张卡转账\n 4. 持久性（durability）：事务完成后，该事务所对数据库所作的更改将被保存到数据库之中，不能回滚。即使系统出现故障，也能够保持。\n\n隔离级别控制了一个事务中的修改，哪些在事务内和事务间是可见的。四种常见的隔离级别：\n\n * 未提交读（read uncommitted），事务中的修改，即使没提交对其他事务也是可见的。事务可能读取未提交的数据，造成脏读。\n * 提交读（read committed），一个事务开始时，只能看见已提交的事务所做的修改。事务未提交之前，所做的修改对其他事务是不可见的。也叫不可重复读，同一个事务多次读取同样记录可能不同。\n * 可重复读（repeattable read），同一个事务中多次读取同样的记录结果时结果相同。\n * 可串行化（serializable），最高隔离级别，强制事务串行执行。\n\n\n# 索引相关\n\n# 索引\n\n索引包含一个或多个列的值。mysql只能高效的利用索引的最左前缀列。索引的优势：\n\n * 减少查询扫描的数据量\n * 避免排序和零时表\n * 将随机io变为顺序io （顺序io的效率高于随机io）\n\nb-tree\n\n使用最多的索引类型。采用b-tree数据结构来存储数据（每个叶子节点都包含指向下一个叶子节点的指针，从而方便叶子节点的遍历）。b-tree索引适用于全键值，键值范围，键前缀查找，支持排序。\n\nb-tree索引限制：\n\n * 如果不是按照索引的最左列开始查询，则无法使用索引。\n * 不能跳过索引中的列。如果使用第一列和第三列索引，则只能使用第一列索引。\n * 如果查询中有个范围查询，则其右边的所有列都无法使用索引优化查询。\n\n哈希索引\n\n只有精确匹配索引的所有列，查询才有效。存储引擎会对所有的索引列计算一个哈希码，哈希索引将所有的哈希码存储在索引中，并保存指向每个数据行的指针。\n\n哈希索引限制：\n\n * 无法用于排序\n * 不支持部分匹配\n * 只支持等值查询如=，in（），不支持 <>\n\n优化建议点\n\n * 注意每种索引的适用范围和适用限制。\n * 索引的列如果是表达式的一部分或者是函数的参数，则失效。\n * 针对特别长的字符串，可以使用前缀索引，根据索引的选择性选择合适的前缀长度。\n * 使用多列索引的时候，可以通过 and 和 or 语法连接。\n * 重复索引没必要，如（a，b）和（a）重复。\n * 索引在where条件查询和group by语法查询的时候特别有效。\n * 将范围查询放在条件查询的最后，防止范围查询导致的右边索引失效的问题。\n * 索引最好不要选择过长的字符串，而且索引列也不宜为null。\n\n# 什么时候索引会失效\n\n> 在写sql想到一个问题, 为什么会认为union all的效率比or的效率【原因可能是or会导致索引失效，假如此列非索引列，union all的效率是不是和or近似】\n\n索引失效的10种场景\n\n * 不满足最左匹配原则\n * 使用了select *\n * 索引列上有计算\n * 索引列用了函数\n * 字段类型不同\n * like左边包含%\n * 列对比\n * 使用or关键字\n * not in和not exists\n * order by的坑\n\n原文链接\n\n# 需要避免的问题\n\n# 1. 视图\n\n个人感觉：视图用不好会导致视图泛滥、重复关联，造成查询效率极低的情况。\n\n看到别人说的很有道理：原文链接\n\n>  1. 做个一般的业务系统，完全可以不用视图，如果你要用视图，只能说明你表没设计好，那就继续理解业务优化表设计去（有的人可能要喷这句，但实际情况就是要连表多表的sql都是复杂的后台数据综合分析系统才需要，这样的sql整个系统也要不了几句，再说现在不是有google的分析工具么，已经可以代替大部分自己要做的分析，只要网页嵌个js代码就行）。\n>  2. 视图一般都只有查询能力，和真正的表并不一样。而许多公司底层dao都是basedao，然后各个表去继承的形式，这样就导致如果你有视图，肯定也要有dao，然而一继承这个basedao，就会暴露出视图根本就不支持的增删改能力。而为了dao层统一性，很多情况下都是不允许你自己去写dao的，你继承又暴露出你根本不支持的功能。你现在用的爽（因为你知道，所有只用了查），而后来者对此一无所知，他就按照公司的习惯，同时你也暴露出来增删改，他就去增删改，结果报错。\n>  3. 我们这次要改表，可我并不知道哪些视图依赖此表，好吧，我改表了，我的业务完成了；你的视图依赖了此表，但这是你很久前就做好的模块，你也不管。结果呢？大家都以为没事一切ok，当真的用到你做的模块时，却报错。你大吼“这是我以前做的，都上线3个月了，一直好好的。而这次谁都没改，怎么可能报错，反正不是我的错”，那谁的错？只是因为你的视图依赖的表结构改了，而你没有重新执行此视图的代码。',charsets:{cjk:!0},lastUpdated:"2025/04/22, 10:19:39",lastUpdatedTimestamp:1745288379e3},{title:"MySQL琐碎知识点",frontmatter:{title:"MySQL琐碎知识点",date:"2022-03-25T14:30:57.000Z",permalink:"/pages/36476d/",categories:["数据库","MySQL"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/02.MySQL/02.MySQL%E7%90%90%E7%A2%8E%E7%9F%A5%E8%AF%86%E7%82%B9.html",relativePath:"03.数据库/02.MySQL/02.MySQL琐碎知识点.md",key:"v-227c94e8",path:"/pages/36476d/",headers:[{level:4,title:"MySQL 大小写敏感问题",slug:"mysql-大小写敏感问题",normalizedTitle:"mysql 大小写敏感问题",charIndex:2},{level:5,title:"不同系统下的MySQL",slug:"不同系统下的mysql",normalizedTitle:"不同系统下的mysql",charIndex:19},{level:5,title:"修改大小写敏感",slug:"修改大小写敏感",normalizedTitle:"修改大小写敏感",charIndex:174},{level:4,title:"MySQL 的 STRTODATE 函数",slug:"mysql-的-str-to-date-函数",normalizedTitle:"mysql 的 strtodate 函数",charIndex:null},{level:4,title:"MySQL实现类似DENSE_RANK()效果",slug:"mysql实现类似dense-rank-效果",normalizedTitle:"mysql实现类似dense_rank()效果",charIndex:757},{level:4,title:"MySQL创建用户，分配远程连接权限",slug:"mysql创建用户-分配远程连接权限",normalizedTitle:"mysql创建用户，分配远程连接权限",charIndex:2010},{level:4,title:"PostgreSQL 和 MySQL 的区别（MySQL的一些缺点）",slug:"postgresql-和-mysql-的区别-mysql的一些缺点",normalizedTitle:"postgresql 和 mysql 的区别（mysql的一些缺点）",charIndex:2362},{level:4,title:"FULL JOIN修改（兼容MySQL）",slug:"full-join修改-兼容mysql",normalizedTitle:"full join修改（兼容mysql）",charIndex:2421},{level:4,title:"踩坑记录",slug:"踩坑记录",normalizedTitle:"踩坑记录",charIndex:2470},{level:5,title:"--",slug:"",normalizedTitle:"--",charIndex:183}],headersStr:"MySQL 大小写敏感问题 不同系统下的MySQL 修改大小写敏感 MySQL 的 STRTODATE 函数 MySQL实现类似DENSE_RANK()效果 MySQL创建用户，分配远程连接权限 PostgreSQL 和 MySQL 的区别（MySQL的一些缺点） FULL JOIN修改（兼容MySQL） 踩坑记录 --",content:"# MySQL 大小写敏感问题\n\n# 不同系统下的MySQL\n\nMySQL在Linux下数据库名、表名、列名、别名大小写规则是这样的： 1、数据库名与表名是严格区分大小写的； 2、表的别名是严格区分大小写的； 3、列名与列的别名在所有的情况下均是忽略大小写的； 4、变量名也是严格区分大小写的； MySQL在Windows下都不区分大小写。\n\n# 修改大小写敏感\n\n-- 应在创建数据库的时候就设置好，否则就得单个表，单个字段进行修改\n-- 查看utf8mb4的校对规则\n-- SHOW COLLATION LIKE 'utf8mb4\\_%';\nALTER TABLE `aa` MODIFY COLUMN `ID` VARCHAR(38) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_as_cs NOT NULL;\n\n\n每个字符集有一个默认校对规则,例如,utf8默认校对规则是utf8_general_ci.并存在校对规则命名约定:它们以其相关的字符集名开始,通常包括一个语言名,并且以_ci（大小写不敏感）,_cs（大小写敏感）或_bin（二元/大小写也敏感）结束\n\n# MySQL 的 STR_TO_DATE 函数\n\n奇奇怪怪的行为\n\n-- 错误日期 union all 时会变成 0000-00-00（正常日期不会），但是单独查询不报错\nselect STR_TO_DATE('2022-04-31', '%Y-%m-%d') union all\nselect STR_TO_DATE('2022-02-30', '%Y-%m-%d') union all\nselect STR_TO_DATE('2022-02-31', '%Y-%m-%d');\n\n\n\n\n# MySQL实现类似DENSE_RANK()效果\n\n前提是子查询是按该字段排序过的，否则不能实现该结果\n\n数据\n\n| weibo_id         | weight               | id   | RN   | PERT_OLD |\n| 4524098644993942 | 0.253893631002748370 |    1 | 18   |        1 |\n| 4524111164205859 | 0.093070061064090660 |    4 | 19   |        4 |\n| 4524138758532594 | 0.015839159909128677 |   16 | 20   |       16 |\n| test100          | 0.500000000000000000 |   -1 | 21   |       -1 |\n| test101          | 0.500000000000000000 |   -1 | 21   |       -1 |\n| test102          | 0.500000000000000000 |   -2 | 22   |       -2 |\n| test103          | 0.500000000000000000 |   -2 | 22   |       -2 |\n| test104          | 0.500000000000000000 |   -3 | 23   |       -3 |\n| test106          | 0.500000000000000000 |   -5 | 24   |       -5 |\n| test107          | 0.500000000000000000 |    1 | 25   |        1 |\n\n\nSELECT T.*  \n       ,@R := case WHEN @RANK = T.id THEN @R ELSE @R + 1 END AS RN\n       ,@RANK := T.id AS PERT_OLD                                  \n  FROM topn T, ( SELECT @R := 0, @RANK := '' ) B \n\n-- 应该为\nSELECT T.*  \n       ,@R := case WHEN @RANK = T.id THEN @R ELSE @R + 1 END AS RN\n       ,@RANK := T.id AS PERT_OLD                                  \n  FROM (select * from topn order by id) T, ( SELECT @R := 0, @RANK := '' ) B \n\n\n# MySQL创建用户，分配远程连接权限\n\n# 创建数据库创建用户，时其可以远程访问（并且设置密码类型）：\ncreate user 'banana'@'%' identified with mysql_native_password by 'banana';\n\n# 如果已经有用户，设置为可远程访问，可以使用：\nalter user 'banana'@'%' identified with mysql_native_password by 'banana';\n\n# 设置可以读写刚创建的demo数据库：\ngrant all privileges on leetcode.* to 'banana'@'%' with grant option;\n\n# 刷新缓存：\nflush privileges;\n\n\n# PostgreSQL 和 MySQL 的区别（MySQL的一些缺点）\n\npostgresql和mysql的区别\n\n# FULL JOIN修改（兼容MySQL）\n\nmysql关于多个full join的处理方式\n\n# 踩坑记录\n\n# --\n\n-- 双短横线后不加空格（提取字符串前数字部分转为double，有空还是字符串前无数字会导致报错！！！）\n-- [22007][1292] Truncated incorrect DOUBLE value: ''\nselect code, --code, CAST(code AS UNSIGNED) from BDP_T_ZJTX;\n",normalizedContent:"# mysql 大小写敏感问题\n\n# 不同系统下的mysql\n\nmysql在linux下数据库名、表名、列名、别名大小写规则是这样的： 1、数据库名与表名是严格区分大小写的； 2、表的别名是严格区分大小写的； 3、列名与列的别名在所有的情况下均是忽略大小写的； 4、变量名也是严格区分大小写的； mysql在windows下都不区分大小写。\n\n# 修改大小写敏感\n\n-- 应在创建数据库的时候就设置好，否则就得单个表，单个字段进行修改\n-- 查看utf8mb4的校对规则\n-- show collation like 'utf8mb4\\_%';\nalter table `aa` modify column `id` varchar(38) character set utf8mb4 collate utf8mb4_0900_as_cs not null;\n\n\n每个字符集有一个默认校对规则,例如,utf8默认校对规则是utf8_general_ci.并存在校对规则命名约定:它们以其相关的字符集名开始,通常包括一个语言名,并且以_ci（大小写不敏感）,_cs（大小写敏感）或_bin（二元/大小写也敏感）结束\n\n# mysql 的 str_to_date 函数\n\n奇奇怪怪的行为\n\n-- 错误日期 union all 时会变成 0000-00-00（正常日期不会），但是单独查询不报错\nselect str_to_date('2022-04-31', '%y-%m-%d') union all\nselect str_to_date('2022-02-30', '%y-%m-%d') union all\nselect str_to_date('2022-02-31', '%y-%m-%d');\n\n\n\n\n# mysql实现类似dense_rank()效果\n\n前提是子查询是按该字段排序过的，否则不能实现该结果\n\n数据\n\n| weibo_id         | weight               | id   | rn   | pert_old |\n| 4524098644993942 | 0.253893631002748370 |    1 | 18   |        1 |\n| 4524111164205859 | 0.093070061064090660 |    4 | 19   |        4 |\n| 4524138758532594 | 0.015839159909128677 |   16 | 20   |       16 |\n| test100          | 0.500000000000000000 |   -1 | 21   |       -1 |\n| test101          | 0.500000000000000000 |   -1 | 21   |       -1 |\n| test102          | 0.500000000000000000 |   -2 | 22   |       -2 |\n| test103          | 0.500000000000000000 |   -2 | 22   |       -2 |\n| test104          | 0.500000000000000000 |   -3 | 23   |       -3 |\n| test106          | 0.500000000000000000 |   -5 | 24   |       -5 |\n| test107          | 0.500000000000000000 |    1 | 25   |        1 |\n\n\nselect t.*  \n       ,@r := case when @rank = t.id then @r else @r + 1 end as rn\n       ,@rank := t.id as pert_old                                  \n  from topn t, ( select @r := 0, @rank := '' ) b \n\n-- 应该为\nselect t.*  \n       ,@r := case when @rank = t.id then @r else @r + 1 end as rn\n       ,@rank := t.id as pert_old                                  \n  from (select * from topn order by id) t, ( select @r := 0, @rank := '' ) b \n\n\n# mysql创建用户，分配远程连接权限\n\n# 创建数据库创建用户，时其可以远程访问（并且设置密码类型）：\ncreate user 'banana'@'%' identified with mysql_native_password by 'banana';\n\n# 如果已经有用户，设置为可远程访问，可以使用：\nalter user 'banana'@'%' identified with mysql_native_password by 'banana';\n\n# 设置可以读写刚创建的demo数据库：\ngrant all privileges on leetcode.* to 'banana'@'%' with grant option;\n\n# 刷新缓存：\nflush privileges;\n\n\n# postgresql 和 mysql 的区别（mysql的一些缺点）\n\npostgresql和mysql的区别\n\n# full join修改（兼容mysql）\n\nmysql关于多个full join的处理方式\n\n# 踩坑记录\n\n# --\n\n-- 双短横线后不加空格（提取字符串前数字部分转为double，有空还是字符串前无数字会导致报错！！！）\n-- [22007][1292] truncated incorrect double value: ''\nselect code, --code, cast(code as unsigned) from bdp_t_zjtx;\n",charsets:{cjk:!0},lastUpdated:"2025/05/16, 18:00:33",lastUpdatedTimestamp:1747389633e3},{title:"达梦数据库",frontmatter:{title:"达梦数据库",date:"2022-07-20T17:35:40.000Z",permalink:"/pages/086761/"},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/06.%E5%9B%BD%E4%BA%A7%E6%95%B0%E6%8D%AE%E5%BA%93/03.%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93.html",relativePath:"03.数据库/06.国产数据库/03.达梦数据库.md",key:"v-1e74358a",path:"/pages/086761/",headers:[{level:2,title:"零、官方文档",slug:"零、官方文档",normalizedTitle:"零、官方文档",charIndex:2},{level:2,title:"一、数据库安装",slug:"一、数据库安装",normalizedTitle:"一、数据库安装",charIndex:224},{level:4,title:"前期准备",slug:"前期准备",normalizedTitle:"前期准备",charIndex:235},{level:4,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:229},{level:4,title:"初始化",slug:"初始化",normalizedTitle:"初始化",charIndex:3618},{level:4,title:"注册数据库服务，启动数据库",slug:"注册数据库服务-启动数据库",normalizedTitle:"注册数据库服务，启动数据库",charIndex:4300},{level:2,title:"二、创建Oracle To 达梦的DBlink（OCI方式）",slug:"二、创建oracle-to-达梦的dblink-oci方式",normalizedTitle:"二、创建oracle to 达梦的dblink（oci方式）",charIndex:5428},{level:4,title:"环境准备",slug:"环境准备",normalizedTitle:"环境准备",charIndex:5468},{level:4,title:"工具准备",slug:"工具准备",normalizedTitle:"工具准备",charIndex:5628},{level:4,title:"Oracle OCI安装配置（达梦数据库所在服务器）",slug:"oracle-oci安装配置-达梦数据库所在服务器",normalizedTitle:"oracle oci安装配置（达梦数据库所在服务器）",charIndex:5715},{level:2,title:"数据库调优方面",slug:"数据库调优方面",normalizedTitle:"数据库调优方面",charIndex:6596},{level:3,title:"数据库统计信息",slug:"数据库统计信息",normalizedTitle:"数据库统计信息",charIndex:6617},{level:4,title:"自动收集",slug:"自动收集",normalizedTitle:"自动收集",charIndex:6628},{level:4,title:"手动收集",slug:"手动收集",normalizedTitle:"手动收集",charIndex:9619},{level:3,title:"ET 工具",slug:"et-工具",normalizedTitle:"et 工具",charIndex:10867},{level:3,title:"dbms_sqltune 工具",slug:"dbms-sqltune-工具",normalizedTitle:"dbms_sqltune 工具",charIndex:11324},{level:3,title:"Hints",slug:"hints",normalizedTitle:"hints",charIndex:11851},{level:4,title:"INI 参数提示",slug:"ini-参数提示",normalizedTitle:"ini 参数提示",charIndex:12055},{level:4,title:"索引提示",slug:"索引提示",normalizedTitle:"索引提示",charIndex:12280},{level:4,title:"连接方法提示",slug:"连接方法提示",normalizedTitle:"连接方法提示",charIndex:12431},{level:4,title:"连接顺序提示",slug:"连接顺序提示",normalizedTitle:"连接顺序提示",charIndex:13472},{level:4,title:"统计信息提示",slug:"统计信息提示",normalizedTitle:"统计信息提示",charIndex:14016},{level:4,title:"其他 Hint",slug:"其他-hint",normalizedTitle:"其他 hint",charIndex:14164},{level:2,title:"DTS 迁移",slug:"dts-迁移",normalizedTitle:"dts 迁移",charIndex:14736},{level:4,title:"注意事项",slug:"注意事项",normalizedTitle:"注意事项",charIndex:14746},{level:2,title:"常用SQL",slug:"常用sql",normalizedTitle:"常用sql",charIndex:14969},{level:4,title:"博客",slug:"博客",normalizedTitle:"博客",charIndex:14978},{level:3,title:"新建用户及表空间",slug:"新建用户及表空间",normalizedTitle:"新建用户及表空间",charIndex:15002},{level:3,title:"元数据获取",slug:"元数据获取",normalizedTitle:"元数据获取",charIndex:15505},{level:4,title:"常用系统视图",slug:"常用系统视图",normalizedTitle:"常用系统视图",charIndex:15514},{level:4,title:"建表语句获取",slug:"建表语句获取",normalizedTitle:"建表语句获取",charIndex:16205},{level:4,title:"查询表空间占用率",slug:"查询表空间占用率",normalizedTitle:"查询表空间占用率",charIndex:17881},{level:4,title:"查看单表（索引）占用空间",slug:"查看单表-索引-占用空间",normalizedTitle:"查看单表（索引）占用空间",charIndex:18244},{level:4,title:"查看达梦数据库是否是集群",slug:"查看达梦数据库是否是集群",normalizedTitle:"查看达梦数据库是否是集群",charIndex:18585},{level:4,title:"查看模式和用户对应关系",slug:"查看模式和用户对应关系",normalizedTitle:"查看模式和用户对应关系",charIndex:18726},{level:3,title:"问题排查",slug:"问题排查",normalizedTitle:"问题排查",charIndex:18884},{level:4,title:"查询锁表 & 杀会话",slug:"查询锁表-杀会话",normalizedTitle:"查询锁表 &amp; 杀会话",charIndex:null},{level:4,title:"查询实例中已执行未提交的 SQL",slug:"查询实例中已执行未提交的-sql",normalizedTitle:"查询实例中已执行未提交的 sql",charIndex:19616},{level:4,title:"查询表上的锁",slug:"查询表上的锁",normalizedTitle:"查询表上的锁",charIndex:19795},{level:4,title:"批量禁用某个用户/模式下所有外键约束",slug:"批量禁用某个用户-模式下所有外键约束",normalizedTitle:"批量禁用某个用户/模式下所有外键约束",charIndex:20439},{level:4,title:"用户锁定/解锁",slug:"用户锁定-解锁",normalizedTitle:"用户锁定/解锁",charIndex:20676},{level:2,title:"FAQ",slug:"faq",normalizedTitle:"faq",charIndex:20986},{level:4,title:"大数据量表加字段慢",slug:"大数据量表加字段慢",normalizedTitle:"大数据量表加字段慢",charIndex:20993}],headersStr:"零、官方文档 一、数据库安装 前期准备 安装 初始化 注册数据库服务，启动数据库 二、创建Oracle To 达梦的DBlink（OCI方式） 环境准备 工具准备 Oracle OCI安装配置（达梦数据库所在服务器） 数据库调优方面 数据库统计信息 自动收集 手动收集 ET 工具 dbms_sqltune 工具 Hints INI 参数提示 索引提示 连接方法提示 连接顺序提示 统计信息提示 其他 Hint DTS 迁移 注意事项 常用SQL 博客 新建用户及表空间 元数据获取 常用系统视图 建表语句获取 查询表空间占用率 查看单表（索引）占用空间 查看达梦数据库是否是集群 查看模式和用户对应关系 问题排查 查询锁表 & 杀会话 查询实例中已执行未提交的 SQL 查询表上的锁 批量禁用某个用户/模式下所有外键约束 用户锁定/解锁 FAQ 大数据量表加字段慢",content:"# 零、官方文档\n\n产品手册\n\n达梦数据库需善用达梦提供的工具\n\n * DM控制台工具：查看 dm.ini 配置（中文描述配置信息）、备份还原 官网在线文档：DM数据库服务配置\n * DM审计分析工具\n * DM数据迁移工具：用于达梦与其他数据库间的数据迁移（包含视图、存储过程、函数、触发器等）\n * DM性能监视工具：性能监控（线程、会话、SQL、资源的监控）、调优向导（内存配置、线程配置、索引优化）\n * SQL交互式查询工具\n\n\n\n\n# 一、数据库安装\n\n# 前期准备\n\n 1. 创建dmdba用户,dinstall组\n    \n    [root@localhost oracle]# groupadd dinstall && useradd -g dinstall dmdba && echo root|passwd --stdin dmdba\n    Changing password for user dmdba.\n    passwd: all authentication tokens updated successfully.\n    \n\n 2. 关闭防火墙和selinux\n 3. 创建软件安装目录 /opt/dmdbms && chown dmdba:dinstall /opt/dmdbms\n 4. 创建数据目录/opt/dmdata && chown dmdba:dinstall /opt/dmdata\n 5. 修改用户资源限制\n    vi /etc/security/limits.conf 增加相应配置\n    \n    dmdba hard nofile 131072\n    dmdba soft nofile 131072\n    dmdba soft nice 0\n    dmdba hard nice 0\n    dmdba soft as unlimited\n    dmdba hard as unlimited\n    dmdba soft fsize unlimited\n    dmdba hard fsize unlimited\n    dmdba soft nproc 131072\n    dmdba hard nproc 131072\n    dmdba soft data unlimited\n    dmdba hard data unlimited\n    dmdba soft core unlimited\n    dmdba hard core unlimited\n    dmdba soft memlock unlimited\n    dmdba hard memlock unlimited\n    \n\n 6. 上传安装包，解压 unzip dm8_20220525_x86_rh6_64.zip\n 7. iso挂载到/mnt mount -o loop dm8_20220525_x86_rh6_64.iso /mnt/\n 8. 取消挂载 umount /mnt/ （全部安装完成后执行）\n\n# 安装\n\n 1. 切换用户 dmdba 进行安装\n\n 2. 执行安装脚本 /mnt/DMInstall.bin -i\n    \n    [dmdba@localhost ~]$ /mnt/DMInstall.bin -i\n    Please select the installer's language (E/e:English C/c:Chinese) [E/e]:c\n    解压安装程序......... \n    欢迎使用达梦数据库安装程序\n    \n    是否输入Key文件路径? (Y/y:是 N/n:否) [Y/y]:n\n    \n    是否设置时区? (Y/y:是 N/n:否) [Y/y]:y\n    设置时区:\n    [ 1]: GTM-12=日界线西\n    [ 2]: GTM-11=萨摩亚群岛\n    [ 3]: GTM-10=夏威夷\n    [ 4]: GTM-09=阿拉斯加\n    [ 5]: GTM-08=太平洋时间（美国和加拿大）\n    [ 6]: GTM-07=亚利桑那\n    [ 7]: GTM-06=中部时间（美国和加拿大）\n    [ 8]: GTM-05=东部部时间（美国和加拿大）\n    [ 9]: GTM-04=大西洋时间（美国和加拿大）\n    [10]: GTM-03=巴西利亚\n    [11]: GTM-02=中大西洋\n    [12]: GTM-01=亚速尔群岛\n    [13]: GTM=格林威治标准时间\n    [14]: GTM+01=萨拉热窝\n    [15]: GTM+02=开罗\n    [16]: GTM+03=莫斯科\n    [17]: GTM+04=阿布扎比\n    [18]: GTM+05=伊斯兰堡\n    [19]: GTM+06=达卡\n    [20]: GTM+07=曼谷，河内\n    [21]: GTM+08=中国标准时间\n    [22]: GTM+09=汉城\n    [23]: GTM+10=关岛\n    [24]: GTM+11=所罗门群岛\n    [25]: GTM+12=斐济\n    [26]: GTM+13=努库阿勒法\n    [27]: GTM+14=基里巴斯\n    请选择设置时区 [6]:21\n    \n    安装类型:\n    1 典型安装\n    2 服务器\n    3 客户端\n    4 自定义\n    请选择安装类型的数字序号 [1 典型安装]:1\n    所需空间: 1585M\n    \n    请选择安装目录 [/home/dmdba/dmdbms]:/opt/dmdbms\n    目录(/opt/dmdbms)下不为空，请选择其他目录。\n    请选择安装目录 [/home/dmdba/dmdbms]:/opt/dmdbms\n    可用空间: 13G\n    是否确认安装路径(/opt/dmdbms)? (Y/y:是 N/n:否)  [Y/y]:y\n    \n    安装前小结\n    安装位置: /opt/dmdbms\n    所需空间: 1585M\n    可用空间: 13G\n    版本信息: \n    有效日期: \n    安装类型: 典型安装\n    是否确认安装? (Y/y:是 N/n:否):y\n    2022-07-18 19:00:36 \n    [INFO] 安装达梦数据库...\n    2022-07-18 19:00:37 \n    [INFO] 安装 基础 模块...\n    2022-07-18 19:00:40 \n    [INFO] 安装 服务器 模块...\n    2022-07-18 19:00:40 \n    [INFO] 安装 客户端 模块...\n    2022-07-18 19:00:42 \n    [INFO] 安装 驱动 模块...\n    2022-07-18 19:00:43 \n    [INFO] 安装 手册 模块...\n    2022-07-18 19:00:43 \n    [INFO] 安装 服务 模块...\n    2022-07-18 19:00:44 \n    [INFO] 移动日志文件。\n    2022-07-18 19:00:44 \n    [INFO] 安装达梦数据库完成。\n    \n    请以root系统用户执行命令:\n    /opt/dmdbms/script/root/root_installer.sh\n    \n    安装结束\n    \n\n 3. root执行脚本 /opt/dmdbms/script/root/root_installer.sh\n    \n    [root@localhost opt]# /opt/dmdbms/script/root/root_installer.sh\n    移动 /opt/dmdbms/bin/dm_svc.conf 到/etc目录\n    修改服务器权限\n    创建DmAPService服务\n    Created symlink from /etc/systemd/system/multi-user.target.wants/DmAPService.service to /usr/lib/systemd/system/DmAPService.service.\n    创建服务(DmAPService)完成\n    启动DmAPService服务\n    [root@localhost opt]#\n    \n\n# 初始化\n\n 1. 执行初始化脚本 ./dminit path=/opt/dmdata db_name=aihb instance_name=aihb\n    \n    [dmdba@localhost bin]$ pwd\n    /opt/dmdbms/bin\n    [dmdba@localhost bin]$ ./dminit path=/opt/dmdata db_name=aihb instance_name=aihb\n    initdb V8\n    db version: 0x7000c\n    file dm.key not found, use default license!\n    License will expire on 2023-05-25\n    Normal of FAST\n    Normal of DEFAULT\n    Normal of RECYCLE\n    Normal of KEEP\n    Normal of ROLL\n    \n     log file path: /opt/dmdata/aihb/aihb01.log\n    \n    \n     log file path: /opt/dmdata/aihb/aihb02.log\n    \n    write to dir [/opt/dmdata/aihb].\n    create dm database success. 2022-07-19 10:05:20\n    [dmdba@localhost bin]$ \n    \n\n# 注册数据库服务，启动数据库\n\n 1. 调用达梦提供的脚本生成数据库服务,自动启动数据库,脚本在安装目录的/script/root子目录下,调用注册脚本需使用root用户 ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini -p aihb\n    \n    * 调用dm_service_installer.sh脚本来生成服务\n    * -t 指定需要创建的服务类型,这里是数据库服务所以是dmserver\n    * -dm_ini 指定在上一步初始化后生成的dm.ini文件\n    * -p 为生成服务的后缀名,可自定义，这里给的czw，所以创建的服务名为DmServiceczw\n    \n    [root@localhost root]# pwd\n    /opt/dmdbms/script/root\n    [root@localhost root]# ll\n    total 48\n    -rwxr-xr-x. 1 dmdba dinstall 29111 Jul 19 10:00 dm_service_installer.sh\n    -rwxr-xr-x. 1 dmdba dinstall  9618 Jul 19 10:00 dm_service_uninstaller.sh\n    -rwxr-xr-x. 1 dmdba dinstall   635 Jul 19 10:00 root_installer.sh\n    [root@localhost root]# ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini\n    请设置参数-p\n    [root@localhost root]# ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini -p aihb\n    Created symlink from /etc/systemd/system/multi-user.target.wants/DmServiceaihb.service to /usr/lib/systemd/system/DmServiceaihb.service.\n    创建服务(DmServiceaihb)完成\n    [root@localhost root]# \n    \n\n 2. 启动数据库 systemctl start DmServiceaihb\n\n\n# 二、创建Oracle To 达梦的DBlink（OCI方式）\n\n参考链接\n\n# 环境准备\n\n键              值\n操作系统           Centos 7\nOracle数据库      11.2.0.4.0\n达梦数据库          Centos 7 x86版本\n达梦安装目录         /opt/dmdbms\nOracle OCI位置   /opt/oracle\n\n# 工具准备\n\nOracle OCI： instantclient-basic-linux.x64-11.2.0.4.0.zip（与系统和Oracle版本对应） 下载地址\n\n# Oracle OCI安装配置（达梦数据库所在服务器）\n\n 1. 进入包所在的路径并解压：\n    \n    cd /opt/oracle/ && unzip instantclient-basic-linux.x64-11.2.0.4.0.zip\n    \n\n 2. （18.3 之前的版本需要这一步）进入解压后目录创建软连接：\n    \n    cd instantclient_11_2 && ln -sfv libclntsh.so.11.1 libclntsh.so\n    \n\n 3. 配置环境变量\n    \n    * 将OCI添加到/etc/ld.so.conf.d目录下（系统用户）\n      \n      echo /opt/oracle/instantclient_11_2 > /etc/ld.so.conf.d/oracle-instantclient.conf\n      \n    \n    * 加载动态链接库（使上一步生效）：ldconfig\n    * 配置LD_LIBRARY_PATH环境变量（dmdba用户）\n      修改dmdba用户下的.bash_profile文件（vim ~/.bash_profile），添加以下内容\n      \n      export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/opt/oracle/instantclient_11_2\"\n      \n    \n    * 加载环境变量（使上一步生效）：source ~/.bash_profile\n\n 4. 启动（重启达梦数据库 系统用户）\n\nsystemctl restart DmServiceXXX #（**实际服务名**）\n\n\n 5. 创建DBLink（注：用户名不要加引号）\n\ncreate link LINKORA connect 'ORACLE' with username identified by \"password\" using 'x.x.x.x:1521/orcl';\n\n\n\n# 数据库调优方面\n\n性能诊断与优化\n\n\n# 数据库统计信息\n\n# 自动收集\n\nDM 数据库支持统计信息的自动收集，当全表数据量变化超过设定阈值后可自动更新统计信息。\n\n--打开表数据量监控开关，参数值为 1 时监控所有表，2 时仅监控配置表\nSP_SET_PARA_VALUE(1,'AUTO_STAT_OBJ',2);\n\n-- 如果 AUTO_STAT_OBJ=2，需进一步使用 DBMS_STATS.SET_TABLE_PREFS 设置 STALE_PERCENT 属性\n--设置 SYSDBA.T 表数据变化率超过 15% 时触发自动更新统计信息\nDBMS_STATS.SET_TABLE_PREFS('SYSDBA','T','STALE_PERCENT',15);\n\n--配置自动收集统计信息触发时机\n-- 停止时最后一个参数配置为0？   参数值需再斟酌！！！！\nSP_CREATE_AUTO_STAT_TRIGGER(1, 1, 1, 1,'1:00', '2025/3/12',60,1);\n\n/*\n函数各参数介绍\nSP_CREATE_AUTO_STAT_TRIGGER(\n    TYPE                    INT,    --间隔类型，默认为天\n    FREQ_INTERVAL         INT,    --间隔频率，默认 1\n    FREQ_SUB_INTERVAL    INT,    --间隔频率，与 FREQ_INTERVAL 配合使用\n    FREQ_MINUTE_INTERVAL INT,    --间隔分钟，默认为 1440\n    STARTTIME              VARCHAR(128), --开始时间，默认为 22:00\n    DURING_START_DATE    VARCHAR(128), --重复执行的起始时间，默认 1900/1/1\n    MAX_RUN_DURATION    INT,    --允许的最长执行时间(秒)，默认不限制\n    ENABLE                  INT     --0 关闭，1 启用  --默认为 1\n);\n*/\n\n\n测试\n\nCREATE TABLE T(A INT);\ninsert into t select level connect by level<=20;\ncommit;\n\n-- SELECT * FROM SYSSTATTABLEIDU order by LAST_STAT_DT desc;\n\nSELECT *\n  FROM sysstats\n WHERE id IN (SELECT object_id\n                FROM dba_objects\n               WHERE object_type = 'TABLE'\n                 AND owner = 'OWNER'\n                 AND object_name = 'T');\n\n\n监控统计信息收集过程\n\n-- 创建一个用户表 AUTO_STAT_INFO，用以保存自动收集过程的相关信息\n-- 最好是系统用户吧？？？SYSDBA？？？\ncreate table AUTO_STAT_INFO\n(\n   task_id               INT,\n   total_stat            INT,\n   table_id              INT,\n   sch_name              varchar(24),\n   table_name            varchar(24),\n   curr_gath_tab_id      INT,\n   curr_gath_sch_name    varchar(24),\n   curr_gath_tab_name    varchar(24),\n   success_stat          INT,\n   fail_stat             INT,\n   task_start_time       DATETIME,\n   task_end_time         DATETIME,\n   gather_tbl_start_time DATETIME,\n   gather_tbl_end_time   DATETIME\n);\n\n\n-- 创建过程 SYSDBA.GET_AUTO_STAT_INFO_FUNC，接收服务器在自动收集统计信息时的过程信息。并在模块体编写用户代码，将过程收集的统计信息写入 AUTO_STAT_INFO 中。\nCREATE OR REPLACE PROCEDURE  SYSDBA.GET_AUTO_STAT_INFO_FUNC(task_id INT,total_stat INT,table_id INT, sch_name varchar(24), table_name varchar(24),curr_gath_tab_id INT, curr_gath_sch_name varchar(24), curr_gath_tab_name varchar(24),success_stat INT,fail_stat INT,task_start_time DATETIME, task_end_time DATETIME,gather_tbl_start_time DATETIME,gather_tbl_end_time DATETIME) as\nBEGIN\n//下面是用户自定义的代码，将SYSDBA.GET_AUTO_STAT_INFO_FUNC过程的信息插入到用户表AUTO_STAT_INFO 中\n    INSERT INTO AUTO_STAT_INFO VALUES(task_id,total_stat,table_id, sch_name,table_name,curr_gath_tab_id, curr_gath_sch_name, curr_gath_tab_name,success_stat ,fail_stat,task_start_time,task_end_time,gather_tbl_start_time,gather_tbl_end_time);\ncommit;\nEXCEPTION\n    WHEN OTHERS THEN\n        NULL;\nEND;\n/\n\n-- 最后，解读表 AUTO_STAT_INFO，介绍一次自动收集统计信息任务的相关过程信息。如果 SP_CREATE_AUTO_STAT_TRIGGER 触发一次自动收集统计信息，在任务开始时，会先记录当前任务的开始时间，当前任务的待收集表的总个数，以及接下来待收集的表的 id。之后每收集完成一个表的统计信息，就会记录该表 table 的 id 及收集该表的开始和结束时间，和截至目前收集成功失败的表个数情况，以及接下来待收集的表的 id。其中“接下来待收集的表的 id”即 current_gather_tab_id，为当前服务器正在收集的表 id。\n\n\n# 手动收集\n\n查看是否已有统计信息\n\n-- 检查表上是否有统计信息\nselect * from sysstats\nwhere id IN\n(\n  select object_id from dba_objects where\n  object_type='TABLE'\n  and owner = '模式名'\n  and object_name='表名'\n) ;\n\n\n-- 用于经过 GATHER_TABLE_STATS、GATHER_INDEX_STATS 或 GATHER_SCHEMA_STATS 收集之后展示。\ndbms_stats.table_stats_show('模式名','表名');\n\n\n收集统计信息\n\n1、收集全库统计信息\nDBMS_STATS.GATHER_SCHEMA_STATS('HNSIMIS', 100,FALSE,'FOR ALL COLUMNS SIZE AUTO');--HNSIMIS是模式名\n-- 这种收集方式，并不是100%收集，所以有一定的弊端。\n\n2、收集表的统计信息\ndbms_stats.GATHER_TABLE_STATS('TEST','test',null,100);--收集表的统计信息，包括列和索引等 第一个参数是模式，第二个参数是表 Null是缺省，100是采样率100%，默认不是。\nDBMS_STATS.GATHER_TABLE_STATS('OWNER','TABLE_NAME',null,100,TRUE,'FOR ALL COLUMNS SIZE AUTO');\n\n3、收集列统计信息\nstat 100 on fw(CREATE_USERID); --收集某一列的统计信息 fw是表名 CREATE_USERID是列名称\n-- 这个在做sql调优的时候比较常用，因为比较准。\n\n4、收集索引统计信息\nsp_index_stat_init('DREAMWEB_PUDONG','IX_FW_ROWSTATE',100); --收集索引的统计信息 DREAMWEB_PUDONG是模式名称 IX_FW_ROWSTATE是索引名称\n-- 这个也比较常用，建议创建完索引，立刻收集下统计信息。\n\n-- 报错 磁盘空间不足 -523[-523]: anonymous block line 2\n-- SYSTEM表空间 不足\n\n\n删除统计信息\n\n--表\nDBMS_STATS.DELETE_TABLE_STATS('模式名','表名','分区名',...);\n\n--模式\nDBMS_STATS.DELETE_SCHMA_STATS('模式名','','',...);\n\n--索引\nDBMS_STATS.DELETE_INDEX_STATS('模式名','索引名','分区表名',...);\n\n--字段\nDBMS_STATS.DELETE_COLUMN_STATS('模式名','表名','列名','分区表名',...);\n\n\n\n# ET 工具\n\nET 工具是 DM 数据库自带的 SQL 性能分析工具，能够统计 SQL 语句执行过程中每个操作符的实际开销，为 SQL 优化提供依据以及指导。\n\n--查看ET是否开启\nselect * from v$parameter t where NAME = 'MONITOR_SQL_EXEC';\nselect * from v$parameter t where NAME = 'ENABLE_MONITOR';\n--ENABLE_MONITOR，动态参数(系统级)\n--MONITOR_SQL_EXEC，动态参数(会话级)\n\n--开启ET\nSP_SET_PARA_VALUE(1,'ENABLE_MONITOR',1);\nSP_SET_PARA_VALUE(1,'MONITOR_SQL_EXEC',1);\n\n--关闭ET\nSP_SET_PARA_VALUE(1,'ENABLE_MONITOR',0);\nSP_SET_PARA_VALUE(1,'MONITOR_SQL_EXEC',0);\n\n\n\n# dbms_sqltune 工具\n\nDBMS_SQLTUNE 包提供一系列实时 SQL 监控的方法。当 SQL 监控功能开启后，DBMS_SQLTUNE 包可以实时监控 SQL 执行过程中的信息，包括：执行时间、执行代价、执行用户、统计信息等情况。\ndbms_sqltune 系统包相比 ET 功能更强大，能够获取 IO 操作量，查看真实执行计划，每个操作符消耗占比和相应的花费时间，还能看出每个操作符执行的次数，非常便于了解执行计划中瓶颈位置。\ndbms_sqltune 功能远不止定位执行计划瓶颈，还拥有调优助手功能（建议性提示建某索引和收集某统计信息），具体使用 DM8 系统包使用手册。\n\n-- 1. 使用前提：建议会话级开启参数 MONITOR_SQL_EXEC=1，而 MONITOR_SQL_EXEC 在达梦数据库中一般默认是 1，无需调整。\nALTER SESSION SET 'MONITOR_SQL_EXEC' = 1;\n-- 2. <执行待优化SQL>\n-- 3. 查看执行计划\nselect DBMS_SQLTUNE.REPORT_SQL_MONITOR(SQL_EXEC_ID=>1213701) from dual;\n\n\n\n# Hints\n\nDM 查询优化器采用基于代价的方法。在估计代价时，主要以统计信息或者普遍的数据分布为依据。在大多数情况下，估计的代价都是准确的。但在一些比较特殊的场合，例如缺少统计信息，或统计信息陈旧，或抽样数据不能很好地反映数据分布时，优化器选择的执行计划不是“最优”的，甚至可能是很差的执行计划。\n如果 HINT 的语法没有写对或指定的值不正确，DM 并不会报错，而是直接忽略 HINT 继续执行。\n\n# INI 参数提示\n\n支持使用 HINT 的 INI 参数可通过 V$HINT_INI_INFO 动态视图查询。支持 HINT 的 INI 参数分为两类：一是 HINT_TYPE 为“OPT”，表示分析阶段使用的参数；二是 HINT_TYPE 为“EXEC”，表示运行阶段使用的参数，运行阶段使用的参数对于视图无效。\n\n * 例：SELECT /*+ENABLE_HASH_JOIN(1)*/ * FROM T1,T2 WHERE C1=D1;\n\n# 索引提示\n\n-- 使用索引(如果查询中给出了表的别名那么必须使用别名)：\n/*+ INDEX (表名[,] 索引名) {INDEX (表名[,] 索引名)} */\n\n-- 不使用索引：\n/*+ NO_INDEX (表名[,] 索引名) { NO_INDEX (表名[,] 索引名)} */\n\n\n\n\n# 连接方法提示\n\n-- 强制两个表间使用指定顺序的哈希连接\n/*+ USE_HASH(T1, T2) */\n\n-- 强制两个表间不能使用指定顺序的哈希连接\n/*+ NO_USE_HASH(T1, T2) */\n\n-- 强制两个表间使用嵌套循环连接\n/*+ USE_NL(A, B) */\n\n-- 强制两个表间不能使用嵌套循环连接\n/*+ NO_USE_NL(A, B) */\n\n-- 当连接情况为左表 + 右表索引时，强制两个表间使用索引连接\n/*+ USE_NL_WITH_INDEX(T1, IDX_T2_ID) */\n\n-- 当连接情况为左表 + 右表索引时，强制两个表间不能使用索引连接\n/*+ NO_USE_NL_WITH_INDEX(T1, IDX_T2_ID) */\n\n-- 强制两个表间使用归并连接。归并连接所用的两个列都必须是索引列。\n/*+ USE_MERGE(T1,T2) */\n\n-- 强制两个表间不能使用归并连接\n/*+ NO_USE_MERGE(T1,T2) */\n\n-- 优先采用半连接转换为等价的内连接，仅 OPTIMIZER_MODE=1 有效。\n/*+ SEMI_GEN_CROSS  OPTIMIZER_MODE(1) */\n\n-- 不采用半连接转换为等价的内连接，仅 OPTIMIZER_MODE=1 有效。\n/*+ NO_SEMI_GEN_CROSS  OPTIMIZER_MODE(1) */\n\n-- 优先采用变量改写方式实现连接，适合驱动表数据量少而另一侧计划较复杂的场景，目前支持变量改写的连接方式有 NEST LOOP INNER JOIN2、NEST LOOP LEFT JOIN2、NEST LOOP SEMI JOIN2，仅 OPTIMIZER_MODE=1 有效。\n/*+ USE_CVT_VAR OPTIMIZER_MODE(1) */\n\n-- 不考虑变量改写方式实现连接，仅 OPTIMIZER_MODE=1 有效。\n/*+ NO_USE_CVT_VAR OPTIMIZER_MODE(1) */\n\n-- 一般情况下，归并连接需要左右孩子的数据按照连接列有序，使用此优化器提示时，优化器将考虑通过插入排序操作符的方式实现归并连接，仅 OPTIMIZER_MODE=1 有效。\n/*+ENHANCED_MERGE_JOIN OPTIMIZER_MODE(1) stat(T1 1M) stat(T2 1M) */\n\n\n\n# 连接顺序提示\n\n-- 多表连接时优化器会考虑各种可能的排列组合顺序。使用 ORDER HINT 指定连接顺序提示可以缩小优化器试探的排列空间，进而得到接近 DBA 所期望的查询计划。如果连接顺序和连接方法提示同时指定且二者间存在自相矛盾，优化器会以连接顺序提示为准。\n/*+ ORDER (T1, T2 , T3, … tn ) */\n\n/*\n如果期望表的连接顺序是 T1, T2, T3，那么可以加入这样的提示：\nSELECT /*+ ORDER(T1, T2, T3 )*/* FROM T1, T2 , T3, T4 WHERE …\n在指定上述连接顺序后，T4,T1,T2,T3 或 T1,T2,T4,T3 会被考虑；T3,T1,T2 或 T1,T3,T2 不被考虑。\n*/\n\n-- 更特定的执行计划\n-- EXPLAIN SELECT /*+ OPTIMIZER_MODE(1), ORDER(T1,T2,T3,T4) ,USE_HASH(T1,T2), USE_HASH(T2,T3), USE_HASH(T3,T4)*/* FROM T1,T2,T3,T4 WHERE T1.c1=T2.d1 AND T2.d2 = T3.e2 AND T3.e1 = T4.f1;\n\n\n# 统计信息提示\n\n-- 统计信息提示只能针对基表设置，视图和派生表等对象设置无效。如果表对象存在别名则必须使用别名。行数只能使用整数，或者整数 +K（千），整数 +M（百万），整数 +G（十亿）。行数提示设置后，统计信息的其它内容也会做相应的调整。\n/*+ STAT (表名, 行数) *\n\n\n# 其他 Hint\n\nMPP 本地对象提示\n\n-- MPP 环境下，提供一种将用户表或动态视图作为本地对象处理的方法，通过指示符 LOCAL_OBJECT(对象名/别名) 进行处理。\n-- 对于系统表当做本地对象的处理，本方法不适用，系统表只能在主站点才能做本地对象处理。\n/*+ LOCAL_OBJECT(对象名/别名) */\n\n\n忽略重复键值提示\n\n-- 当执行 INSERT 操作时，如果存在 UNIQUE 索引，那么发生了重复键值冲突。使用 HINT IGNORE_ROW_ON_DUPKEY_INDEX 则可以忽略该冲突，冲突数据既不进行插入也不会报错，其他非冲突插入正常进行。\n/*+IGNORE_ROW_ON_DUPKEY_INDEX(<表名> [(<列名>{,<列名>})])*/\n\n\n禁用计划缓存提示\n\n-- 使用 HINT PLAN_NO_CACHE 禁用计划缓存，当前语句的执行计划将不会被缓存。\n/*+PLAN_NO_CACHE*/\n\n\nDMDPC 数据分发方式提示\n\nDMDPC 环境下提供了一种专门针对指定的连接、分组、排序、去重和分析函数操作符数据分发方式进行人工干预的优化器提示。该提示被采纳的前提是指定的分发路径有效，因为代价原因没有被优化器选中。\n/*+DPC(分发方式探测序号 分发方式字符串)*/\n\n\n\n# DTS 迁移\n\n# 注意事项\n\n 1. 一定要用新版本DTS工具，旧版本一堆坑\n 2. 如果允许的话，迁移表勾选已存在的先删除表再创建（绕过奇奇怪怪的报错）\n 3. 数据库区分大小写时，是否有字段名转大写的选项（去掉 保持对象名大小写 的勾选）\n 4. 表已存在且不能删表时：一定要先禁用触发器、索引等（Oracle不能禁用唯一索引，DM不知道能行不）\n 5. 报错：数据迁移 A 模式时报 B 模式主键冲突；原因可能是有 A 模式同步到 B 模式的触发器\n\n\n# 常用SQL\n\n# 博客\n\n达梦8数据库运维常用基础sql\n\n\n# 新建用户及表空间\n\n-- 表空间文件\ncreate tablespace user_name datafile '/data/dmdata/DAMENG/user_name.DBF' size 61952 autoextend on next 512 maxsize 67108863 CACHE = NORMAL;  -- 最大64TB\n-- 创建用户模式\nCREATE USER user_name IDENTIFIED BY \"PASSWD\"\n  DEFAULT TABLESPACE user_name\n  TEMPORARY TABLESPACE TEMP\n  QUOTA UNLIMITED ON user_name;\n-- 授权\nGRANT DBA TO user_name;\n\n\nDROP USER 用户名 CASCADE;  -- 强制删除用户及其所有对象\nSELECT TABLESPACE_NAME, SEGMENT_TYPE FROM DBA_SEGMENTS WHERE TABLESPACE_NAME = '表空间名';\nDROP TABLESPACE 表空间名 ;\n\n\n\n# 元数据获取\n\n# 常用系统视图\n\nv$dynamic_tables 可以获取所有动态视图\n\nuser_tables  -- dba_tables\nuser_tab_columns\nuser_indexes\n-- 查看系统中的作业信息\nselect t.job, t.schema_user, t.last_date, t.last_sec, t.next_date, t.next_sec, t.\"INTERVAL\", t.broken, t.failures,t.what from dba_jobs t;\n-- 查询数据库实例启动状态\nselect name, status$ from v$instance;\n-- 查询license信息\nselect * from V$LICENSE;\n-- 查询系统函数及其参数\nselect a.name, b.* from v$ifun a, v$ifun_arg b where a.id = b.id and a.name like 'SF_ARCHIVELOG_%';  --系统函数名\n-- 查询函数/存储过程/包源码信息\nselect * from DBA_SOURCE t where name = 'P_TEST';  --查询对象名\n\n\n触发器\n\nselect * from DBA_TRIGGERS where owner = 'xxx' and TABLE_NAME = 'xxx';\n\n-- 禁用启用触发器\nALTER TRIGGER 触发器名称 DISABLE;\nALTER TRIGGER 触发器名称 ENABLE;\n\n\n# 建表语句获取\n\nSELECT DBMS_METADATA.GET_DDL('TABLE', '表名', '模式名') FROM DUAL;\n\n-- 未使用，理论上没问题，不知道是否有错误的地方\nWITH TABLES AS\n (SELECT TABLE_NAME AS T_NAME, OWNER\n    FROM DBA_TABLES\n   WHERE OWNER = 'OWNER'\n     AND TABLE_NAME = 'TABLE_NAME')\n\nSELECT SUB.T_NAME,\n       LISTAGG(SQL_PART, CHR(13)) WITHIN GROUP(ORDER BY SUB.FLAG) AS FULL_DDL\n  FROM (\n        -- 表定义\n        SELECT 1 AS FLAG,\n                T.T_NAME,\n                DBMS_METADATA.GET_DDL('TABLE', T.T_NAME, T.OWNER) || CHR(13) AS SQL_PART\n          FROM TABLES T\n        UNION ALL\n        -- 表注释\n        SELECT 2 AS FLAG,\n                T.T_NAME,\n                'COMMENT ON TABLE ' || T.T_NAME || ' IS ''' || TC.COMMENTS || ''';' AS SQL_PART\n          FROM TABLES T\n          LEFT JOIN ALL_TAB_COMMENTS TC\n            ON TC.TABLE_NAME = T.T_NAME\n           AND TC.OWNER = T.OWNER\n         WHERE TC.COMMENTS IS NOT NULL\n        UNION ALL\n        -- 字段注释\n        SELECT 3 AS FLAG,\n                T.T_NAME,\n                'COMMENT ON COLUMN ' || T.T_NAME || '.' || CC.COLUMN_NAME || ' IS ''' || CC.COMMENTS || ''';' AS SQL_PART\n          FROM TABLES T\n          LEFT JOIN ALL_COL_COMMENTS CC\n            ON CC.TABLE_NAME = T.T_NAME\n           AND CC.OWNER = T.OWNER\n         WHERE CC.COMMENTS IS NOT NULL\n        UNION ALL\n        -- 索引定义\n        SELECT 4 AS FLAG,\n                T.T_NAME,\n                DBMS_METADATA.GET_DDL('INDEX', I.INDEX_NAME, T.OWNER) AS SQL_PART\n          FROM TABLES T\n          LEFT JOIN ALL_INDEXES I\n            ON I.TABLE_NAME = T.T_NAME\n           AND I.TABLE_OWNER = T.OWNER\n         WHERE I.INDEX_TYPE = 'NORMAL'\n           AND I.UNIQUENESS = 'NONUNIQUE') SUB\n GROUP BY SUB.T_NAME;\n\n\n# 查询表空间占用率\n\nselect b.file_name,\n       b.tablespace_name,\n       b.bytes/1024/1024 size_m,\n       (b.bytes-(nvl(a.bytes,0)))/1024/1024  used_m,\n       round((b.bytes-(nvl(a.bytes,0)))/(b.bytes)*100,2)  usedrate\n  from dba_free_space a,dba_data_files b\n where a.file_id(+) = b.file_id\n   and a.tablespace_name(+) = b.tablespace_name\n order by b.tablespace_name;\n\n\n# 查看单表（索引）占用空间\n\n-- user_segments \n-- dba_segments\nselect  t.segment_name,\n       t.segment_type,\n       t.tablespace_name,\n       t.owner,\n       t.bytes,\n       t.bytes/1024 byte_kb,\n       t.bytes/1024 byte_mb\n  from dba_segments t\n where t.owner = 'DMHR'   -- 用户/模式名 \n   and t.SEGMENT_TYPE = 'TABLE'  -- 'INDEX'\n order by t.bytes desc;\n\n\n# 查看达梦数据库是否是集群\n\nselect * from v$instance;    -- MODE$为STANDBY/PRIMARY是 数据守护集群，否则普通单机或DSC集群\nselect * from v$dsc_ep_info;   -- 返回空  则不是dsc集群\n\n\n# 查看模式和用户对应关系\n\nselect a.NAME schname, a.ID schid, b.id userid, b.NAME username\n  from sysobjects a, sysobjects b\nwhere a.\"TYPE$\"='SCH'\n  and a.pid = b.id;\n\n\n\n# 问题排查\n\n# 查询锁表 & 杀会话\n\n-- 查询锁表\nSELECT obs.OBJECT_NAME, ob.OBJECT_ID, ob.SESSION_ID, ob.USERNAME\n  FROM V$LOCKED_OBJECT ob\n  JOIN DBA_OBJECTS obs\n    ON ob.OBJECT_ID = obs.OBJECT_ID\n WHERE obs.OBJECT_TYPE = 'TABLE';\n\n-- 终止会话\nSP_CLOSE_SESSION(SESS_ID); -- 替换为实际会话ID\n\n-- 查询正在执行的SQL\nselect * from v$sessions where state = 'ACTIVE';\n\n-- 查询阻塞\nSELECT DS.SESS_ID     \"被阻塞的会话ID\",\n       DS.SQL_TEXT    \"被阻塞的SQL\",\n       DS.TRX_ID      \"被阻塞的事务ID\",\n       DS.CREATE_TIME \"开始阻塞时间\",\n       SS.SESS_ID     \"占用锁的会话ID\",\n       SS.SQL_TEXT    \"占用锁的SQL\",\n       SS.CLNT_IP     \"占用锁的IP\",\n       L.wait_for_id  \"占用锁的事务ID\"\n  FROM v$trxwait L\n  LEFT JOIN V$SESSIONS DS\n    ON DS.TRX_ID = L.ID\n  LEFT JOIN V$SESSIONS SS\n    ON SS.TRX_ID = L.wait_for_id;\n\n\n# 查询实例中已执行未提交的 SQL\n\nSELECT t1.sess_id, t1.sql_text, t1.state, t1.trx_id\nFROM v$sessions t1, v$trx t2\nWHERE t1.trx_id = t2.id\n  AND t1.state = 'IDLE'\n  AND t2.status = 'ACTIVE';\n\n\n# 查询表上的锁\n\n 1. 无锁（LOCK_MODE=0）\n    表示当前未对资源加锁，仅作为锁状态标识存在。\n 2. 共享锁（S锁，LOCK_MODE=1）\n    * 允许其他事务读取被锁资源，但禁止修改。\n    * 适用于读多写少的场景，如 SELECT ... LOCK IN SHARE MODE。\n 3. 排他锁（X锁，LOCK_MODE=2）\n    * 禁止其他事务读写被锁资源，仅当前事务可修改。\n    * 常用于数据更新操作（如 UPDATE、DELETE）。\n 4. 意向共享锁（IS锁，LOCK_MODE=3）\n    * 表级锁，表示事务计划在表中某些行上添加共享锁（S锁）。\n    * 作用：通过提前声明意向，避免其他事务对表结构进行不兼容操作（如加X锁）。\n 5. 意向排他锁（IX锁，LOCK_MODE=4）\n    * 表级锁，表示事务计划在表中某些行上添加排他锁（X锁）。\n    * 作用：与IS锁类似，但用于更高粒度的排他操作声明，例如批量更新前的预检测。\n\nSELECT *\nFROM V$LOCK\nWHERE TABLE_ID IN (SELECT OBJECT_ID\n                   FROM DBA_OBJECTS\n                   WHERE OWNER = 'OWNER'\n                     AND OBJECT_NAME = 'OBJECT_NAME')\n\n\n# 批量禁用某个用户/模式下所有外键约束\n\n其他索引应该能以同样方式拼接禁用语句\n\nselect 'alter table '|| t.owner||'.'||t.table_name ||' disable constraint '||t.constraint_name||';'\n  from dba_constraints t\n where t.owner = 'DMHR'   -- 用户/模式名\n   and t.constraint_type = 'R';\n\n\n# 用户锁定/解锁\n\n-- 查询系统中锁定的用户及对应的锁定时间：\nselect t.username, \n       t.user_id, \n       t.account_status, \n       t.lock_date\n  from dba_users t\n where t.account_status = 'LOCKED';\n\n-- 对于被锁定的用户，可以使用SYSDBA或者具有alter user权限的用户解锁。\nalter user hruser ACCOUNT UNLOCK;   --解锁用户\nalter user hruser ACCOUNT LOCK;      --锁定某用户\n\n\n\n# FAQ\n\n# 大数据量表加字段慢\n\n1. select SF_GET_SESSION_PARA_VALUE ('ALTER_TABLE_OPT');   -- 查询会话参数\n2. ALTER SESSION SET 'ALTER_TABLE_OPT' = 2 PURGE;    -- 修改会话参数\n3. ALTER SESSION SET 'ALTER_TABLE_OPT' = 0 PURGE;    -- 恢复会话参数（将0替换为第1步所查询参数）\n",normalizedContent:"# 零、官方文档\n\n产品手册\n\n达梦数据库需善用达梦提供的工具\n\n * dm控制台工具：查看 dm.ini 配置（中文描述配置信息）、备份还原 官网在线文档：dm数据库服务配置\n * dm审计分析工具\n * dm数据迁移工具：用于达梦与其他数据库间的数据迁移（包含视图、存储过程、函数、触发器等）\n * dm性能监视工具：性能监控（线程、会话、sql、资源的监控）、调优向导（内存配置、线程配置、索引优化）\n * sql交互式查询工具\n\n\n\n\n# 一、数据库安装\n\n# 前期准备\n\n 1. 创建dmdba用户,dinstall组\n    \n    [root@localhost oracle]# groupadd dinstall && useradd -g dinstall dmdba && echo root|passwd --stdin dmdba\n    changing password for user dmdba.\n    passwd: all authentication tokens updated successfully.\n    \n\n 2. 关闭防火墙和selinux\n 3. 创建软件安装目录 /opt/dmdbms && chown dmdba:dinstall /opt/dmdbms\n 4. 创建数据目录/opt/dmdata && chown dmdba:dinstall /opt/dmdata\n 5. 修改用户资源限制\n    vi /etc/security/limits.conf 增加相应配置\n    \n    dmdba hard nofile 131072\n    dmdba soft nofile 131072\n    dmdba soft nice 0\n    dmdba hard nice 0\n    dmdba soft as unlimited\n    dmdba hard as unlimited\n    dmdba soft fsize unlimited\n    dmdba hard fsize unlimited\n    dmdba soft nproc 131072\n    dmdba hard nproc 131072\n    dmdba soft data unlimited\n    dmdba hard data unlimited\n    dmdba soft core unlimited\n    dmdba hard core unlimited\n    dmdba soft memlock unlimited\n    dmdba hard memlock unlimited\n    \n\n 6. 上传安装包，解压 unzip dm8_20220525_x86_rh6_64.zip\n 7. iso挂载到/mnt mount -o loop dm8_20220525_x86_rh6_64.iso /mnt/\n 8. 取消挂载 umount /mnt/ （全部安装完成后执行）\n\n# 安装\n\n 1. 切换用户 dmdba 进行安装\n\n 2. 执行安装脚本 /mnt/dminstall.bin -i\n    \n    [dmdba@localhost ~]$ /mnt/dminstall.bin -i\n    please select the installer's language (e/e:english c/c:chinese) [e/e]:c\n    解压安装程序......... \n    欢迎使用达梦数据库安装程序\n    \n    是否输入key文件路径? (y/y:是 n/n:否) [y/y]:n\n    \n    是否设置时区? (y/y:是 n/n:否) [y/y]:y\n    设置时区:\n    [ 1]: gtm-12=日界线西\n    [ 2]: gtm-11=萨摩亚群岛\n    [ 3]: gtm-10=夏威夷\n    [ 4]: gtm-09=阿拉斯加\n    [ 5]: gtm-08=太平洋时间（美国和加拿大）\n    [ 6]: gtm-07=亚利桑那\n    [ 7]: gtm-06=中部时间（美国和加拿大）\n    [ 8]: gtm-05=东部部时间（美国和加拿大）\n    [ 9]: gtm-04=大西洋时间（美国和加拿大）\n    [10]: gtm-03=巴西利亚\n    [11]: gtm-02=中大西洋\n    [12]: gtm-01=亚速尔群岛\n    [13]: gtm=格林威治标准时间\n    [14]: gtm+01=萨拉热窝\n    [15]: gtm+02=开罗\n    [16]: gtm+03=莫斯科\n    [17]: gtm+04=阿布扎比\n    [18]: gtm+05=伊斯兰堡\n    [19]: gtm+06=达卡\n    [20]: gtm+07=曼谷，河内\n    [21]: gtm+08=中国标准时间\n    [22]: gtm+09=汉城\n    [23]: gtm+10=关岛\n    [24]: gtm+11=所罗门群岛\n    [25]: gtm+12=斐济\n    [26]: gtm+13=努库阿勒法\n    [27]: gtm+14=基里巴斯\n    请选择设置时区 [6]:21\n    \n    安装类型:\n    1 典型安装\n    2 服务器\n    3 客户端\n    4 自定义\n    请选择安装类型的数字序号 [1 典型安装]:1\n    所需空间: 1585m\n    \n    请选择安装目录 [/home/dmdba/dmdbms]:/opt/dmdbms\n    目录(/opt/dmdbms)下不为空，请选择其他目录。\n    请选择安装目录 [/home/dmdba/dmdbms]:/opt/dmdbms\n    可用空间: 13g\n    是否确认安装路径(/opt/dmdbms)? (y/y:是 n/n:否)  [y/y]:y\n    \n    安装前小结\n    安装位置: /opt/dmdbms\n    所需空间: 1585m\n    可用空间: 13g\n    版本信息: \n    有效日期: \n    安装类型: 典型安装\n    是否确认安装? (y/y:是 n/n:否):y\n    2022-07-18 19:00:36 \n    [info] 安装达梦数据库...\n    2022-07-18 19:00:37 \n    [info] 安装 基础 模块...\n    2022-07-18 19:00:40 \n    [info] 安装 服务器 模块...\n    2022-07-18 19:00:40 \n    [info] 安装 客户端 模块...\n    2022-07-18 19:00:42 \n    [info] 安装 驱动 模块...\n    2022-07-18 19:00:43 \n    [info] 安装 手册 模块...\n    2022-07-18 19:00:43 \n    [info] 安装 服务 模块...\n    2022-07-18 19:00:44 \n    [info] 移动日志文件。\n    2022-07-18 19:00:44 \n    [info] 安装达梦数据库完成。\n    \n    请以root系统用户执行命令:\n    /opt/dmdbms/script/root/root_installer.sh\n    \n    安装结束\n    \n\n 3. root执行脚本 /opt/dmdbms/script/root/root_installer.sh\n    \n    [root@localhost opt]# /opt/dmdbms/script/root/root_installer.sh\n    移动 /opt/dmdbms/bin/dm_svc.conf 到/etc目录\n    修改服务器权限\n    创建dmapservice服务\n    created symlink from /etc/systemd/system/multi-user.target.wants/dmapservice.service to /usr/lib/systemd/system/dmapservice.service.\n    创建服务(dmapservice)完成\n    启动dmapservice服务\n    [root@localhost opt]#\n    \n\n# 初始化\n\n 1. 执行初始化脚本 ./dminit path=/opt/dmdata db_name=aihb instance_name=aihb\n    \n    [dmdba@localhost bin]$ pwd\n    /opt/dmdbms/bin\n    [dmdba@localhost bin]$ ./dminit path=/opt/dmdata db_name=aihb instance_name=aihb\n    initdb v8\n    db version: 0x7000c\n    file dm.key not found, use default license!\n    license will expire on 2023-05-25\n    normal of fast\n    normal of default\n    normal of recycle\n    normal of keep\n    normal of roll\n    \n     log file path: /opt/dmdata/aihb/aihb01.log\n    \n    \n     log file path: /opt/dmdata/aihb/aihb02.log\n    \n    write to dir [/opt/dmdata/aihb].\n    create dm database success. 2022-07-19 10:05:20\n    [dmdba@localhost bin]$ \n    \n\n# 注册数据库服务，启动数据库\n\n 1. 调用达梦提供的脚本生成数据库服务,自动启动数据库,脚本在安装目录的/script/root子目录下,调用注册脚本需使用root用户 ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini -p aihb\n    \n    * 调用dm_service_installer.sh脚本来生成服务\n    * -t 指定需要创建的服务类型,这里是数据库服务所以是dmserver\n    * -dm_ini 指定在上一步初始化后生成的dm.ini文件\n    * -p 为生成服务的后缀名,可自定义，这里给的czw，所以创建的服务名为dmserviceczw\n    \n    [root@localhost root]# pwd\n    /opt/dmdbms/script/root\n    [root@localhost root]# ll\n    total 48\n    -rwxr-xr-x. 1 dmdba dinstall 29111 jul 19 10:00 dm_service_installer.sh\n    -rwxr-xr-x. 1 dmdba dinstall  9618 jul 19 10:00 dm_service_uninstaller.sh\n    -rwxr-xr-x. 1 dmdba dinstall   635 jul 19 10:00 root_installer.sh\n    [root@localhost root]# ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini\n    请设置参数-p\n    [root@localhost root]# ./dm_service_installer.sh -t dmserver -dm_ini /opt/dmdata/aihb/dm.ini -p aihb\n    created symlink from /etc/systemd/system/multi-user.target.wants/dmserviceaihb.service to /usr/lib/systemd/system/dmserviceaihb.service.\n    创建服务(dmserviceaihb)完成\n    [root@localhost root]# \n    \n\n 2. 启动数据库 systemctl start dmserviceaihb\n\n\n# 二、创建oracle to 达梦的dblink（oci方式）\n\n参考链接\n\n# 环境准备\n\n键              值\n操作系统           centos 7\noracle数据库      11.2.0.4.0\n达梦数据库          centos 7 x86版本\n达梦安装目录         /opt/dmdbms\noracle oci位置   /opt/oracle\n\n# 工具准备\n\noracle oci： instantclient-basic-linux.x64-11.2.0.4.0.zip（与系统和oracle版本对应） 下载地址\n\n# oracle oci安装配置（达梦数据库所在服务器）\n\n 1. 进入包所在的路径并解压：\n    \n    cd /opt/oracle/ && unzip instantclient-basic-linux.x64-11.2.0.4.0.zip\n    \n\n 2. （18.3 之前的版本需要这一步）进入解压后目录创建软连接：\n    \n    cd instantclient_11_2 && ln -sfv libclntsh.so.11.1 libclntsh.so\n    \n\n 3. 配置环境变量\n    \n    * 将oci添加到/etc/ld.so.conf.d目录下（系统用户）\n      \n      echo /opt/oracle/instantclient_11_2 > /etc/ld.so.conf.d/oracle-instantclient.conf\n      \n    \n    * 加载动态链接库（使上一步生效）：ldconfig\n    * 配置ld_library_path环境变量（dmdba用户）\n      修改dmdba用户下的.bash_profile文件（vim ~/.bash_profile），添加以下内容\n      \n      export ld_library_path=\"$ld_library_path:/opt/oracle/instantclient_11_2\"\n      \n    \n    * 加载环境变量（使上一步生效）：source ~/.bash_profile\n\n 4. 启动（重启达梦数据库 系统用户）\n\nsystemctl restart dmservicexxx #（**实际服务名**）\n\n\n 5. 创建dblink（注：用户名不要加引号）\n\ncreate link linkora connect 'oracle' with username identified by \"password\" using 'x.x.x.x:1521/orcl';\n\n\n\n# 数据库调优方面\n\n性能诊断与优化\n\n\n# 数据库统计信息\n\n# 自动收集\n\ndm 数据库支持统计信息的自动收集，当全表数据量变化超过设定阈值后可自动更新统计信息。\n\n--打开表数据量监控开关，参数值为 1 时监控所有表，2 时仅监控配置表\nsp_set_para_value(1,'auto_stat_obj',2);\n\n-- 如果 auto_stat_obj=2，需进一步使用 dbms_stats.set_table_prefs 设置 stale_percent 属性\n--设置 sysdba.t 表数据变化率超过 15% 时触发自动更新统计信息\ndbms_stats.set_table_prefs('sysdba','t','stale_percent',15);\n\n--配置自动收集统计信息触发时机\n-- 停止时最后一个参数配置为0？   参数值需再斟酌！！！！\nsp_create_auto_stat_trigger(1, 1, 1, 1,'1:00', '2025/3/12',60,1);\n\n/*\n函数各参数介绍\nsp_create_auto_stat_trigger(\n    type                    int,    --间隔类型，默认为天\n    freq_interval         int,    --间隔频率，默认 1\n    freq_sub_interval    int,    --间隔频率，与 freq_interval 配合使用\n    freq_minute_interval int,    --间隔分钟，默认为 1440\n    starttime              varchar(128), --开始时间，默认为 22:00\n    during_start_date    varchar(128), --重复执行的起始时间，默认 1900/1/1\n    max_run_duration    int,    --允许的最长执行时间(秒)，默认不限制\n    enable                  int     --0 关闭，1 启用  --默认为 1\n);\n*/\n\n\n测试\n\ncreate table t(a int);\ninsert into t select level connect by level<=20;\ncommit;\n\n-- select * from sysstattableidu order by last_stat_dt desc;\n\nselect *\n  from sysstats\n where id in (select object_id\n                from dba_objects\n               where object_type = 'table'\n                 and owner = 'owner'\n                 and object_name = 't');\n\n\n监控统计信息收集过程\n\n-- 创建一个用户表 auto_stat_info，用以保存自动收集过程的相关信息\n-- 最好是系统用户吧？？？sysdba？？？\ncreate table auto_stat_info\n(\n   task_id               int,\n   total_stat            int,\n   table_id              int,\n   sch_name              varchar(24),\n   table_name            varchar(24),\n   curr_gath_tab_id      int,\n   curr_gath_sch_name    varchar(24),\n   curr_gath_tab_name    varchar(24),\n   success_stat          int,\n   fail_stat             int,\n   task_start_time       datetime,\n   task_end_time         datetime,\n   gather_tbl_start_time datetime,\n   gather_tbl_end_time   datetime\n);\n\n\n-- 创建过程 sysdba.get_auto_stat_info_func，接收服务器在自动收集统计信息时的过程信息。并在模块体编写用户代码，将过程收集的统计信息写入 auto_stat_info 中。\ncreate or replace procedure  sysdba.get_auto_stat_info_func(task_id int,total_stat int,table_id int, sch_name varchar(24), table_name varchar(24),curr_gath_tab_id int, curr_gath_sch_name varchar(24), curr_gath_tab_name varchar(24),success_stat int,fail_stat int,task_start_time datetime, task_end_time datetime,gather_tbl_start_time datetime,gather_tbl_end_time datetime) as\nbegin\n//下面是用户自定义的代码，将sysdba.get_auto_stat_info_func过程的信息插入到用户表auto_stat_info 中\n    insert into auto_stat_info values(task_id,total_stat,table_id, sch_name,table_name,curr_gath_tab_id, curr_gath_sch_name, curr_gath_tab_name,success_stat ,fail_stat,task_start_time,task_end_time,gather_tbl_start_time,gather_tbl_end_time);\ncommit;\nexception\n    when others then\n        null;\nend;\n/\n\n-- 最后，解读表 auto_stat_info，介绍一次自动收集统计信息任务的相关过程信息。如果 sp_create_auto_stat_trigger 触发一次自动收集统计信息，在任务开始时，会先记录当前任务的开始时间，当前任务的待收集表的总个数，以及接下来待收集的表的 id。之后每收集完成一个表的统计信息，就会记录该表 table 的 id 及收集该表的开始和结束时间，和截至目前收集成功失败的表个数情况，以及接下来待收集的表的 id。其中“接下来待收集的表的 id”即 current_gather_tab_id，为当前服务器正在收集的表 id。\n\n\n# 手动收集\n\n查看是否已有统计信息\n\n-- 检查表上是否有统计信息\nselect * from sysstats\nwhere id in\n(\n  select object_id from dba_objects where\n  object_type='table'\n  and owner = '模式名'\n  and object_name='表名'\n) ;\n\n\n-- 用于经过 gather_table_stats、gather_index_stats 或 gather_schema_stats 收集之后展示。\ndbms_stats.table_stats_show('模式名','表名');\n\n\n收集统计信息\n\n1、收集全库统计信息\ndbms_stats.gather_schema_stats('hnsimis', 100,false,'for all columns size auto');--hnsimis是模式名\n-- 这种收集方式，并不是100%收集，所以有一定的弊端。\n\n2、收集表的统计信息\ndbms_stats.gather_table_stats('test','test',null,100);--收集表的统计信息，包括列和索引等 第一个参数是模式，第二个参数是表 null是缺省，100是采样率100%，默认不是。\ndbms_stats.gather_table_stats('owner','table_name',null,100,true,'for all columns size auto');\n\n3、收集列统计信息\nstat 100 on fw(create_userid); --收集某一列的统计信息 fw是表名 create_userid是列名称\n-- 这个在做sql调优的时候比较常用，因为比较准。\n\n4、收集索引统计信息\nsp_index_stat_init('dreamweb_pudong','ix_fw_rowstate',100); --收集索引的统计信息 dreamweb_pudong是模式名称 ix_fw_rowstate是索引名称\n-- 这个也比较常用，建议创建完索引，立刻收集下统计信息。\n\n-- 报错 磁盘空间不足 -523[-523]: anonymous block line 2\n-- system表空间 不足\n\n\n删除统计信息\n\n--表\ndbms_stats.delete_table_stats('模式名','表名','分区名',...);\n\n--模式\ndbms_stats.delete_schma_stats('模式名','','',...);\n\n--索引\ndbms_stats.delete_index_stats('模式名','索引名','分区表名',...);\n\n--字段\ndbms_stats.delete_column_stats('模式名','表名','列名','分区表名',...);\n\n\n\n# et 工具\n\net 工具是 dm 数据库自带的 sql 性能分析工具，能够统计 sql 语句执行过程中每个操作符的实际开销，为 sql 优化提供依据以及指导。\n\n--查看et是否开启\nselect * from v$parameter t where name = 'monitor_sql_exec';\nselect * from v$parameter t where name = 'enable_monitor';\n--enable_monitor，动态参数(系统级)\n--monitor_sql_exec，动态参数(会话级)\n\n--开启et\nsp_set_para_value(1,'enable_monitor',1);\nsp_set_para_value(1,'monitor_sql_exec',1);\n\n--关闭et\nsp_set_para_value(1,'enable_monitor',0);\nsp_set_para_value(1,'monitor_sql_exec',0);\n\n\n\n# dbms_sqltune 工具\n\ndbms_sqltune 包提供一系列实时 sql 监控的方法。当 sql 监控功能开启后，dbms_sqltune 包可以实时监控 sql 执行过程中的信息，包括：执行时间、执行代价、执行用户、统计信息等情况。\ndbms_sqltune 系统包相比 et 功能更强大，能够获取 io 操作量，查看真实执行计划，每个操作符消耗占比和相应的花费时间，还能看出每个操作符执行的次数，非常便于了解执行计划中瓶颈位置。\ndbms_sqltune 功能远不止定位执行计划瓶颈，还拥有调优助手功能（建议性提示建某索引和收集某统计信息），具体使用 dm8 系统包使用手册。\n\n-- 1. 使用前提：建议会话级开启参数 monitor_sql_exec=1，而 monitor_sql_exec 在达梦数据库中一般默认是 1，无需调整。\nalter session set 'monitor_sql_exec' = 1;\n-- 2. <执行待优化sql>\n-- 3. 查看执行计划\nselect dbms_sqltune.report_sql_monitor(sql_exec_id=>1213701) from dual;\n\n\n\n# hints\n\ndm 查询优化器采用基于代价的方法。在估计代价时，主要以统计信息或者普遍的数据分布为依据。在大多数情况下，估计的代价都是准确的。但在一些比较特殊的场合，例如缺少统计信息，或统计信息陈旧，或抽样数据不能很好地反映数据分布时，优化器选择的执行计划不是“最优”的，甚至可能是很差的执行计划。\n如果 hint 的语法没有写对或指定的值不正确，dm 并不会报错，而是直接忽略 hint 继续执行。\n\n# ini 参数提示\n\n支持使用 hint 的 ini 参数可通过 v$hint_ini_info 动态视图查询。支持 hint 的 ini 参数分为两类：一是 hint_type 为“opt”，表示分析阶段使用的参数；二是 hint_type 为“exec”，表示运行阶段使用的参数，运行阶段使用的参数对于视图无效。\n\n * 例：select /*+enable_hash_join(1)*/ * from t1,t2 where c1=d1;\n\n# 索引提示\n\n-- 使用索引(如果查询中给出了表的别名那么必须使用别名)：\n/*+ index (表名[,] 索引名) {index (表名[,] 索引名)} */\n\n-- 不使用索引：\n/*+ no_index (表名[,] 索引名) { no_index (表名[,] 索引名)} */\n\n\n\n\n# 连接方法提示\n\n-- 强制两个表间使用指定顺序的哈希连接\n/*+ use_hash(t1, t2) */\n\n-- 强制两个表间不能使用指定顺序的哈希连接\n/*+ no_use_hash(t1, t2) */\n\n-- 强制两个表间使用嵌套循环连接\n/*+ use_nl(a, b) */\n\n-- 强制两个表间不能使用嵌套循环连接\n/*+ no_use_nl(a, b) */\n\n-- 当连接情况为左表 + 右表索引时，强制两个表间使用索引连接\n/*+ use_nl_with_index(t1, idx_t2_id) */\n\n-- 当连接情况为左表 + 右表索引时，强制两个表间不能使用索引连接\n/*+ no_use_nl_with_index(t1, idx_t2_id) */\n\n-- 强制两个表间使用归并连接。归并连接所用的两个列都必须是索引列。\n/*+ use_merge(t1,t2) */\n\n-- 强制两个表间不能使用归并连接\n/*+ no_use_merge(t1,t2) */\n\n-- 优先采用半连接转换为等价的内连接，仅 optimizer_mode=1 有效。\n/*+ semi_gen_cross  optimizer_mode(1) */\n\n-- 不采用半连接转换为等价的内连接，仅 optimizer_mode=1 有效。\n/*+ no_semi_gen_cross  optimizer_mode(1) */\n\n-- 优先采用变量改写方式实现连接，适合驱动表数据量少而另一侧计划较复杂的场景，目前支持变量改写的连接方式有 nest loop inner join2、nest loop left join2、nest loop semi join2，仅 optimizer_mode=1 有效。\n/*+ use_cvt_var optimizer_mode(1) */\n\n-- 不考虑变量改写方式实现连接，仅 optimizer_mode=1 有效。\n/*+ no_use_cvt_var optimizer_mode(1) */\n\n-- 一般情况下，归并连接需要左右孩子的数据按照连接列有序，使用此优化器提示时，优化器将考虑通过插入排序操作符的方式实现归并连接，仅 optimizer_mode=1 有效。\n/*+enhanced_merge_join optimizer_mode(1) stat(t1 1m) stat(t2 1m) */\n\n\n\n# 连接顺序提示\n\n-- 多表连接时优化器会考虑各种可能的排列组合顺序。使用 order hint 指定连接顺序提示可以缩小优化器试探的排列空间，进而得到接近 dba 所期望的查询计划。如果连接顺序和连接方法提示同时指定且二者间存在自相矛盾，优化器会以连接顺序提示为准。\n/*+ order (t1, t2 , t3, … tn ) */\n\n/*\n如果期望表的连接顺序是 t1, t2, t3，那么可以加入这样的提示：\nselect /*+ order(t1, t2, t3 )*/* from t1, t2 , t3, t4 where …\n在指定上述连接顺序后，t4,t1,t2,t3 或 t1,t2,t4,t3 会被考虑；t3,t1,t2 或 t1,t3,t2 不被考虑。\n*/\n\n-- 更特定的执行计划\n-- explain select /*+ optimizer_mode(1), order(t1,t2,t3,t4) ,use_hash(t1,t2), use_hash(t2,t3), use_hash(t3,t4)*/* from t1,t2,t3,t4 where t1.c1=t2.d1 and t2.d2 = t3.e2 and t3.e1 = t4.f1;\n\n\n# 统计信息提示\n\n-- 统计信息提示只能针对基表设置，视图和派生表等对象设置无效。如果表对象存在别名则必须使用别名。行数只能使用整数，或者整数 +k（千），整数 +m（百万），整数 +g（十亿）。行数提示设置后，统计信息的其它内容也会做相应的调整。\n/*+ stat (表名, 行数) *\n\n\n# 其他 hint\n\nmpp 本地对象提示\n\n-- mpp 环境下，提供一种将用户表或动态视图作为本地对象处理的方法，通过指示符 local_object(对象名/别名) 进行处理。\n-- 对于系统表当做本地对象的处理，本方法不适用，系统表只能在主站点才能做本地对象处理。\n/*+ local_object(对象名/别名) */\n\n\n忽略重复键值提示\n\n-- 当执行 insert 操作时，如果存在 unique 索引，那么发生了重复键值冲突。使用 hint ignore_row_on_dupkey_index 则可以忽略该冲突，冲突数据既不进行插入也不会报错，其他非冲突插入正常进行。\n/*+ignore_row_on_dupkey_index(<表名> [(<列名>{,<列名>})])*/\n\n\n禁用计划缓存提示\n\n-- 使用 hint plan_no_cache 禁用计划缓存，当前语句的执行计划将不会被缓存。\n/*+plan_no_cache*/\n\n\ndmdpc 数据分发方式提示\n\ndmdpc 环境下提供了一种专门针对指定的连接、分组、排序、去重和分析函数操作符数据分发方式进行人工干预的优化器提示。该提示被采纳的前提是指定的分发路径有效，因为代价原因没有被优化器选中。\n/*+dpc(分发方式探测序号 分发方式字符串)*/\n\n\n\n# dts 迁移\n\n# 注意事项\n\n 1. 一定要用新版本dts工具，旧版本一堆坑\n 2. 如果允许的话，迁移表勾选已存在的先删除表再创建（绕过奇奇怪怪的报错）\n 3. 数据库区分大小写时，是否有字段名转大写的选项（去掉 保持对象名大小写 的勾选）\n 4. 表已存在且不能删表时：一定要先禁用触发器、索引等（oracle不能禁用唯一索引，dm不知道能行不）\n 5. 报错：数据迁移 a 模式时报 b 模式主键冲突；原因可能是有 a 模式同步到 b 模式的触发器\n\n\n# 常用sql\n\n# 博客\n\n达梦8数据库运维常用基础sql\n\n\n# 新建用户及表空间\n\n-- 表空间文件\ncreate tablespace user_name datafile '/data/dmdata/dameng/user_name.dbf' size 61952 autoextend on next 512 maxsize 67108863 cache = normal;  -- 最大64tb\n-- 创建用户模式\ncreate user user_name identified by \"passwd\"\n  default tablespace user_name\n  temporary tablespace temp\n  quota unlimited on user_name;\n-- 授权\ngrant dba to user_name;\n\n\ndrop user 用户名 cascade;  -- 强制删除用户及其所有对象\nselect tablespace_name, segment_type from dba_segments where tablespace_name = '表空间名';\ndrop tablespace 表空间名 ;\n\n\n\n# 元数据获取\n\n# 常用系统视图\n\nv$dynamic_tables 可以获取所有动态视图\n\nuser_tables  -- dba_tables\nuser_tab_columns\nuser_indexes\n-- 查看系统中的作业信息\nselect t.job, t.schema_user, t.last_date, t.last_sec, t.next_date, t.next_sec, t.\"interval\", t.broken, t.failures,t.what from dba_jobs t;\n-- 查询数据库实例启动状态\nselect name, status$ from v$instance;\n-- 查询license信息\nselect * from v$license;\n-- 查询系统函数及其参数\nselect a.name, b.* from v$ifun a, v$ifun_arg b where a.id = b.id and a.name like 'sf_archivelog_%';  --系统函数名\n-- 查询函数/存储过程/包源码信息\nselect * from dba_source t where name = 'p_test';  --查询对象名\n\n\n触发器\n\nselect * from dba_triggers where owner = 'xxx' and table_name = 'xxx';\n\n-- 禁用启用触发器\nalter trigger 触发器名称 disable;\nalter trigger 触发器名称 enable;\n\n\n# 建表语句获取\n\nselect dbms_metadata.get_ddl('table', '表名', '模式名') from dual;\n\n-- 未使用，理论上没问题，不知道是否有错误的地方\nwith tables as\n (select table_name as t_name, owner\n    from dba_tables\n   where owner = 'owner'\n     and table_name = 'table_name')\n\nselect sub.t_name,\n       listagg(sql_part, chr(13)) within group(order by sub.flag) as full_ddl\n  from (\n        -- 表定义\n        select 1 as flag,\n                t.t_name,\n                dbms_metadata.get_ddl('table', t.t_name, t.owner) || chr(13) as sql_part\n          from tables t\n        union all\n        -- 表注释\n        select 2 as flag,\n                t.t_name,\n                'comment on table ' || t.t_name || ' is ''' || tc.comments || ''';' as sql_part\n          from tables t\n          left join all_tab_comments tc\n            on tc.table_name = t.t_name\n           and tc.owner = t.owner\n         where tc.comments is not null\n        union all\n        -- 字段注释\n        select 3 as flag,\n                t.t_name,\n                'comment on column ' || t.t_name || '.' || cc.column_name || ' is ''' || cc.comments || ''';' as sql_part\n          from tables t\n          left join all_col_comments cc\n            on cc.table_name = t.t_name\n           and cc.owner = t.owner\n         where cc.comments is not null\n        union all\n        -- 索引定义\n        select 4 as flag,\n                t.t_name,\n                dbms_metadata.get_ddl('index', i.index_name, t.owner) as sql_part\n          from tables t\n          left join all_indexes i\n            on i.table_name = t.t_name\n           and i.table_owner = t.owner\n         where i.index_type = 'normal'\n           and i.uniqueness = 'nonunique') sub\n group by sub.t_name;\n\n\n# 查询表空间占用率\n\nselect b.file_name,\n       b.tablespace_name,\n       b.bytes/1024/1024 size_m,\n       (b.bytes-(nvl(a.bytes,0)))/1024/1024  used_m,\n       round((b.bytes-(nvl(a.bytes,0)))/(b.bytes)*100,2)  usedrate\n  from dba_free_space a,dba_data_files b\n where a.file_id(+) = b.file_id\n   and a.tablespace_name(+) = b.tablespace_name\n order by b.tablespace_name;\n\n\n# 查看单表（索引）占用空间\n\n-- user_segments \n-- dba_segments\nselect  t.segment_name,\n       t.segment_type,\n       t.tablespace_name,\n       t.owner,\n       t.bytes,\n       t.bytes/1024 byte_kb,\n       t.bytes/1024 byte_mb\n  from dba_segments t\n where t.owner = 'dmhr'   -- 用户/模式名 \n   and t.segment_type = 'table'  -- 'index'\n order by t.bytes desc;\n\n\n# 查看达梦数据库是否是集群\n\nselect * from v$instance;    -- mode$为standby/primary是 数据守护集群，否则普通单机或dsc集群\nselect * from v$dsc_ep_info;   -- 返回空  则不是dsc集群\n\n\n# 查看模式和用户对应关系\n\nselect a.name schname, a.id schid, b.id userid, b.name username\n  from sysobjects a, sysobjects b\nwhere a.\"type$\"='sch'\n  and a.pid = b.id;\n\n\n\n# 问题排查\n\n# 查询锁表 & 杀会话\n\n-- 查询锁表\nselect obs.object_name, ob.object_id, ob.session_id, ob.username\n  from v$locked_object ob\n  join dba_objects obs\n    on ob.object_id = obs.object_id\n where obs.object_type = 'table';\n\n-- 终止会话\nsp_close_session(sess_id); -- 替换为实际会话id\n\n-- 查询正在执行的sql\nselect * from v$sessions where state = 'active';\n\n-- 查询阻塞\nselect ds.sess_id     \"被阻塞的会话id\",\n       ds.sql_text    \"被阻塞的sql\",\n       ds.trx_id      \"被阻塞的事务id\",\n       ds.create_time \"开始阻塞时间\",\n       ss.sess_id     \"占用锁的会话id\",\n       ss.sql_text    \"占用锁的sql\",\n       ss.clnt_ip     \"占用锁的ip\",\n       l.wait_for_id  \"占用锁的事务id\"\n  from v$trxwait l\n  left join v$sessions ds\n    on ds.trx_id = l.id\n  left join v$sessions ss\n    on ss.trx_id = l.wait_for_id;\n\n\n# 查询实例中已执行未提交的 sql\n\nselect t1.sess_id, t1.sql_text, t1.state, t1.trx_id\nfrom v$sessions t1, v$trx t2\nwhere t1.trx_id = t2.id\n  and t1.state = 'idle'\n  and t2.status = 'active';\n\n\n# 查询表上的锁\n\n 1. 无锁（lock_mode=0）\n    表示当前未对资源加锁，仅作为锁状态标识存在。\n 2. 共享锁（s锁，lock_mode=1）\n    * 允许其他事务读取被锁资源，但禁止修改。\n    * 适用于读多写少的场景，如 select ... lock in share mode。\n 3. 排他锁（x锁，lock_mode=2）\n    * 禁止其他事务读写被锁资源，仅当前事务可修改。\n    * 常用于数据更新操作（如 update、delete）。\n 4. 意向共享锁（is锁，lock_mode=3）\n    * 表级锁，表示事务计划在表中某些行上添加共享锁（s锁）。\n    * 作用：通过提前声明意向，避免其他事务对表结构进行不兼容操作（如加x锁）。\n 5. 意向排他锁（ix锁，lock_mode=4）\n    * 表级锁，表示事务计划在表中某些行上添加排他锁（x锁）。\n    * 作用：与is锁类似，但用于更高粒度的排他操作声明，例如批量更新前的预检测。\n\nselect *\nfrom v$lock\nwhere table_id in (select object_id\n                   from dba_objects\n                   where owner = 'owner'\n                     and object_name = 'object_name')\n\n\n# 批量禁用某个用户/模式下所有外键约束\n\n其他索引应该能以同样方式拼接禁用语句\n\nselect 'alter table '|| t.owner||'.'||t.table_name ||' disable constraint '||t.constraint_name||';'\n  from dba_constraints t\n where t.owner = 'dmhr'   -- 用户/模式名\n   and t.constraint_type = 'r';\n\n\n# 用户锁定/解锁\n\n-- 查询系统中锁定的用户及对应的锁定时间：\nselect t.username, \n       t.user_id, \n       t.account_status, \n       t.lock_date\n  from dba_users t\n where t.account_status = 'locked';\n\n-- 对于被锁定的用户，可以使用sysdba或者具有alter user权限的用户解锁。\nalter user hruser account unlock;   --解锁用户\nalter user hruser account lock;      --锁定某用户\n\n\n\n# faq\n\n# 大数据量表加字段慢\n\n1. select sf_get_session_para_value ('alter_table_opt');   -- 查询会话参数\n2. alter session set 'alter_table_opt' = 2 purge;    -- 修改会话参数\n3. alter session set 'alter_table_opt' = 0 purge;    -- 恢复会话参数（将0替换为第1步所查询参数）\n",charsets:{cjk:!0},lastUpdated:"2025/04/09, 14:11:14",lastUpdatedTimestamp:1744179074e3},{title:"华为高斯数据库",frontmatter:{title:"华为高斯数据库",date:"2022-07-21T11:18:24.000Z",permalink:"/pages/e461e3/"},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/06.%E5%9B%BD%E4%BA%A7%E6%95%B0%E6%8D%AE%E5%BA%93/09.%E5%8D%8E%E4%B8%BA%E9%AB%98%E6%96%AF%E6%95%B0%E6%8D%AE%E5%BA%93.html",relativePath:"03.数据库/06.国产数据库/09.华为高斯数据库.md",key:"v-656f9cf6",path:"/pages/e461e3/",headers:[{level:4,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:4,title:"关于数据迁移",slug:"关于数据迁移",normalizedTitle:"关于数据迁移",charIndex:327},{level:4,title:"元数据使用",slug:"元数据使用",normalizedTitle:"元数据使用",charIndex:763},{level:5,title:"元数据表或视图",slug:"元数据表或视图",normalizedTitle:"元数据表或视图",charIndex:772},{level:5,title:"查询所有模式",slug:"查询所有模式",normalizedTitle:"查询所有模式",charIndex:11744},{level:5,title:"查询当前模式下的所有表名以及中文注释",slug:"查询当前模式下的所有表名以及中文注释",normalizedTitle:"查询当前模式下的所有表名以及中文注释",charIndex:11995},{level:5,title:"表名查询字段属性",slug:"表名查询字段属性",normalizedTitle:"表名查询字段属性",charIndex:12218},{level:5,title:"查询视图定义语句",slug:"查询视图定义语句",normalizedTitle:"查询视图定义语句",charIndex:13118},{level:5,title:"查询表字段信息",slug:"查询表字段信息",normalizedTitle:"查询表字段信息",charIndex:13359},{level:4,title:"踩坑日记",slug:"踩坑日记",normalizedTitle:"踩坑日记",charIndex:13523},{level:5,title:"date 字段类型",slug:"date-字段类型",normalizedTitle:"date 字段类型",charIndex:13531}],headersStr:"简介 关于数据迁移 元数据使用 元数据表或视图 查询所有模式 查询当前模式下的所有表名以及中文注释 表名查询字段属性 查询视图定义语句 查询表字段信息 踩坑日记 date 字段类型",content:"# 简介\n\nGaussDB(for openGauss)是基于华为主导的openGauss生态推出的企业级分布式关系型数据库。该产品具备企业级复杂事务混合负载能力，同时支持分布式事务，同城跨AZ部署，数据0丢失，支持1000+的扩展能力，PB级海量存储。\n\n目前官方收费版本：（2019年10月左右，命名再次调整）\n\n * gaussdb 100，更名为 GaussDB T (以OLTP和集群为方向，在线事务处理）\n * gaussdb 200 合并 300 的部分设计，更名为 GaussDB A (主打OLAP 在线分析处理）\n * gaussdb 300 型号取消，涉及功能并入 100 或 200\n\n目前免费开源版本：openGauss\n\n# 关于数据迁移\n\nGaussDB 最初是由 PostgreSQL 开源项目自研而来，虽几乎已经是全部自研，但还保留了驱动包以及驱动类。\n\n官方提供了3个驱动包：（任意一个都行，但需注意冲突问题）\n\n 1. gsjdbc4.jar：驱动类为 org.postgresql.Driver\n\n> 与 PostgreSQL 驱动类名一样，在无 PostgreSQL 时使用\n\n 2. gsjdbc200.jar：驱动类为 com.huawei.gauss200.jdbc.Driver\n\n> 解决类名冲突问题，项目中同时有 PostgreSQL 和 GaussDB 时使用\n\n 3. openguassjdbc.jar：驱动类为 com.huawei.opengauss.jdbc.Driver\n\n任意一个驱动类都行，可以通过使用 gsjdbc4.jar 替换 Datax、Kettle 等工具中 PostgreSQL 驱动包，来使其支持 GaussDB，从而进行数据迁移。\n\n# 元数据使用\n\n# 元数据表或视图\n\n系统表\n\nGS_                             PG_                            PG_                     -\nGS_AUDITING_POLICY              PG_AGGREGATE                   PG_NAMESPACE            PGXC_CLASS\nGS_AUDITING_POLICY_ACCESS       PG_AM                          PG_OBJECT               PGXC_GROUP\nGS_AUDITING_POLICY_FILTERS      PG_AMOP                        PG_OPCLASS              PGXC_NODE\nGS_AUDITING_POLICY_PRIVILEGES   PG_AMPROC                      PG_OPERATOR             PGXC_REDISTB\nGS_ASP                          PG_APP_WORKLOADGROUP_MAPPING   PG_OPFAMILY             PGXC_SLICE\nGS_CLIENT_GLOBAL_KEYS           PG_ATTRDEF                     PG_PARTITION            PLAN_TABLE_DATA\nGS_CLIENT_GLOBAL_KEYS_ARGS      PG_ATTRIBUTE                   PG_PLTEMPLATE           STATEMENT_HISTORY\nGS_COLUMN_KEYS                  PG_AUTHID                      PG_PROC                 STREAMING_STREAM\nGS_COLUMN_KEYS_ARGS             PG_AUTH_HISTORY                PG_PUBLICATION          STREAMING_CONT_QUERY\nGS_DB_PRIVILEGE                 PG_AUTH_MEMBERS                PG_PUBLICATION_REL      STREAMING_REAPER_STATUS\nGS_ENCRYPTED_COLUMNS            PG_CAST                        PG_RANGE                \nGS_ENCRYPTED_PROC               PG_CLASS                       PG_REPLICATION_ORIGIN   \nGS_GLOBAL_CHAIN                 PG_COLLATION                   PG_RESOURCE_POOL        \nGS_GLOBAL_CONFIG                PG_CONSTRAINT                  PG_REWRITE              \nGS_JOB_ATTRIBUTE                PG_CONVERSION                  PG_RLSPOLICY            \nGS_JOB_ARGUMENT                 PG_DATABASE                    PG_SECLABEL             \nGS_MASKING_POLICY               PG_DB_ROLE_SETTING             PG_SHDEPEND             \nGS_MASKING_POLICY_ACTIONS       PG_DEFAULT_ACL                 PG_SHDESCRIPTION        \nGS_MASKING_POLICY_FILTERS       PG_DEPEND                      PG_SHSECLABEL           \nGS_MATVIEW                      PG_DESCRIPTION                 PG_STATISTIC            \nGS_MATVIEW_DEPENDENCY           PG_DIRECTORY                   PG_SUBSCRIPTION         \nGS_MODEL_WAREHOUSE              PG_ENUM                        PG_SYNONYM              \nGS_POLICY_LABEL                 PG_EXTENSION_DATA_SOURCE       PG_TABLESPACE           \nGS_RECYCLEBIN                   PG_FOREIGN_DATA_WRAPPER        PG_TRIGGER              \nGS_SQL_PATCH                    PG_FOREIGN_SERVER              PG_TS_CONFIG            \nGS_TXN_SNAPSHOT                 PG_FOREIGN_TABLE               PG_TS_CONFIG_MAP        \nGS_UID                          PG_HASHBUCKET                  PG_TS_DICT              \nGS_WLM_INSTANCE_HISTORY         PG_INDEX                       PG_TS_PARSER            \nGS_WLM_OPERATOR_INFO            PG_INHERITS                    PG_TS_TEMPLATE          \nGS_WLM_SESSION_QUERY_INFO_ALL   PG_JOB                         PG_TYPE                 \nGS_WLM_USER_RESOURCE_HISTORY    PG_JOB_PROC                    PG_USER_MAPPING         \n                                PG_LANGUAGE                    PG_USER_STATUS          \n                                PG_LARGEOBJECT                 PG_WORKLOAD_GROUP       \n                                PG_LARGEOBJECT_METADATA                                \n\n系统视图\n\nADM/GLOBAL/PV                 DB/MY                GS/PGXC                             PG_\nADM_COL_COMMENTS              DB_ALL_TABLES        GS_ALL_CONTROL_GROUP_INFO           PG_AVAILABLE_EXTENSIONS\nADM_CONS_COLUMNS              DB_CONSTRAINTS       GS_AUDITING                         PG_AVAILABLE_EXTENSION_VERSIONS\nADM_CONSTRAINTS               DB_CONS_COLUMNS      GS_AUDITING_ACCESS                  PG_COMM_DELAY\nADM_DATA_FILES                DB_DEPENDENCIES      GS_AUDITING_PRIVILEGE               PG_COMM_RECV_STREAM\nADM_HIST_SNAPSHOT             DB_IND_COLUMNS       GS_CLUSTER_RESOURCE_INFO            PG_COMM_SEND_STREAM\nADM_HIST_SQL_PLAN             DB_IND_EXPRESSIONS   GS_DB_PRIVILEGES                    PG_COMM_STATUS\nADM_HIST_SQLSTAT              DB_INDEXES           GS_GET_CONTROL_GROUP_INFO           PG_CONTROL_GROUP_CONFIG\nADM_HIST_SQLSTAT_FUNC         DB_OBJECTS           GS_GSC_MEMORY_DETAIL                PG_CURSORS\nADM_HIST_SQLSTAT_IDLAG_FUNC   DB_PROCEDURES        GS_LABELS                           PG_GET_INVALID_BACKENDS\nADM_INDEXES                   DB_SEQUENCES         GS_LSC_MEMORY_DETAIL                PG_GET_SENDERS_CATCHUP_TIME\nADM_IND_COLUMNS               DB_SOURCE            GS_MASKING                          PG_GROUP\nADM_IND_EXPRESSIONS           DB_SYNONYMS          GS_MATVIEWS                         PG_INDEXES\nADM_IND_PARTITIONS            DB_TAB_COLUMNS       GS_MATVIEWS                         PG_LOCKS\nADM_OBJECTS                   DB_TAB_COMMENTS      GS_SESSION_CPU_STATISTICS           PG_NODE_ENV\nADM_PART_INDEXES              DB_COL_COMMENTS      GS_SESSION_MEMORY_STATISTICS        PG_OS_THREADS\nADM_PART_TABLES               DB_TABLES            GS_SQL_COUNT                        PG_POOLER_STATUS\nADM_PROCEDURES                DB_TRIGGERS          GS_STAT_DB_CU                       PG_PREPARED_STATEMENTS\nADM_SEQUENCES                 DB_USERS             GS_STAT_SESSION_CU                  PG_PREPARED_XACTS\nADM_SCHEDULER_JOBS            DB_VIEWS             GS_WLM_CGROUP_INFO                  PG_PUBLICATION_TABLES\nADM_SOURCE                    MY_COL_COMMENTS      GS_WLM_OPERATOR_HISTORY             PG_REPLICATION_ORIGIN_STATUS\nADM_SYNONYMS                  MY_CONS_COLUMNS      GS_WLM_OPERATOR_STATISTICS          PG_REPLICATION_SLOTS\nADM_TABLES                    MY_CONSTRAINTS       GS_WLM_REBUILD_USER_RESOURCE_POOL   PG_RLSPOLICIES\nADM_TABLESPACES               MY_INDEXES           GS_WLM_RESOURCE_POOL                PG_ROLES\nADM_TAB_COLUMNS               MY_IND_COLUMNS       GS_WLM_SESSION_HISTORY              PG_RULES\nADM_TAB_COMMENTS              MY_IND_EXPRESSIONS   GS_WLM_SESSION_INFO                 PG_RUNNING_XACTS\nADM_TAB_PARTITIONS            MY_IND_PARTITIONS    GS_WLM_SESSION_INFO_ALL             PG_SECLABELS\nADM_TRIGGERS                  MY_JOBS              GS_WLM_USER_INFO                    PG_SESSION_IOSTAT\nADM_TYPE_ATTRS                MY_OBJECTS           GS_WLM_USER_SESSION_INFO            PG_SESSION_WLMSTAT\nADM_USERS                     MY_PART_INDEXES      GS_WLM_SESSION_STATISTICS           PG_SETTINGS\nADM_VIEWS                     MY_PART_TABLES       GS_WLM_WORKLOAD_RECORDS             PG_SHADOW\nCOMM_CLIENT_INFO              MY_PROCEDURES        GS_WRITE_TERM_LOG                   PG_SHARED_MEMORY_DETAIL\nDV_SESSIONS                   MY_SEQUENCES         PGXC_COMM_DELAY                     PG_STATS\nDV_SESSION_LONGOPS            MY_SOURCE            PGXC_COMM_RECV_STREAM               PG_STAT_ACTIVITY\nGET_GLOBAL_PREPARED_XACTS     MY_SYNONYMS          PGXC_COMM_SEND_STREAM               PG_STAT_ALL_INDEXES\nGV_SESSION                    MY_TAB_COLUMNS       PGXC_COMM_STATUS                    PG_STAT_ALL_TABLES\nMPP_TABLES                    MY_TAB_COMMENTS      PGXC_GET_STAT_ALL_TABLES            PG_STAT_BAD_BLOCK\nPLAN_TABLE                    MY_TAB_PARTITIONS    PGXC_GET_TABLE_SKEWNESS             PG_STAT_BGWRITER\nSYS_DUMMY                     MY_TABLES            PGXC_NODE_ENV                       PG_STAT_DATABASE\nGLOBAL_BAD_BLOCK_INFO         MY_TRIGGERS          PGXC_OS_THREADS                     PG_STAT_DATABASE_CONFLICTS\nGLOBAL_CLEAR_BAD_BLOCK_INFO   MY_VIEWS             PGXC_PREPARED_XACTS                 PG_STAT_REPLICATION\nGLOBAL_COMM_CLIENT_INFO                            PGXC_RUNNING_XACTS                  PG_STAT_SUBSCRIPTION\nGLOBAL_STAT_HOTKEYS_INFO                           PGXC_STAT_ACTIVITY                  PG_STAT_SYS_INDEXES\nGLOBAL_WAL_SENDER_STATUS                           PGXC_STAT_BAD_BLOCK                 PG_STAT_SYS_TABLES\nPV_FILE_STAT                                       PGXC_SQL_COUNT                      PG_STAT_USER_FUNCTIONS\nPV_INSTANCE_TIME                                   PGXC_THREAD_WAIT_STATUS             PG_STAT_USER_INDEXES\nPV_OS_RUN_INFO                                     PGXC_TOTAL_MEMORY_DETAIL            PG_STAT_USER_TABLES\nPV_REDO_STAT                                       PGXC_VARIABLE_INFO                  PG_STAT_XACT_ALL_TABLES\nPV_SESSION_MEMORY                                  PGXC_WLM_REBUILD_USER_RESPOOL       PG_STAT_XACT_SYS_TABLES\nPV_SESSION_MEMORY_CONTEXT                          PGXC_WLM_SESSION_HISTORY            PG_STAT_XACT_USER_FUNCTIONS\nPV_SESSION_MEMORY_DETAIL                           PGXC_WLM_SESSION_INFO               PG_STAT_XACT_USER_TABLES\nPV_SESSION_STAT                                    PGXC_WLM_SESSION_STATISTICS         PG_STATIO_ALL_INDEXES\nPV_SESSION_TIME                                    PGXC_WLM_WORKLOAD_RECORDS           PG_STATIO_ALL_SEQUENCES\nPV_THREAD_MEMORY_CONTEXT                                                               PG_STATIO_ALL_TABLES\nPV_TOTAL_MEMORY_DETAIL                                                                 PG_STATIO_SYS_INDEXES\n                                                                                       PG_STATIO_SYS_SEQUENCES\n                                                                                       PG_STATIO_SYS_TABLES\n                                                                                       PG_STATIO_USER_INDEXES\n                                                                                       PG_STATIO_USER_SEQUENCES\n                                                                                       PG_STATIO_USER_TABLES\n                                                                                       PG_THREAD_WAIT_STATUS\n                                                                                       PG_TABLES\n                                                                                       PG_TDE_INFO\n                                                                                       PG_TIMEZONE_ABBREVS\n                                                                                       PG_TIMEZONE_NAMES\n                                                                                       PG_TOTAL_MEMORY_DETAIL\n                                                                                       PG_TOTAL_USER_RESOURCE_INFO\n                                                                                       PG_TOTAL_USER_RESOURCE_INFO_OID\n                                                                                       PG_USER\n                                                                                       PG_USER_MAPPINGS\n                                                                                       PG_VARIABLE_INFO\n                                                                                       PG_VIEWS\n                                                                                       PG_WLM_STATISTICS\n\n# 查询所有模式\n\nSELECT\n            pn.oid AS schema_oid\n           ,iss.CATALOG_NAME\n           ,iss.schema_owner\n           ,iss.SCHEMA_NAME \n      FROM information_schema.schemata iss\nINNER JOIN pg_namespace pn \n        ON pn.nspname = iss.SCHEMA_NAME;\n\n\n# 查询当前模式下的所有表名以及中文注释\n\nSELECT DISTINCT \"table_name\", obj_description ( oid, 'pg_class' ) AS table_alias \n  FROM information_schema.tables t1, pg_class t2 \n WHERE table_schema = 'gisdb' \n   AND t1.\"table_name\" = t2.relname\n\n\n# 表名查询字段属性\n\n# 方式1：（支持查询指定模式schema下某张表的字段信息）\n    SELECT u.relname, a.attname AS field, t.typname AS type\n      FROM (select c.relname,c.oid,n.nspname from pg_class c left join pg_catalog.pg_namespace n on c.relnamespace = n.oid) u,\n           pg_attribute a,\n           pg_type t\n     WHERE u.relname = '实际的表名'\n       AND u.nspname = '实际的schema名称'\n       AND a.attnum > 0\n       AND a.attrelid = u.oid\n       AND a.atttypid = t.oid\n  ORDER BY a.attnum;\n  \n# 方式:2：\n    SELECT a.attnum, a.attname AS field, t.typname AS type, a.attlen AS length, a.atttypmod AS lengthvar, a.attnotnull AS notnull, b.description AS comment\n      FROM pg_class c, pg_attribute a\n LEFT JOIN pg_description b\n        ON a.attrelid = b.objoid\n       AND a.attnum = b.objsubid, pg_type t\n     WHERE c.relname = '实际的表名'\n       AND a.attnum > 0\n       AND a.attrelid = c.oid\n       AND a.atttypid = t.oid\n  ORDER BY a.attnum;\n\n\n# 查询视图定义语句\n\nselect 'create or repacle view ' || viewname || ' as ' || definition FROM pg_view WHERE schemaname = '模式' AND viewowner = '用户';\nselect 'create or repacle view ' || view_name || ' as ' || text from db_views  where owner = '用户';\n\n\n# 查询表字段信息\n\nSELECT table_name, column_name\n  FROM information_schema.columns\n WHERE table_schema = '模式'\n   AND table_name = '表名'\n ORDER BY table_name, column_name\n\n\n# 踩坑日记\n\n# date 字段类型\n\n高斯数据库兼容模式：\n\n可能不同兼容模式行为不一致，可查询系统表 PG_DATABASE（datcompatibility字段） 查看当前数据库兼容模式（当前支持四种兼容模式：A、B、C、PG，分别表示兼容O、MY、TD和POSTGRES，默认为MySQL兼容模式）\n20221122 补充：确实是因为创建模式时兼容模式导致，重新创建模式后问题解决\n\n> 由于 date 字段类型不存储时分秒（Oracle模式下？），故需修改为 timestamp 类型，所有表及视图都需要重新创建。",normalizedContent:"# 简介\n\ngaussdb(for opengauss)是基于华为主导的opengauss生态推出的企业级分布式关系型数据库。该产品具备企业级复杂事务混合负载能力，同时支持分布式事务，同城跨az部署，数据0丢失，支持1000+的扩展能力，pb级海量存储。\n\n目前官方收费版本：（2019年10月左右，命名再次调整）\n\n * gaussdb 100，更名为 gaussdb t (以oltp和集群为方向，在线事务处理）\n * gaussdb 200 合并 300 的部分设计，更名为 gaussdb a (主打olap 在线分析处理）\n * gaussdb 300 型号取消，涉及功能并入 100 或 200\n\n目前免费开源版本：opengauss\n\n# 关于数据迁移\n\ngaussdb 最初是由 postgresql 开源项目自研而来，虽几乎已经是全部自研，但还保留了驱动包以及驱动类。\n\n官方提供了3个驱动包：（任意一个都行，但需注意冲突问题）\n\n 1. gsjdbc4.jar：驱动类为 org.postgresql.driver\n\n> 与 postgresql 驱动类名一样，在无 postgresql 时使用\n\n 2. gsjdbc200.jar：驱动类为 com.huawei.gauss200.jdbc.driver\n\n> 解决类名冲突问题，项目中同时有 postgresql 和 gaussdb 时使用\n\n 3. openguassjdbc.jar：驱动类为 com.huawei.opengauss.jdbc.driver\n\n任意一个驱动类都行，可以通过使用 gsjdbc4.jar 替换 datax、kettle 等工具中 postgresql 驱动包，来使其支持 gaussdb，从而进行数据迁移。\n\n# 元数据使用\n\n# 元数据表或视图\n\n系统表\n\ngs_                             pg_                            pg_                     -\ngs_auditing_policy              pg_aggregate                   pg_namespace            pgxc_class\ngs_auditing_policy_access       pg_am                          pg_object               pgxc_group\ngs_auditing_policy_filters      pg_amop                        pg_opclass              pgxc_node\ngs_auditing_policy_privileges   pg_amproc                      pg_operator             pgxc_redistb\ngs_asp                          pg_app_workloadgroup_mapping   pg_opfamily             pgxc_slice\ngs_client_global_keys           pg_attrdef                     pg_partition            plan_table_data\ngs_client_global_keys_args      pg_attribute                   pg_pltemplate           statement_history\ngs_column_keys                  pg_authid                      pg_proc                 streaming_stream\ngs_column_keys_args             pg_auth_history                pg_publication          streaming_cont_query\ngs_db_privilege                 pg_auth_members                pg_publication_rel      streaming_reaper_status\ngs_encrypted_columns            pg_cast                        pg_range                \ngs_encrypted_proc               pg_class                       pg_replication_origin   \ngs_global_chain                 pg_collation                   pg_resource_pool        \ngs_global_config                pg_constraint                  pg_rewrite              \ngs_job_attribute                pg_conversion                  pg_rlspolicy            \ngs_job_argument                 pg_database                    pg_seclabel             \ngs_masking_policy               pg_db_role_setting             pg_shdepend             \ngs_masking_policy_actions       pg_default_acl                 pg_shdescription        \ngs_masking_policy_filters       pg_depend                      pg_shseclabel           \ngs_matview                      pg_description                 pg_statistic            \ngs_matview_dependency           pg_directory                   pg_subscription         \ngs_model_warehouse              pg_enum                        pg_synonym              \ngs_policy_label                 pg_extension_data_source       pg_tablespace           \ngs_recyclebin                   pg_foreign_data_wrapper        pg_trigger              \ngs_sql_patch                    pg_foreign_server              pg_ts_config            \ngs_txn_snapshot                 pg_foreign_table               pg_ts_config_map        \ngs_uid                          pg_hashbucket                  pg_ts_dict              \ngs_wlm_instance_history         pg_index                       pg_ts_parser            \ngs_wlm_operator_info            pg_inherits                    pg_ts_template          \ngs_wlm_session_query_info_all   pg_job                         pg_type                 \ngs_wlm_user_resource_history    pg_job_proc                    pg_user_mapping         \n                                pg_language                    pg_user_status          \n                                pg_largeobject                 pg_workload_group       \n                                pg_largeobject_metadata                                \n\n系统视图\n\nadm/global/pv                 db/my                gs/pgxc                             pg_\nadm_col_comments              db_all_tables        gs_all_control_group_info           pg_available_extensions\nadm_cons_columns              db_constraints       gs_auditing                         pg_available_extension_versions\nadm_constraints               db_cons_columns      gs_auditing_access                  pg_comm_delay\nadm_data_files                db_dependencies      gs_auditing_privilege               pg_comm_recv_stream\nadm_hist_snapshot             db_ind_columns       gs_cluster_resource_info            pg_comm_send_stream\nadm_hist_sql_plan             db_ind_expressions   gs_db_privileges                    pg_comm_status\nadm_hist_sqlstat              db_indexes           gs_get_control_group_info           pg_control_group_config\nadm_hist_sqlstat_func         db_objects           gs_gsc_memory_detail                pg_cursors\nadm_hist_sqlstat_idlag_func   db_procedures        gs_labels                           pg_get_invalid_backends\nadm_indexes                   db_sequences         gs_lsc_memory_detail                pg_get_senders_catchup_time\nadm_ind_columns               db_source            gs_masking                          pg_group\nadm_ind_expressions           db_synonyms          gs_matviews                         pg_indexes\nadm_ind_partitions            db_tab_columns       gs_matviews                         pg_locks\nadm_objects                   db_tab_comments      gs_session_cpu_statistics           pg_node_env\nadm_part_indexes              db_col_comments      gs_session_memory_statistics        pg_os_threads\nadm_part_tables               db_tables            gs_sql_count                        pg_pooler_status\nadm_procedures                db_triggers          gs_stat_db_cu                       pg_prepared_statements\nadm_sequences                 db_users             gs_stat_session_cu                  pg_prepared_xacts\nadm_scheduler_jobs            db_views             gs_wlm_cgroup_info                  pg_publication_tables\nadm_source                    my_col_comments      gs_wlm_operator_history             pg_replication_origin_status\nadm_synonyms                  my_cons_columns      gs_wlm_operator_statistics          pg_replication_slots\nadm_tables                    my_constraints       gs_wlm_rebuild_user_resource_pool   pg_rlspolicies\nadm_tablespaces               my_indexes           gs_wlm_resource_pool                pg_roles\nadm_tab_columns               my_ind_columns       gs_wlm_session_history              pg_rules\nadm_tab_comments              my_ind_expressions   gs_wlm_session_info                 pg_running_xacts\nadm_tab_partitions            my_ind_partitions    gs_wlm_session_info_all             pg_seclabels\nadm_triggers                  my_jobs              gs_wlm_user_info                    pg_session_iostat\nadm_type_attrs                my_objects           gs_wlm_user_session_info            pg_session_wlmstat\nadm_users                     my_part_indexes      gs_wlm_session_statistics           pg_settings\nadm_views                     my_part_tables       gs_wlm_workload_records             pg_shadow\ncomm_client_info              my_procedures        gs_write_term_log                   pg_shared_memory_detail\ndv_sessions                   my_sequences         pgxc_comm_delay                     pg_stats\ndv_session_longops            my_source            pgxc_comm_recv_stream               pg_stat_activity\nget_global_prepared_xacts     my_synonyms          pgxc_comm_send_stream               pg_stat_all_indexes\ngv_session                    my_tab_columns       pgxc_comm_status                    pg_stat_all_tables\nmpp_tables                    my_tab_comments      pgxc_get_stat_all_tables            pg_stat_bad_block\nplan_table                    my_tab_partitions    pgxc_get_table_skewness             pg_stat_bgwriter\nsys_dummy                     my_tables            pgxc_node_env                       pg_stat_database\nglobal_bad_block_info         my_triggers          pgxc_os_threads                     pg_stat_database_conflicts\nglobal_clear_bad_block_info   my_views             pgxc_prepared_xacts                 pg_stat_replication\nglobal_comm_client_info                            pgxc_running_xacts                  pg_stat_subscription\nglobal_stat_hotkeys_info                           pgxc_stat_activity                  pg_stat_sys_indexes\nglobal_wal_sender_status                           pgxc_stat_bad_block                 pg_stat_sys_tables\npv_file_stat                                       pgxc_sql_count                      pg_stat_user_functions\npv_instance_time                                   pgxc_thread_wait_status             pg_stat_user_indexes\npv_os_run_info                                     pgxc_total_memory_detail            pg_stat_user_tables\npv_redo_stat                                       pgxc_variable_info                  pg_stat_xact_all_tables\npv_session_memory                                  pgxc_wlm_rebuild_user_respool       pg_stat_xact_sys_tables\npv_session_memory_context                          pgxc_wlm_session_history            pg_stat_xact_user_functions\npv_session_memory_detail                           pgxc_wlm_session_info               pg_stat_xact_user_tables\npv_session_stat                                    pgxc_wlm_session_statistics         pg_statio_all_indexes\npv_session_time                                    pgxc_wlm_workload_records           pg_statio_all_sequences\npv_thread_memory_context                                                               pg_statio_all_tables\npv_total_memory_detail                                                                 pg_statio_sys_indexes\n                                                                                       pg_statio_sys_sequences\n                                                                                       pg_statio_sys_tables\n                                                                                       pg_statio_user_indexes\n                                                                                       pg_statio_user_sequences\n                                                                                       pg_statio_user_tables\n                                                                                       pg_thread_wait_status\n                                                                                       pg_tables\n                                                                                       pg_tde_info\n                                                                                       pg_timezone_abbrevs\n                                                                                       pg_timezone_names\n                                                                                       pg_total_memory_detail\n                                                                                       pg_total_user_resource_info\n                                                                                       pg_total_user_resource_info_oid\n                                                                                       pg_user\n                                                                                       pg_user_mappings\n                                                                                       pg_variable_info\n                                                                                       pg_views\n                                                                                       pg_wlm_statistics\n\n# 查询所有模式\n\nselect\n            pn.oid as schema_oid\n           ,iss.catalog_name\n           ,iss.schema_owner\n           ,iss.schema_name \n      from information_schema.schemata iss\ninner join pg_namespace pn \n        on pn.nspname = iss.schema_name;\n\n\n# 查询当前模式下的所有表名以及中文注释\n\nselect distinct \"table_name\", obj_description ( oid, 'pg_class' ) as table_alias \n  from information_schema.tables t1, pg_class t2 \n where table_schema = 'gisdb' \n   and t1.\"table_name\" = t2.relname\n\n\n# 表名查询字段属性\n\n# 方式1：（支持查询指定模式schema下某张表的字段信息）\n    select u.relname, a.attname as field, t.typname as type\n      from (select c.relname,c.oid,n.nspname from pg_class c left join pg_catalog.pg_namespace n on c.relnamespace = n.oid) u,\n           pg_attribute a,\n           pg_type t\n     where u.relname = '实际的表名'\n       and u.nspname = '实际的schema名称'\n       and a.attnum > 0\n       and a.attrelid = u.oid\n       and a.atttypid = t.oid\n  order by a.attnum;\n  \n# 方式:2：\n    select a.attnum, a.attname as field, t.typname as type, a.attlen as length, a.atttypmod as lengthvar, a.attnotnull as notnull, b.description as comment\n      from pg_class c, pg_attribute a\n left join pg_description b\n        on a.attrelid = b.objoid\n       and a.attnum = b.objsubid, pg_type t\n     where c.relname = '实际的表名'\n       and a.attnum > 0\n       and a.attrelid = c.oid\n       and a.atttypid = t.oid\n  order by a.attnum;\n\n\n# 查询视图定义语句\n\nselect 'create or repacle view ' || viewname || ' as ' || definition from pg_view where schemaname = '模式' and viewowner = '用户';\nselect 'create or repacle view ' || view_name || ' as ' || text from db_views  where owner = '用户';\n\n\n# 查询表字段信息\n\nselect table_name, column_name\n  from information_schema.columns\n where table_schema = '模式'\n   and table_name = '表名'\n order by table_name, column_name\n\n\n# 踩坑日记\n\n# date 字段类型\n\n高斯数据库兼容模式：\n\n可能不同兼容模式行为不一致，可查询系统表 pg_database（datcompatibility字段） 查看当前数据库兼容模式（当前支持四种兼容模式：a、b、c、pg，分别表示兼容o、my、td和postgres，默认为mysql兼容模式）\n20221122 补充：确实是因为创建模式时兼容模式导致，重新创建模式后问题解决\n\n> 由于 date 字段类型不存储时分秒（oracle模式下？），故需修改为 timestamp 类型，所有表及视图都需要重新创建。",charsets:{cjk:!0},lastUpdated:"2022/11/22, 17:20:22",lastUpdatedTimestamp:1669108822e3},{title:"Redis命令学习",frontmatter:{title:"Redis命令学习",date:"2022-03-10T20:22:35.000Z",permalink:"/pages/ca5c12/",categories:["数据库","Redis"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/09.Redis/01.Redis%E5%91%BD%E4%BB%A4%E5%AD%A6%E4%B9%A0.html",relativePath:"03.数据库/09.Redis/01.Redis命令学习.md",key:"v-5a91a923",path:"/pages/ca5c12/",headers:[{level:2,title:"进入客户端",slug:"进入客户端",normalizedTitle:"进入客户端",charIndex:2},{level:2,title:"1.数据类型",slug:"_1-数据类型",normalizedTitle:"1.数据类型",charIndex:104},{level:3,title:"（1）String(字符串)",slug:"_1-string-字符串",normalizedTitle:"（1）string(字符串)",charIndex:115},{level:3,title:"（2）Hash(哈希)",slug:"_2-hash-哈希",normalizedTitle:"（2）hash(哈希)",charIndex:412},{level:3,title:"（3）List(列表)",slug:"_3-list-列表",normalizedTitle:"（3）list(列表)",charIndex:836},{level:3,title:"（4）Set(集合)",slug:"_4-set-集合",normalizedTitle:"（4）set(集合)",charIndex:1263},{level:3,title:"（5）Zset(sorted set：有序集合)",slug:"_5-zset-sorted-set-有序集合",normalizedTitle:"（5）zset(sorted set：有序集合)",charIndex:1832},{level:3,title:"（6） 代码练习",slug:"_6-代码练习",normalizedTitle:"（6） 代码练习",charIndex:2505}],headersStr:"进入客户端 1.数据类型 （1）String(字符串) （2）Hash(哈希) （3）List(列表) （4）Set(集合) （5）Zset(sorted set：有序集合) （6） 代码练习",content:'# 进入客户端\n\n启动： redis-server redis.conf\n\n客户端： redis-cli\n\n查看端口占用： netstat -tunpl|grep 6379\n\n退出客户端： exit\n\n\n# 1.数据类型\n\n\n# （1）String(字符串)\n\nset xxx aaa     //设置xxx\nget xxx     //获取xxx\ndel xxx     //删除xxx\nmset name1 111 name2 222 name3 333 name4 444    //设置多个\nmget name1 name2 name3    //查看多个\nexists xxx     //查看是否存在\ntype aaa      //查看value的数据类型\nrandomkey     //从当前库中随机返回一个key\nFLUSHdb     //清空数据 \nFLUSHALL     //清空所有\n\n\n\n# （2）Hash(哈希)\n\n赋值：\nHSET KEY  FIELD  VALUE    //为指定的KEY，设定FIELD/VALUE  \nHMSET  KEY  FIELD VALUE [FIELD1,VALUE1]…… 同时将多个 field-value (域-值)对设置到哈希表 key 中。\n\n取值：\nHGET KEY FIELD   //获取存储在HASH中的值，根据FIELD得到VALUE\nHMGET key field[field1]      //获取key所有给定字段的值\nHGETALL key                 //返回HASH表中所有的字段和值\nHKEYS key   //获取所有哈希表中的字段\nHVALS key   //获取所有哈希表中的值\nHLEN key   //获取哈希表中字段的数量\n\n删除语法：\nHDEL KEY field1[field2]    //删除一个或多个HASH表字段\n\n\n\n# （3）List(列表)\n\nLPUSH key value1 [value2]     // 将一个或多个值插入到列表头部\nRPUSH key value1 [value2]    // 在列表中添加一个或多个值\nBLPOP key1 [key2 ] timeout    // 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\nBRPOP key1 [key2 ] timeout    // 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\nLINSERT key BEFORE|AFTER pivot value    // 在列表的元素前或者后插入元素\nLINDEX key index    // 通过索引获取列表中的元素\nLLEN key     // 获取列表长度\nLRANGE key start stop    //获取列表指定范围内的元素\n\n\n\n# （4）Set(集合)\n\nSADD key member1 [member2]    // 向集合添加一个或多个成员\nSMEMBERS key    // 返回集合中的所有成员\nSISMEMBER key member    // 1表示存在，0表示不存在或该key本身就不存在（无论集合中有多少元素都可以极速地返回结果）\nSREM key member1 [member2]    // 移除集合中一个或多个成员\nSINTER key1 [key2]      //返回给定所有集合的交集\nSDIFF key1 [key2]     // 返回给定所有集合的差集（属于key1不属于key2的集合）\nSUNION key1 [key2]     // 返回所有给定集合的并集\nSCARD key    //获取集合中成员的数量\nsdiffstore destination key1 [key2]    // 将key1、key2相差的成员存储在destination中\nsinterstore destination key1 [key2]     //将返回的交集存储在destination中\nsunionstore destination key1 [key2]     //将返回的并集存储在destination中\n\n\n\n# （5）Zset(sorted set：有序集合)\n\nZADD key score1 member1 [score2 member2]    // 向有序集合添加一个或多个成员，或者更新已存在成员的分数\nZRANGE key start stop [WITHSCORES]     // 通过索引区间返回有序集合指定区间内的成员\nZCOUNT key min max    // 计算在有序集合中指定区间分数的成员数\nZREM key member [member ...]    // 移除有序集合中的一个或多个成员\nZCARD key    // 获取有序集合的成员数\nZINCRBY key increment member    // 有序集合中对指定成员的分数加上增量 increment \nZSCORE key member    // 返回有序集中，成员的分数值\nZRANK key member    // 返回有序集合中指定成员的索引\nZRANGEBYSCORE key min max [WITHSCORES] [LIMIT]    // 通过分数返回有序集合指定区间内的成员\nZINTERSTORE destination numkeys key [key ...]    //计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中\nZUNIONSTORE destination numkeys key [key ...]    //计算给定的一个或多个有序集的并集，并存储在新的 key 中\n\n\n\n\n# （6） 代码练习\n\npublic class App \n{\n    public static void main( String[] args )\n    {\n    \tJedis jedis = new Jedis("8.8.8.8",6379);\n    \t//jedis.flushAll();\n        //System.out.println( "Hello World!" + jedis.ping());\n        /*****1.字符串(String)*****/\n//    \tjedis.set("name1", "aaa");\n//        System.out.println(jedis.get("name1"));\n//    \tjedis.del("name1");\n//    \t\n//    \tjedis.mset("name1","aaa","name2","bbb","name3","ccc");\n//    \tSystem.out.println(jedis.mget("name1","name2","name3"));\n//    \t\n//    \tSystem.out.println(jedis.exists("name1"));\n//    \tSystem.out.println(jedis.exists("name","name0","name1","name2","name3"));\n//    \tSystem.out.println(jedis.keys("*"));\n//    \tSystem.out.println(jedis.type("name1"));\n//    \tSystem.out.println(jedis.randomKey());\n//    \tSystem.out.println(jedis.flushDB());\n//    \tSystem.out.println(jedis.get("name1"));\n//    \tSystem.out.println(jedis.flushAll());\n//    \tSystem.out.println(jedis.randomKey());\n    \t\n    \t/****2.哈希(Hash)******/\n    \t/*\n    \tHashMap<String,String> hmap = new HashMap<String,String>();\n    \thmap.put("name5", "eee");\n    \thmap.put("name4", "ddd");\n    \thmap.put("id", "666");\n    \t// 设置值\n    \tjedis.hset("user", "name6", "fff");\n    \tjedis.hmset("user", hmap);\n    \t// 取值\n    \tSystem.out.println("hget:\\t" + jedis.hget("user", "name4"));\n    \tSystem.out.println("hmget:\\t" + jedis.hmget("user", "name4","name5","name6"));\n    \tSystem.out.println("hgetAll:\\t" + jedis.hgetAll("user"));\n    \tSystem.out.println("keys:\\t" + jedis.keys("*"));\n    \tSystem.out.println("hkeys:\\t" + jedis.hkeys("user"));\n    \tSystem.out.println("hvals:\\t" + jedis.hvals("user"));\n    \tSystem.out.println("hlen:\\t" + jedis.hlen("user"));\n    \t// 删除field\n    \tSystem.out.println("hdel\\t" + jedis.hdel("user","name4"));\n    \tSystem.out.println("hdel\\t" + jedis.hdel("user","name5","name6"));\n    \tSystem.out.println(jedis.hgetAll("user"));\n    \t// 清空\n    \tSystem.out.println(jedis.flushAll());\n    \tSystem.out.println(jedis.hgetAll("user"));\n    \t*/\n\n    \t\n    \t/*******3.列表List(类似于栈???)*********/\n    \t/*\n    \t// 放值\n    \tjedis.lpushx("list", "999");\n    \tjedis.lpush("list", "hhh","ggg","iii");\t\t//1或多到  开始\n    \tjedis.rpush("list", "kkk","jjj");\t\t\t//1或多到  末尾\n    \tjedis.lpushx("list", "666");\t\t\t\t// 插入已存在列表头部\n    \t// 取值\n    \tSystem.out.println(jedis.lrange("list", 0, 10));\t//获取指定范围元素\n    \tSystem.out.println(jedis.blpop("list","5"));\t\t//移出 第一个元素 等待超时\n    \tSystem.out.println(jedis.brpop("list", "5"));\t\t//移出 最后一个元素 等待超时\n    \tSystem.out.println(jedis.lindex("list", 3));\t\t//索引获取元素\n    \tSystem.out.println(jedis.llen("list"));\t\t\t\t//获取列表长度\n    \tSystem.out.println(jedis.lrange("list", 0, 10));\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t*/\n    \t\n    \t\n    \t/********4.集合(Set)****************/\n    \t/*\n    \t// 放值\n    \tjedis.sadd("set", "lll", "nnn", "mmm" ,"ooo");\n    \t// 取值\n    \tSystem.out.println(jedis.smembers("set"));\t\t// 所有元素\n    \tSystem.out.println(jedis.sismember("set", "ooo"));\t\t\t// key(value)是否存在\n    \tSystem.out.println(jedis.sismember("sett", "ooo"));\n    \tSystem.out.println(jedis.srem("set","ooo","mmm"));\t\t// 移除\n    \tSystem.out.println(jedis.smembers("set"));\n    \t// 运算\n    \tjedis.sadd("set", "set");\n    \tjedis.sadd("sett", "lll", "nnn", "mmm", "ooo", "sett");\n    \tSystem.out.println(jedis.sinter("set", "sett"));\t\t// 交集\n    \tSystem.out.println(jedis.sdiff("set", "sett"));\t\t\t// 差集\n    \tSystem.out.println(jedis.sunion("set", "sett"));\t\t// 并集\n    \t\n    \tSystem.out.println(jedis.scard("set"));\t\t// 元素数目\n    \tSystem.out.println(jedis.scard("sett"));\t\t// 元素数目\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t*/\n    \t\n    \t/********5.有序集合sorted set(zset)*************/\n    \tHashMap<String,Double> scoremap = new HashMap<String, Double>(); \n    \tscoremap.put("vvv", 0.22);\n    \tscoremap.put("ppp", 0.16);\n    \tscoremap.put("sss", 0.19);\n    \tscoremap.put("qqq", 0.17);\n    \tscoremap.put("www", 0.23);\n    \tscoremap.put("rrr", 0.18);\n    \tscoremap.put("uuu", 0.21);\n    \tscoremap.put("ttt", 0.20);\n    \t// 放值\n    \tjedis.zadd("zset", scoremap);\t\t// 添加元素或更新分数\n    \tjedis.zadd("zset", 0.24, "xxx");\n    \t// 元素查找修改\n    \tSystem.out.println(jedis.zrange("zset", 0, 10));\t\t// 根据索引返回区间\n    \tSystem.out.println(jedis.zcount("zset", 0.18, 0.21));\t\t// 根据分数返回元素数\n    \tSystem.out.println(jedis.zrem("zset", "sss", "ppp"));\t\t// 移除元素\n    \tSystem.out.println(jedis.zcard("zset"));\t\t\t\t\t// 元素数目\n    \tSystem.out.println(jedis.zincrby("zset", 1, "www"));\t\t// 分数增量\n    \tSystem.out.println(jedis.zscore("zset", "www"));\t\t// 返回分数值\n    \tSystem.out.println(jedis.zrank("zset", "www"));\t\t// 返回元素索引\n    \tSystem.out.println(jedis.zrangeByScore("zset", 0, 2));\t\t// 根据分数返回元素区间\n    \t//清空\n    \tSystem.out.println(jedis.flushAll());\n    \t\n    \t\n        jedis.close();\n    }\n}\n',normalizedContent:'# 进入客户端\n\n启动： redis-server redis.conf\n\n客户端： redis-cli\n\n查看端口占用： netstat -tunpl|grep 6379\n\n退出客户端： exit\n\n\n# 1.数据类型\n\n\n# （1）string(字符串)\n\nset xxx aaa     //设置xxx\nget xxx     //获取xxx\ndel xxx     //删除xxx\nmset name1 111 name2 222 name3 333 name4 444    //设置多个\nmget name1 name2 name3    //查看多个\nexists xxx     //查看是否存在\ntype aaa      //查看value的数据类型\nrandomkey     //从当前库中随机返回一个key\nflushdb     //清空数据 \nflushall     //清空所有\n\n\n\n# （2）hash(哈希)\n\n赋值：\nhset key  field  value    //为指定的key，设定field/value  \nhmset  key  field value [field1,value1]…… 同时将多个 field-value (域-值)对设置到哈希表 key 中。\n\n取值：\nhget key field   //获取存储在hash中的值，根据field得到value\nhmget key field[field1]      //获取key所有给定字段的值\nhgetall key                 //返回hash表中所有的字段和值\nhkeys key   //获取所有哈希表中的字段\nhvals key   //获取所有哈希表中的值\nhlen key   //获取哈希表中字段的数量\n\n删除语法：\nhdel key field1[field2]    //删除一个或多个hash表字段\n\n\n\n# （3）list(列表)\n\nlpush key value1 [value2]     // 将一个或多个值插入到列表头部\nrpush key value1 [value2]    // 在列表中添加一个或多个值\nblpop key1 [key2 ] timeout    // 移出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\nbrpop key1 [key2 ] timeout    // 移出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\nlinsert key before|after pivot value    // 在列表的元素前或者后插入元素\nlindex key index    // 通过索引获取列表中的元素\nllen key     // 获取列表长度\nlrange key start stop    //获取列表指定范围内的元素\n\n\n\n# （4）set(集合)\n\nsadd key member1 [member2]    // 向集合添加一个或多个成员\nsmembers key    // 返回集合中的所有成员\nsismember key member    // 1表示存在，0表示不存在或该key本身就不存在（无论集合中有多少元素都可以极速地返回结果）\nsrem key member1 [member2]    // 移除集合中一个或多个成员\nsinter key1 [key2]      //返回给定所有集合的交集\nsdiff key1 [key2]     // 返回给定所有集合的差集（属于key1不属于key2的集合）\nsunion key1 [key2]     // 返回所有给定集合的并集\nscard key    //获取集合中成员的数量\nsdiffstore destination key1 [key2]    // 将key1、key2相差的成员存储在destination中\nsinterstore destination key1 [key2]     //将返回的交集存储在destination中\nsunionstore destination key1 [key2]     //将返回的并集存储在destination中\n\n\n\n# （5）zset(sorted set：有序集合)\n\nzadd key score1 member1 [score2 member2]    // 向有序集合添加一个或多个成员，或者更新已存在成员的分数\nzrange key start stop [withscores]     // 通过索引区间返回有序集合指定区间内的成员\nzcount key min max    // 计算在有序集合中指定区间分数的成员数\nzrem key member [member ...]    // 移除有序集合中的一个或多个成员\nzcard key    // 获取有序集合的成员数\nzincrby key increment member    // 有序集合中对指定成员的分数加上增量 increment \nzscore key member    // 返回有序集中，成员的分数值\nzrank key member    // 返回有序集合中指定成员的索引\nzrangebyscore key min max [withscores] [limit]    // 通过分数返回有序集合指定区间内的成员\nzinterstore destination numkeys key [key ...]    //计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中\nzunionstore destination numkeys key [key ...]    //计算给定的一个或多个有序集的并集，并存储在新的 key 中\n\n\n\n\n# （6） 代码练习\n\npublic class app \n{\n    public static void main( string[] args )\n    {\n    \tjedis jedis = new jedis("8.8.8.8",6379);\n    \t//jedis.flushall();\n        //system.out.println( "hello world!" + jedis.ping());\n        /*****1.字符串(string)*****/\n//    \tjedis.set("name1", "aaa");\n//        system.out.println(jedis.get("name1"));\n//    \tjedis.del("name1");\n//    \t\n//    \tjedis.mset("name1","aaa","name2","bbb","name3","ccc");\n//    \tsystem.out.println(jedis.mget("name1","name2","name3"));\n//    \t\n//    \tsystem.out.println(jedis.exists("name1"));\n//    \tsystem.out.println(jedis.exists("name","name0","name1","name2","name3"));\n//    \tsystem.out.println(jedis.keys("*"));\n//    \tsystem.out.println(jedis.type("name1"));\n//    \tsystem.out.println(jedis.randomkey());\n//    \tsystem.out.println(jedis.flushdb());\n//    \tsystem.out.println(jedis.get("name1"));\n//    \tsystem.out.println(jedis.flushall());\n//    \tsystem.out.println(jedis.randomkey());\n    \t\n    \t/****2.哈希(hash)******/\n    \t/*\n    \thashmap<string,string> hmap = new hashmap<string,string>();\n    \thmap.put("name5", "eee");\n    \thmap.put("name4", "ddd");\n    \thmap.put("id", "666");\n    \t// 设置值\n    \tjedis.hset("user", "name6", "fff");\n    \tjedis.hmset("user", hmap);\n    \t// 取值\n    \tsystem.out.println("hget:\\t" + jedis.hget("user", "name4"));\n    \tsystem.out.println("hmget:\\t" + jedis.hmget("user", "name4","name5","name6"));\n    \tsystem.out.println("hgetall:\\t" + jedis.hgetall("user"));\n    \tsystem.out.println("keys:\\t" + jedis.keys("*"));\n    \tsystem.out.println("hkeys:\\t" + jedis.hkeys("user"));\n    \tsystem.out.println("hvals:\\t" + jedis.hvals("user"));\n    \tsystem.out.println("hlen:\\t" + jedis.hlen("user"));\n    \t// 删除field\n    \tsystem.out.println("hdel\\t" + jedis.hdel("user","name4"));\n    \tsystem.out.println("hdel\\t" + jedis.hdel("user","name5","name6"));\n    \tsystem.out.println(jedis.hgetall("user"));\n    \t// 清空\n    \tsystem.out.println(jedis.flushall());\n    \tsystem.out.println(jedis.hgetall("user"));\n    \t*/\n\n    \t\n    \t/*******3.列表list(类似于栈???)*********/\n    \t/*\n    \t// 放值\n    \tjedis.lpushx("list", "999");\n    \tjedis.lpush("list", "hhh","ggg","iii");\t\t//1或多到  开始\n    \tjedis.rpush("list", "kkk","jjj");\t\t\t//1或多到  末尾\n    \tjedis.lpushx("list", "666");\t\t\t\t// 插入已存在列表头部\n    \t// 取值\n    \tsystem.out.println(jedis.lrange("list", 0, 10));\t//获取指定范围元素\n    \tsystem.out.println(jedis.blpop("list","5"));\t\t//移出 第一个元素 等待超时\n    \tsystem.out.println(jedis.brpop("list", "5"));\t\t//移出 最后一个元素 等待超时\n    \tsystem.out.println(jedis.lindex("list", 3));\t\t//索引获取元素\n    \tsystem.out.println(jedis.llen("list"));\t\t\t\t//获取列表长度\n    \tsystem.out.println(jedis.lrange("list", 0, 10));\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t*/\n    \t\n    \t\n    \t/********4.集合(set)****************/\n    \t/*\n    \t// 放值\n    \tjedis.sadd("set", "lll", "nnn", "mmm" ,"ooo");\n    \t// 取值\n    \tsystem.out.println(jedis.smembers("set"));\t\t// 所有元素\n    \tsystem.out.println(jedis.sismember("set", "ooo"));\t\t\t// key(value)是否存在\n    \tsystem.out.println(jedis.sismember("sett", "ooo"));\n    \tsystem.out.println(jedis.srem("set","ooo","mmm"));\t\t// 移除\n    \tsystem.out.println(jedis.smembers("set"));\n    \t// 运算\n    \tjedis.sadd("set", "set");\n    \tjedis.sadd("sett", "lll", "nnn", "mmm", "ooo", "sett");\n    \tsystem.out.println(jedis.sinter("set", "sett"));\t\t// 交集\n    \tsystem.out.println(jedis.sdiff("set", "sett"));\t\t\t// 差集\n    \tsystem.out.println(jedis.sunion("set", "sett"));\t\t// 并集\n    \t\n    \tsystem.out.println(jedis.scard("set"));\t\t// 元素数目\n    \tsystem.out.println(jedis.scard("sett"));\t\t// 元素数目\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t*/\n    \t\n    \t/********5.有序集合sorted set(zset)*************/\n    \thashmap<string,double> scoremap = new hashmap<string, double>(); \n    \tscoremap.put("vvv", 0.22);\n    \tscoremap.put("ppp", 0.16);\n    \tscoremap.put("sss", 0.19);\n    \tscoremap.put("qqq", 0.17);\n    \tscoremap.put("www", 0.23);\n    \tscoremap.put("rrr", 0.18);\n    \tscoremap.put("uuu", 0.21);\n    \tscoremap.put("ttt", 0.20);\n    \t// 放值\n    \tjedis.zadd("zset", scoremap);\t\t// 添加元素或更新分数\n    \tjedis.zadd("zset", 0.24, "xxx");\n    \t// 元素查找修改\n    \tsystem.out.println(jedis.zrange("zset", 0, 10));\t\t// 根据索引返回区间\n    \tsystem.out.println(jedis.zcount("zset", 0.18, 0.21));\t\t// 根据分数返回元素数\n    \tsystem.out.println(jedis.zrem("zset", "sss", "ppp"));\t\t// 移除元素\n    \tsystem.out.println(jedis.zcard("zset"));\t\t\t\t\t// 元素数目\n    \tsystem.out.println(jedis.zincrby("zset", 1, "www"));\t\t// 分数增量\n    \tsystem.out.println(jedis.zscore("zset", "www"));\t\t// 返回分数值\n    \tsystem.out.println(jedis.zrank("zset", "www"));\t\t// 返回元素索引\n    \tsystem.out.println(jedis.zrangebyscore("zset", 0, 2));\t\t// 根据分数返回元素区间\n    \t//清空\n    \tsystem.out.println(jedis.flushall());\n    \t\n    \t\n        jedis.close();\n    }\n}\n',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Excel技巧",frontmatter:{title:"Excel技巧",date:"2022-09-22T14:41:03.000Z",permalink:"/pages/265b1a/"},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/10.Excel/01.Excel%E6%8A%80%E5%B7%A7.html",relativePath:"03.数据库/10.Excel/01.Excel技巧.md",key:"v-50566ea5",path:"/pages/265b1a/",headers:[{level:2,title:"Excel 使用",slug:"excel-使用",normalizedTitle:"excel 使用",charIndex:2},{level:3,title:"相同值的单元格合并",slug:"相同值的单元格合并",normalizedTitle:"相同值的单元格合并",charIndex:15},{level:3,title:"打印列多的表",slug:"打印列多的表",normalizedTitle:"打印列多的表",charIndex:250},{level:3,title:"Vlookup 绝对引用",slug:"vlookup-绝对引用",normalizedTitle:"vlookup 绝对引用",charIndex:377},{level:2,title:"Word 使用",slug:"word-使用",normalizedTitle:"word 使用",charIndex:638},{level:3,title:"一个文档的样式应用于另一个文档",slug:"一个文档的样式应用于另一个文档",normalizedTitle:"一个文档的样式应用于另一个文档",charIndex:650}],headersStr:"Excel 使用 相同值的单元格合并 打印列多的表 Vlookup 绝对引用 Word 使用 一个文档的样式应用于另一个文档",content:'# Excel 使用\n\n\n# 相同值的单元格合并\n\n使用功能：分类汇总、条件定位\n\n 1. 选中需要合并的列：点击【数据】 -> 【分类汇总】 -> 【确定】\n 2. 选中上一步生成列的部分行：【F5/Ctrl+G】 -> （定位条件）勾选【空值】 -> 【确定】 -> 【开始】 -> 【合并居中】\n 3. 选中任意单元格：点击【数据】 -> 【分类汇总】 -> 【全部删除】\n 4. 选中格式正确的空白列：点击【开始】-> 【格式刷】 刷好我们需要合并的列\n 5. 选中空白列：右键删除\n\n\n# 打印列多的表\n\nOffice\n\n【文件】 -> 【打印】 -> （打印整个文件薄、横向）【无缩放】修改为【将所有列调整为一页】\n\nWPS\n\n点击左上方：【打印预览】 -> 【分页预览】 -> 可通过拖动边线调整打印范围（去掉空白页、调整分页等）\n\n\n# Vlookup 绝对引用\n\n在 Excel 中，当你使用 VLOOKUP 函数并向下拖动时，匹配域（lookup_range）会相应地改变，这是因为 Excel 默认情况下会调整相对引用的范围。\n\n假设你有一个 VLOOKUP 函数的公式如下：\n\n=IFNA(VLOOKUP(A2, $B$2:$C$10, 2, FALSE), "")\n\n\n在这个例子中，$B$2:$C$10 是一个绝对引用（也可以选择区域后按F4键），意味着它不会在向下拖动时改变。但是 A2 是一个相对引用，它会根据单元格的相对位置而改变。\n\n\n# Word 使用\n\n\n# 一个文档的样式应用于另一个文档\n\n\n\n样式(Alt+Ctrl+Shift+S) -> 管理样式 -> 导入/导出 -> 关闭文件（x2）-> 打开文件（x2）-> 选中样式 -> 复制（注意箭头方向，由哪个文档到哪个文档）',normalizedContent:'# excel 使用\n\n\n# 相同值的单元格合并\n\n使用功能：分类汇总、条件定位\n\n 1. 选中需要合并的列：点击【数据】 -> 【分类汇总】 -> 【确定】\n 2. 选中上一步生成列的部分行：【f5/ctrl+g】 -> （定位条件）勾选【空值】 -> 【确定】 -> 【开始】 -> 【合并居中】\n 3. 选中任意单元格：点击【数据】 -> 【分类汇总】 -> 【全部删除】\n 4. 选中格式正确的空白列：点击【开始】-> 【格式刷】 刷好我们需要合并的列\n 5. 选中空白列：右键删除\n\n\n# 打印列多的表\n\noffice\n\n【文件】 -> 【打印】 -> （打印整个文件薄、横向）【无缩放】修改为【将所有列调整为一页】\n\nwps\n\n点击左上方：【打印预览】 -> 【分页预览】 -> 可通过拖动边线调整打印范围（去掉空白页、调整分页等）\n\n\n# vlookup 绝对引用\n\n在 excel 中，当你使用 vlookup 函数并向下拖动时，匹配域（lookup_range）会相应地改变，这是因为 excel 默认情况下会调整相对引用的范围。\n\n假设你有一个 vlookup 函数的公式如下：\n\n=ifna(vlookup(a2, $b$2:$c$10, 2, false), "")\n\n\n在这个例子中，$b$2:$c$10 是一个绝对引用（也可以选择区域后按f4键），意味着它不会在向下拖动时改变。但是 a2 是一个相对引用，它会根据单元格的相对位置而改变。\n\n\n# word 使用\n\n\n# 一个文档的样式应用于另一个文档\n\n\n\n样式(alt+ctrl+shift+s) -> 管理样式 -> 导入/导出 -> 关闭文件（x2）-> 打开文件（x2）-> 选中样式 -> 复制（注意箭头方向，由哪个文档到哪个文档）',charsets:{cjk:!0},lastUpdated:"2025/01/15, 20:27:10",lastUpdatedTimestamp:173694403e4},{title:"SQL非常规用法",frontmatter:{title:"SQL非常规用法",date:"2022-06-12T22:15:30.000Z",permalink:"/pages/e02b49/",categories:["数据库"],tags:["记录一些不太常见，但非常有用的SQL写法"]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/1000.SQL%E9%9D%9E%E5%B8%B8%E8%A7%84%E7%94%A8%E6%B3%95%E9%9B%86%E9%94%A6.html",relativePath:"03.数据库/1000.SQL非常规用法集锦.md",key:"v-00c7823d",path:"/pages/e02b49/",headers:[{level:2,title:"SQL",slug:"sql",normalizedTitle:"sql",charIndex:2},{level:4,title:"递归CTEs",slug:"递归ctes",normalizedTitle:"递归ctes",charIndex:9},{level:4,title:"窗口函数 rowsbetween、rangebetween 的使用",slug:"窗口函数-rowsbetween、rangebetween-的使用",normalizedTitle:"窗口函数 rowsbetween、rangebetween 的使用",charIndex:5609},{level:4,title:"博客：10个SQL杀手级特性",slug:"博客-10个sql杀手级特性",normalizedTitle:"博客：10个sql杀手级特性",charIndex:6176}],headersStr:"SQL 递归CTEs 窗口函数 rowsbetween、rangebetween 的使用 博客：10个SQL杀手级特性",content:"# SQL\n\n# 递归CTEs\n\n> 递归CET可用于查询组织结构图、文件系统、网页之间的链接图等分层数据\n\n递归CTE三部分：\n\n 1. 锚构件（定点成员）：返回 CTE 的基本结果的初始查询\n 2. 递归成员：引用 CTE 的递归查询。这是所有与锚构件的联盟\n 3. 停止递归构件的终止条件（隐式的；当上一个调用中未返回行时，递归将停止。）\n\n点击查看\n\n示例\n\n-- 测试表建表语句\nCREATE TABLE TABLENAME(\n  ItemId INT PRIMARY KEY,\n  ParentItemId INT,\n  ItemName VARCHAR(200)\n)\n\n-- 插入数据\ninsert into tablename values(2,0,'管理费用');\ninsert into tablename values(3,0,'销售费用');\ninsert into tablename values(4,0,'财务费用');\ninsert into tablename values(5,0,'生产成本');\ninsert into tablename values(35,5,'材料');\ninsert into tablename values(36,5,'人工');\ninsert into tablename values(37,5,'制造费用');\ninsert into tablename values(38,35,'原材料');\ninsert into tablename values(39,35,'主要材料');\ninsert into tablename values(40,35,'间辅材料');\ninsert into tablename values(41,36,'工资');\ninsert into tablename values(42,36,'福利');\ninsert into tablename values(43,2,'管理费用子项');\ninsert into tablename values(113,43,'管理费用子项的子项');\n\n-- 递归 CTE 语句（在 MySQL8.0 尝试不好使，在 Oracle 是好使的）\nWITH tablenameTemp(ItemId, ItemName, levelno) AS (\nSELECT ItemId, ItemName, 0 as levelno\n  FROM tablename\n WHERE ParentItemId = 0\nUNION ALL\nSELECT T1.ItemId, T1.ItemName, T2.levelno + 1 as levelno\n  FROM tablename T1\n INNER JOIN tablenameTemp T2\n    ON T1.parentitemid = T2.itemid\n)\nSELECT * FROM tablenameTemp\n\n\n\n参考链接\n\n很牛的用法\n\nWITH    RECURSIVE\n        q (r, i, rx, ix, g) AS\n        (\n        SELECT  r::DOUBLE PRECISION * 0.02, i::DOUBLE PRECISION * 0.02, .0::DOUBLE PRECISION, .0::DOUBLE PRECISION, 0\n        FROM    generate_series(-60, 20) r, generate_series(-50, 50) i\n        UNION ALL\n        SELECT  r, i, CASE WHEN ABS(rx * rx + ix * ix) <= 2 THEN rx * rx - ix * ix END + r, CASE WHEN ABS(rx * rx + ix * ix) <= 2 THEN 2 * rx * ix END + i, g + 1\n        FROM    q\n        WHERE   rx IS NOT NULL\n                AND g < 99\n        )\nSELECT  ARRAY_TO_STRING(ARRAY_AGG(s ORDER BY r), '')\nFROM    (\n        SELECT  i, r, SUBSTRING(' .:-=+*#%@', MAX(g) / 10 + 1, 1) s\n        FROM    q\n        GROUP BY\n                i, r\n        ) q\nGROUP BY\n        i\nORDER BY\n        i\n\n\nWITH    RECURSIVE\n        q (r, i, rx, ix, g) AS\n        (\n        SELECT  r::DOUBLE PRECISION * 0.04, i::DOUBLE PRECISION * 0.04, .0::DOUBLE PRECISION, .0::DOUBLE PRECISION, 0\n        FROM    generate_series(-40, 20) r, generate_series(-40, 20) i\n        UNION ALL\n        SELECT  r, i, CASE WHEN ABS(rx * rx + ix * ix) <= 1E8 THEN rx * rx - ix * ix END + r, CASE WHEN ABS(rx * rx + ix * ix) <= 2 THEN ABS(2 * rx * ix) END + i, g + 1\n        FROM    q\n        WHERE   rx IS NOT NULL\n                AND g < 99\n        )\nSELECT  ARRAY_TO_STRING(ARRAY_AGG(s ORDER BY r), '')\nFROM    (\n        SELECT  i, r, SUBSTRING(' .:-=+*#%@', MAX(g) / 10 + 1, 1) s\n        FROM    q\n        GROUP BY\n                i, r\n        ) q\nGROUP BY\n        i\nORDER BY\n        i\n\n\nWITH    RECURSIVE\n        q (r, i, rx, ix, g) AS\n        (\n        SELECT  r::DOUBLE PRECISION * 0.000001, i::DOUBLE PRECISION * 0.000001,\n                r::DOUBLE PRECISION * 0.000001, i::DOUBLE PRECISION * 0.000001,\n                0\n        FROM    generate_series(-40, 40) r, generate_series(-50, 50) i\n        UNION ALL\n        SELECT  r, i,\n                CASE WHEN ABS(rx * rx + ix * ix) < 1E8 THEN rx * rx - ix * ix END + 0,\n                CASE WHEN ABS(rx * rx + ix * ix) < 1E8 THEN 2 * rx * ix END + 1,\n                g + 1\n        FROM    q\n        WHERE   rx IS NOT NULL\n                AND g < 99\n        )\nSELECT  ARRAY_TO_STRING(ARRAY_AGG(s ORDER BY r), '')\nFROM    (\n        SELECT  i, r, SUBSTRING(' .:-=+*#%@', MAX(g) / 10 + 1, 1) s\n        FROM    q\n        GROUP BY\n                i, r\n        ) q\nGROUP BY\n        i\nORDER BY\n        i\n\n\nWITH    RECURSIVE\n        q (r, i, rx, ix, g) AS\n        (\n        SELECT  r::DOUBLE PRECISION * 0.0002, i::DOUBLE PRECISION * 0.0002,\n                r::DOUBLE PRECISION * 0.0002, i::DOUBLE PRECISION * 0.0002,\n                0\n        FROM    generate_series(-200, -120) r, generate_series(0, 100) i\n        UNION ALL\n        SELECT  r, i,\n                CASE WHEN ABS(rx * rx + ix * ix) < 1E8 THEN rx * rx - ix * ix END - 0.70176,\n                CASE WHEN ABS(rx * rx + ix * ix) < 1E8 THEN 2 * rx * ix END + 0.3842,\n                g + 1\n        FROM    q\n        WHERE   rx IS NOT NULL\n                AND g < 99\n        )\nSELECT  ARRAY_TO_STRING(ARRAY_AGG(s ORDER BY r), '')\nFROM    (\n        SELECT  i, r, SUBSTRING(' .:-=+*#%@', MAX(g) / 10 + 1, 1) s\n        FROM    q\n        GROUP BY\n                i, r\n        ) q\nGROUP BY\n        i\nORDER BY\n        i\n\n\nWITH    RECURSIVE\n        q (r, i, rx, ix, g) AS\n        (\n        SELECT  x + r::DOUBLE PRECISION * step, y + i::DOUBLE PRECISION * step,\n                x + r::DOUBLE PRECISION * step, y + i::DOUBLE PRECISION * step,\n                0\n        FROM    (\n                SELECT  0.25 x, -0.55 y, 0.002 step, r, i\n                FROM    generate_series(-40, 40) r\n                CROSS JOIN\n                        generate_series(-40, 40) i\n                ) q\n        UNION ALL\n        SELECT  r, i,\n                CASE WHEN (rx * rx + ix * ix) < 1E8 THEN (rx * rx + ix * ix) ^ 0.75 * COS(1.5 * ATAN2(ix, rx)) END - 0.2,\n                CASE WHEN (rx * rx + ix * ix) < 1E8 THEN (rx * rx + ix * ix) ^ 0.75 * SIN(1.5 * ATAN2(ix, rx)) END,\n                g + 1\n        FROM    q\n        WHERE   rx IS NOT NULL\n                AND g < 99\n        )\nSELECT  ARRAY_TO_STRING(ARRAY_AGG(s ORDER BY r), '')\nFROM    (\n        SELECT  i, r, SUBSTRING(' .:-=+*#%@', MAX(g) / 10 + 1, 1) s\n        FROM    q\n        GROUP BY\n                i, r\n        ) q\nGROUP BY\n        i\nORDER BY\n        i\n\n\n# 窗口函数 rowsbetween、rangebetween 的使用\n\n-- 待补充\n\n\nSELECT CODE\n,TO_CHAR(WM_CONCAT(CODE) OVER(PARTITION BY LEVELNO ORDER BY CODE )) AS test1\n--,TO_CHAR(WM_CONCAT(CODE) OVER(PARTITION BY LEVELNO ORDER BY CODE rows between 1 preceding and 3 following)) AS test1   -- 当前之前一行到后面三行\n--,TO_CHAR(WM_CONCAT(CODE) OVER(PARTITION BY LEVELNO ORDER BY CODE rows between UNBOUNDED PRECEDING and CURRENT ROW)) AS test2  -- 区间第一行到当前行\n,TO_CHAR(WM_CONCAT(CODE) OVER(PARTITION BY LEVELNO ORDER BY CODE rows between CURRENT ROW and UNBOUNDED FOLLOWING)) AS test3  -- 当前行区间最后一行\nFROM AD_TABLE\n\n\n# 博客：10个SQL杀手级特性\n\n原文地址",normalizedContent:"# sql\n\n# 递归ctes\n\n> 递归cet可用于查询组织结构图、文件系统、网页之间的链接图等分层数据\n\n递归cte三部分：\n\n 1. 锚构件（定点成员）：返回 cte 的基本结果的初始查询\n 2. 递归成员：引用 cte 的递归查询。这是所有与锚构件的联盟\n 3. 停止递归构件的终止条件（隐式的；当上一个调用中未返回行时，递归将停止。）\n\n点击查看\n\n示例\n\n-- 测试表建表语句\ncreate table tablename(\n  itemid int primary key,\n  parentitemid int,\n  itemname varchar(200)\n)\n\n-- 插入数据\ninsert into tablename values(2,0,'管理费用');\ninsert into tablename values(3,0,'销售费用');\ninsert into tablename values(4,0,'财务费用');\ninsert into tablename values(5,0,'生产成本');\ninsert into tablename values(35,5,'材料');\ninsert into tablename values(36,5,'人工');\ninsert into tablename values(37,5,'制造费用');\ninsert into tablename values(38,35,'原材料');\ninsert into tablename values(39,35,'主要材料');\ninsert into tablename values(40,35,'间辅材料');\ninsert into tablename values(41,36,'工资');\ninsert into tablename values(42,36,'福利');\ninsert into tablename values(43,2,'管理费用子项');\ninsert into tablename values(113,43,'管理费用子项的子项');\n\n-- 递归 cte 语句（在 mysql8.0 尝试不好使，在 oracle 是好使的）\nwith tablenametemp(itemid, itemname, levelno) as (\nselect itemid, itemname, 0 as levelno\n  from tablename\n where parentitemid = 0\nunion all\nselect t1.itemid, t1.itemname, t2.levelno + 1 as levelno\n  from tablename t1\n inner join tablenametemp t2\n    on t1.parentitemid = t2.itemid\n)\nselect * from tablenametemp\n\n\n\n参考链接\n\n很牛的用法\n\nwith    recursive\n        q (r, i, rx, ix, g) as\n        (\n        select  r::double precision * 0.02, i::double precision * 0.02, .0::double precision, .0::double precision, 0\n        from    generate_series(-60, 20) r, generate_series(-50, 50) i\n        union all\n        select  r, i, case when abs(rx * rx + ix * ix) <= 2 then rx * rx - ix * ix end + r, case when abs(rx * rx + ix * ix) <= 2 then 2 * rx * ix end + i, g + 1\n        from    q\n        where   rx is not null\n                and g < 99\n        )\nselect  array_to_string(array_agg(s order by r), '')\nfrom    (\n        select  i, r, substring(' .:-=+*#%@', max(g) / 10 + 1, 1) s\n        from    q\n        group by\n                i, r\n        ) q\ngroup by\n        i\norder by\n        i\n\n\nwith    recursive\n        q (r, i, rx, ix, g) as\n        (\n        select  r::double precision * 0.04, i::double precision * 0.04, .0::double precision, .0::double precision, 0\n        from    generate_series(-40, 20) r, generate_series(-40, 20) i\n        union all\n        select  r, i, case when abs(rx * rx + ix * ix) <= 1e8 then rx * rx - ix * ix end + r, case when abs(rx * rx + ix * ix) <= 2 then abs(2 * rx * ix) end + i, g + 1\n        from    q\n        where   rx is not null\n                and g < 99\n        )\nselect  array_to_string(array_agg(s order by r), '')\nfrom    (\n        select  i, r, substring(' .:-=+*#%@', max(g) / 10 + 1, 1) s\n        from    q\n        group by\n                i, r\n        ) q\ngroup by\n        i\norder by\n        i\n\n\nwith    recursive\n        q (r, i, rx, ix, g) as\n        (\n        select  r::double precision * 0.000001, i::double precision * 0.000001,\n                r::double precision * 0.000001, i::double precision * 0.000001,\n                0\n        from    generate_series(-40, 40) r, generate_series(-50, 50) i\n        union all\n        select  r, i,\n                case when abs(rx * rx + ix * ix) < 1e8 then rx * rx - ix * ix end + 0,\n                case when abs(rx * rx + ix * ix) < 1e8 then 2 * rx * ix end + 1,\n                g + 1\n        from    q\n        where   rx is not null\n                and g < 99\n        )\nselect  array_to_string(array_agg(s order by r), '')\nfrom    (\n        select  i, r, substring(' .:-=+*#%@', max(g) / 10 + 1, 1) s\n        from    q\n        group by\n                i, r\n        ) q\ngroup by\n        i\norder by\n        i\n\n\nwith    recursive\n        q (r, i, rx, ix, g) as\n        (\n        select  r::double precision * 0.0002, i::double precision * 0.0002,\n                r::double precision * 0.0002, i::double precision * 0.0002,\n                0\n        from    generate_series(-200, -120) r, generate_series(0, 100) i\n        union all\n        select  r, i,\n                case when abs(rx * rx + ix * ix) < 1e8 then rx * rx - ix * ix end - 0.70176,\n                case when abs(rx * rx + ix * ix) < 1e8 then 2 * rx * ix end + 0.3842,\n                g + 1\n        from    q\n        where   rx is not null\n                and g < 99\n        )\nselect  array_to_string(array_agg(s order by r), '')\nfrom    (\n        select  i, r, substring(' .:-=+*#%@', max(g) / 10 + 1, 1) s\n        from    q\n        group by\n                i, r\n        ) q\ngroup by\n        i\norder by\n        i\n\n\nwith    recursive\n        q (r, i, rx, ix, g) as\n        (\n        select  x + r::double precision * step, y + i::double precision * step,\n                x + r::double precision * step, y + i::double precision * step,\n                0\n        from    (\n                select  0.25 x, -0.55 y, 0.002 step, r, i\n                from    generate_series(-40, 40) r\n                cross join\n                        generate_series(-40, 40) i\n                ) q\n        union all\n        select  r, i,\n                case when (rx * rx + ix * ix) < 1e8 then (rx * rx + ix * ix) ^ 0.75 * cos(1.5 * atan2(ix, rx)) end - 0.2,\n                case when (rx * rx + ix * ix) < 1e8 then (rx * rx + ix * ix) ^ 0.75 * sin(1.5 * atan2(ix, rx)) end,\n                g + 1\n        from    q\n        where   rx is not null\n                and g < 99\n        )\nselect  array_to_string(array_agg(s order by r), '')\nfrom    (\n        select  i, r, substring(' .:-=+*#%@', max(g) / 10 + 1, 1) s\n        from    q\n        group by\n                i, r\n        ) q\ngroup by\n        i\norder by\n        i\n\n\n# 窗口函数 rowsbetween、rangebetween 的使用\n\n-- 待补充\n\n\nselect code\n,to_char(wm_concat(code) over(partition by levelno order by code )) as test1\n--,to_char(wm_concat(code) over(partition by levelno order by code rows between 1 preceding and 3 following)) as test1   -- 当前之前一行到后面三行\n--,to_char(wm_concat(code) over(partition by levelno order by code rows between unbounded preceding and current row)) as test2  -- 区间第一行到当前行\n,to_char(wm_concat(code) over(partition by levelno order by code rows between current row and unbounded following)) as test3  -- 当前行区间最后一行\nfrom ad_table\n\n\n# 博客：10个sql杀手级特性\n\n原文地址",charsets:{cjk:!0},lastUpdated:"2022/07/28, 09:54:00",lastUpdatedTimestamp:165897324e4},{title:"Python简单语法学习",frontmatter:{title:"Python简单语法学习",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/f2a330/",categories:["其他","Python"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/01.Python/01.Python%E7%AE%80%E5%8D%95%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0.html",relativePath:"04.其他/01.Python/01.Python简单语法学习.md",key:"v-2a8f5aa8",path:"/pages/f2a330/",headers:[{level:2,title:"基础",slug:"基础",normalizedTitle:"基础",charIndex:2},{level:2,title:"流程控制",slug:"流程控制",normalizedTitle:"流程控制",charIndex:726},{level:2,title:"数据类型",slug:"数据类型",normalizedTitle:"数据类型",charIndex:4109},{level:3,title:"序列数据类型  List(列表)",slug:"序列数据类型-list-列表",normalizedTitle:"序列数据类型  list(列表)",charIndex:4138},{level:3,title:"序列数据类型  Tuple(元组)",slug:"序列数据类型-tuple-元组",normalizedTitle:"序列数据类型  tuple(元组)",charIndex:4935},{level:3,title:"序列数据类型  Set(集合)",slug:"序列数据类型-set-集合",normalizedTitle:"序列数据类型  set(集合)",charIndex:5166},{level:3,title:"序列数据类型  dictionary(字典)",slug:"序列数据类型-dictionary-字典",normalizedTitle:"序列数据类型  dictionary(字典)",charIndex:5560},{level:2,title:"函数和类",slug:"函数和类",normalizedTitle:"函数和类",charIndex:5841},{level:3,title:"函数参数和返回值的类型",slug:"函数参数和返回值的类型",normalizedTitle:"函数参数和返回值的类型",charIndex:5850},{level:3,title:"类的练习",slug:"类的练习",normalizedTitle:"类的练习",charIndex:7415},{level:2,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:9783},{level:3,title:"手工测试",slug:"手工测试",normalizedTitle:"手工测试",charIndex:9790},{level:3,title:"代码测试工具unittest",slug:"代码测试工具unittest",normalizedTitle:"代码测试工具unittest",charIndex:10192},{level:2,title:"文件读写",slug:"文件读写",normalizedTitle:"文件读写",charIndex:11824},{level:3,title:"文件读取",slug:"文件读取",normalizedTitle:"文件读取",charIndex:11833},{level:3,title:"文件写入",slug:"文件写入",normalizedTitle:"文件写入",charIndex:12725},{level:3,title:"json数据读写",slug:"json数据读写",normalizedTitle:"json数据读写",charIndex:13437}],headersStr:"基础 流程控制 数据类型 序列数据类型  List(列表) 序列数据类型  Tuple(元组) 序列数据类型  Set(集合) 序列数据类型  dictionary(字典) 函数和类 函数参数和返回值的类型 类的练习 测试 手工测试 代码测试工具unittest 文件读写 文件读取 文件写入 json数据读写",content:'# 基础\n\n"""Jupyter Notebook 的快捷键: https://www.jianshu.com/p/72493e81a708"""\n# 1. 打印关键字\nimport keyword\nprint(keyword.kwlist)\n\n# 2. 打印语句\nprint("Hello\\\n\tPython\\\n\tHello\\\n\tWorld")\n\n\n# 3.变量不需声明  变量赋值为任意类型(动态语言)\na = 12\nprint(f"a:{a} type:{type(a)}")\n\na = "python"\nprint("a:", a, "type:", type(a))\n\n# 输出对象地址\nprint(id(a))\ndel a\n# print(a)\n\n\n# 4. input 和 字符串连接\nname = "John"\n# + 连接\nmes1 = name + " is a coder"\n# ,连接\nmes2 = name, " is a coder"\nprint(name, " is a coder")\n# .join连接\nmes3 = " ".join(mes2)\n# 格式化\nmes4 = "%s and %s is a coder" % (name, "Smith")\n# f("{}")\nmes5 = f"{name} is a coder"\n\nprint(f"{mes1}\\n{mes2}\\n{mes3}\\n{mes4}\\n{mes5}")\ndel mes1, mes2, mes3, mes4, mes5\n\n\n# 5.input\nname = input("请输入姓名:")\nprint("Hello", name)\n\n\n\n# 流程控制\n\n\'\'\' 流程控制 1 \'\'\'\n# 6. 函数\ndef run():\n        print("car started...")\n        pass\n\ndef stop():\n        print("car stopped...")\n        pass\n\ndef error():\n        print("I can\'t understand...")\n        pass\n\n# 7. 分支\n        # ==： 用来判断两个对象的值是否相等\n        # is: 判断两个变量是否引用的是同一个对象，底层判断的依据是两个变量的id是否相等\nstatus = "stop"\ndef message(mes):\n        # 声明 status 为全局变量\n        global status\n        if mes in "start" and status in "stop":\n            run()\n            status = "start"\n        elif mes == "stop" and status == "start":\n            stop()\n            status = "stop"\n        elif mes in "start" and status in "start":\n            print("Car is already started")\n        elif mes in "stop" and status in "stop":\n            print("Car is already stopped")\n        else:\n            error()\n\n# 8. 循环\n\nwhile True:\n        order = input("请输入命令:")\n        if order not in ["END", "end"]:\n            message(order)\n        else:\n            print("finish")\n            break\ndel status\n\n\n点击查看\n\n练习\n\n\'\'\' 流程控制 2 \'\'\'\n# 9 * 9 乘法表\nfor i in range(1, 10, 1):\n    for j in range(1, i+1):\n        print(f"{i} * {j} = {i * j}", end="\\t")\n    print()\n\n\'\'\'斐波那契数列\'\'\'\ndef fibonacci(n):\n    if n==1 or n==2:\n        return 1\n    return fibonacci(n-1) + fibonacci(n-2)\n\nfor i in range(1, 20):\n    print(fibonacci(i), end=" ")\n    \nfibonacci(10)\n\n\'\'\'素数\'\'\'\nimport math\n\ndef sushu(start, end):\n    # 去掉1 0\n    if start<2:\n        start=2\n    # 定义返回结果\n    result= []\n    for i in range(start, end+1):\n        # 默认都是素数\n        flag = False\n        #从2作为除数开始判断当前数是否能够被除1和本身的其他数整除\n        for j in range(2, int(math.sqrt(i)+1)): \n            # 如果能被2或者小于自己的数整除，这不是素数，改变flag为True\n            if i%j == 0:\n                flag = True\n                break\n        if flag == False:\n            result.append(i)\n    return result\n\nresult = sushu(0,101)\nprint(len(result))\nprint(result)\n\n\'\'\'输入某年某月某日，判断这一天是这一年的第几天\'\'\'\n#输入某年某月某日，判断这一天是这一年的第几天？\n\n\ndef outter(func):\n    def inner():\n        year = int(input("请输入一个年份:"))\n        # global year\n        if year % 100 != 0 and year % 4 == 0 or year % 400 == 0:\n            print("%d是闰年"%year)\n            dict1[2]=29\n            func()\n        else:\n            print("%d是平年"%year)\n            func()\n    return inner\n\ndict1 ={1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:30,9:31,10:31,11:30,12:31}\n@outter\ndef f():\n    ymd2 = input("输入年-月-日[year-month-day]:")\n    ymd1 =ymd2.split(\'-\')\n    day =0\n    for x in range(1,int(ymd1[1])):\n        day += dict1[x]\n    Day = day+int(ymd1[2])\n    print("这一天是这一年的第%d天"%Day)\n\nf()\n\n\n\'\'\'时间转换\'\'\'\nimport datetime\n\n# 输入时间\ninput_time = input("请输入时间(%Y-%m-%d):")  # input_time = "2020-7-3"\n# 字符串转为时间\nend_time = datetime.datetime.strptime(input_time, \'%Y-%m-%d\')\n# 拼接上一年最后一天的时间\nstart_time = datetime.datetime.strptime(str(end_time.year-1) + "-12-31", \'%Y-%m-%d\')\n# 时间相减 得到天数\n(end_time-start_time).days\n\n\'\'\'时间转换2\'\'\'\n# 接收输入的信息，并拆分成年月日变量\nyear = int(input(\'year:\\n\'))\nmonth = int(input(\'month:\\n\'))\nday = int(input(\'day:\\n\'))\n# 预定义每个月对应年的第几天\nmonths = (0,31,59,90,120,151,181,212,243,273,304,334)\nif 0 < month <= 12:\n    # 第几天用sum变量表示，并初始化为months数组对应的天数\n    sum = months[month-1]\nelse:\n    print(\'data error\')\n# 添加day所代表的天数\nsum += day\n# 闰年标记\nleap = 0\n# 判断是否为闰年\nif year % 400 == 0 or year % 4 == 0 and year % 100 != 0:\n    leap = 1\n    # 如果是闰年，总天数需要加一天\n    if leap == 1 and month > 2:\n        sum += 1       \nprint(\'it is the %dth day.\' % sum)\n\n\n\n\n# 数据类型\n\n\n# 序列数据类型 List(列表)\n\n"""序列数据类型  List(列表)"""\n\n\n# 创建 1.python列表可以存储任意类型的对象 2.按照顺序存储\nmy_list = [1.0, "python", True, None, print, list(range(0, 10, 3))]\nprint(type(my_list), end="类型\\t")\nprint(len(my_list), end="长度\\n")\n\n# 访问\nprint(f"{my_list[4]}\\t{my_list[-1]}")\ndel my_list\n\n# 遍历\nlist1 = ["John", "Smaith", "Tom", "Lily", "Jim"]\nfor elem in list1:\n    print(elem, end="\\t")\n    \n# 修改\n## 修改值\nlist1[2] = "nicai"\n## 追加\nlist1.append("last")\n## 插入\nlist1.insert(1, "first")\n# list1\n\n# 删除\n# del list1[1]\n## 删除并取出\n# str = list1.pop(3)\n# str\n## 指定值删除\n# list.remove("nicai")\n## 查找下标\n# list1.index("first")\n\n# 排序\n## 临时排序\nprint(sorted(list1))\n## 永久排序\n# list1.sort()\n# list1\n## 列表倒序\nlist2 = sorted(list1)\nlist2.reverse()\nlist2\n\n# 切片 1.语法: 列表[起始:结束:步长] \nstus = [\'孙悟空\',\'猪八戒\',\'沙和尚\',\'唐僧\',\'蜘蛛精\',\'白骨精\']\nstus[0: 5: 2]\n\n\n\n# 序列数据类型 Tuple(元组)\n\n"""序列数据类型  Tuple(元组)"""\n### 元组 1.类似list 2.属于不可变序列  ###\nlist3 = list(range(0, 10, 3))\n# 元组不可变 但其中元素可以变\ntuple1 = ("hello", "python", list3)\nfor elem in tuple1:\n    print(elem, end=" ")\n\ntuple1[2][1] = 123\ntuple1\n\n\n\n# 序列数据类型 Set(集合)\n\n"""序列数据类型  Set(集合)"""\n### Set集合 无序不重复\n## 创建空集合\nset1 = set()\n## list转化为set\nset1 = set(list(range(0, 10, 3)))\nprint(set1)\n\na_set = {-1, -3, 2, 3, 5}\nb_set = {2, 3, 5, 25, 36}\n## 交集\nprint( a_set.union(b_set) )\nprint( a_set | b_set )\n\n## 并集\nprint( a_set.intersection(b_set) )\nprint( a_set & b_set )\n\n## 差集\nprint( a_set.difference(b_set) )\n\n## 集合异或\nprint( a_set ^b_set )\n\n\n\n# 序列数据类型 dictionary(字典)\n\n"""序列数据类型  dictionary(字典) 1.key值唯一"""\n\n# 定义\ndic = { "k1": "v1"}\n# dic = dict([(1, "baidu"), (2, "Goole"), (3, "toabao")])\nprint(dic[1])\nprint(dic)\nprint(dic.keys())\ndic.values()\n\n# 修改/新增元素\ndic["k2"] = "v2"\n# 删除元素\ndel dic["k2"]\ndic.clear()      # 清空字典所有条目\ndel dic          # 删除字典\n\n\n\n# 函数和类\n\n\n# 函数参数和返回值的类型\n\n"""函数参数和返回值的类型 200124"""\n### 顺序实参\ndef info(heroName, petName):\n    print("英雄名字:{" + heroName + "}\\t宠物名字:{" + petName + "}")\ninfo("德鲁伊", "龙狼")\n\n### 位置实参\ninfo(petName="龙狼", heroName = "德鲁伊")\n\n### 默认值\ndef info2(heroName, petName="烈焰神虎", attack="5680"):\n    print(f"英雄名字:{heroName}\\t宠物名字:{petName}\\t攻击力{attack}")\ninfo2("苍瞳")\ninfo2(heroName="苍瞳", attack="12345")\n\n### 任意数量的参数\ndef fun1(*p):\n    print(p)\nfun1(0, 1)\n\n### 任意数量关键字参数\ndef fun2(**p):\n    for elem in p.items():\n        print( elem, end="\\t" )\nfun2(x=1, y=2, z=3)\n\n### 通过 **来对一个字典进行解包操作\ndef fun3(name, info):\n    print(f"name={name} \\t info={info}")\ndic = { "name":"酒神", "info":"阴阳冕" }\nfun3(**dic)\n\n### 单值返回\ndef info2(heroName, petName="烈焰神虎", attack="5680"):\n    return f"英雄名字:{heroName}\\t宠物名字:{petName}\\t攻击力{attack}"\nprint( info2("苍瞳") )\n\n### 多值返回\ndef arithmetic1(x, y):\n    add = x+y\n    subtract= x-y \n    multiply= x*y\n    if y != 0:\n        divide= x/y\n    else:\n        print("除数不能为零")\n    return add, subtract, multiply, divide\n\n#eval()将字符串str当成有效的表达式来求值并返回计算结果\nnum1,num2=eval(input("请输入需要计算的两个数字："\'\\n\'))\n# num1=int(num1)\n# num2=int(num2)\na,s,m,d = arithmetic1(num1, num2)\nprint(f"{num1} + {num2} = {a}\\t{num1} - {num2} = {s}\\t{num1} * {num2} = {a}\\t{num1} / {num2} = {d}")\n\n### 模块\n## 引入模块\n# from data import cycle\n## 引入函数 并起别名\n# from data.cycle import sphere_surface_area as ssa\n##引入模块 起别名\nfrom data import cycle as cy\nradius = 2\nprint(f"圆面积: {cy.area(radius)}\\t圆周长:{cy.circumference(radius)}\\t \\\n        球体积:{cy.sphere_volume(radius)}\\t球表面积:{cy.sphere_surface_area(radius)}")\n\n# 常用库\n\n\n\n# 类的练习\n\n""" 9.类的练习 """\nclass Mammal:\n    #_init_是一个特殊的方法，类的实例化操作会自动为新创建的类实例调用_init_()方法\n    # name为实例属性\n    def __init__(self,name):\n        self.name = name\n\n    #类的方法至少有一个参数self且必须是第一个参数\n    def walk(self):\n        print(f\'{self.name} walking\')\n        \n    def shout(self):\n        print(f\'{self.name} shouting\')\n        \n        \nclass Dog(Mammal):\n    print(\'===============Dog===============\')\n    # 类属性\n    action = "摇尾巴"\n    def shout(self):\n        print(f\'{self.name} 汪汪\')\n        \n\nclass Cat(Mammal):\n    print(\'===============Cat===============\')\n    pass\n\n\nmammal = Mammal(\'哺乳动物\')\nmammal.walk()\nmammal.shout()\n\ncat = Cat(\'喵喵\')\ncat.walk()\ncat.shout()\n\ndog = Dog(\'二哈\')\ndog.walk()\ndog.shout()\nDog.action = "喝水"\nprint(dog.name + "在" + Dog.action)\n\n\n"""类的练习2"""\nclass Car():\n    \'\'\'模拟汽车的类\'\'\'\n    def __init__(self, make, model, year):\n        # 初始化属性\n        self.make = make #制造商\n        self.model = model #型号\n        self.year = year #生产年份\n        self.odometer_reading = 0\n        \n    def base_message(self):\n        # 汽车描述信息\n        cmessage = f"{self.make} {self.model} {self.year}"\n        return cmessage.title()\n    \n    def read_odometer(self):\n        # 打印里程信息\n        print(f"This car has {self.odometer_reading} miles on it")\n        \n    def update_odometer(self, miles):\n        # 修改里程信息 不能调小\n        if self.odometer_reading < miles:\n            self.odometer_reading = miles\n        else:\n            print("您不能调小里程数")\n            \n    def increment_odometer(self, miles):\n        # 增加里程数\n        self.odometer_reading += miles\n    \n    \ncar = Car("audo", "a6", 2016)\nprint(car.base_message())\ncar.read_odometer()\n## 直接修改属性\ncar.odometer_reading = 21\ncar.read_odometer()\n## 方法修改\ncar.update_odometer(20)\ncar.read_odometer()\ncar.update_odometer(50)\ncar.read_odometer()\n## 增加里程数\ncar.increment_odometer(10)\ncar.read_odometer()\n\n\nclass ElectricCar(Car):\n    """电动车"""\n    def __init__(self, make, model, year, battery_size):\n        super().__init__(make, model, year)\n        self.battery_size = battery_size\n        \n    def desctibe_battery(self):\n        # 属于电池容量的信息\n        print(f"This  car has a {self.battery_size} -kwh battery")\n        \n    def base_message(self):\n        return "ElectricCar:" + super().base_message()\n    \n\nele_car = ElectricCar("tesla", "model s", 2017, 70)\nprint(ele_car.base_message())\nele_car.desctibe_battery()\n\n\n\n# 测试\n\n\n# 手工测试\n\n# 手工测试  函数\nfrom data.MyPythonFunTest import get_formatted_name as gfn\nprint("Enter \'q\' at any time to quit." )\nwhile True:\n    first = input("\\nPlease give me a first name:")\n    if first in "q":\n        break\n    last = input("Please give me a last name:")\n    if last == "q":\n        break\n    formatted_name = gfn(first, last)\n    print("\\tNeatly foematted name:" + formatted_name + ".")\n\n\n\n# 代码测试工具unittest\n\n"""代码测试工具 unittest 单元测试(函数)"""\n"""\nunittest 无法运行 :\n    https://blog.csdn.net/u012291393/article/details/78636502\n    https://www.liaoxuefeng.com/discuss/969955749132672/1203224296196800\n"""\nimport unittest\nfrom data.MyPythonFunTest import get_formatted_name\n\nclass NamesTestCase(unittest.TestCase):\n    """测试data.MyPythonFunTest.get_formatted_name"""\n    \n    def test_first_last_name(self):\n        """能够正确处理包含姓和名的情况"""\n        formatted_name = get_formatted_name("jim", "green")\n#         self.assertEqual(formatted_name, "jim green")\n        self.assertEqual(formatted_name, "Jim Green")\n    \n    def test_first_last_middle_name(self):\n        """能够正确处理包含姓. 名和中间名的情况"""\n        formatted_name = get_formatted_name("martin", "king", "luther")\n        self.assertEqual(formatted_name, "Martin Luther King")\n        \n        \n# 在jupter不好使\n# unittest.main()\nif __name__ == \'__main__\':\n    unittest.main(argv=[\'first-arg-is-ignored\'], exit=False)\n\n\n"""代码测试工具 unittest 单元测试(类)"""\nfrom data.MyPythonFunTest import Area\nimport unittest  \n  \nclass AreaTestCase(unittest.TestCase):  \n    def setUp(self):  \n        self.area = Area()  \n      \n    def tearDown(self):  \n        self.area = None  \n      \n    def testArea(self):  \n        self.assertEqual(self.area.getArea(),10000)  \n      \n    def testWidth(self):  \n        self.area.setWidth(10)  \n        self.assertEqual(self.area.getWidth(),10)\n        \n    def testLength(self):  \n        self.area.setLenth(10)  \n        self.assertEqual(self.area.getLength(),10)  \n  \nif __name__ == "__main__":  \n    unittest.main(argv=[\'first-arg-is-ignored\'], exit=False)  \n\n\n\n# 文件读写\n\n\n# 文件读取\n\n"""文件读取"""\n"""\nwith 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，\n比如文件使用后自动关闭／线程中锁的自动获取和释放等\n"""\nfilepath = r"data\\hello.txt"\n\n# 传统模式\n# try:\n#     file = open(filename, \'r\', encoding=\'utf-8\')\n#     contents = file.read()\n#     print(contents)\n#     file.close()\n# except FileNotFoundError:\n#     print("文件不存在")\n# else:\n#     print("文件读取成功")\n\n# 用 with 方式\n# with open(filename, \'r\', encoding=\'utf-8\') as file:\n#     contents = file.read()\n#     print(contents.rstrip()) # rstrip() 删除文件末尾的空白\n    \n# 单行读取\n# with open(filename, \'r\', encoding=\'utf-8\') as file:\n#     lines = file.readlines() # 读取全部内容 ，并以列表方式返回\n#     for line in lines:\n#         print(line, end="")\n\n# 判断文件是否存在\nimport os\n\nflag = os.path.exists(filepath)\nif flag == True:\n    with open(filename, \'r\', encoding=\'utf-8\') as file:\n        contents = file.read()\n        print(contents.rstrip())\nelse:\n    print("文件不存在")\n\n\n\n# 文件写入\n\n"""文件写入"""\nfilename = r"data/hello.txt"\n\n# "w"把原来的文件覆盖掉\n# with open(filename, \'w\', encoding=\'utf-8\') as file:\n#     # write返回值为写入字符数\n#     contents = file.write("你好世界\\nHello World")\n#     print(contents)\n    \n# "a" 追加  \n# with open(filename, \'a\', encoding=\'utf-8\') as file:\n#     # write返回值为写入字符数\n#     contents = file.write("\\nHello Python")\n#     print(contents)\n\n\n"""异常处理"""\n# try:\n#     num1 = eval(input("输入被除数:"))\n#     num2 = eval(input("输入除数:"))\n#     answer = num1/num2\n# except ZeroDivisionError:\n#     print("除数不能为零")\n# else:\n#     print("计算结果:" + str(answer))\n\nnum1 = eval(input("输入被除数:"))\nnum2 = eval(input("输入除数:"))\nif(num2 != 0):\n    print(num1/num2)\nelse:\n    print("除数不能为0")\n    pass\n\n\n\n# json数据读写\n\n"""json数据 的读取,存储"""\nimport json\nimport os\n\ndef json_store(filepath):\n    """文件存在什么都不做 文件不存在保存"""\n    # 创建字典\n    dic = {\n        "name":"李雷",\n        "age":20,\n        "addr":"上海"\n    }\n    flag = os.path.exists(filepath)\n    if flag:\n        pass\n    else:\n        # python对象编码成json字符串 dump()编码并存储\n        with open(filepath, \'w\', encoding=\'utf-8\') as file:\n            json.dump(dic, file)\n            print("保存成功")\n\ndef json_read(filepath):\n    """从文件读取"""\n    flag = os.path.exists(filepath)\n    if flag:\n        # 文件读取 json解码为python对象(load)\n        with open(filepath, \'r\', encoding=\'utf-8\') as file:\n            json_obj = json.load(file)\n        return json_obj\n    else:\n        pass\n\nfilepath = r"data\\test.json"\njson_store(filepath)\ndata = json_read(filepath=filepath)\nprint("欢迎" + data["name"] + "同学")\n',normalizedContent:'# 基础\n\n"""jupyter notebook 的快捷键: https://www.jianshu.com/p/72493e81a708"""\n# 1. 打印关键字\nimport keyword\nprint(keyword.kwlist)\n\n# 2. 打印语句\nprint("hello\\\n\tpython\\\n\thello\\\n\tworld")\n\n\n# 3.变量不需声明  变量赋值为任意类型(动态语言)\na = 12\nprint(f"a:{a} type:{type(a)}")\n\na = "python"\nprint("a:", a, "type:", type(a))\n\n# 输出对象地址\nprint(id(a))\ndel a\n# print(a)\n\n\n# 4. input 和 字符串连接\nname = "john"\n# + 连接\nmes1 = name + " is a coder"\n# ,连接\nmes2 = name, " is a coder"\nprint(name, " is a coder")\n# .join连接\nmes3 = " ".join(mes2)\n# 格式化\nmes4 = "%s and %s is a coder" % (name, "smith")\n# f("{}")\nmes5 = f"{name} is a coder"\n\nprint(f"{mes1}\\n{mes2}\\n{mes3}\\n{mes4}\\n{mes5}")\ndel mes1, mes2, mes3, mes4, mes5\n\n\n# 5.input\nname = input("请输入姓名:")\nprint("hello", name)\n\n\n\n# 流程控制\n\n\'\'\' 流程控制 1 \'\'\'\n# 6. 函数\ndef run():\n        print("car started...")\n        pass\n\ndef stop():\n        print("car stopped...")\n        pass\n\ndef error():\n        print("i can\'t understand...")\n        pass\n\n# 7. 分支\n        # ==： 用来判断两个对象的值是否相等\n        # is: 判断两个变量是否引用的是同一个对象，底层判断的依据是两个变量的id是否相等\nstatus = "stop"\ndef message(mes):\n        # 声明 status 为全局变量\n        global status\n        if mes in "start" and status in "stop":\n            run()\n            status = "start"\n        elif mes == "stop" and status == "start":\n            stop()\n            status = "stop"\n        elif mes in "start" and status in "start":\n            print("car is already started")\n        elif mes in "stop" and status in "stop":\n            print("car is already stopped")\n        else:\n            error()\n\n# 8. 循环\n\nwhile true:\n        order = input("请输入命令:")\n        if order not in ["end", "end"]:\n            message(order)\n        else:\n            print("finish")\n            break\ndel status\n\n\n点击查看\n\n练习\n\n\'\'\' 流程控制 2 \'\'\'\n# 9 * 9 乘法表\nfor i in range(1, 10, 1):\n    for j in range(1, i+1):\n        print(f"{i} * {j} = {i * j}", end="\\t")\n    print()\n\n\'\'\'斐波那契数列\'\'\'\ndef fibonacci(n):\n    if n==1 or n==2:\n        return 1\n    return fibonacci(n-1) + fibonacci(n-2)\n\nfor i in range(1, 20):\n    print(fibonacci(i), end=" ")\n    \nfibonacci(10)\n\n\'\'\'素数\'\'\'\nimport math\n\ndef sushu(start, end):\n    # 去掉1 0\n    if start<2:\n        start=2\n    # 定义返回结果\n    result= []\n    for i in range(start, end+1):\n        # 默认都是素数\n        flag = false\n        #从2作为除数开始判断当前数是否能够被除1和本身的其他数整除\n        for j in range(2, int(math.sqrt(i)+1)): \n            # 如果能被2或者小于自己的数整除，这不是素数，改变flag为true\n            if i%j == 0:\n                flag = true\n                break\n        if flag == false:\n            result.append(i)\n    return result\n\nresult = sushu(0,101)\nprint(len(result))\nprint(result)\n\n\'\'\'输入某年某月某日，判断这一天是这一年的第几天\'\'\'\n#输入某年某月某日，判断这一天是这一年的第几天？\n\n\ndef outter(func):\n    def inner():\n        year = int(input("请输入一个年份:"))\n        # global year\n        if year % 100 != 0 and year % 4 == 0 or year % 400 == 0:\n            print("%d是闰年"%year)\n            dict1[2]=29\n            func()\n        else:\n            print("%d是平年"%year)\n            func()\n    return inner\n\ndict1 ={1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:30,9:31,10:31,11:30,12:31}\n@outter\ndef f():\n    ymd2 = input("输入年-月-日[year-month-day]:")\n    ymd1 =ymd2.split(\'-\')\n    day =0\n    for x in range(1,int(ymd1[1])):\n        day += dict1[x]\n    day = day+int(ymd1[2])\n    print("这一天是这一年的第%d天"%day)\n\nf()\n\n\n\'\'\'时间转换\'\'\'\nimport datetime\n\n# 输入时间\ninput_time = input("请输入时间(%y-%m-%d):")  # input_time = "2020-7-3"\n# 字符串转为时间\nend_time = datetime.datetime.strptime(input_time, \'%y-%m-%d\')\n# 拼接上一年最后一天的时间\nstart_time = datetime.datetime.strptime(str(end_time.year-1) + "-12-31", \'%y-%m-%d\')\n# 时间相减 得到天数\n(end_time-start_time).days\n\n\'\'\'时间转换2\'\'\'\n# 接收输入的信息，并拆分成年月日变量\nyear = int(input(\'year:\\n\'))\nmonth = int(input(\'month:\\n\'))\nday = int(input(\'day:\\n\'))\n# 预定义每个月对应年的第几天\nmonths = (0,31,59,90,120,151,181,212,243,273,304,334)\nif 0 < month <= 12:\n    # 第几天用sum变量表示，并初始化为months数组对应的天数\n    sum = months[month-1]\nelse:\n    print(\'data error\')\n# 添加day所代表的天数\nsum += day\n# 闰年标记\nleap = 0\n# 判断是否为闰年\nif year % 400 == 0 or year % 4 == 0 and year % 100 != 0:\n    leap = 1\n    # 如果是闰年，总天数需要加一天\n    if leap == 1 and month > 2:\n        sum += 1       \nprint(\'it is the %dth day.\' % sum)\n\n\n\n\n# 数据类型\n\n\n# 序列数据类型 list(列表)\n\n"""序列数据类型  list(列表)"""\n\n\n# 创建 1.python列表可以存储任意类型的对象 2.按照顺序存储\nmy_list = [1.0, "python", true, none, print, list(range(0, 10, 3))]\nprint(type(my_list), end="类型\\t")\nprint(len(my_list), end="长度\\n")\n\n# 访问\nprint(f"{my_list[4]}\\t{my_list[-1]}")\ndel my_list\n\n# 遍历\nlist1 = ["john", "smaith", "tom", "lily", "jim"]\nfor elem in list1:\n    print(elem, end="\\t")\n    \n# 修改\n## 修改值\nlist1[2] = "nicai"\n## 追加\nlist1.append("last")\n## 插入\nlist1.insert(1, "first")\n# list1\n\n# 删除\n# del list1[1]\n## 删除并取出\n# str = list1.pop(3)\n# str\n## 指定值删除\n# list.remove("nicai")\n## 查找下标\n# list1.index("first")\n\n# 排序\n## 临时排序\nprint(sorted(list1))\n## 永久排序\n# list1.sort()\n# list1\n## 列表倒序\nlist2 = sorted(list1)\nlist2.reverse()\nlist2\n\n# 切片 1.语法: 列表[起始:结束:步长] \nstus = [\'孙悟空\',\'猪八戒\',\'沙和尚\',\'唐僧\',\'蜘蛛精\',\'白骨精\']\nstus[0: 5: 2]\n\n\n\n# 序列数据类型 tuple(元组)\n\n"""序列数据类型  tuple(元组)"""\n### 元组 1.类似list 2.属于不可变序列  ###\nlist3 = list(range(0, 10, 3))\n# 元组不可变 但其中元素可以变\ntuple1 = ("hello", "python", list3)\nfor elem in tuple1:\n    print(elem, end=" ")\n\ntuple1[2][1] = 123\ntuple1\n\n\n\n# 序列数据类型 set(集合)\n\n"""序列数据类型  set(集合)"""\n### set集合 无序不重复\n## 创建空集合\nset1 = set()\n## list转化为set\nset1 = set(list(range(0, 10, 3)))\nprint(set1)\n\na_set = {-1, -3, 2, 3, 5}\nb_set = {2, 3, 5, 25, 36}\n## 交集\nprint( a_set.union(b_set) )\nprint( a_set | b_set )\n\n## 并集\nprint( a_set.intersection(b_set) )\nprint( a_set & b_set )\n\n## 差集\nprint( a_set.difference(b_set) )\n\n## 集合异或\nprint( a_set ^b_set )\n\n\n\n# 序列数据类型 dictionary(字典)\n\n"""序列数据类型  dictionary(字典) 1.key值唯一"""\n\n# 定义\ndic = { "k1": "v1"}\n# dic = dict([(1, "baidu"), (2, "goole"), (3, "toabao")])\nprint(dic[1])\nprint(dic)\nprint(dic.keys())\ndic.values()\n\n# 修改/新增元素\ndic["k2"] = "v2"\n# 删除元素\ndel dic["k2"]\ndic.clear()      # 清空字典所有条目\ndel dic          # 删除字典\n\n\n\n# 函数和类\n\n\n# 函数参数和返回值的类型\n\n"""函数参数和返回值的类型 200124"""\n### 顺序实参\ndef info(heroname, petname):\n    print("英雄名字:{" + heroname + "}\\t宠物名字:{" + petname + "}")\ninfo("德鲁伊", "龙狼")\n\n### 位置实参\ninfo(petname="龙狼", heroname = "德鲁伊")\n\n### 默认值\ndef info2(heroname, petname="烈焰神虎", attack="5680"):\n    print(f"英雄名字:{heroname}\\t宠物名字:{petname}\\t攻击力{attack}")\ninfo2("苍瞳")\ninfo2(heroname="苍瞳", attack="12345")\n\n### 任意数量的参数\ndef fun1(*p):\n    print(p)\nfun1(0, 1)\n\n### 任意数量关键字参数\ndef fun2(**p):\n    for elem in p.items():\n        print( elem, end="\\t" )\nfun2(x=1, y=2, z=3)\n\n### 通过 **来对一个字典进行解包操作\ndef fun3(name, info):\n    print(f"name={name} \\t info={info}")\ndic = { "name":"酒神", "info":"阴阳冕" }\nfun3(**dic)\n\n### 单值返回\ndef info2(heroname, petname="烈焰神虎", attack="5680"):\n    return f"英雄名字:{heroname}\\t宠物名字:{petname}\\t攻击力{attack}"\nprint( info2("苍瞳") )\n\n### 多值返回\ndef arithmetic1(x, y):\n    add = x+y\n    subtract= x-y \n    multiply= x*y\n    if y != 0:\n        divide= x/y\n    else:\n        print("除数不能为零")\n    return add, subtract, multiply, divide\n\n#eval()将字符串str当成有效的表达式来求值并返回计算结果\nnum1,num2=eval(input("请输入需要计算的两个数字："\'\\n\'))\n# num1=int(num1)\n# num2=int(num2)\na,s,m,d = arithmetic1(num1, num2)\nprint(f"{num1} + {num2} = {a}\\t{num1} - {num2} = {s}\\t{num1} * {num2} = {a}\\t{num1} / {num2} = {d}")\n\n### 模块\n## 引入模块\n# from data import cycle\n## 引入函数 并起别名\n# from data.cycle import sphere_surface_area as ssa\n##引入模块 起别名\nfrom data import cycle as cy\nradius = 2\nprint(f"圆面积: {cy.area(radius)}\\t圆周长:{cy.circumference(radius)}\\t \\\n        球体积:{cy.sphere_volume(radius)}\\t球表面积:{cy.sphere_surface_area(radius)}")\n\n# 常用库\n\n\n\n# 类的练习\n\n""" 9.类的练习 """\nclass mammal:\n    #_init_是一个特殊的方法，类的实例化操作会自动为新创建的类实例调用_init_()方法\n    # name为实例属性\n    def __init__(self,name):\n        self.name = name\n\n    #类的方法至少有一个参数self且必须是第一个参数\n    def walk(self):\n        print(f\'{self.name} walking\')\n        \n    def shout(self):\n        print(f\'{self.name} shouting\')\n        \n        \nclass dog(mammal):\n    print(\'===============dog===============\')\n    # 类属性\n    action = "摇尾巴"\n    def shout(self):\n        print(f\'{self.name} 汪汪\')\n        \n\nclass cat(mammal):\n    print(\'===============cat===============\')\n    pass\n\n\nmammal = mammal(\'哺乳动物\')\nmammal.walk()\nmammal.shout()\n\ncat = cat(\'喵喵\')\ncat.walk()\ncat.shout()\n\ndog = dog(\'二哈\')\ndog.walk()\ndog.shout()\ndog.action = "喝水"\nprint(dog.name + "在" + dog.action)\n\n\n"""类的练习2"""\nclass car():\n    \'\'\'模拟汽车的类\'\'\'\n    def __init__(self, make, model, year):\n        # 初始化属性\n        self.make = make #制造商\n        self.model = model #型号\n        self.year = year #生产年份\n        self.odometer_reading = 0\n        \n    def base_message(self):\n        # 汽车描述信息\n        cmessage = f"{self.make} {self.model} {self.year}"\n        return cmessage.title()\n    \n    def read_odometer(self):\n        # 打印里程信息\n        print(f"this car has {self.odometer_reading} miles on it")\n        \n    def update_odometer(self, miles):\n        # 修改里程信息 不能调小\n        if self.odometer_reading < miles:\n            self.odometer_reading = miles\n        else:\n            print("您不能调小里程数")\n            \n    def increment_odometer(self, miles):\n        # 增加里程数\n        self.odometer_reading += miles\n    \n    \ncar = car("audo", "a6", 2016)\nprint(car.base_message())\ncar.read_odometer()\n## 直接修改属性\ncar.odometer_reading = 21\ncar.read_odometer()\n## 方法修改\ncar.update_odometer(20)\ncar.read_odometer()\ncar.update_odometer(50)\ncar.read_odometer()\n## 增加里程数\ncar.increment_odometer(10)\ncar.read_odometer()\n\n\nclass electriccar(car):\n    """电动车"""\n    def __init__(self, make, model, year, battery_size):\n        super().__init__(make, model, year)\n        self.battery_size = battery_size\n        \n    def desctibe_battery(self):\n        # 属于电池容量的信息\n        print(f"this  car has a {self.battery_size} -kwh battery")\n        \n    def base_message(self):\n        return "electriccar:" + super().base_message()\n    \n\nele_car = electriccar("tesla", "model s", 2017, 70)\nprint(ele_car.base_message())\nele_car.desctibe_battery()\n\n\n\n# 测试\n\n\n# 手工测试\n\n# 手工测试  函数\nfrom data.mypythonfuntest import get_formatted_name as gfn\nprint("enter \'q\' at any time to quit." )\nwhile true:\n    first = input("\\nplease give me a first name:")\n    if first in "q":\n        break\n    last = input("please give me a last name:")\n    if last == "q":\n        break\n    formatted_name = gfn(first, last)\n    print("\\tneatly foematted name:" + formatted_name + ".")\n\n\n\n# 代码测试工具unittest\n\n"""代码测试工具 unittest 单元测试(函数)"""\n"""\nunittest 无法运行 :\n    https://blog.csdn.net/u012291393/article/details/78636502\n    https://www.liaoxuefeng.com/discuss/969955749132672/1203224296196800\n"""\nimport unittest\nfrom data.mypythonfuntest import get_formatted_name\n\nclass namestestcase(unittest.testcase):\n    """测试data.mypythonfuntest.get_formatted_name"""\n    \n    def test_first_last_name(self):\n        """能够正确处理包含姓和名的情况"""\n        formatted_name = get_formatted_name("jim", "green")\n#         self.assertequal(formatted_name, "jim green")\n        self.assertequal(formatted_name, "jim green")\n    \n    def test_first_last_middle_name(self):\n        """能够正确处理包含姓. 名和中间名的情况"""\n        formatted_name = get_formatted_name("martin", "king", "luther")\n        self.assertequal(formatted_name, "martin luther king")\n        \n        \n# 在jupter不好使\n# unittest.main()\nif __name__ == \'__main__\':\n    unittest.main(argv=[\'first-arg-is-ignored\'], exit=false)\n\n\n"""代码测试工具 unittest 单元测试(类)"""\nfrom data.mypythonfuntest import area\nimport unittest  \n  \nclass areatestcase(unittest.testcase):  \n    def setup(self):  \n        self.area = area()  \n      \n    def teardown(self):  \n        self.area = none  \n      \n    def testarea(self):  \n        self.assertequal(self.area.getarea(),10000)  \n      \n    def testwidth(self):  \n        self.area.setwidth(10)  \n        self.assertequal(self.area.getwidth(),10)\n        \n    def testlength(self):  \n        self.area.setlenth(10)  \n        self.assertequal(self.area.getlength(),10)  \n  \nif __name__ == "__main__":  \n    unittest.main(argv=[\'first-arg-is-ignored\'], exit=false)  \n\n\n\n# 文件读写\n\n\n# 文件读取\n\n"""文件读取"""\n"""\nwith 语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，\n比如文件使用后自动关闭／线程中锁的自动获取和释放等\n"""\nfilepath = r"data\\hello.txt"\n\n# 传统模式\n# try:\n#     file = open(filename, \'r\', encoding=\'utf-8\')\n#     contents = file.read()\n#     print(contents)\n#     file.close()\n# except filenotfounderror:\n#     print("文件不存在")\n# else:\n#     print("文件读取成功")\n\n# 用 with 方式\n# with open(filename, \'r\', encoding=\'utf-8\') as file:\n#     contents = file.read()\n#     print(contents.rstrip()) # rstrip() 删除文件末尾的空白\n    \n# 单行读取\n# with open(filename, \'r\', encoding=\'utf-8\') as file:\n#     lines = file.readlines() # 读取全部内容 ，并以列表方式返回\n#     for line in lines:\n#         print(line, end="")\n\n# 判断文件是否存在\nimport os\n\nflag = os.path.exists(filepath)\nif flag == true:\n    with open(filename, \'r\', encoding=\'utf-8\') as file:\n        contents = file.read()\n        print(contents.rstrip())\nelse:\n    print("文件不存在")\n\n\n\n# 文件写入\n\n"""文件写入"""\nfilename = r"data/hello.txt"\n\n# "w"把原来的文件覆盖掉\n# with open(filename, \'w\', encoding=\'utf-8\') as file:\n#     # write返回值为写入字符数\n#     contents = file.write("你好世界\\nhello world")\n#     print(contents)\n    \n# "a" 追加  \n# with open(filename, \'a\', encoding=\'utf-8\') as file:\n#     # write返回值为写入字符数\n#     contents = file.write("\\nhello python")\n#     print(contents)\n\n\n"""异常处理"""\n# try:\n#     num1 = eval(input("输入被除数:"))\n#     num2 = eval(input("输入除数:"))\n#     answer = num1/num2\n# except zerodivisionerror:\n#     print("除数不能为零")\n# else:\n#     print("计算结果:" + str(answer))\n\nnum1 = eval(input("输入被除数:"))\nnum2 = eval(input("输入除数:"))\nif(num2 != 0):\n    print(num1/num2)\nelse:\n    print("除数不能为0")\n    pass\n\n\n\n# json数据读写\n\n"""json数据 的读取,存储"""\nimport json\nimport os\n\ndef json_store(filepath):\n    """文件存在什么都不做 文件不存在保存"""\n    # 创建字典\n    dic = {\n        "name":"李雷",\n        "age":20,\n        "addr":"上海"\n    }\n    flag = os.path.exists(filepath)\n    if flag:\n        pass\n    else:\n        # python对象编码成json字符串 dump()编码并存储\n        with open(filepath, \'w\', encoding=\'utf-8\') as file:\n            json.dump(dic, file)\n            print("保存成功")\n\ndef json_read(filepath):\n    """从文件读取"""\n    flag = os.path.exists(filepath)\n    if flag:\n        # 文件读取 json解码为python对象(load)\n        with open(filepath, \'r\', encoding=\'utf-8\') as file:\n            json_obj = json.load(file)\n        return json_obj\n    else:\n        pass\n\nfilepath = r"data\\test.json"\njson_store(filepath)\ndata = json_read(filepath=filepath)\nprint("欢迎" + data["name"] + "同学")\n',charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"SQL练习题",frontmatter:{title:"SQL练习题",date:"2022-03-27T18:50:09.000Z",permalink:"/pages/d5b8e9/",categories:["数据库"],tags:[null]},regularPath:"/03.%E6%95%B0%E6%8D%AE%E5%BA%93/1006.SQL%E7%BB%83%E4%B9%A0%E9%A2%98.html",relativePath:"03.数据库/1006.SQL练习题.md",key:"v-a4ab2664",path:"/pages/d5b8e9/",headers:[{level:3,title:"SQL题目",slug:"sql题目",normalizedTitle:"sql题目",charIndex:2},{level:4,title:"获取上面行的值",slug:"获取上面行的值",normalizedTitle:"获取上面行的值",charIndex:11},{level:4,title:"部门工资和公司比较（未完成）",slug:"部门工资和公司比较-未完成",normalizedTitle:"部门工资和公司比较（未完成）",charIndex:89},{level:4,title:"产品销售分析II",slug:"产品销售分析ii",normalizedTitle:"产品销售分析ii",charIndex:176},{level:4,title:"产品销售分析III",slug:"产品销售分析iii",normalizedTitle:"产品销售分析iii",charIndex:236},{level:4,title:"游戏玩法分析V",slug:"游戏玩法分析v",normalizedTitle:"游戏玩法分析v",charIndex:316},{level:4,title:"销售分析",slug:"销售分析",normalizedTitle:"销售分析",charIndex:178},{level:4,title:"每位学生的最高成绩",slug:"每位学生的最高成绩",normalizedTitle:"每位学生的最高成绩",charIndex:450},{level:4,title:"每日新用户统计",slug:"每日新用户统计",normalizedTitle:"每日新用户统计",charIndex:554},{level:4,title:"报告的记录I",slug:"报告的记录i",normalizedTitle:"报告的记录i",charIndex:632},{level:4,title:"重新格式化部门表",slug:"重新格式化部门表",normalizedTitle:"重新格式化部门表",charIndex:706},{level:4,title:"查询活跃业务",slug:"查询活跃业务",normalizedTitle:"查询活跃业务",charIndex:783},{level:4,title:"用户购买平台",slug:"用户购买平台",normalizedTitle:"用户购买平台",charIndex:893},{level:4,title:"市场分析II",slug:"市场分析ii",normalizedTitle:"市场分析ii",charIndex:968},{level:4,title:"报告的记录II",slug:"报告的记录ii",normalizedTitle:"报告的记录ii",charIndex:1055},{level:4,title:"文章预览I",slug:"文章预览i",normalizedTitle:"文章预览i",charIndex:1127},{level:4,title:"文章预览II",slug:"文章预览ii",normalizedTitle:"文章预览ii",charIndex:1183},{level:4,title:"即时食物配送I",slug:"即时食物配送i",normalizedTitle:"即时食物配送i",charIndex:1241},{level:4,title:"即时食物配送II",slug:"即时食物配送ii",normalizedTitle:"即时食物配送ii",charIndex:1291},{level:4,title:"最后一个能进入电梯的人",slug:"最后一个能进入电梯的人",normalizedTitle:"最后一个能进入电梯的人",charIndex:1349},{level:4,title:"行转列",slug:"行转列",normalizedTitle:"行转列",charIndex:1436},{level:4,title:"月末考试（未完成）",slug:"月末考试-未完成",normalizedTitle:"月末考试（未完成）",charIndex:1457},{level:4,title:"找出连续3天及以上减少碳排放量在100以上的用户",slug:"找出连续3天及以上减少碳排放量在100以上的用户",normalizedTitle:"找出连续3天及以上减少碳排放量在100以上的用户",charIndex:1479}],headersStr:"SQL题目 获取上面行的值 部门工资和公司比较（未完成） 产品销售分析II 产品销售分析III 游戏玩法分析V 销售分析 每位学生的最高成绩 每日新用户统计 报告的记录I 重新格式化部门表 查询活跃业务 用户购买平台 市场分析II 报告的记录II 文章预览I 文章预览II 即时食物配送I 即时食物配送II 最后一个能进入电梯的人 行转列 月末考试（未完成） 找出连续3天及以上减少碳排放量在100以上的用户",content:"# SQL题目\n\n# 获取上面行的值\n\n已知前4列，用sql算出res列，即同一个uid下，上一次is_succ=1 时的 id是谁 (行偏移, 笛卡尔积后过滤)\n\n详情\n\n# 部门工资和公司比较（未完成）\n\n给如下两个表，写一个查询语句，求出在每一个工资发放日，每个部门的平均工资与公司的平均工资的比较结果 （高 / 低 / 相同）。\n\n详情\n\n# 产品销售分析II\n\n编写一个 SQL 查询，按产品 id product_id 来统计每个产品的销售总量\n\n详情\n\n# 产品销售分析III\n\n编写一个SQL查询，报告2019年春季才售出的产品。即仅在2019-01-01至2019-03-31（含）之间出售的商品。\n\n详情\n\n# 游戏玩法分析V\n\n编写一个 SQL 查询，报告每个安装日期、当天安装游戏的玩家数量和第一天的留存时间。\n\n详情\n\n# 销售分析\n\n编写一个SQL查询，报告2019年春季才售出的产品。即仅在2019-01-01至2019-03-31（含）之间出售的商品。\n\n详情\n\n# 每位学生的最高成绩\n\n编写一个 SQL 查询，查询每位学生获得的最高成绩和它所对应的科目，若科目成绩并列，取 course_id 最小的一门。查询结果需按 student_id 增序进行排序。\n\n详情\n\n# 每日新用户统计\n\n编写一个 SQL 查询，以查询从今天起最多 90 天内，每个日期该日期首次登录的用户数。假设今天是 2019-06-30.\n\n详情\n\n# 报告的记录I\n\n编写一条SQL，查询每种 报告理由（report reason）在昨天的报告数量。假设今天是 2019-07-05。\n\n详情\n\n# 重新格式化部门表\n\n编写一个 SQL 查询来重新格式化表，使得新的表中有一个部门 id 列和一些对应 每个月 的收入（revenue）列。\n\n详情\n\n# 查询活跃业务\n\n写一段 SQL 来查询所有活跃的业务。(如果一个业务的某个事件类型的发生次数大于此事件类型在所有业务中的平均发生次数，并且该业务至少有两个这样的事件类型，那么该业务就可被看做是活跃业务。)\n\n详情\n\n# 用户购买平台\n\n写一段 SQL 来查找每天 仅 使用手机端用户、仅 使用桌面端用户和 同时 使用桌面端和手机端的用户人数和总支出金额。\n\n详情\n\n# 市场分析II\n\n写一个 SQL 查询确定每一个用户按日期顺序卖出的第二件商品的品牌是否是他们最喜爱的品牌。如果一个用户卖出少于两件商品，查询的结果是 no 。\n\n详情\n\n# 报告的记录II\n\n编写一段 SQL 来查找：在被报告为垃圾广告的帖子中，被移除的帖子的每日平均占比，四舍五入到小数点后 2 位。\n\n详情\n\n# 文章预览I\n\n请编写一条 SQL 查询以找出所有浏览过自己文章的作者，结果按照 id 升序排列。\n\n详情\n\n# 文章预览II\n\n编写一条 SQL 查询来找出在同一天阅读至少两篇文章的人，结果按照 id 升序排序。\n\n详情\n\n# 即时食物配送I\n\n写一条 SQL 查询语句获取即时订单所占的百分比， 保留两位小数。\n\n详情\n\n# 即时食物配送II\n\n写一条 SQL 查询语句获取即时订单在所有用户的首次订单中的比例。保留两位小数。\n\n详情\n\n# 最后一个能进入电梯的人\n\n写一条 SQL 查询语句查找最后一个能进入电梯且不超过重量限制的 person_name 。题目确保队列中第一位的人可以进入电梯 。\n\n详情\n\n# 行转列\n\n查询为规定的结果\n\n详情\n\n# 月末考试（未完成）\n\n未完成\n\n详情\n\n# 找出连续3天及以上减少碳排放量在100以上的用户\n\n> 连续登录问题\n\n详情",normalizedContent:"# sql题目\n\n# 获取上面行的值\n\n已知前4列，用sql算出res列，即同一个uid下，上一次is_succ=1 时的 id是谁 (行偏移, 笛卡尔积后过滤)\n\n详情\n\n# 部门工资和公司比较（未完成）\n\n给如下两个表，写一个查询语句，求出在每一个工资发放日，每个部门的平均工资与公司的平均工资的比较结果 （高 / 低 / 相同）。\n\n详情\n\n# 产品销售分析ii\n\n编写一个 sql 查询，按产品 id product_id 来统计每个产品的销售总量\n\n详情\n\n# 产品销售分析iii\n\n编写一个sql查询，报告2019年春季才售出的产品。即仅在2019-01-01至2019-03-31（含）之间出售的商品。\n\n详情\n\n# 游戏玩法分析v\n\n编写一个 sql 查询，报告每个安装日期、当天安装游戏的玩家数量和第一天的留存时间。\n\n详情\n\n# 销售分析\n\n编写一个sql查询，报告2019年春季才售出的产品。即仅在2019-01-01至2019-03-31（含）之间出售的商品。\n\n详情\n\n# 每位学生的最高成绩\n\n编写一个 sql 查询，查询每位学生获得的最高成绩和它所对应的科目，若科目成绩并列，取 course_id 最小的一门。查询结果需按 student_id 增序进行排序。\n\n详情\n\n# 每日新用户统计\n\n编写一个 sql 查询，以查询从今天起最多 90 天内，每个日期该日期首次登录的用户数。假设今天是 2019-06-30.\n\n详情\n\n# 报告的记录i\n\n编写一条sql，查询每种 报告理由（report reason）在昨天的报告数量。假设今天是 2019-07-05。\n\n详情\n\n# 重新格式化部门表\n\n编写一个 sql 查询来重新格式化表，使得新的表中有一个部门 id 列和一些对应 每个月 的收入（revenue）列。\n\n详情\n\n# 查询活跃业务\n\n写一段 sql 来查询所有活跃的业务。(如果一个业务的某个事件类型的发生次数大于此事件类型在所有业务中的平均发生次数，并且该业务至少有两个这样的事件类型，那么该业务就可被看做是活跃业务。)\n\n详情\n\n# 用户购买平台\n\n写一段 sql 来查找每天 仅 使用手机端用户、仅 使用桌面端用户和 同时 使用桌面端和手机端的用户人数和总支出金额。\n\n详情\n\n# 市场分析ii\n\n写一个 sql 查询确定每一个用户按日期顺序卖出的第二件商品的品牌是否是他们最喜爱的品牌。如果一个用户卖出少于两件商品，查询的结果是 no 。\n\n详情\n\n# 报告的记录ii\n\n编写一段 sql 来查找：在被报告为垃圾广告的帖子中，被移除的帖子的每日平均占比，四舍五入到小数点后 2 位。\n\n详情\n\n# 文章预览i\n\n请编写一条 sql 查询以找出所有浏览过自己文章的作者，结果按照 id 升序排列。\n\n详情\n\n# 文章预览ii\n\n编写一条 sql 查询来找出在同一天阅读至少两篇文章的人，结果按照 id 升序排序。\n\n详情\n\n# 即时食物配送i\n\n写一条 sql 查询语句获取即时订单所占的百分比， 保留两位小数。\n\n详情\n\n# 即时食物配送ii\n\n写一条 sql 查询语句获取即时订单在所有用户的首次订单中的比例。保留两位小数。\n\n详情\n\n# 最后一个能进入电梯的人\n\n写一条 sql 查询语句查找最后一个能进入电梯且不超过重量限制的 person_name 。题目确保队列中第一位的人可以进入电梯 。\n\n详情\n\n# 行转列\n\n查询为规定的结果\n\n详情\n\n# 月末考试（未完成）\n\n未完成\n\n详情\n\n# 找出连续3天及以上减少碳排放量在100以上的用户\n\n> 连续登录问题\n\n详情",charsets:{cjk:!0},lastUpdated:"2022/07/20, 18:02:04",lastUpdatedTimestamp:1658311324e3},{title:"Python操作Office",frontmatter:{title:"Python操作Office",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/f2a340/",categories:["其他","Python"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/01.Python/02.Python%E6%93%8D%E4%BD%9COffice.html",relativePath:"04.其他/01.Python/02.Python操作Office.md",key:"v-2bc194fa",path:"/pages/f2a340/",headers:[{level:2,title:"修改Excel",slug:"修改excel",normalizedTitle:"修改excel",charIndex:2},{level:3,title:"示例代码",slug:"示例代码",normalizedTitle:"示例代码",charIndex:14},{level:2,title:"读写Word",slug:"读写word",normalizedTitle:"读写word",charIndex:4887},{level:3,title:"文本",slug:"文本",normalizedTitle:"文本",charIndex:4973},{level:3,title:"表格",slug:"表格",normalizedTitle:"表格",charIndex:5971},{level:3,title:"图片",slug:"图片",normalizedTitle:"图片",charIndex:7118},{level:3,title:"文档",slug:"文档",normalizedTitle:"文档",charIndex:7267},{level:3,title:"按顺序读取doc文档",slug:"按顺序读取doc文档",normalizedTitle:"按顺序读取doc文档",charIndex:9018},{level:2,title:"按模版生成Word文档",slug:"按模版生成word文档",normalizedTitle:"按模版生成word文档",charIndex:10684},{level:3,title:"docxtpl",slug:"docxtpl",normalizedTitle:"docxtpl",charIndex:10700},{level:2,title:"按模版生成 Excel 文档",slug:"按模版生成-excel-文档",normalizedTitle:"按模版生成 excel 文档",charIndex:12346},{level:3,title:"xlsxtpl",slug:"xlsxtpl",normalizedTitle:"xlsxtpl",charIndex:12365},{level:2,title:"使用 Python + Mermaid 绘图并插入 Word 文档",slug:"使用-python-mermaid-绘图并插入-word-文档",normalizedTitle:"使用 python + mermaid 绘图并插入 word 文档",charIndex:12428}],headersStr:"修改Excel 示例代码 读写Word 文本 表格 图片 文档 按顺序读取doc文档 按模版生成Word文档 docxtpl 按模版生成 Excel 文档 xlsxtpl 使用 Python + Mermaid 绘图并插入 Word 文档",content:"# 修改Excel\n\n\n# 示例代码\n\n# https://blog.csdn.net/sinat_28576553/article/details/81275650\nimport openpyxl\n\nfilepath = \"D:\\\\Desktop\\\\基础信息(2)(1).xlsx\"\n\n#获取 工作簿对象\nworkbook=openpyxl.load_workbook(filepath)\n#与xlrd 模块的区别\n#wokrbook=xlrd.open_workbook(\"\"DataSource\\Economics.xls)\n\n#获取工作簿 workbook的所有工作表\n# shenames=workbook.get_sheet_names()    # wb['Sheet'] #通过名称获取工作薄\n# print(shenames)  #['各省市', '测试表']\n#在xlrd模块中为 sheetnames=workbook.sheet_names()\n \n#使用上述语句会发出警告：DeprecationWarning: Call to deprecated function get_sheet_names (Use wb.sheetnames).\n#说明 get_sheet_names已经被弃用 可以改用 wb.sheetnames 方法\nshenames=workbook.sheetnames\n# print(shenames)  #['各省市', '测试表']\n\n\n\n\"\"\"\nfor sheetName in shenames: \n    # print(sheetName)\n    #获得工作簿的表名后，就可以获得表对象\n    worksheet=workbook.get_sheet_by_name(sheetName)     # workbook[shenames[1]]\n\"\"\"\nworksheet=workbook.get_sheet_by_name(\"单位基本信息表\")\nprint(worksheet)\n\n\nrows=worksheet.max_row\ncolumns=worksheet.max_column\n\nprint(rows,columns)\n\n\n#设置第一列的宽度\n#sheet.column_dimensions['A'].width = 20.0\n \n# #设置第一行的高度\n# sheet.row_dimensions[1].height = 25.0\n\n#设置（1,1）的单元格的颜色为8E236B， 填充方式用solid(纯色)\nsheet.cell(1,1).fill=PatternFill(fill_type=\"solid\",start_color=\"8E236B\")\n\n#在第一列之前插入一列\nworksheet.insert_cols(1)  #\nworksheet.insert_rows(7)#在第行前面插入一行\n\n# 合并单元格\nfanwei = \"'A{}:B{}'\".format('1','2')\nsheet.merge_cells('A1:B2') #这样可以\nsheet.merge_cells(fanwei) #这样不行\nsheet.merge_cells('A{}:B{}'.format(1,2)) #这样可以？神奇\nsheet.merge_cells('A{}:B{}'.format('1','2')) #这样也行\n\nfrom openpyxl.styles import PatternFill, Border, Side, Font, Alignment\n# 字体\nfont = Font(size=18, bold=True, color=\"1874CD\")\nsheet.cell(row=1, column=1).font = font\n\n# 边框\nthin = Side(border_style=\"thin\", color=\"000000\")\nborder = Border(top=thin, left=thin, right=thin, bottom=thin)\nsheet.cell(row=2, column=2).border = border\n\n# 对齐方式\nsheet.cell(row=2, column=2).alignment = Alignment(horizontal='center', vertical='center')\n\n# 自动换行\nworksheet.cell(row=1, column=1, value=value).alignment = Alignment(wrapText=True)\n\nwk_sheet.cell(row=2,column=2,value='大区') #在第二行，第二列下入“大区”数值\n\n\nwb.close()#关闭\n\n\nimport openpyxl\nfrom openpyxl.styles import Border, Side, Font, Alignment\n\nfile = \"07决算和报告.xlsx\"\n\nfilepath = \"D:\\\\Desktop\\\\技术标准excel\\\\\" + file\ntopath = \"D:\\\\Desktop\\\\技术标准excel\\\\new\\\\test.xlsx\" # + file\n\n#获取 工作簿对象\nworkbook=openpyxl.load_workbook(filepath)\n\n#获取工作簿 workbook的所有工作表\nshenames=workbook.sheetnames\n\nfor sheetName in shenames: \n    #获得工作簿的表名后，就可以获得表对象\n    worksheet=workbook.get_sheet_by_name(sheetName)     # workbook[shenames[1]]\n\n    # 插入两行并修改行高\n    worksheet.insert_rows(2)               #在第行前面插入一行\n    worksheet.insert_rows(2)               #在第行前面插入一行\n\n    # 边框\n    thin = Side(border_style=\"thin\", color=\"000000\")\n    border = Border(top=thin, left=thin, right=thin, bottom=thin)\n    worksheet.cell(row=2, column=1).border = border\n    worksheet.cell(row=3, column=1).border = border\n\n    # 字体\n    font = Font(size=16, bold=True, color=\"000000\")\n    font2 = Font(size=10.5, bold=True, color=\"000000\")\n    worksheet.cell(row=2, column=1).font = font\n    worksheet.cell(row=3, column=1).font = font\n    worksheet.cell(row=4, column=9).font = font2\n    worksheet.cell(row=4, column=10).font = font2\n    worksheet.cell(row=4, column=11).font = font2\n\n    # 自动换行\n    worksheet.cell(row=4, column=9).alignment = Alignment(horizontal='center', vertical='center', wrapText=True)\n    worksheet.cell(row=4, column=10).alignment = Alignment(horizontal='center', vertical='center', wrapText=True)\n    worksheet.cell(row=4, column=11).alignment = Alignment(horizontal='center', vertical='center', wrapText=True)\n    worksheet.cell(row=2, column=1).alignment = Alignment(horizontal='center', vertical='center', wrapText=True)\n    worksheet.cell(row=3, column=1).alignment = Alignment(horizontal='center', vertical='center', wrapText=True)\n\n    worksheet.row_dimensions[2].height = 37.2  #设置第行的高度\n    worksheet.row_dimensions[3].height = 37.2  #设置第行的高度\n    worksheet.row_dimensions[4].height = 67.1  #设置第行的高度\n\n    worksheet.column_dimensions['I'].width = 30.0\n    worksheet.column_dimensions['J'].width = 30.0\n    worksheet.column_dimensions['K'].width = 35.0\n\n    #worksheet.merge_cells('A1:K1')\n    worksheet.merge_cells('A2:K2')\n    worksheet.merge_cells('A3:K3')\n\n    worksheet.cell(row=2,column=1,value='请结合系统实现，详细描述本表的使用说明（业务场景、业务环节对表的具体操作、与其他表的配合使用、存储的具体内容）：')\n    worksheet.cell(row=3,column=1,value='请填写是否有其他需要修改的内容：')\n    worksheet.cell(row=4,column=9,value='是否必填（数据库设置要求）')\n    worksheet.cell(row=4,column=10,value='结合系统实现，详细描述字段的使用说明')\n    worksheet.cell(row=4,column=11,value='对字段的修改建议（1是如建议“新增”或“删除”字段，请注明“新增”或“删除”。2是对已有字段长度、值域、备注等信息提出修改建议）')\n\n    for row in range(4, worksheet.max_row + 1) :\n        worksheet.cell(row=row, column=9).border = border\n        worksheet.cell(row=row, column=10).border = border\n        worksheet.cell(row=row, column=11).border = border\n\n\nworkbook.save(topath) \n\nworkbook.close()#关闭\n\n\n\n# 读写Word\n\n前提：\n\n# 导入包\nfrom docx import Document\nfrom docx.shared import Inches  #英寸\n\n\n\n# 文本\n\n * 文本操作（基础）\n\n# 在末尾添加段落\nparagraph = document.add_paragraph('Lorem ipsum dolor sit amet.')\n# 在标识之前添加段落\nprior_paragraph = paragraph.insert_paragraph_before('Lorem ipsum')\n# 添加标题（默认1级）\ndocument.add_heading('The REAL meaning of the universe')\n# 添加2级标题\ndocument.add_heading('The role of dolphins', level=2)\n# 添加分页符\ndocument.add_page_break()\n\n\n\n * 段落样式\n\n# 添加段落时设置样式\ndocument.add_paragraph('Lorem ipsum dolor sit amet.', style='ListBullet')\n\n# 添加段落后设置样式\nparagraph = document.add_paragraph('Lorem ipsum dolor sit amet.')\nparagraph.style = 'List Bullet'\n\n# 通过run的两个属性来设置粗体和斜体\nparagraph = document.add_paragraph('Lorem ipsum ')\nrun = paragraph.add_run('dolor')\nrun.bold = True # == paragraph.add_run('dolor').bold = True\nparagraph.add_run(' sit amet.')\n\n\n\n * 字体样式\n\nparagraph = document.add_paragraph('Normal text, ')\nparagraph.add_run('text with emphasis.', 'Emphasis')\n\n# 等价于\n\nparagraph = document.add_paragraph('Normal text, ')\nrun = paragraph.add_run('text with emphasis.')\nrun.style = 'Emphasis'\n\n\n\n# 表格\n\n * 表格操作（基础）\n\n# 添加一个2行2列的表格\ntable = document.add_table(rows=2, cols=2)\n# 获取单元格\ncell = table.cell(0, 1)\n# 单元格赋值\ncell.text = 'parrot, possibly dead'\n# 获取一行\nrow = table.rows[1]\n# 添加一行\nrow = table.add_row()\n# 添加样式\ntable.style = 'LightShading-Accent1'\n\n\n\n示例：将数组的数据放入表格\n\n# get table data -------------\nitems = (\n(7, '1024', 'Plush kittens'),\n(3, '2042', 'Furbees'),\n(1, '1288', 'French Poodle Collars, Deluxe'),\n\n# add table ------------------\ntable = document.add_table(1, 3)\n# populate header row --------\nheading_cells = table.rows[0].cells\nheading_cells[0].text = 'Qty'\nheading_cells[1].text = 'SKU'\nheading_cells[2].text = 'Description'\n# add a data row for each item\nfor item in items:\ncells = table.add_row().cells\ncells[0].text = str(item.qty)\ncells[1].text = item.sku\ncells[2].text = item.desc\n\n\n * 读取表格\n\npath = \"text\\\\预算管理一体化地债系统数据库设计(代码集).docx\"\ndocument = Document(path)  # 读入文件\ntables = document.tables   # 获取文件中的表格集\ntable = tables[1]  # 获取文件中的第一个表格\n\n# 遍历表格内容\nfor i in range(0, len(table.rows)):  # 从表格第一行开始循环读取表格数据\n    for j in range(0, len(table.columns)):\n        print(table.cell(i,j).text, end = '\\t')\n    print('', end = '\\n')\n\n\n\n# 图片\n\n * 图片操作（基础）\n\n# 添加图片\ndocument.add_picture('image-filename.png')\n# 添加图片时设置图片大小\ndocument.add_picture('image-filename.png', width=Inches(1.0))\n\n\n\n\n# 文档\n\n * 文档操作（基础）\n\n# 新建文件\nfrom docx import Document\ndocument = Document()\ndocument.save('test.docx')\n\n# 流式读写？？？\nf = open('foobar.docx', 'rb')\ndocument = Document(f)\nf.close()\n\n\nwith open('foobar.docx', 'rb') as f:\nsource_stream = StringIO(f.read())\ndocument = Document(source_stream)\nsource_stream.close()\n...\ntarget_stream = StringIO()\ndocument.save(target_stream)\n\n\n * 文本对齐\n\n# 从父级元素继承\nfrom docx.enum.text import WD_ALIGN_PARAGRAPH\ndocument = Document()\nparagraph = document.add_paragraph()\nparagraph_format = paragraph.paragraph_format\nparagraph_format.alignment\n# None# indicating alignment is inherited from the style hierarc\n\n# 从对象获取值\nparagraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\nparagraph_format.alignment\n# CENTER (1)\n\n\n * 左右（首行）缩进\n\n# 左缩进\nfrom docx.shared import Inches\nparagraph = document.add_paragraph()\nparagraph_format = paragraph.paragraph_format\nparagraph_format.left_indent\n# None # indicating indentation is inherited from the style hierarchy\nparagraph_format.left_indent = Inches(0.5)\nparagraph_format.left_indent\n# 457200\nparagraph_format.left_indent.inches\n# 0.5\n\n# 右缩进\nfrom docx.shared import Pt\nparagraph_format.right_indent\n# None\nparagraph_format.right_indent = Pt(24)\nparagraph_format.right_indent\n# 304800\nparagraph_format.right_indent.pt\n# 24.0\n\n\n# 首行缩进\nparagraph_format.first_line_indent\n#None\nparagraph_format.first_line_indent = Inches(-0.25)\nparagraph_format.first_line_indent\n# -228600\nparagraph_format.first_line_indent.inches\n# -0.25\n\n\n * 制表符（见文档）\n * 段间距（见文档）\n * 行间距（见文档）\n * 分页（见文档）\n * 字体格式和颜色（见文档）\n\nfrom docx import Document\ndocument = Document()\nrun = document.add_paragraph().add_run()\nfont = run.font\n\nfrom docx.shared import Pt\nfont.name = 'Calibri'\nfont.size = Pt(12)\n\n\n * sections（见文档）\n * 页眉页脚（见文档）\n\n\n# 按顺序读取doc文档\n\nimport os\nimport docx\n\nfrom docx.document import Document\nfrom docx.oxml.table import CT_Tbl\nfrom docx.oxml.text.paragraph import CT_P\nfrom docx.table import _Cell, Table\nfrom docx.text.paragraph import Paragraph\n\n\ndef iter_block_items(parent):\n    \"\"\"\n    Yield each paragraph and table child within *parent*, in document order.\n    Each returned value is an instance of either Table or Paragraph. *parent*\n    would most commonly be a reference to a main Document object, but\n    also works for a _Cell object, which itself can contain paragraphs and tables.\n    \"\"\"\n    if isinstance(parent, Document):\n        parent_elm = parent.element.body\n    elif isinstance(parent, _Cell):\n        parent_elm = parent._tc\n    else:\n        raise ValueError(\"something's not right\")\n\n    for child in parent_elm.iterchildren():\n        if isinstance(child, CT_P):\n            yield Paragraph(child, parent)\n        elif isinstance(child, CT_Tbl):\n            yield Table(child, parent)\n\n\ndef read_table(table):\n    return [[cell.text for cell in row.cells] for row in table.rows]\n\n\ndef read_word(word_path):\n    doc = docx.Document(word_path)\n    for block in iter_block_items(doc):\n        if isinstance(block, Paragraph):\n            print(\"text\", [block.text])\n        elif isinstance(block, Table):\n            print(\"table\", read_table(block))\n\n\nif __name__ == '__main__':\n    ROOT_DIR_P = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))  # 项目根目录\n    word_path = os.path.join(ROOT_DIR_P, \"data/test_to_word.docx\")  # pdf文件路径及文件名\n    # word_path = os.path.join(ROOT_DIR_P, \"data/test_to_word2.docx\")  # pdf文件路径及文件名\n    read_word(word_path)\n\n\n\n\n# 按模版生成Word文档\n\n\n# docxtpl\n\n第三方库官网 （遵循 jinja2 模板的语法）\n参考模版 python-docx-template\n\n测试脚本\n\nimport json\nfrom docxtpl import DocxTemplate\n\n# 指定JSON文件的路径\njson_file_path = 'conf/doc_data.json'\nres_doc_path = \"files/my_word_template_res.docx\"\ndoc = DocxTemplate(\"conf/my_word_template.docx\")\n\n# 读取JSON文件并将其内容解析为字典\nwith open(json_file_path, 'r', encoding='utf-8') as file:\n    context = json.load(file)\ndoc.render(context)\ndoc.save(res_doc_path)\n\n\n测试数据\n\n{\n  \"name\": \"名称\",\n  \"rtext\": \"富文本__\\n_&\",\n  \"special\": \"R('转义_ _<>_&')\",\n  \"fruits\": [\"Apple\", \"Banana\", \"Cherry\"],\n  \"display_paragraph\":true,\n  \"Paragraphs\" : [\n    {\n      \"name\": \"段落 2.1\",\n      \"table_name\": \"table_name1\",\n      \"table_fields\": [\"id\", \"name\", \"age\", \"gender\"],\n      \"table_data\": [\n        {\"id\": \"1\", \"name\": \"张三\", \"age\": \"20\", \"gender\": \"男\"},\n        {\"id\": \"2\", \"name\": \"李四\", \"age\": \"21\", \"gender\": \"女\"},\n        {\"id\": \"3\", \"name\": \"王五\", \"age\": \"22\", \"gender\": \"男\"}\n      ]\n    },\n    {\"name\":\"段落 2.2\"}\n  ]\n}\n\n\n测试模版（word）\n\n------------- 循环\n{% for fruit in fruits %}\n- {{ fruit }}\n{% endfor %}\n\n\n------------- 段落\n{% set paragraph %}\nThis is a new paragraph that we want to insert. It can contain multiple sentences.\n{% endset %}\n\n{{ paragraph }}\n\n------------- 判断\n{%p if display_paragraph %}\nHere is my paragraph\n{%p endif %}\n\n\n------------- 拼接行\n1111\n{%- if display_paragraph -%}\n2222\n{%- else -%}\n3333\n{%- endif -%}\n9999\n\n\n------------- 循环段落（嵌套内容）\n{% for Paragraph in Paragraphs %}\n{{ Paragraph.name }}\n{{ Paragraph.table_name }}\n\nid  name    age Gender\n{%tr for row in Paragraph. table_data %}\n{{ row.id }}    {{ row.name }}  {{ row.age }}   {{ row.gender }}\n{%tr endfor %}\n\n{% endfor %}\n\n\n\n\n# 按模版生成 Excel 文档\n\n\n# xlsxtpl\n\n第三方库官网\nxlsxtpl 使用 jinja2 作为其模板引擎，遵循 jinja2 模板的语法。\n\n\n# 使用 Python + Mermaid 绘图并插入 Word 文档\n\n使用 nodejs 安装 mermaid-cli，通过 Python 代码调用客户端生成图片保存到磁盘，再将磁盘图片插入到 Word 文档\n\n 1. 安装 mermaid-cli npm install -g @mermaid-js/mermaid-cli\n 2. 代码示例\n\nimport subprocess\nfrom docx import Document\nfrom docx.shared import Inches\nimport os\n\n# 你的Mermaid代码\nmermaid_code = \"\"\"\ngraph TD\n    A[Christmas] --\x3e|Get money| B(Go shopping)\n    B --\x3e C{Let me think}\n    C --\x3e|One| D[Laptop]\n    C --\x3e|Two| E[iPhone]\n    C --\x3e|Three| F[Car]\n\"\"\"\n\n# 将Mermaid代码写入临时文件\nwith open('temp.mmd', 'w') as file:\n    file.write(mermaid_code)\n\nmmscpath = \"D:\\\\Program Files\\\\nodejs\\\\npm_global\\\\mmdc.cmd\"\n# 使用Mermaid CLI将Mermaid代码转换为SVG\n# subprocess.run(['mmdc', '-i', 'temp.mmd', '-o', 'temp.svg'])\nsubprocess.run([mmscpath, '-i', 'temp.mmd', '-o', 'temp.png'])\n# 创建或加载Word文档\ndoc = Document()\ndoc.add_heading('Mermaid Diagram in Word', 0)\n# 将图片插入到Word文档中\ndoc.add_picture('temp.png', width=Inches(4.0))\n# 保存Word文档\ndoc.save('diagram.docx')\n# 清理临时文件\nos.remove('temp.mmd')\n# os.remove('temp.svg')\nos.remove('temp.png')\n",normalizedContent:"# 修改excel\n\n\n# 示例代码\n\n# https://blog.csdn.net/sinat_28576553/article/details/81275650\nimport openpyxl\n\nfilepath = \"d:\\\\desktop\\\\基础信息(2)(1).xlsx\"\n\n#获取 工作簿对象\nworkbook=openpyxl.load_workbook(filepath)\n#与xlrd 模块的区别\n#wokrbook=xlrd.open_workbook(\"\"datasource\\economics.xls)\n\n#获取工作簿 workbook的所有工作表\n# shenames=workbook.get_sheet_names()    # wb['sheet'] #通过名称获取工作薄\n# print(shenames)  #['各省市', '测试表']\n#在xlrd模块中为 sheetnames=workbook.sheet_names()\n \n#使用上述语句会发出警告：deprecationwarning: call to deprecated function get_sheet_names (use wb.sheetnames).\n#说明 get_sheet_names已经被弃用 可以改用 wb.sheetnames 方法\nshenames=workbook.sheetnames\n# print(shenames)  #['各省市', '测试表']\n\n\n\n\"\"\"\nfor sheetname in shenames: \n    # print(sheetname)\n    #获得工作簿的表名后，就可以获得表对象\n    worksheet=workbook.get_sheet_by_name(sheetname)     # workbook[shenames[1]]\n\"\"\"\nworksheet=workbook.get_sheet_by_name(\"单位基本信息表\")\nprint(worksheet)\n\n\nrows=worksheet.max_row\ncolumns=worksheet.max_column\n\nprint(rows,columns)\n\n\n#设置第一列的宽度\n#sheet.column_dimensions['a'].width = 20.0\n \n# #设置第一行的高度\n# sheet.row_dimensions[1].height = 25.0\n\n#设置（1,1）的单元格的颜色为8e236b， 填充方式用solid(纯色)\nsheet.cell(1,1).fill=patternfill(fill_type=\"solid\",start_color=\"8e236b\")\n\n#在第一列之前插入一列\nworksheet.insert_cols(1)  #\nworksheet.insert_rows(7)#在第行前面插入一行\n\n# 合并单元格\nfanwei = \"'a{}:b{}'\".format('1','2')\nsheet.merge_cells('a1:b2') #这样可以\nsheet.merge_cells(fanwei) #这样不行\nsheet.merge_cells('a{}:b{}'.format(1,2)) #这样可以？神奇\nsheet.merge_cells('a{}:b{}'.format('1','2')) #这样也行\n\nfrom openpyxl.styles import patternfill, border, side, font, alignment\n# 字体\nfont = font(size=18, bold=true, color=\"1874cd\")\nsheet.cell(row=1, column=1).font = font\n\n# 边框\nthin = side(border_style=\"thin\", color=\"000000\")\nborder = border(top=thin, left=thin, right=thin, bottom=thin)\nsheet.cell(row=2, column=2).border = border\n\n# 对齐方式\nsheet.cell(row=2, column=2).alignment = alignment(horizontal='center', vertical='center')\n\n# 自动换行\nworksheet.cell(row=1, column=1, value=value).alignment = alignment(wraptext=true)\n\nwk_sheet.cell(row=2,column=2,value='大区') #在第二行，第二列下入“大区”数值\n\n\nwb.close()#关闭\n\n\nimport openpyxl\nfrom openpyxl.styles import border, side, font, alignment\n\nfile = \"07决算和报告.xlsx\"\n\nfilepath = \"d:\\\\desktop\\\\技术标准excel\\\\\" + file\ntopath = \"d:\\\\desktop\\\\技术标准excel\\\\new\\\\test.xlsx\" # + file\n\n#获取 工作簿对象\nworkbook=openpyxl.load_workbook(filepath)\n\n#获取工作簿 workbook的所有工作表\nshenames=workbook.sheetnames\n\nfor sheetname in shenames: \n    #获得工作簿的表名后，就可以获得表对象\n    worksheet=workbook.get_sheet_by_name(sheetname)     # workbook[shenames[1]]\n\n    # 插入两行并修改行高\n    worksheet.insert_rows(2)               #在第行前面插入一行\n    worksheet.insert_rows(2)               #在第行前面插入一行\n\n    # 边框\n    thin = side(border_style=\"thin\", color=\"000000\")\n    border = border(top=thin, left=thin, right=thin, bottom=thin)\n    worksheet.cell(row=2, column=1).border = border\n    worksheet.cell(row=3, column=1).border = border\n\n    # 字体\n    font = font(size=16, bold=true, color=\"000000\")\n    font2 = font(size=10.5, bold=true, color=\"000000\")\n    worksheet.cell(row=2, column=1).font = font\n    worksheet.cell(row=3, column=1).font = font\n    worksheet.cell(row=4, column=9).font = font2\n    worksheet.cell(row=4, column=10).font = font2\n    worksheet.cell(row=4, column=11).font = font2\n\n    # 自动换行\n    worksheet.cell(row=4, column=9).alignment = alignment(horizontal='center', vertical='center', wraptext=true)\n    worksheet.cell(row=4, column=10).alignment = alignment(horizontal='center', vertical='center', wraptext=true)\n    worksheet.cell(row=4, column=11).alignment = alignment(horizontal='center', vertical='center', wraptext=true)\n    worksheet.cell(row=2, column=1).alignment = alignment(horizontal='center', vertical='center', wraptext=true)\n    worksheet.cell(row=3, column=1).alignment = alignment(horizontal='center', vertical='center', wraptext=true)\n\n    worksheet.row_dimensions[2].height = 37.2  #设置第行的高度\n    worksheet.row_dimensions[3].height = 37.2  #设置第行的高度\n    worksheet.row_dimensions[4].height = 67.1  #设置第行的高度\n\n    worksheet.column_dimensions['i'].width = 30.0\n    worksheet.column_dimensions['j'].width = 30.0\n    worksheet.column_dimensions['k'].width = 35.0\n\n    #worksheet.merge_cells('a1:k1')\n    worksheet.merge_cells('a2:k2')\n    worksheet.merge_cells('a3:k3')\n\n    worksheet.cell(row=2,column=1,value='请结合系统实现，详细描述本表的使用说明（业务场景、业务环节对表的具体操作、与其他表的配合使用、存储的具体内容）：')\n    worksheet.cell(row=3,column=1,value='请填写是否有其他需要修改的内容：')\n    worksheet.cell(row=4,column=9,value='是否必填（数据库设置要求）')\n    worksheet.cell(row=4,column=10,value='结合系统实现，详细描述字段的使用说明')\n    worksheet.cell(row=4,column=11,value='对字段的修改建议（1是如建议“新增”或“删除”字段，请注明“新增”或“删除”。2是对已有字段长度、值域、备注等信息提出修改建议）')\n\n    for row in range(4, worksheet.max_row + 1) :\n        worksheet.cell(row=row, column=9).border = border\n        worksheet.cell(row=row, column=10).border = border\n        worksheet.cell(row=row, column=11).border = border\n\n\nworkbook.save(topath) \n\nworkbook.close()#关闭\n\n\n\n# 读写word\n\n前提：\n\n# 导入包\nfrom docx import document\nfrom docx.shared import inches  #英寸\n\n\n\n# 文本\n\n * 文本操作（基础）\n\n# 在末尾添加段落\nparagraph = document.add_paragraph('lorem ipsum dolor sit amet.')\n# 在标识之前添加段落\nprior_paragraph = paragraph.insert_paragraph_before('lorem ipsum')\n# 添加标题（默认1级）\ndocument.add_heading('the real meaning of the universe')\n# 添加2级标题\ndocument.add_heading('the role of dolphins', level=2)\n# 添加分页符\ndocument.add_page_break()\n\n\n\n * 段落样式\n\n# 添加段落时设置样式\ndocument.add_paragraph('lorem ipsum dolor sit amet.', style='listbullet')\n\n# 添加段落后设置样式\nparagraph = document.add_paragraph('lorem ipsum dolor sit amet.')\nparagraph.style = 'list bullet'\n\n# 通过run的两个属性来设置粗体和斜体\nparagraph = document.add_paragraph('lorem ipsum ')\nrun = paragraph.add_run('dolor')\nrun.bold = true # == paragraph.add_run('dolor').bold = true\nparagraph.add_run(' sit amet.')\n\n\n\n * 字体样式\n\nparagraph = document.add_paragraph('normal text, ')\nparagraph.add_run('text with emphasis.', 'emphasis')\n\n# 等价于\n\nparagraph = document.add_paragraph('normal text, ')\nrun = paragraph.add_run('text with emphasis.')\nrun.style = 'emphasis'\n\n\n\n# 表格\n\n * 表格操作（基础）\n\n# 添加一个2行2列的表格\ntable = document.add_table(rows=2, cols=2)\n# 获取单元格\ncell = table.cell(0, 1)\n# 单元格赋值\ncell.text = 'parrot, possibly dead'\n# 获取一行\nrow = table.rows[1]\n# 添加一行\nrow = table.add_row()\n# 添加样式\ntable.style = 'lightshading-accent1'\n\n\n\n示例：将数组的数据放入表格\n\n# get table data -------------\nitems = (\n(7, '1024', 'plush kittens'),\n(3, '2042', 'furbees'),\n(1, '1288', 'french poodle collars, deluxe'),\n\n# add table ------------------\ntable = document.add_table(1, 3)\n# populate header row --------\nheading_cells = table.rows[0].cells\nheading_cells[0].text = 'qty'\nheading_cells[1].text = 'sku'\nheading_cells[2].text = 'description'\n# add a data row for each item\nfor item in items:\ncells = table.add_row().cells\ncells[0].text = str(item.qty)\ncells[1].text = item.sku\ncells[2].text = item.desc\n\n\n * 读取表格\n\npath = \"text\\\\预算管理一体化地债系统数据库设计(代码集).docx\"\ndocument = document(path)  # 读入文件\ntables = document.tables   # 获取文件中的表格集\ntable = tables[1]  # 获取文件中的第一个表格\n\n# 遍历表格内容\nfor i in range(0, len(table.rows)):  # 从表格第一行开始循环读取表格数据\n    for j in range(0, len(table.columns)):\n        print(table.cell(i,j).text, end = '\\t')\n    print('', end = '\\n')\n\n\n\n# 图片\n\n * 图片操作（基础）\n\n# 添加图片\ndocument.add_picture('image-filename.png')\n# 添加图片时设置图片大小\ndocument.add_picture('image-filename.png', width=inches(1.0))\n\n\n\n\n# 文档\n\n * 文档操作（基础）\n\n# 新建文件\nfrom docx import document\ndocument = document()\ndocument.save('test.docx')\n\n# 流式读写？？？\nf = open('foobar.docx', 'rb')\ndocument = document(f)\nf.close()\n\n\nwith open('foobar.docx', 'rb') as f:\nsource_stream = stringio(f.read())\ndocument = document(source_stream)\nsource_stream.close()\n...\ntarget_stream = stringio()\ndocument.save(target_stream)\n\n\n * 文本对齐\n\n# 从父级元素继承\nfrom docx.enum.text import wd_align_paragraph\ndocument = document()\nparagraph = document.add_paragraph()\nparagraph_format = paragraph.paragraph_format\nparagraph_format.alignment\n# none# indicating alignment is inherited from the style hierarc\n\n# 从对象获取值\nparagraph_format.alignment = wd_align_paragraph.center\nparagraph_format.alignment\n# center (1)\n\n\n * 左右（首行）缩进\n\n# 左缩进\nfrom docx.shared import inches\nparagraph = document.add_paragraph()\nparagraph_format = paragraph.paragraph_format\nparagraph_format.left_indent\n# none # indicating indentation is inherited from the style hierarchy\nparagraph_format.left_indent = inches(0.5)\nparagraph_format.left_indent\n# 457200\nparagraph_format.left_indent.inches\n# 0.5\n\n# 右缩进\nfrom docx.shared import pt\nparagraph_format.right_indent\n# none\nparagraph_format.right_indent = pt(24)\nparagraph_format.right_indent\n# 304800\nparagraph_format.right_indent.pt\n# 24.0\n\n\n# 首行缩进\nparagraph_format.first_line_indent\n#none\nparagraph_format.first_line_indent = inches(-0.25)\nparagraph_format.first_line_indent\n# -228600\nparagraph_format.first_line_indent.inches\n# -0.25\n\n\n * 制表符（见文档）\n * 段间距（见文档）\n * 行间距（见文档）\n * 分页（见文档）\n * 字体格式和颜色（见文档）\n\nfrom docx import document\ndocument = document()\nrun = document.add_paragraph().add_run()\nfont = run.font\n\nfrom docx.shared import pt\nfont.name = 'calibri'\nfont.size = pt(12)\n\n\n * sections（见文档）\n * 页眉页脚（见文档）\n\n\n# 按顺序读取doc文档\n\nimport os\nimport docx\n\nfrom docx.document import document\nfrom docx.oxml.table import ct_tbl\nfrom docx.oxml.text.paragraph import ct_p\nfrom docx.table import _cell, table\nfrom docx.text.paragraph import paragraph\n\n\ndef iter_block_items(parent):\n    \"\"\"\n    yield each paragraph and table child within *parent*, in document order.\n    each returned value is an instance of either table or paragraph. *parent*\n    would most commonly be a reference to a main document object, but\n    also works for a _cell object, which itself can contain paragraphs and tables.\n    \"\"\"\n    if isinstance(parent, document):\n        parent_elm = parent.element.body\n    elif isinstance(parent, _cell):\n        parent_elm = parent._tc\n    else:\n        raise valueerror(\"something's not right\")\n\n    for child in parent_elm.iterchildren():\n        if isinstance(child, ct_p):\n            yield paragraph(child, parent)\n        elif isinstance(child, ct_tbl):\n            yield table(child, parent)\n\n\ndef read_table(table):\n    return [[cell.text for cell in row.cells] for row in table.rows]\n\n\ndef read_word(word_path):\n    doc = docx.document(word_path)\n    for block in iter_block_items(doc):\n        if isinstance(block, paragraph):\n            print(\"text\", [block.text])\n        elif isinstance(block, table):\n            print(\"table\", read_table(block))\n\n\nif __name__ == '__main__':\n    root_dir_p = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))  # 项目根目录\n    word_path = os.path.join(root_dir_p, \"data/test_to_word.docx\")  # pdf文件路径及文件名\n    # word_path = os.path.join(root_dir_p, \"data/test_to_word2.docx\")  # pdf文件路径及文件名\n    read_word(word_path)\n\n\n\n\n# 按模版生成word文档\n\n\n# docxtpl\n\n第三方库官网 （遵循 jinja2 模板的语法）\n参考模版 python-docx-template\n\n测试脚本\n\nimport json\nfrom docxtpl import docxtemplate\n\n# 指定json文件的路径\njson_file_path = 'conf/doc_data.json'\nres_doc_path = \"files/my_word_template_res.docx\"\ndoc = docxtemplate(\"conf/my_word_template.docx\")\n\n# 读取json文件并将其内容解析为字典\nwith open(json_file_path, 'r', encoding='utf-8') as file:\n    context = json.load(file)\ndoc.render(context)\ndoc.save(res_doc_path)\n\n\n测试数据\n\n{\n  \"name\": \"名称\",\n  \"rtext\": \"富文本__\\n_&\",\n  \"special\": \"r('转义_ _<>_&')\",\n  \"fruits\": [\"apple\", \"banana\", \"cherry\"],\n  \"display_paragraph\":true,\n  \"paragraphs\" : [\n    {\n      \"name\": \"段落 2.1\",\n      \"table_name\": \"table_name1\",\n      \"table_fields\": [\"id\", \"name\", \"age\", \"gender\"],\n      \"table_data\": [\n        {\"id\": \"1\", \"name\": \"张三\", \"age\": \"20\", \"gender\": \"男\"},\n        {\"id\": \"2\", \"name\": \"李四\", \"age\": \"21\", \"gender\": \"女\"},\n        {\"id\": \"3\", \"name\": \"王五\", \"age\": \"22\", \"gender\": \"男\"}\n      ]\n    },\n    {\"name\":\"段落 2.2\"}\n  ]\n}\n\n\n测试模版（word）\n\n------------- 循环\n{% for fruit in fruits %}\n- {{ fruit }}\n{% endfor %}\n\n\n------------- 段落\n{% set paragraph %}\nthis is a new paragraph that we want to insert. it can contain multiple sentences.\n{% endset %}\n\n{{ paragraph }}\n\n------------- 判断\n{%p if display_paragraph %}\nhere is my paragraph\n{%p endif %}\n\n\n------------- 拼接行\n1111\n{%- if display_paragraph -%}\n2222\n{%- else -%}\n3333\n{%- endif -%}\n9999\n\n\n------------- 循环段落（嵌套内容）\n{% for paragraph in paragraphs %}\n{{ paragraph.name }}\n{{ paragraph.table_name }}\n\nid  name    age gender\n{%tr for row in paragraph. table_data %}\n{{ row.id }}    {{ row.name }}  {{ row.age }}   {{ row.gender }}\n{%tr endfor %}\n\n{% endfor %}\n\n\n\n\n# 按模版生成 excel 文档\n\n\n# xlsxtpl\n\n第三方库官网\nxlsxtpl 使用 jinja2 作为其模板引擎，遵循 jinja2 模板的语法。\n\n\n# 使用 python + mermaid 绘图并插入 word 文档\n\n使用 nodejs 安装 mermaid-cli，通过 python 代码调用客户端生成图片保存到磁盘，再将磁盘图片插入到 word 文档\n\n 1. 安装 mermaid-cli npm install -g @mermaid-js/mermaid-cli\n 2. 代码示例\n\nimport subprocess\nfrom docx import document\nfrom docx.shared import inches\nimport os\n\n# 你的mermaid代码\nmermaid_code = \"\"\"\ngraph td\n    a[christmas] --\x3e|get money| b(go shopping)\n    b --\x3e c{let me think}\n    c --\x3e|one| d[laptop]\n    c --\x3e|two| e[iphone]\n    c --\x3e|three| f[car]\n\"\"\"\n\n# 将mermaid代码写入临时文件\nwith open('temp.mmd', 'w') as file:\n    file.write(mermaid_code)\n\nmmscpath = \"d:\\\\program files\\\\nodejs\\\\npm_global\\\\mmdc.cmd\"\n# 使用mermaid cli将mermaid代码转换为svg\n# subprocess.run(['mmdc', '-i', 'temp.mmd', '-o', 'temp.svg'])\nsubprocess.run([mmscpath, '-i', 'temp.mmd', '-o', 'temp.png'])\n# 创建或加载word文档\ndoc = document()\ndoc.add_heading('mermaid diagram in word', 0)\n# 将图片插入到word文档中\ndoc.add_picture('temp.png', width=inches(4.0))\n# 保存word文档\ndoc.save('diagram.docx')\n# 清理临时文件\nos.remove('temp.mmd')\n# os.remove('temp.svg')\nos.remove('temp.png')\n",charsets:{cjk:!0},lastUpdated:"2025/01/02, 13:03:48",lastUpdatedTimestamp:1735794228e3},{title:"自己写的python程序（减少工作量）",frontmatter:{title:"自己写的python程序（减少工作量）",date:"2022-03-15T09:04:59.000Z",permalink:"/pages/c2b99b/",categories:["其他","Python"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/01.Python/04.%E8%87%AA%E5%B7%B1%E5%86%99%E7%9A%84python%E7%A8%8B%E5%BA%8F.html",relativePath:"04.其他/01.Python/04.自己写的python程序.md",key:"v-1dc96cde",path:"/pages/c2b99b/",headers:[{level:2,title:"拼接sql",slug:"拼接sql",normalizedTitle:"拼接sql",charIndex:2},{level:2,title:"尝试将Oracle替换为MySQL语法(未完成)",slug:"尝试将oracle替换为mysql语法-未完成",normalizedTitle:"尝试将oracle替换为mysql语法(未完成)",charIndex:4255},{level:2,title:"练习题",slug:"练习题",normalizedTitle:"练习题",charIndex:6936},{level:3,title:"字母count",slug:"字母count",normalizedTitle:"字母count",charIndex:6944}],headersStr:"拼接sql 尝试将Oracle替换为MySQL语法(未完成) 练习题 字母count",content:"# 拼接sql\n\nGD_STOCK_PAYMENT\tPAY_ID\t偿还信息主键\tDEBT_T_ZWGL_CHBJ\tCHBJ_ID\t偿还本金主单ID\nGD_STOCK_PAYMENT\tDEPT_STOCK_ID\t债务信息主键\tDEBT_T_ZWGL_CHBJ\tZW_ID\t债务ID\nGD_STOCK_PAYMENT\tMOF_DIV_CODE\t财政区划代码\tDEBT_T_ZWGL_CHBJ\tAD_CODE\t区划编码\nGD_STOCK_PAYMENT\tAGENCY_CODE\t单位代码\tDEBT_T_ZWGL_CHBJ\tAG_CODE\t单位编码\n\n\nimport pandas as pd\nimport collections\n\nt_name = \"GD_ISSUE_PLAN\"\n\nfilepath = 'data\\{}.csv'.format(t_name)\n\n# 读取文件\ndf = pd.read_csv(filepath, sep='\\t', header = None)\n\n# 获取第一列并去重\ntag_table = df[0].drop_duplicates().values[0]  \n# 获取源表\nsource_tables = df[3].drop_duplicates().dropna().values   # ndarray类型\n\n# 表名和别名放入字典\nnum = 0\n# dic = { tag_table: \"T{}\".format(num) }\ndic = collections.OrderedDict()\nfor table in source_tables:\n    num += 1\n    dic[table] = \"T{}\".format(num)\n\ncols = \",\".join(df.iloc[:, 1])\n\nlist1 = []\nlist1.append(\"INSERT INTO {}({})\".format(tag_table, cols))\nlist1.append(\"\\nSELECT\")\n\n# 目标表名 目标字段名 源表表名 源表字段名\ncolumns = df.iloc[:, [0,1,3,4]]\n\nsource_ad_table = ''   # 区划在哪个源表\nsource_agency_table = ''  # 单位在哪个源表 ?哪个字段关联\n# 拼接select部分\nfor row in range(0, columns.shape[0]):\n    if pd.isna(columns[4][row]):\n        if row != 0 :\n            list1.append(\"\\n\\t  ,{} AS {}\".format(\"''\", columns[1][row]))\n        else:\n            list1.append(\"\\n\\t   {} AS {}\".format(\"''\", columns[1][row]))\n    else:\n        tablename = dic[columns[3][row]]\n        # 处理区划\n        if columns[1][row] == \"MOF_DIV_CODE\":\n            num += 1\n            list1.append( \"\\n\\t  ,NVL(T{}.CZ_CODE, {}.AD_CODE) AS {}\".format(num, tablename, columns[1][row]) )\n            dic[\"DSY_V_ELE_AD\"] = \"T{}\".format(num)\n            source_ad_table = columns[3][row]\n        # 处理单位\n        elif columns[1][row] in (\"AGENCY_CODE\", \"AGENCY_COD\"):\n            num += 1\n            list1.append( \"\\n\\t  ,CASE WHEN T{}.CODE IS NULL THEN {}.AG_CODE ELSE T{}.AGENCY_CODE END AS AGENCY_CODE\".format(num, tablename, num) )\n            dic[\"BDA_T_DWDZ\"] = \"T{}\".format(num)\n            source_agency_table = columns[3][row]\n        # 处理时间\n        elif columns[1][row].endswith( (\"TIME\", \"DATE\") ) : #, beg=[0, len(str)]\n            list1.append(\"\\n\\t  ,regexp_replace({}.{}, '-|:| ', '') AS {}\".format(tablename, columns[4][row], columns[1][row]))\n        else :\n            if row != 0 :\n                list1.append(\"\\n\\t  ,{}.{} AS {}\".format(tablename, columns[4][row], columns[1][row]))\n            else:\n                list1.append(\"\\n\\t   {}.{} AS {}\".format(tablename, columns[4][row], columns[1][row]))\n\n# 拼接from和join部分\nindex = 0\nfor key in dic:\n    index += 1\n    if index == 1:\n        list1.append(\"\\n     FROM {}@DSY_HBDZ_DBLINK {}\".format(key, dic[key]))\n    else:\n        if key == \"DSY_V_ELE_AD\":\n            list1.append(\"\\nLEFT JOIN {} {}\\n       ON case when {}.AD_CODE='4200' then '420000' when {}.AD_CODE='4290'  then '4298' else {}.AD_CODE end = {}.CODE\".format(key, dic[key], dic[source_ad_table],dic[source_ad_table],dic[source_ad_table], dic[key]))\n        elif key == \"BDA_T_DWDZ\":\n            list1.append(\"\\nLEFT JOIN {} {}\\n       ON {}.AG_ID = {}.GUID\".format(key, dic[key], dic[source_agency_table], dic[key]))\n        else:\n            list1.append(\"\\nLEFT JOIN {}@DSY_HBDZ_DBLINK {}\\n       ON \".format(key, dic[key]))\n\n# dic\n# list1\nprint( ' '.join(list1) )\n\n# df\ncolumns\n# cols\n\n\n修改加一列\n\nGD_STOCK_PAYMENT\tPAY_ID\t偿还信息主键\tDEBT_T_ZWGL_CHBJ\tCHBJ_ID\t偿还本金主单ID\tCHBJ_ID\nGD_STOCK_PAYMENT\tDEPT_STOCK_ID\t债务信息主键\tDEBT_T_ZWGL_CHBJ\tZW_ID\t债务ID\tZW_ID\nGD_STOCK_PAYMENT\tMOF_DIV_CODE\t财政区划代码\tDEBT_T_ZWGL_CHBJ\tAD_CODE\t区划编码\tAD_CODE\nGD_STOCK_PAYMENT\tAGENCY_CODE\t单位代码\tDEBT_T_ZWGL_CHBJ\tAG_CODE\t单位编码\tAG_CODE\n\t\t\t\t\t\tPAY_ID\n\t\t\t\t\t\tDEPT_STOCK_ID\n\t\t\t\t\t\tMOF_DIV_CODE\n\t\t\t\t\t\tAGENCY_CODE\n\n\n\n修改：\ndf0 = pd.read_csv(filepath, sep='\\t', header = None)\ndf = df0.iloc[:, [0,1,2,3,4,5]].dropna(thresh=2)\n\n\n\ndf2 = df0.iloc[:, [1,4,6]] #5\n\ndic2 = {}\nlist2 = []\n# 赋值\nfor row in range(0, df2.shape[0]):\n    if( pd.isna(df2[4][row]) ):\n        pass\n    else:\n        dic2[df2[4][row]] = df2[1][row]\n\nfor row in range(0, df2.shape[0]):\n    if pd.isna(df2[6][row]):\n        pass\n    else:\n        if df2[6][row] in dic2.keys():\n            list2.append(\"\\n,{} as {}\".format( dic2[df2[6][row]], df2[6][row] ) )\n        else:\n            list2.append(\"\\n,null as {}\".format(df2[6][row]) )\n\nprint(\"\".join(list2))\n# df2\n# dic2\n\n\n\n# 尝试将Oracle替换为MySQL语法(未完成)\n\n由于有些SQL函数嵌套太复杂, 暂时搁置\n\n# import pandas as pd\n# t_name = \"数据\"\n# filepath = 'data{}.xlsx'.format(t_name)\n# df = pd.read_excel(filepath,  engine='openpyxl')\n# df['Q_TABLE'].apply(函数, axis=1)\n\n\nimport re\n\nstr = \"\"\"SELECT Length(BILL.AD_CODE) as AD_CODE,\nsys_Guid() as guid,\n to_char(sysdate, 'yyyy-MM/dd HH24:mi:ss') as test2,\nto_char(sysdate, 'yyyy/MM/dd') as test3,\nto_char(sysdate, 'yyyy-MM') as test4,\nto_char(sysdate, 'yyyy') as test5,\nto_char(1540265121) as test6,\nto_date(a.xxx_date, 'YYYY-MM-DD HH24:mi:ss') as test7,\nto_date(a.xxx_date, 'YYYY-MM-DD') as test8,\n\"\"\"\n\n\n# length(str)函数\ndef rep_length(text):\n    return re.sub(r'length\\(', r'char_length(', text, flags = re.IGNORECASE)\n\n# sys_guid()函数\ndef rep_guid(text):\n    return re.sub(r'sys_guid\\(\\)', r'UUID()', text, flags = re.IGNORECASE)\n\n# to_char\ndef rep_tochar(text):\n    # to_char(sysdate, 'yyyy-MM-dd HH24:mi:ss') -> DATE_FORMAT(NOW(),'%Y-%m-%d %H:%i:%s')\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2} [h|\\d|:|m|i|s]{10}\\'\\)', r'\\1date_format(\\2, \"%Y\\3%m\\4%d %h:%i:%s\")', text, flags = re.IGNORECASE)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2}\\'\\)', r'\\1date_format(\\2, \"%Y\\3%m\\4%d\")', text, flags = re.IGNORECASE)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}\\'\\)', r'\\1date_format(\\2, \"%Y\\3%m\")', text, flags = re.IGNORECASE)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}\\'\\)', r'\\1date_format(\\2, \"%Y\")', text, flags = re.IGNORECASE)\n    # text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),(\\s+\\'[y|m|d|/|-]{8,10} [h|\\d|:|m|i|s]{10}\\')\\)', r'\\1date_format(\\2, \"%Y-%m-%d %h:%i:%s\")', text, flags = re.IGNORECASE)\n    # to_char(154643546466)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+)\\)', r'\\1CAST(\\2 AS CHAR)', text, flags = re.IGNORECASE)\n    return text\n\n# to_date\ndef rep_todate(text):\n    # to_date(a.xxx_date, 'YYYY-MM-DD') to_date('2019-01-01', 'YYYY-MM-DD')未匹配\n    text = re.sub(r'(\\s+)to_date\\(([\\w|\\.]+),(\\s+\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2} [h|\\d|:|m|i|s]{10}\\')\\)', r'\\1str_to_date(\\2, \"%Y\\3%m\\4%d %h:%i:%s\")', text, flags = re.IGNORECASE)\n    text = re.sub(r'(\\s+)to_date\\(([\\w|\\.]+),(\\s+\\'[y]{4}([/|-])[m]{2}\\')\\)', r'\\1str_to_date(\\2, \"%Y\\3%m\\4%d\")', text, flags = re.IGNORECASE)\n    return text\n\n# nvl\ndef rep_nvl(text):\n    return re.sub(r'(\\s+)nvl\\(', r'\\1ifnull(', text, flags = re.IGNORECASE)\n\n# to_number\ndef rep_tonumber(text):\n    return re.sub(r'(\\s+)to_number\\(', r'\\1ifnull(', text, flags = re.IGNORECASE)\n\n# sysdate   \ndef rep_sysdate(text):\n    return re.sub(r'sysdate', r'now() ', text, flags = re.IGNORECASE)\n\n# concat\n# ROWNUM\n# full join\n# decode\n\n\n\n# 练习题\n\n\n# 字母count\n\n频次相同, 大写字母在前小写字母在后\n\nimport re\n\nstr = input(\"请输入字符串：\")\n# str=\"A BVYLKG computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\"\n\nfilename='word_count.txt'\n\n# 正则匹配找到所有的字母\nlist = re.findall(r'[a-z|A-Z]',str)\n\n# type(list)  # 查看类型\ndic = {}      # 定义字典(键值对)\nfor ch in list:\n    dic[ch] = dic.get(ch, 0) + 1      # 若key对应的value不存在,置为0+1\n\n# 按两列倒序  由于大写字母在小写字母之前，转ascii码后取负解决\nres = sorted(dic.items(), key=lambda kv: (kv[1], -ord(kv[0])), reverse=True)\nprint(res)\n\nwith open(filename, 'w', encoding='utf-8') as file:\n    for row in res:\n        file.write(\"(\\'{}\\', {})\\n\".format(row[0], row[1]))\n\n\"\"\"--------------------------------------------------------------------\"\"\"\n\nimport pandas as pd\nimport re\n\nfilename='word_count.txt'\nstr=\"A BVYLKG computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.\"\n\n# 正则匹配找到所有的字母\nlist1 = re.findall(r'[a-z|A-Z]',str)\n\nlist2 = [1 for x in range(0, len(list1))]\n\nzip1 = zip(list1, list2)\n\ndf = pd.DataFrame(zip1, columns=['key', 'value'])\n\ndf1 = df.groupby('key').sum().sort_values(by=['value', 'key'], ascending=[False, True])   # 分组求和排序\n\ndf1.to_csv(filename, header=None)\n\n# df1\n",normalizedContent:"# 拼接sql\n\ngd_stock_payment\tpay_id\t偿还信息主键\tdebt_t_zwgl_chbj\tchbj_id\t偿还本金主单id\ngd_stock_payment\tdept_stock_id\t债务信息主键\tdebt_t_zwgl_chbj\tzw_id\t债务id\ngd_stock_payment\tmof_div_code\t财政区划代码\tdebt_t_zwgl_chbj\tad_code\t区划编码\ngd_stock_payment\tagency_code\t单位代码\tdebt_t_zwgl_chbj\tag_code\t单位编码\n\n\nimport pandas as pd\nimport collections\n\nt_name = \"gd_issue_plan\"\n\nfilepath = 'data\\{}.csv'.format(t_name)\n\n# 读取文件\ndf = pd.read_csv(filepath, sep='\\t', header = none)\n\n# 获取第一列并去重\ntag_table = df[0].drop_duplicates().values[0]  \n# 获取源表\nsource_tables = df[3].drop_duplicates().dropna().values   # ndarray类型\n\n# 表名和别名放入字典\nnum = 0\n# dic = { tag_table: \"t{}\".format(num) }\ndic = collections.ordereddict()\nfor table in source_tables:\n    num += 1\n    dic[table] = \"t{}\".format(num)\n\ncols = \",\".join(df.iloc[:, 1])\n\nlist1 = []\nlist1.append(\"insert into {}({})\".format(tag_table, cols))\nlist1.append(\"\\nselect\")\n\n# 目标表名 目标字段名 源表表名 源表字段名\ncolumns = df.iloc[:, [0,1,3,4]]\n\nsource_ad_table = ''   # 区划在哪个源表\nsource_agency_table = ''  # 单位在哪个源表 ?哪个字段关联\n# 拼接select部分\nfor row in range(0, columns.shape[0]):\n    if pd.isna(columns[4][row]):\n        if row != 0 :\n            list1.append(\"\\n\\t  ,{} as {}\".format(\"''\", columns[1][row]))\n        else:\n            list1.append(\"\\n\\t   {} as {}\".format(\"''\", columns[1][row]))\n    else:\n        tablename = dic[columns[3][row]]\n        # 处理区划\n        if columns[1][row] == \"mof_div_code\":\n            num += 1\n            list1.append( \"\\n\\t  ,nvl(t{}.cz_code, {}.ad_code) as {}\".format(num, tablename, columns[1][row]) )\n            dic[\"dsy_v_ele_ad\"] = \"t{}\".format(num)\n            source_ad_table = columns[3][row]\n        # 处理单位\n        elif columns[1][row] in (\"agency_code\", \"agency_cod\"):\n            num += 1\n            list1.append( \"\\n\\t  ,case when t{}.code is null then {}.ag_code else t{}.agency_code end as agency_code\".format(num, tablename, num) )\n            dic[\"bda_t_dwdz\"] = \"t{}\".format(num)\n            source_agency_table = columns[3][row]\n        # 处理时间\n        elif columns[1][row].endswith( (\"time\", \"date\") ) : #, beg=[0, len(str)]\n            list1.append(\"\\n\\t  ,regexp_replace({}.{}, '-|:| ', '') as {}\".format(tablename, columns[4][row], columns[1][row]))\n        else :\n            if row != 0 :\n                list1.append(\"\\n\\t  ,{}.{} as {}\".format(tablename, columns[4][row], columns[1][row]))\n            else:\n                list1.append(\"\\n\\t   {}.{} as {}\".format(tablename, columns[4][row], columns[1][row]))\n\n# 拼接from和join部分\nindex = 0\nfor key in dic:\n    index += 1\n    if index == 1:\n        list1.append(\"\\n     from {}@dsy_hbdz_dblink {}\".format(key, dic[key]))\n    else:\n        if key == \"dsy_v_ele_ad\":\n            list1.append(\"\\nleft join {} {}\\n       on case when {}.ad_code='4200' then '420000' when {}.ad_code='4290'  then '4298' else {}.ad_code end = {}.code\".format(key, dic[key], dic[source_ad_table],dic[source_ad_table],dic[source_ad_table], dic[key]))\n        elif key == \"bda_t_dwdz\":\n            list1.append(\"\\nleft join {} {}\\n       on {}.ag_id = {}.guid\".format(key, dic[key], dic[source_agency_table], dic[key]))\n        else:\n            list1.append(\"\\nleft join {}@dsy_hbdz_dblink {}\\n       on \".format(key, dic[key]))\n\n# dic\n# list1\nprint( ' '.join(list1) )\n\n# df\ncolumns\n# cols\n\n\n修改加一列\n\ngd_stock_payment\tpay_id\t偿还信息主键\tdebt_t_zwgl_chbj\tchbj_id\t偿还本金主单id\tchbj_id\ngd_stock_payment\tdept_stock_id\t债务信息主键\tdebt_t_zwgl_chbj\tzw_id\t债务id\tzw_id\ngd_stock_payment\tmof_div_code\t财政区划代码\tdebt_t_zwgl_chbj\tad_code\t区划编码\tad_code\ngd_stock_payment\tagency_code\t单位代码\tdebt_t_zwgl_chbj\tag_code\t单位编码\tag_code\n\t\t\t\t\t\tpay_id\n\t\t\t\t\t\tdept_stock_id\n\t\t\t\t\t\tmof_div_code\n\t\t\t\t\t\tagency_code\n\n\n\n修改：\ndf0 = pd.read_csv(filepath, sep='\\t', header = none)\ndf = df0.iloc[:, [0,1,2,3,4,5]].dropna(thresh=2)\n\n\n\ndf2 = df0.iloc[:, [1,4,6]] #5\n\ndic2 = {}\nlist2 = []\n# 赋值\nfor row in range(0, df2.shape[0]):\n    if( pd.isna(df2[4][row]) ):\n        pass\n    else:\n        dic2[df2[4][row]] = df2[1][row]\n\nfor row in range(0, df2.shape[0]):\n    if pd.isna(df2[6][row]):\n        pass\n    else:\n        if df2[6][row] in dic2.keys():\n            list2.append(\"\\n,{} as {}\".format( dic2[df2[6][row]], df2[6][row] ) )\n        else:\n            list2.append(\"\\n,null as {}\".format(df2[6][row]) )\n\nprint(\"\".join(list2))\n# df2\n# dic2\n\n\n\n# 尝试将oracle替换为mysql语法(未完成)\n\n由于有些sql函数嵌套太复杂, 暂时搁置\n\n# import pandas as pd\n# t_name = \"数据\"\n# filepath = 'data{}.xlsx'.format(t_name)\n# df = pd.read_excel(filepath,  engine='openpyxl')\n# df['q_table'].apply(函数, axis=1)\n\n\nimport re\n\nstr = \"\"\"select length(bill.ad_code) as ad_code,\nsys_guid() as guid,\n to_char(sysdate, 'yyyy-mm/dd hh24:mi:ss') as test2,\nto_char(sysdate, 'yyyy/mm/dd') as test3,\nto_char(sysdate, 'yyyy-mm') as test4,\nto_char(sysdate, 'yyyy') as test5,\nto_char(1540265121) as test6,\nto_date(a.xxx_date, 'yyyy-mm-dd hh24:mi:ss') as test7,\nto_date(a.xxx_date, 'yyyy-mm-dd') as test8,\n\"\"\"\n\n\n# length(str)函数\ndef rep_length(text):\n    return re.sub(r'length\\(', r'char_length(', text, flags = re.ignorecase)\n\n# sys_guid()函数\ndef rep_guid(text):\n    return re.sub(r'sys_guid\\(\\)', r'uuid()', text, flags = re.ignorecase)\n\n# to_char\ndef rep_tochar(text):\n    # to_char(sysdate, 'yyyy-mm-dd hh24:mi:ss') -> date_format(now(),'%y-%m-%d %h:%i:%s')\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2} [h|\\d|:|m|i|s]{10}\\'\\)', r'\\1date_format(\\2, \"%y\\3%m\\4%d %h:%i:%s\")', text, flags = re.ignorecase)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2}\\'\\)', r'\\1date_format(\\2, \"%y\\3%m\\4%d\")', text, flags = re.ignorecase)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}([/|-])[m]{2}\\'\\)', r'\\1date_format(\\2, \"%y\\3%m\")', text, flags = re.ignorecase)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),\\s*\\'[y]{4}\\'\\)', r'\\1date_format(\\2, \"%y\")', text, flags = re.ignorecase)\n    # text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+),(\\s+\\'[y|m|d|/|-]{8,10} [h|\\d|:|m|i|s]{10}\\')\\)', r'\\1date_format(\\2, \"%y-%m-%d %h:%i:%s\")', text, flags = re.ignorecase)\n    # to_char(154643546466)\n    text = re.sub(r'(\\s+)to_char\\(([\\w|\\.]+)\\)', r'\\1cast(\\2 as char)', text, flags = re.ignorecase)\n    return text\n\n# to_date\ndef rep_todate(text):\n    # to_date(a.xxx_date, 'yyyy-mm-dd') to_date('2019-01-01', 'yyyy-mm-dd')未匹配\n    text = re.sub(r'(\\s+)to_date\\(([\\w|\\.]+),(\\s+\\'[y]{4}([/|-])[m]{2}([/|-])[d]{2} [h|\\d|:|m|i|s]{10}\\')\\)', r'\\1str_to_date(\\2, \"%y\\3%m\\4%d %h:%i:%s\")', text, flags = re.ignorecase)\n    text = re.sub(r'(\\s+)to_date\\(([\\w|\\.]+),(\\s+\\'[y]{4}([/|-])[m]{2}\\')\\)', r'\\1str_to_date(\\2, \"%y\\3%m\\4%d\")', text, flags = re.ignorecase)\n    return text\n\n# nvl\ndef rep_nvl(text):\n    return re.sub(r'(\\s+)nvl\\(', r'\\1ifnull(', text, flags = re.ignorecase)\n\n# to_number\ndef rep_tonumber(text):\n    return re.sub(r'(\\s+)to_number\\(', r'\\1ifnull(', text, flags = re.ignorecase)\n\n# sysdate   \ndef rep_sysdate(text):\n    return re.sub(r'sysdate', r'now() ', text, flags = re.ignorecase)\n\n# concat\n# rownum\n# full join\n# decode\n\n\n\n# 练习题\n\n\n# 字母count\n\n频次相同, 大写字母在前小写字母在后\n\nimport re\n\nstr = input(\"请输入字符串：\")\n# str=\"a bvylkg computer program is said to learn from experience e with respect to some task t and some performance measure p, if its performance on t, as measured by p, improves with experience e.\"\n\nfilename='word_count.txt'\n\n# 正则匹配找到所有的字母\nlist = re.findall(r'[a-z|a-z]',str)\n\n# type(list)  # 查看类型\ndic = {}      # 定义字典(键值对)\nfor ch in list:\n    dic[ch] = dic.get(ch, 0) + 1      # 若key对应的value不存在,置为0+1\n\n# 按两列倒序  由于大写字母在小写字母之前，转ascii码后取负解决\nres = sorted(dic.items(), key=lambda kv: (kv[1], -ord(kv[0])), reverse=true)\nprint(res)\n\nwith open(filename, 'w', encoding='utf-8') as file:\n    for row in res:\n        file.write(\"(\\'{}\\', {})\\n\".format(row[0], row[1]))\n\n\"\"\"--------------------------------------------------------------------\"\"\"\n\nimport pandas as pd\nimport re\n\nfilename='word_count.txt'\nstr=\"a bvylkg computer program is said to learn from experience e with respect to some task t and some performance measure p, if its performance on t, as measured by p, improves with experience e.\"\n\n# 正则匹配找到所有的字母\nlist1 = re.findall(r'[a-z|a-z]',str)\n\nlist2 = [1 for x in range(0, len(list1))]\n\nzip1 = zip(list1, list2)\n\ndf = pd.dataframe(zip1, columns=['key', 'value'])\n\ndf1 = df.groupby('key').sum().sort_values(by=['value', 'key'], ascending=[false, true])   # 分组求和排序\n\ndf1.to_csv(filename, header=none)\n\n# df1\n",charsets:{cjk:!0},lastUpdated:"2022/04/13, 21:51:31",lastUpdatedTimestamp:1649857891e3},{title:"Python类库学习",frontmatter:{title:"Python类库学习",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/f2a341/",categories:["其他","Python"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/01.Python/03.Python%E7%B1%BB%E5%BA%93%E5%AD%A6%E4%B9%A0.html",relativePath:"04.其他/01.Python/03.Python类库学习.md",key:"v-152fe1e4",path:"/pages/f2a341/",headers:[{level:2,title:"基础语法",slug:"基础语法",normalizedTitle:"基础语法",charIndex:2},{level:2,title:"Numpy学习",slug:"numpy学习",normalizedTitle:"numpy学习",charIndex:11},{level:3,title:"Ndarray类学习",slug:"ndarray类学习",normalizedTitle:"ndarray类学习",charIndex:23},{level:3,title:"np.array方法",slug:"np-array方法",normalizedTitle:"np.array方法",charIndex:1120},{level:3,title:"Numpy数组创建方法",slug:"numpy数组创建方法",normalizedTitle:"numpy数组创建方法",charIndex:1865},{level:3,title:"打印数组",slug:"打印数组",normalizedTitle:"打印数组",charIndex:2407},{level:3,title:"基本操作 (数组元素的运算)",slug:"基本操作-数组元素的运算",normalizedTitle:"基本操作 (数组元素的运算)",charIndex:2679},{level:3,title:"基本操作 (矩阵乘积)",slug:"基本操作-矩阵乘积",normalizedTitle:"基本操作 (矩阵乘积)",charIndex:2968},{level:3,title:"形状操纵",slug:"形状操纵",normalizedTitle:"形状操纵",charIndex:3699},{level:3,title:"索引、切片和迭代",slug:"索引、切片和迭代",normalizedTitle:"索引、切片和迭代",charIndex:5279},{level:3,title:"深入:",slug:"深入",normalizedTitle:"深入:",charIndex:5746},{level:3,title:"深入: 直方图",slug:"深入-直方图",normalizedTitle:"深入: 直方图",charIndex:6611},{level:3,title:"附:创建一个3*3 的数组方法",slug:"附-创建一个3-3-的数组方法",normalizedTitle:"附:创建一个3*3 的数组方法",charIndex:7120},{level:2,title:"Pandas（两种数据结构学习）",slug:"pandas-两种数据结构学习",normalizedTitle:"pandas（两种数据结构学习）",charIndex:7459},{level:3,title:"1.Series(一维标记数组)学习",slug:"_1-series-一维标记数组-学习",normalizedTitle:"1.series(一维标记数组)学习",charIndex:7480},{level:3,title:"2.DataFrame(二维标记数据结构)学习",slug:"_2-dataframe-二维标记数据结构-学习",normalizedTitle:"2.dataframe(二维标记数据结构)学习",charIndex:8105},{level:4,title:"创建",slug:"创建",normalizedTitle:"创建",charIndex:394},{level:4,title:"DataFrame值索引",slug:"dataframe值索引",normalizedTitle:"dataframe值索引",charIndex:9366},{level:4,title:"层次化索引与unstack",slug:"层次化索引与unstack",normalizedTitle:"层次化索引与unstack",charIndex:10481},{level:4,title:"DataFrame堆叠",slug:"dataframe堆叠",normalizedTitle:"dataframe堆叠",charIndex:10812},{level:4,title:"DataFrame常用函数介绍(一) 重新索引(reindex)",slug:"dataframe常用函数介绍-一-重新索引-reindex",normalizedTitle:"dataframe常用函数介绍(一) 重新索引(reindex)",charIndex:11377},{level:4,title:"DataFrame常用函数介绍(二) 丢弃值(drop)",slug:"dataframe常用函数介绍-二-丢弃值-drop",normalizedTitle:"dataframe常用函数介绍(二) 丢弃值(drop)",charIndex:11852},{level:4,title:"DataFrame常用函数介绍(三) 算术方法",slug:"dataframe常用函数介绍-三-算术方法",normalizedTitle:"dataframe常用函数介绍(三) 算术方法",charIndex:12578},{level:4,title:"DataFrame常用函数介绍(四) 索引排序",slug:"dataframe常用函数介绍-四-索引排序",normalizedTitle:"dataframe常用函数介绍(四) 索引排序",charIndex:13134},{level:4,title:"DataFrame常用函数介绍(五) 描述和汇总统计(待补充)",slug:"dataframe常用函数介绍-五-描述和汇总统计-待补充",normalizedTitle:"dataframe常用函数介绍(五) 描述和汇总统计(待补充)",charIndex:13823},{level:4,title:"DataFrame常用函数介绍(六) 缺失值填充",slug:"dataframe常用函数介绍-六-缺失值填充",normalizedTitle:"dataframe常用函数介绍(六) 缺失值填充",charIndex:14053},{level:4,title:"Pandas文件读取",slug:"pandas文件读取",normalizedTitle:"pandas文件读取",charIndex:14433},{level:4,title:"Pandas文件写入",slug:"pandas文件写入",normalizedTitle:"pandas文件写入",charIndex:15122},{level:4,title:"Pandas合并xls文件",slug:"pandas合并xls文件",normalizedTitle:"pandas合并xls文件",charIndex:15579},{level:2,title:"Pandas数据合并、清洗",slug:"pandas数据合并、清洗",normalizedTitle:"pandas数据合并、清洗",charIndex:15967},{level:3,title:"merge函数 默认内连接",slug:"merge函数-默认内连接",normalizedTitle:"merge函数 默认内连接",charIndex:15985},{level:3,title:"外连接",slug:"外连接",normalizedTitle:"外连接",charIndex:16546},{level:4,title:"外连接",slug:"外连接-2",normalizedTitle:"外连接",charIndex:16546},{level:4,title:"多列连接on=[]",slug:"多列连接on",normalizedTitle:"多列连接on=[]",charIndex:16612},{level:4,title:"左连接 how = 'left'",slug:"左连接-how-left",normalizedTitle:"左连接 how = 'left'",charIndex:17314},{level:4,title:"how = 'right'",slug:"how-right",normalizedTitle:"how = 'right'",charIndex:17597},{level:3,title:"用表的行索引名作为连接",slug:"用表的行索引名作为连接",normalizedTitle:"用表的行索引名作为连接",charIndex:17881},{level:3,title:"join函数(为merge的特例) 默认外连接",slug:"join函数-为merge的特例-默认外连接",normalizedTitle:"join函数(为merge的特例) 默认外连接",charIndex:18240},{level:3,title:"combine_first函数  以一个为基准,另一个进行补充",slug:"combine-first函数-以一个为基准-另一个进行补充",normalizedTitle:"combine_first函数  以一个为基准,另一个进行补充",charIndex:18639},{level:3,title:"待补充",slug:"待补充",normalizedTitle:"待补充",charIndex:13850},{level:3,title:"数据清理与转换(一) 值替换",slug:"数据清理与转换-一-值替换",normalizedTitle:"数据清理与转换(一) 值替换",charIndex:19001},{level:3,title:"数据清理与转换(二) 去重复值",slug:"数据清理与转换-二-去重复值",normalizedTitle:"数据清理与转换(二) 去重复值",charIndex:19583},{level:3,title:"数据清理与转换(三) 索引重命名",slug:"数据清理与转换-三-索引重命名",normalizedTitle:"数据清理与转换(三) 索引重命名",charIndex:19950},{level:3,title:"数据清理与转换(四) 数据转换",slug:"数据清理与转换-四-数据转换",normalizedTitle:"数据清理与转换(四) 数据转换",charIndex:20267},{level:3,title:"数据清理与转换(五) 数据离散化和装箱 指定划分边界",slug:"数据清理与转换-五-数据离散化和装箱-指定划分边界",normalizedTitle:"数据清理与转换(五) 数据离散化和装箱 指定划分边界",charIndex:20849},{level:3,title:"数据清理与转换(五) 数据离散化和装箱 平均划分边界",slug:"数据清理与转换-五-数据离散化和装箱-平均划分边界",normalizedTitle:"数据清理与转换(五) 数据离散化和装箱 平均划分边界",charIndex:21540},{level:3,title:"数据清理与转换(五) 数据离散化和装箱 分位划分边界",slug:"数据清理与转换-五-数据离散化和装箱-分位划分边界",normalizedTitle:"数据清理与转换(五) 数据离散化和装箱 分位划分边界",charIndex:21895},{level:3,title:"哑变量",slug:"哑变量",normalizedTitle:"哑变量",charIndex:22278},{level:3,title:"数据随机取样(排序)",slug:"数据随机取样-排序",normalizedTitle:"数据随机取样(排序)",charIndex:22619},{level:3,title:"补充",slug:"补充",normalizedTitle:"补充",charIndex:13851},{level:2,title:"Pandas聚合与分组",slug:"pandas聚合与分组",normalizedTitle:"pandas聚合与分组",charIndex:24169},{level:3,title:"数据分组操作(1)  (groupby函数 & series分组)",slug:"数据分组操作-1-groupby函数-series分组",normalizedTitle:"数据分组操作(1)  (groupby函数 &amp; series分组)",charIndex:null},{level:3,title:"数据分组操作(2)  (DataFrme分组)",slug:"数据分组操作-2-datafrme分组",normalizedTitle:"数据分组操作(2)  (datafrme分组)",charIndex:24874},{level:3,title:"数据分组操作(3)  分组指定应用聚合列",slug:"数据分组操作-3-分组指定应用聚合列",normalizedTitle:"数据分组操作(3)  分组指定应用聚合列",charIndex:25788},{level:3,title:"数据分组操作(4)  分组的迭代操作",slug:"数据分组操作-4-分组的迭代操作",normalizedTitle:"数据分组操作(4)  分组的迭代操作",charIndex:26428},{level:3,title:"数据分组操作(5)  对行索引名进行分组",slug:"数据分组操作-5-对行索引名进行分组",normalizedTitle:"数据分组操作(5)  对行索引名进行分组",charIndex:26969},{level:3,title:"数据分组操作(6)  聚合函数",slug:"数据分组操作-6-聚合函数",normalizedTitle:"数据分组操作(6)  聚合函数",charIndex:27322},{level:3,title:"数据分组操作(7)  自定义聚合函数agg()",slug:"数据分组操作-7-自定义聚合函数agg",normalizedTitle:"数据分组操作(7)  自定义聚合函数agg()",charIndex:28066},{level:3,title:"自定义聚合操作  分组转换与分组应用",slug:"自定义聚合操作-分组转换与分组应用",normalizedTitle:"自定义聚合操作  分组转换与分组应用",charIndex:28717},{level:3,title:"通用的apply方法",slug:"通用的apply方法",normalizedTitle:"通用的apply方法",charIndex:29505},{level:3,title:"透视表与交叉表  透视表(Pivot Table)",slug:"透视表与交叉表-透视表-pivot-table",normalizedTitle:"透视表与交叉表  透视表(pivot table)",charIndex:30460},{level:3,title:"透视表与交叉表  交叉表(Cross Table)",slug:"透视表与交叉表-交叉表-cross-table",normalizedTitle:"透视表与交叉表  交叉表(cross table)",charIndex:31441},{level:2,title:"Seaborn(Pandas)可视化",slug:"seaborn-pandas-可视化",normalizedTitle:"seaborn(pandas)可视化",charIndex:32030},{level:2,title:"matplotlib可视化",slug:"matplotlib可视化",normalizedTitle:"matplotlib可视化",charIndex:37680},{level:3,title:"条形图",slug:"条形图",normalizedTitle:"条形图",charIndex:32259},{level:4,title:"条形图",slug:"条形图-2",normalizedTitle:"条形图",charIndex:32259},{level:4,title:"条形图 bar()",slug:"条形图-bar",normalizedTitle:"条形图 bar()",charIndex:38775},{level:4,title:"水平条形图 barh()",slug:"水平条形图-barh",normalizedTitle:"水平条形图 barh()",charIndex:40077},{level:3,title:"子图",slug:"子图",normalizedTitle:"子图",charIndex:41328},{level:3,title:"饼图",slug:"饼图",normalizedTitle:"饼图",charIndex:42032},{level:3,title:"折线图(完整)",slug:"折线图-完整",normalizedTitle:"折线图(完整)",charIndex:43522}],headersStr:"基础语法 Numpy学习 Ndarray类学习 np.array方法 Numpy数组创建方法 打印数组 基本操作 (数组元素的运算) 基本操作 (矩阵乘积) 形状操纵 索引、切片和迭代 深入: 深入: 直方图 附:创建一个3*3 的数组方法 Pandas（两种数据结构学习） 1.Series(一维标记数组)学习 2.DataFrame(二维标记数据结构)学习 创建 DataFrame值索引 层次化索引与unstack DataFrame堆叠 DataFrame常用函数介绍(一) 重新索引(reindex) DataFrame常用函数介绍(二) 丢弃值(drop) DataFrame常用函数介绍(三) 算术方法 DataFrame常用函数介绍(四) 索引排序 DataFrame常用函数介绍(五) 描述和汇总统计(待补充) DataFrame常用函数介绍(六) 缺失值填充 Pandas文件读取 Pandas文件写入 Pandas合并xls文件 Pandas数据合并、清洗 merge函数 默认内连接 外连接 外连接 多列连接on=[] 左连接 how = 'left' how = 'right' 用表的行索引名作为连接 join函数(为merge的特例) 默认外连接 combine_first函数  以一个为基准,另一个进行补充 待补充 数据清理与转换(一) 值替换 数据清理与转换(二) 去重复值 数据清理与转换(三) 索引重命名 数据清理与转换(四) 数据转换 数据清理与转换(五) 数据离散化和装箱 指定划分边界 数据清理与转换(五) 数据离散化和装箱 平均划分边界 数据清理与转换(五) 数据离散化和装箱 分位划分边界 哑变量 数据随机取样(排序) 补充 Pandas聚合与分组 数据分组操作(1)  (groupby函数 & series分组) 数据分组操作(2)  (DataFrme分组) 数据分组操作(3)  分组指定应用聚合列 数据分组操作(4)  分组的迭代操作 数据分组操作(5)  对行索引名进行分组 数据分组操作(6)  聚合函数 数据分组操作(7)  自定义聚合函数agg() 自定义聚合操作  分组转换与分组应用 通用的apply方法 透视表与交叉表  透视表(Pivot Table) 透视表与交叉表  交叉表(Cross Table) Seaborn(Pandas)可视化 matplotlib可视化 条形图 条形图 条形图 bar() 水平条形图 barh() 子图 饼图 折线图(完整)",content:"# 基础语法\n\n\n# Numpy学习\n\n\n# Ndarray类学习\n\n点击查看\n\n# NumPy 参考手册 https://www.numpy.org.cn/reference/\n\"\"\"Ndarray类学习 (存放同类型元素的多维数组)\"\"\"\nimport numpy as np\n\n\"\"\"\nndarray.ndim - 数组的轴（维度）的个数。在Python世界中，维度的数量被称为rank。\nndarray.shape - 数组的维度。这是一个整数的元组，表示每个维度中数组的大小。对于有 n 行和 m 列的矩阵，shape 将是 (n,m)。因此，shape 元组的长度就是rank或维度的个数 ndim。\nndarray.size - 数组元素的总数。这等于 shape 的元素的乘积。\nndarray.dtype - 一个描述数组中元素类型的对象。可以使用标准的Python类型创建或指定dtype。另外NumPy提供它自己的类型。例如numpy.int32、numpy.int16和numpy.float64。\nndarray.itemsize - 数组中每个元素的字节大小。例如，元素为 float64 类型的数组的 itemsize 为8（=64/8），而 complex32 类型的数组的 itemsize 为4（=32/8）。它等于 ndarray.dtype.itemsize 。\nndarray.data - 该缓冲区包含数组的实际元素。通常，我们不需要使用此属性，因为我们将使用索引访问数组中的元素\n\"\"\"\n# order=\"C\" 行优先\n# arr1 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7]), offset=0, order=\"C\")\n# arr1\n\n# order=\"F\" 列优先\n# arr2 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7]), offset=0, order=\"F\")\n# arr2\n\n# offset=8 buffer中用于初始化数组的首个数据的偏移  (字节数的偏移 ndarray.itemsize为4 设置为8偏移两个值)\narr3 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7,8]), offset=8, order=\"C\")\n# arr3.itemsize\narr3\n\n\n\n# np.array方法\n\n点击查看\n\n\"\"\"\nnp.array只是一个便捷的函数,用来创建ndarray,\n它本身并不是一个类\n\"\"\"\nfrom numpy import *\n\narr4 = array(range(15)).reshape(3, 5)\n# arr4\n# print(arr4.T)\n# print(arr4.size)\n# print(arr4.itemsize)\n# print(arr4.ndim)\n# print(arr4.shape)\n# print(arr4.dtype)\n\n\"\"\"通过常规类型创建array\"\"\"\n# 1.通过tuple创建array\n# yuanzu = (4, 5, 6)\n# arr5 = array(yuanzu)\n# print(arr5)\n\n# 2.通过list创建array\n# pylist = [0, 1, 2]\n# arr6 = array(pylist)\n# print(arr6)\n\n# 3.构建多维的array\n# pylist2 = [4, 5, 6]\n# arr7 = array( [pylist, pylist2] )\n# print(\"多维数组:\\n\" + str(arr7))\n\n# 4.类型自动推断\n# arr8 = array( [1, 2, 3.3] )\n# print(arr8)\n# arr8 = array( [\"1\", 2, 3] )\n# print(arr8)\n\n# 5.明确数组类型\n# arr9 = array([1, 3, 6, 9], dtype=float32)\n# arr9\narr9 = array(['1', 3, 6, 9], dtype=ubyte)\narr9\n\n\n\n# Numpy数组创建方法\n\n点击查看\n\n\"\"\"Numpy数组创建方法\"\"\"\n# from numpy import *\n\n# 1. 全0数组\n# arr = zeros( (3, 4) ) # 二维全0数组\n# arr = zeros( (2,2,2) ) # 三维全0数组\n\n# 1.1 全1数组\n# arr = ones( (2, 3) )\n\n# 1.2 初始内容是随机的，取决于内存的状态\narr = empty( (2, 3) )\n\n# 1.2 全x数组\n# arr = full( (2, 3), 6 )\n\n# 1.3 根据步长创建数组arange(start, end, step)\n# arr = arange(0, 1, 0.1)\n\n# 2.等差数列\n# arr = linspace(0, 1, 10) # linspace(start, end, count, endpoint=True)\n# arr = linspace(0, 1, 10, endpoint=False)\n\n# 3.等比数列\n# arr = logspace(0, 10, 1, base=2) # logspace(start, end, count, base=10)\n\narr\n\n\n\n# 打印数组\n\n点击查看\n\n\"\"\"打印数组\"\"\"\n# import sys\n# 一维数组打印为行，将二维数据打印为矩阵，将三维数据打印为矩数组表\n# arr = arange(10000)\n\n# 如果数组太大而无法打印，NumPy会自动跳过数组的中心部分并仅打印角点\n# arr.reshape(100, 100)\n# 禁用此行为并强制NumPy打印整个数组 更改打印选项set_printoptions\n# set_printoptions(threshold=sys.maxsize)\n# arr.reshape(100, 100)\n\n\n\n# 基本操作 (数组元素的运算)\n\n点击查看\n\n\"\"\"基本操作 (数组元素的运算)\"\"\"\nimport numpy as np\n\na = np.array([10, 20, 30, 40, 50])\nb = np.array(np.arange(5))\nprint(\"%s%s\" % (\"数组a-数组b:\\t\",a - b)) # 数组相减\nprint(\"%s%s\" % (\"数组b的2次方:\\t\",b**2))\nprint(\"%s%s\" % (\"sin(a):\\t\", np.sin(a)))\nprint(\"%s%s\" % (\"数组a < 35\\t\",a < 35))\n\n\n\n# 基本操作 (矩阵乘积)\n\n点击查看\n\n\"\"\"基本操作 (矩阵乘积)\"\"\"\nA = np.array( [[1,1], [0,1]] )\nB = np.array( [[2,0], [3,4]] )\n\nprint(\"矩阵乘积:\" + str(A @ B))\nprint(\"矩阵乘积:\" + str(A.dot(B)))\n\n\n\"\"\"\n某些操作（例如+=和 *=）会更直接更改被操作的矩阵数组而不会创建新矩阵数组\n\"\"\"\nA *= 0\nA += 3\nB = np.random.random( (2, 2) )\nprint(B)\n# A += B # 需要向上转换 TypeError: Cannot cast ufunc add output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\nB += A\nprint(\"B += A:\\n\" + str(B))\n\n\"\"\"一元操作\"\"\"\n# B.sum() # 所有元素的和\n# B.min() # 最小的元素\n# B.max() # 最大的元素\n\n# B.sum(axis=0) # sum of each column\n# B.min(axis=1) # min of each row\n# B.cumsum(axis=1) # 在每一行的累积 cumulative sum along each row\n\n\"\"\"\n通函数\nNumPy提供熟悉的数学函数，例如sin，cos和exp。在NumPy中，这些被称为“通函数”（ufunc）。在NumPy中，这些函数在数组上按元素进行运算，产生一个数组作为输出\n\"\"\"\n\n\n\n# 形状操纵\n\n点击查看\n\n\"\"\"形状操纵 0428\"\"\"\nimport numpy as np\n\n# 改变数组的形状\narr = np.floor(np.random.random( (3,4) ) * 10)\nprint(arr.shape)\nprint(arr)\n# arr.ravel() # returns the array, flattened\n# arr.T\n# arr.reshape(6, -2)\n\n# 将不同数组堆叠在一起\narr1 = np.array([ [[1,2], [3,4]], [[5,6], [7,8]] ])\narr2 = np.array([ [[10,20], [30,40]], [[50,60], [70,80]] ])\n# np.vstack( (arr1, arr2) ) # 沿第一轴[水平(按列顺序)]堆叠\n# np.row_stack( (arr1, arr2) )\n# np.hstack( (arr1, arr2) )   # 沿第二轴[垂直(按照行顺序)]堆叠\n# np.column_stack( (arr1, arr2) )\n## 在复杂的情况下，r_和 c_于通过沿一个轴堆叠数字来创建数组很有用。它们允许使用范围操作符(“：”)。\n# np.r_[1:6, 0, 4]\n# np.r_[arr1, arr2]\n# np.c_[arr1, arr2]\n\n# 复制堆叠  numpy.repeat(a, repeats, axis=None)\n# '''\n#     a(array_like): 输入数组。\n#     repeats(int or array of ints): 每个元素的重复次数。 重复播放以适合给定轴的形状\n#     axis(int, optional) 重复值所沿的轴。默认情况下，使用展平的输入数组，并返回展平的输出数组。\n# '''\n# np.repeat(a=3, repeats=4)\n# np.repeat(a=arr1, repeats=2)\n# np.repeat(a=arr1, repeats=2, axis=2)\n\n# '''title'''\n\n# 将一个数组拆分成几个较小的数组\n# np.hsplit(arr1, (2,2))\n# a = np.array([np.arange(1,13), np.arange(1,13)*10])\n# np.hsplit(a, 3) # 无论数组尺寸如何，数组始终沿第二轴分割\n# np.hsplit(a, (3, 6, 9)) # (第二个参数是切分的块??? 012 345 678 9-)\n# np.vsplit(a, 2) # 该阵列被始终沿第一轴线分裂不管阵列的尺寸\n# '''split split(array, splits,axis=1) 将数组拆分为大小相等的多个子数组\n#     numpy.array_split（ary，indexs_or_sections，axis = 0 ）\n#     array_split允许 indices_or_sections是整数，它不平分轴。对于应分为n个部分的长度为l的数组，它返回大小为l // n + 1的l％n个子数组，其余大小为l // n\n# '''\n# np.array_split(ary=arr1, indices_or_sections=2, axis= 2)\narr3 = np.array([arr, arr*10])\nprint(\"arr3:\\n\" + str(arr3))\n# np.split(ary=arr3, indices_or_sections=arr3.shape[0], axis=0)\n\n\n\n# 索引、切片和迭代\n\n点击查看\n\nimport numpy as np\n\"\"\"索引、切片和迭代\"\"\"\n'''\n一维的数组可以进行索引、切片和迭代操作的，就像 列表 和其他Python序列类型一样。\n'''\narr = np.arange(12)**3\nprint(arr[5]) # 索引\nprint(arr[0:12:2]) # 切片\n# 迭代\nfor i in arr:\n    print(i, end=\" \")\n\n'''\n多维的数组每个轴可以有一个索引。这些索引以逗号分隔的元组给出：\n'''\narr = arr.reshape( (3,4) )\nprint(\"第三行第一个元素:\" + str(arr[2, 0])) # 索引\n\n# -1对应二维数组里的一维说的，但不包含最后一个一维数组；-2对应一维数组里的元素，不包含每个一维数组最后两个\nprint(arr[:-1,:-2]) # 切片\n# 迭代\nfor elem in arr.flat:\n    print(elem, end=\" \")\n    \narr\n\n\n\n# 深入:\n\n点击查看\n\n\"\"\"拷贝和视图\"\"\"\n# 完全不复制\n# 视图或浅拷贝\n# 深拷贝\n\"\"\"Less基础 广播（Broadcasting）规则\"\"\"\n\"\"\"花式索引和索引技巧\"\"\"\n# 使用索引数组进行索引\n# 使用布尔数组进行索引\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef mandelbrot( h,w, maxit=20 ):\n    \"\"\"用布尔索引生成Mandelbrot集的图像：\"\"\"\n    \"\"\"Returns an image of the Mandelbrot fractal of size (h,w).\"\"\"\n    y,x = np.ogrid[ -1.4:1.4:h*1j, -2:0.8:w*1j ]\n    c = x+y*1j\n    z = c\n    divtime = maxit + np.zeros(z.shape, dtype=int)\n\n    for i in range(maxit):\n     z = z**2 + c\n     diverge = z*np.conj(z) > 2**2            # who is diverging\n     div_now = diverge & (divtime==maxit)  # who is diverging now\n     divtime[div_now] = i                  # note when\n     z[diverge] = 2                        # avoid diverging too much\n\n    return divtime\nplt.imshow(mandelbrot(400,400))\nplt.show()\n\n# ix_()函数\n# 使用字符串建立索引\n\"\"\"线性代数 简单数组操作\"\"\"\n\"\"\"“自动”整形\"\"\"\n\"\"\"矢量堆叠\"\"\"\n\n\n\n# 深入: 直方图\n\n点击查看\n\n\"\"\"直方图\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Build a vector of 10000 normal deviates with variance 0.5^2 and mean 2\nmu, sigma = 2, 0.5\nv = np.random.normal(mu,sigma,10000)\n# Plot a normalized histogram with 50 bins\nplt.hist(v, bins=50, density=1)       # matplotlib version (plot)\nplt.show()\n\n# Compute the histogram with numpy and then plot it\n(n, bins) = np.histogram(v, bins=50, density=True)  # NumPy version (no plot)\nplt.plot(.5*(bins[1:]+bins[:-1]), n)\nplt.show()\n\n\n\n# 附:创建一个3*3 的数组方法\n\n点击查看\n\nimport numpy as np\n\n# 创建一个3*3 的数组, 下列代码错误的是\n# A:np.arange(9).reshape(3,3)\n# B:np.eye(3)\n# C:np.random.random([3,3,3])\n# D:np.mat(\"1 2 3;4 5 6;7 8 9\")\n# 正确答案:C\n\n# arr = np.arange(9).reshape(3,3)\n# arr = np.eye(3) # 生成对角矩阵\narr = np.random.random([3,3,3])\n# arr = np.mat(\"1 2 3;4 5 6;7 8 9\")\n\nprint(arr.shape)\narr\n\n\n\n# Pandas（两种数据结构学习）\n\n\n# 1.Series(一维标记数组)学习\n\n点击查看\n\n\"\"\"pandas 简介:https://www.pypandas.cn/docs/getting_started/ \"\"\"\nimport pandas as pd\nimport numpy as np\n\n\"\"\"Series(一维标记数组)学习\"\"\"\n\n# obj = pd.Series([1, 3, 5, np.nan, 6, \"ai\"])  # 默认下标0123\nobj = pd.Series([1, 2, 3, 4, 5], index=['d', 'b', 'a', 'c', 'e']) \n\n# obj\n# obj.values # 返回Series的值 为ndarray类型\n# obj.index # 返回索引名称\n\n'''series索引'''\n# 1.类似numpy索引方式\n# obj[2:6:2]\n\n# 2.index名称索引\n# obj[\"a\"] # 单个\n# obj[ [\"a\", \"d\", \"e\"] ] # 索引多个值,需要传入名称列表\n# obj[\"a\":\"c\"] # 包括\"c\"\n\n# 3.通过布尔表达式索引\n# obj[obj>=3]\n\n'''series赋值'''\n# 1.单个值赋值\n# obj[2] = 9\n\n# 2.多个值赋值\n# obj[0:2] = [-9, -6]\n\n# 3.通过布尔表达式赋值\nobj[obj<3] = 0\n\nobj\n\n\n\n# 2.DataFrame(二维标记数据结构)学习\n\n# 创建\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\"\"\"\n    DataFrame( data, index, columns, dtype, copy)(二维标记数据结构)学习\n    1. 像Series一样可以接收多种输入:lists、dicts、series和DataFrame等\n    2.初始化对象时,除了数据还可以传index和columns这两个参数\n    附:可以把DataFrame想象成一个电子表格，它由行名（index）、列名(columns)和数据(values)组成。\n\"\"\"\n\n# 1.根据字典新建DataFrame\n# data = {\n#     'column_a':[1, 2, 3],\n#     'column_b':[4, 5, 6],\n#     'column_c':[7, 8, 9]\n# }\n# df = pd.DataFrame(data, index=['r1', 'r2', 'r3'])\n\n# 1.2.根据嵌套字典新建DataFrame\n# data = {\n#     'c1':{'r1':111, 'r2':122},\n#     'c2':{'r1':211, 'r2':222}\n# }\n# df = pd.DataFrame(data)\n\n# 2. 根据列表创建DataFrame\n# data = [\n#     [1111, 2222, 3333],\n#     [111, 222, 333],\n#     [11, 22, 33],\n#     [1, 2, 3]\n# ]\n# df = pd.DataFrame(data, columns=['c1', 'c2', 'c3'], index=['r1', 'r2', 'r3', 'r4'])\n\n# 3. DataFrame 和 ndarray 互操作\n# 3.1 用ndarray构造DataFrame\nnarr = np.array([\n    [11, 22, 33, 44, 55], \n    [1.1, 2.2, 3.3, 4.4, 5.5]\n])\ndf = pd.DataFrame(narr, columns=['c1', 'c2', 'c3', 'c4', 'c5'], index=['r1', 'r2'])\n# 3.2 用DataFrame构造ndarray\n## narr2 = np.array(df)\n# narr2 = df.values\n# print(narr2)\n\n### end.输出\n# print(df.index)\n# print(df.columns)\n# print(df.values) # 返回值为ndarray类型\n# print(df.values.shape)\n# print(df.index.shape)\ndf\n\n\n# DataFrame值索引\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\n\"\"\"DataFrame值索引\"\"\"\n\n\ndata = [\n    [1111, 2222, 3333],\n    [111, 222, 333],\n    [11, 22, 33],\n    [1, 2, 3]\n]\ndf = pd.DataFrame(data, columns=['c1', 'c2', 'c3'], index=['r1', 'r2', 'r3', 'r4'])\n\n# 1.列索引(DataFrame[column_name],返回对应列的所有值)\n# df['c1']\n\n# 2. 行索引(DataFrame.ix[index_name],返回对应行的所有值。返回值类型为Series。)\n# df.ix['r1'] # 注意这里是中括号,不是函数??? (被弃用????)\n\n# 3.DataFrame.loc[index_name，column_name],返回对应元素。\n# df.loc['r1'] # 行索引\n# df.loc[:, 'c1'] # 列索引\n# df.loc['r1', 'c1']\n# df.loc[ ['r1', 'r3'] ] # 返回值为DataFrame。\n# df.loc['r1': 'r3', 'c2'] # 切片 包括起始和结束\n# df.loc[ df['c1']>100, ['c2'] ] # 有条件的返回布尔序列 + 指定列\n# df[df>100] # bool值的索引方法\n\n# 3.1 设定值 (实质上是给索引赋值??)\n# df.loc[df['c1']>100, ['c2'] ] = 2000\n# df\n\n# 4.DataFrame.iloc[x，y],返回对应元素。\n    # 参数(整数 # df.iloc[0] # 整数  具有整数的切片对象,例如1:7  布尔数组  一个callable带有一个参数的函数（调用Series或DataFrame）)\n# df.iloc[0] # 整数\n# df.iloc[ [0, 1] ] # df.iloc[0] # 整数\n# df.iloc[ 0:3:2 ] # 切片对象\n# df.iloc[[True, False, True, True]] # 布尔掩码与索引的长度相同\n\n# df = pd.DataFrame(data, columns=['c1', 'c2', 'c3'])\n# df.iloc[lambda x: x.index % 2 == 0]\n\n\n# 层次化索引与unstack\n\n点击查看\n\n\"\"\"层次化索引与unstack\"\"\"\n\"\"\"\n层次化索引可以在一个轴上拥有多个索引级别。也就是以低维度形式处理高维度数据。\nunstack()函数可以将层次化series转换成高维的DataFrame。\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series(np.random.randn(10), index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])\n# data # 两层索引\ndata.unstack()\n\n\n# DataFrame堆叠\n\n点击查看\n\n\"\"\"DataFrame堆叠 (shape相同)  [DataFrame表有行和列标签，因此堆叠时shape可以不一致]\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(np.array([[1,2,3],[4,5,6]]), index=['Ⅰ', 'Ⅱ'])\ndf2 = pd.DataFrame(np.array([[10,20,30],[40,50,60]]), index=['Ⅰ', 'Ⅱ'])\n\n# concat([pd1,pd2],axis=0,ignore_index=False)\n# print( pd.concat([df, df2]) )\n# pd.concat([df, df2], ignore_index=False) # 纵向堆叠时，忽略索引名\npd.concat([df, df2], axis=1)# 横向堆叠\n\n# frame = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n# print('值排序1  :\\n',   frame.sort_index(by='b', axis=0))\n# frame\n\n\n# DataFrame常用函数介绍(一) 重新索引(reindex)\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(一) 重新索引(reindex)\"\"\"\n\"\"\"\n    参数DataFrame.reindex(self, \n                labels=None, index=None, columns=None, axis=None, \n                method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n\"\"\"\nimport pandas as pd\n\ndf = pd.DataFrame(np.array([[1,2,3],[4,5,6]]), index=['Ⅰ', 'Ⅱ'], columns=['a', 'b', 'c'])\ndf.reindex(index=['Ⅰ', 'Ⅱ', 'Ⅲ'], columns=['a', 'b', 'c', 'd'], fill_value=0 )\n\n\n# DataFrame常用函数介绍(二) 丢弃值(drop)\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(二) 丢弃值(drop) [Ⅰ, Ⅱ, Ⅲ, Ⅳ, Ⅴ, Ⅵ, Ⅶ, Ⅷ, Ⅸ, Ⅹ]\"\"\"\n\"\"\"\n    参数DataFrame.drop(self, labels=None, axis=0, index=None, \n    columns=None, level=None, inplace=False, errors='raise')\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.array([[1,2,3],[4,5,6], [7,8,9], [np.nan,10,np.nan]]), \n                  index=['Ⅰ', 'Ⅱ', 'Ⅲ', 'Ⅳ'], columns=['a', 'b', 'c'])\n# df.drop(index='Ⅲ', axis=0) # 删除行 (返回新对象)\n# df.drop(columns='b', axis=1) # 删除列 (返回新对象)\n# 参数 DataFrame.dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n# df.dropna() # 清除有空值(NaN)的行\ndf.dropna(how='all') # 清除全为空的行(axis=1的列)\ndf.dropna(subset=['列名'],inplace=True)  # 某列为空删除这一行\n# df\n\n\n# DataFrame常用函数介绍(三) 算术方法\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(三) 算术方法\"\"\"\n\"\"\"\n    参数:add(self, other, axis='columns', level=None, fill_value=None)\n    sub(self, other, axis='columns', level=None, fill_value=None)\n    div(self, other, axis='columns', level=None, fill_value=None)\n    sub(self, other, axis='columns', level=None, fill_value=None)\n\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(np.arange(4).reshape((2,2)), columns=list('ab'))\ndf2 = pd.DataFrame(np.arange(6).reshape((2,3)), columns=('Ⅰ', 'Ⅱ', 'Ⅲ'))\n# df + df2\n# df.add(df2)\ndf.add(10)\n\n\n# DataFrame常用函数介绍(四) 索引排序\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(四) 索引排序\"\"\"\n\"\"\"\n    DataFrame.sort_index(self, axis=0, level=None, ascending=True, inplace=False, \n        kind='quicksort', na_position='last', sort_remaining=True, ignore_index: bool = False)\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.array([[1,2,3], [7,8,9], [4,5,6], [np.nan,5.5,np.nan]]), \n                  index=['Ⅲ', 'Ⅳ', 'Ⅰ', 'Ⅱ'], columns=['b', 'a', 'c'])\n# print(df)\n# df.sort_index() # 按索引排序\n# df.sort_index(by=['a', 'b']) # 不推荐使用sort_index的参数，请使用.sort_values（by = ...）\n# df.sort_index(axis = 1, ascending=False) # 按照列索引名降序排序\ndf.sort_index(axis = 0, ascending=False)\n# df.sort_values(by=[ 'a']) # 按值排序\n\n\n# DataFrame常用函数介绍(五) 描述和汇总统计(待补充)\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(五) 描述和汇总统计(补充)\"\"\"\nimport pandas as pd\n\ndf = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\ndf.cov() # 协方差计算方法，series需要通过参数传入\ndf.corr() # 相关系数计算方法，series需要通过参数传入\n\n\n# DataFrame常用函数介绍(六) 缺失值填充\n\n点击查看\n\n\"\"\"DataFrame常用函数介绍(六) 缺失值填充\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame(np.array([[1,2,3], [7,8,9], [4,5,6], [np.nan,5.5,np.nan]]), \n                  index=['Ⅲ', 'Ⅳ', 'Ⅰ', 'Ⅱ'], columns=['b', 'a', 'c'])\n# print(df)\n# df.fillna(0) # 全填为0\n# df.fillna({'b':666, 'c':999}) # 参数为字典类型 不同列填充不同值\ndf.fillna(df.mean()) # 列平均值填充列对应的NaN值\n\n\n# Pandas文件读取\n\n点击查看\n\n\"\"\"文件读取\"\"\"\nimport pandas as pd\n\n# filepath = 'data\\music.csv'\nfilepath = 'data\\sales-副本.csv' # 含中文的文件 65行\n\n# 1.read_csv方法\ndf = pd.read_csv(filepath, \n                 encoding='gbk', \n                 names=['发票id', '销售日期', '总金额', '支付金额', '收银员'], # 指定列名,不使用第一行作为列名\n                 skiprows=[0], # 忽略指定列\n#                  na_values=['NULL'], # 显示空值\n#                  nrows=12, # 文件大时 设置读取行\n#                  chunksize=4 # 每次读取4行\n                ) \n\n# 1.1使用chunksize=4参数,读取后的数据类型为TextFileReader\n# for ele in df:\n#     print(ele)\n\n# 2.read_table方法\n# df = pd.read_table(filepath, sep=',', encoding='gbk')\n# print(\"Dataframe的形状\" + str(df.shape))\ndf\n\n# df.fillna(\"空值\")\n\n\n# Pandas文件写入\n\n点击查看\n\n\"\"\"文件写入\"\"\"\nimport pandas as pd\nimport numpy as np\n# import sys\n\ndf = pd.DataFrame([\n    ['NaN', 88, 66, 55, 39],\n    [53, 52, 86, 66, np.nan],\n    [21, 98, 68, 'NULL', 99]\n])\n# df\nfilepath = 'data\\pfile_test.csv'\ndf.to_csv(filepath, # sys.stdout, # 输出到控制台\n          na_rep='non', # 存储空值\n          sep='\\t', # 设置分隔符\n          index=False, # 不存储索引(index)\n          header=False, # 不存储列名\n#           columns=[0, 1] # 设置只保存 某些列\n         )\n\n\n# Pandas合并xls文件\n\n点击查看\n\nimport pandas as pd\nimport os\n\nfile_path = \"D:\\\\software\\\\pythonProjects\\\\weibospider\\\\weibospider\\\\spiders\\\\data\\\\weibo\"\nfile_list = [f\"{file_path}\" + i for i in os.listdir(file_path)]'\n\nli=[]\nfor i in file_list:\n    li.append(pd.read_excel(i))\nwriter = pd.ExcelWriter(f'{file_path}\\微博.xlsx')\npd.concat(li).to_excel(writer,'Sheet1',index=False)\n \nwriter.save()\n\n\n\n# Pandas数据合并、清洗\n\n\n# merge函数 默认内连接\n\n点击查看\n\nimport pandas as pd\n\"\"\"merge函数 默认内连接\"\"\"\n\n\"\"\"1.内连接(默认) how = 'inner'\"\"\"\n# 1.1 按 相同列名 内连接\n# df1 = pd.DataFrame({'key':['b','b','a','c'], 'data1':range(4)})\n# df2 = pd.DataFrame({'key':['a','b','d'], 'data2':range(3)})\n# df3 = pd.merge(df1, df2, on = 'key', how = 'inner')\n\n# 1.2 没有同名列 (相当于把参数on= 变为 left_on 和 right_on两个参数)\ndf1 = pd.DataFrame({'key1':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.DataFrame({'key2':['a','b','d'], 'data1':range(3)})\ndf3 = pd.merge(df1, df2, left_on='key1', right_on='key2')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# 外连接\n\n# 外连接\n\n点击查看\n\nimport pandas as pd\n\n\"\"\" 2.外连接 \"\"\"\n''' 1.how  2.多列连接on=[] 3.区分相同列名suffixes= 4.索引名连接right_index=True'''\n# 2.1.1  how = 'outer'\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c'],'data1': range(4)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'd'],'data2': range(3)})\ndf3 = pd.merge(df1,df2,how='outer')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# 多列连接on=[]\n\n点击查看\n\nimport pandas as pd\n\n# 2.1.2 多列连接on=[]\ndf1 = pd.DataFrame({'k1': ['A', 'A', 'B'], 'k2': ['a', 'b', 'a'], 'lval': [1, 2, 3]})\ndf2 = pd.DataFrame({'k1': ['A', 'A', 'B', 'B'], 'k2': ['a', 'a', 'a', 'b'], 'rval': [4, 5, 6, 7]})\ndf3 = pd.merge(df1, df2, how='outer',on= ['k1', 'k2'])\n\n# 2.1.3 非连接列有重名时指定后缀\n# df3 = pd.merge(df1, df2, how='outer',on='k1', suffixes=['_x', '_y'])\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# 左连接 how = 'left'\n\n点击查看\n\nimport pandas as pd\n\n# 2.2\ndf1 = pd.DataFrame({'key':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.DataFrame({'key':['a','b','d'], 'data2':range(3)})\n# 2.2 左连接 how = 'left'\ndf3 = pd.merge(df1, df2, on = 'key', how = 'left')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# how = 'right'\n\n点击查看\n\nimport pandas as pd\n\n# 2.2\ndf1 = pd.DataFrame({'key':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.DataFrame({'key':['a','b','d'], 'data2':range(3)})\n\n# 2.3 右连接 how = 'right'\ndf3 = pd.merge(df1, df2, on = 'key', how = 'right')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# 用表的行索引名作为连接\n\n点击查看\n\nimport pandas as pd\n# 2.4.1 用表的行索引名作为连接\ndf1 = pd.DataFrame({'key': ['a', 'b', 'a', 'c'],'value': range(4)})\ndf2 = pd.DataFrame({'val': [4, 9]}, index=['a', 'b']) \ndf3 = pd.merge(df1, df2, left_on='key', right_index=True, how='outer')\ndf3 = pd.merge(df1, df2, left_on='key', right_index=True, how='outer')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# join函数(为merge的特例) 默认外连接\n\n点击查看\n\nimport pandas as pd\n\"\"\"join函数(为merge的特例) 默认外连接\"\"\"\n\ndf1 = pd.DataFrame({'key1': ['b', 'b', 'a', 'c'],'data1': range(4)})\ndf2 = pd.DataFrame({'key2': ['a', 'b', 'd'],'data2': range(3)})\n\n# 两种方式相当\nprint(pd.merge(df1, df2,left_index=True, right_index=True))\ndf1.join(df2, how='inner')\n\n\n\n# combine_first函数 以一个为基准,另一个进行补充\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\n\n\"\"\"combine_first函数  以一个为基准,另一个进行补充\"\"\"\ndf1 = pd.DataFrame(np.arange(6).reshape((2, 3)),index=['a','b'])\ndf2 = pd.DataFrame(np.arange(6).reshape((3, 2)),index=['a','b','c'])\n\n# 体会两者的区别\nprint(df1.combine_first(df2)) # df1值为NaN的位置，由df2来填充\ndf2.combine_first(df1) # 以df2为准，用df1补空\n\n\n\n# 待补充\n\n点击查看\n\n\"\"\"\npd.concat与np.concatenate对比\npd.concat与pd.merge与join\nConcat忽略索引\n\"\"\"\n\n\n\n# 数据清理与转换(一) 值替换\n\n点击查看\n\n\"\"\"数据清理与转换(一) 值替换\"\"\"\n\nimport numpy as np\nimport pandas as pd\n\"\"\"数据清理--值替换\"\"\"\n\n''' 1. df.fillna()方法[对NaN值进行填充] '''\ndf =  pd.DataFrame([[1,np.nan,2,0], [np.nan, np.nan, np.nan, np.nan,], [3, np.nan,5,6]])\nprint(df) # 打印原始值\n\n# 1.1 全部填充为0\n# df.fillna(0)\n\n# 1.2 填充为列平均值\n# df.fillna(df.mean())\n\n# 1.3 不同列采用不同填充\n# df.fillna({0:0.0, 1:1.1, 2:2.2, 3:3.3})\n\n''' \n2.df.replace()方法,对不同值(比如0, -1, NaN)进行填充 \n    附:df.replace(np.nan, 0) 相当于 df.fillna(0)\n'''\n# 2.1 把多个值[np.nan, 0] 替换为 -1\n# df.replace([np.nan, 0], -1)\n\n# 2.2 把多个值 替换为 多个值\ndf.replace([np.nan, 0], [0, -1])\n\n\n\n# 数据清理与转换(二) 去重复值\n\n点击查看\n\n\"\"\"数据清理与转换(二) 去重复值\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf1 = pd.DataFrame({'k1': ['a','a','b','c','c','c','a'], 'k2': [1, 1, 2, 3, 3, 4, 6]}) \n# print(df1)\n\n# 1 duplicated()函数 [找出重复记录]\n# df1.duplicated()\n# 2.1 drop_duplicates()函数 [直接剔除对应的重复记录]\n# df1.drop_duplicates()\n# 2.2以列为单位比较是否存在重复记录[默认行为单位]\ndf1.drop_duplicates(['k1', 'k2'])\n\n\n\n\n# 数据清理与转换(三) 索引重命名\n\n点击查看\n\n\"\"\"数据清理与转换(三) 索引重命名\"\"\"\nimport pandas as pd\n\n# 1.df.rename(index={},columns={})方法\ndf1 = pd.DataFrame([[1111, 2222, 3333, 4444], [111, 222, 333, 444], [11, 22, 33, 44]])\n# print(df1)\n\ndf1.rename(index={0:'row_1', 1:'row_2', 2:'row_3'}, columns={0:'col_1', 1:'col_2', 2:'col_3', 3:'col_4'})\n\n\n\n# 数据清理与转换(四) 数据转换\n\n点击查看\n\n\"\"\"数据清理与转换(四) 数据转换\"\"\"\nimport pandas as pd\n\n'''函数转换 map(Func)函数'''\n# 1. 替换fillna replace(见前面)\n# 2. map(Func)函数 [内部值进行函数转换。如统一字符的大小写等]\ndf1 = pd.DataFrame({\"course\":[\"Chinese\", \"math\", \"English\", \"physics\" , \"chemistry\", \"biologic\"], \n                    \"score\":[96, 94, 92, 62, 45, 60]})\n# 2.1第一列转换为首字母大写\n# df1['course'] = df1['course'].map(str.title) # upper\n\n'''映射转换 map(Func)函数'''\n# 1.根据字典的映射进行相应转换\ncourse = {\"Chinese\":\"语文\", \"math\":\"数学\", \"English\":\"英语\", \"physics\":\"物理\", \"chemistry\":\"化学\", \"biologic\":\"生物\"}\ndf1['course'] = df1['course'].map(course)\n\ndf1\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 指定划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\nimport pandas as pd\nimport numpy as np\n\n\"\"\"\n    数值类型  1.连续值:一定区间可连续取值(比如天气的温度)  2.离散值:按一定顺序一一列举(比如'多云','晴天','雨天','阴天')\n    Categoricals:  1.是 pandas 的一种数据类型,是由固定的且有限数量的离散变量组成的 2.不能排序(sort_by): 顺序是创建时手工设定的，是静态的\n\"\"\"\n\n'''指定划分边界  cut()函数[实现数据装箱bin(连续->离散)。返回一个Categorical对象]'''\n# arr = np.arange(0, 100, 7)\narr = np.random.randint(0, 100, 18) # 生成在半开半闭区间[low,high)上离散均匀分布的整数值\nprint(f\"arr:{arr}\")\nbins = [0, 40, 80, 100]\ncats = pd.cut(arr, bins)\n# cats \nprint(f\"编号:{cats.codes}\") # 从0开始生成编号,不在范围内为-1\n\n# 把array转换为DataFrame\ndf1 = pd.DataFrame( arr.reshape(3, 6) )\nprint(f\"矩阵:\\n{df1}\")\n\ndf1[3] = pd.cut(df1[3], bins).values.codes\ndf1\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 平均划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\nimport pandas as pd\nimport numpy as np\n\n'''平均划分边界  cut()函数 可以通过数值平均等分(平均数)自动划分并装箱'''\narr = np.random.randint(0, 100, 18)\ncats = pd.cut(arr, 4)\n# print(f\"装箱后矩阵:\\n{cats.codes.reshape(3, 6)}\")\n\ndf1 = pd.DataFrame( arr.reshape(3, 6) )\nprint(df1)\npd.DataFrame( cats.codes.reshape(3, 6) )\n# cats\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 分位划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\n\nimport pandas as pd\nimport numpy as np\n\n'''分位划分边界  qcut(data,count) 使用中位数来划分数据并装箱'''\narr = np.random.randint(0, 100, 18)\ncats = pd.qcut(arr, 4)\n# print(f\"装箱后矩阵:\\n{cats.codes.reshape(3, 6)}\")\n\ndf1 = pd.DataFrame( arr.reshape(3, 6) )\nprint(f\"随机矩阵:{df1}\")\nprint(f\"cats:{cats}\")\npd.DataFrame( cats.codes.reshape(3, 6) )\n\n\n\n\n# 哑变量\n\n点击查看\n\n\"\"\"\n哑变量(可以提高运算速度) 哑变量(dummy variable)是指用0或1表示某个类别是否出现\n1. 有N种互斥属性时，哑变量需要引入N-1个变量，独热编码需要N个变量\n2. get_dummies(drop_first=True)为真正哑变量，默认的drop_first=False为独热编码\n\n\"\"\"\nimport pandas as pd\n\ndf1 = pd.DataFrame({\"key\":['a', 'b', 'a', 'c']})\n# 独热编码\n# pd.get_dummies(df1['key'])\n\n# 哑变量\npd.get_dummies(df1['key'], drop_first=True)\n\n# 连接哑变量\n\n\n\n# 数据随机取样(排序)\n\n点击查看\n\n\"\"\"数据随机取样\"\"\"\nimport pandas as pd\nimport numpy as np\n\n# 1.随机排序\ndf1 = pd.DataFrame({'k1': ['a','a','b','c','c','c'], 'k2': [1, 1, 2, 3, 3, 4]}) \n# sampler = np.random.permutation(6) # 生成随机序列\n# df1.take(sampler) # 以随机序列为行索引,重新排序后输出\n\n# 2.随机下采样 [随机排序后,取前n行]\nsampler = np.random.permutation(len(df1))[:3] # simpler = array([x, x, x])\n\n# 3.随机上采样 [样本较少时,扩大样本(),再取样]\n## 生成12个元素在0 - 6范围内的数组(正态)\n# sampler = np.random.randint(0, len(df1), size=2*len(df1))\n\ndf1.take(sampler)\n# sampler\n\n\n\n# 补充\n\n点击查看\n\n\"\"\"字符串操作\"\"\"\n\n# 打印内置方法和属性\n# dir(): 返回参数的属性、方法列表\n# dir(\"\")\n\n# 编码解码\n# \"你好\".encode()\nb'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'.decode('utf-8')\n\n\n\"\"\"老师的代码\"\"\"\n\n# 前缀使用\ndf=pd.DataFrame([[1,'a'],[2,'b'],[3,'c'],[1,'d'],[3,'e'],[2,'f']],columns=['lie1','lie2'])\nprint(df)\ndf1=pd.get_dummies(df['lie1'],prefix='lie1')\nprint(df1)\n\n'''\n一个对统计应用有用的秘诀是：结合get_dummies和cut之类的离散化函数\n'''\n#正态分布是个数值\ndata=np.random.rand(10)\nprint(data)\n# [0.01472476 0.21786879 0.80685543 0.33888554 0.28585739 0.03260082\n#  0.86698275 0.86326211 0.36818782 0.04061498]\n \n#设置面元\nbins=[0,0.2,0.4,0.6,0.8,1]\n \n#面元划分\nprint(pd.cut(data,bins))\n# [0.09044921 0.34034557 0.16417927 0.45625488 0.05030981 0.26397673\n#  0.93966121 0.17444847 0.19196159 0.48356917]\n# [(0.0, 0.2], (0.2, 0.4], (0.0, 0.2], (0.4, 0.6], (0.0, 0.2], (0.2, 0.4], (0.8, 1.0], (0.0, 0.2], (0.0, 0.2], (0.4, 0.6]]\n# Categories (5, interval[float64]): [(0.0, 0.2] < (0.2, 0.4] < (0.4, 0.6] < (0.6, 0.8] < (0.8, 1.0]]\n#    (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]\n \n#哑变量\nprint(pd.get_dummies(pd.cut(data,bins)))\n\n\n\n# Pandas聚合与分组\n\n\n# 数据分组操作(1) (groupby函数 & series分组)\n\n点击查看\n\n\"\"\"数据分组操作(1)  (groupby函数 & series分组)\"\"\"\nimport pandas as pd\nimport numpy as np\n\n# 1.groupy()函数返回一个GroupBy对象,此对象没有做任何计算，只生成符合分组条件的中间数据，当执行apply方法时才进行真正的计算\ndf = pd.DataFrame({ 'k1':['a', 'a', 'b', 'b'], 'k2':['one', 'two', 'one', 'one'], 'v1':np.arange(4), 'v2':np.arange(6,10)})\n\n'''单列分组'''\n# grouped = df['v1'].groupby(df['k1'])\n\n'''多列分组 (多层次索引的Series,可转化为DataFeame)'''\ngrouped = df['v1'].groupby([df['k1'], df['k2']])\n\n# grouped # 显示GroupBy对象\n\nprint(df) # 打印df\n\n# GroupBy对象在执行apply方法时，才会进行真正的计算和组合\n## 如:在GroupBy对象上应用求平均的应用，并聚合输出一个新的Series\n# grouped.mean()\npd.DataFrame(grouped.mean()) # 多层索引Series转化为DataFrame\n\n\n\n# 数据分组操作(2) (DataFrme分组)\n\n点击查看\n\n\"\"\"数据分组操作(2)  (DataFrme分组)\"\"\"\n# np.array?? # help(np.array) # 查看方法详细信息\n\n# DataFrame数据表对象，使用groupby()函数，指定分组的列，即可对数据表其它列进行应用和聚合\ndf = pd.DataFrame({'k1' : ['a', 'a', 'b', 'b'], 'k2' : ['one', 'two', 'one', 'one'],'v1' : np.arange(4), 'v2' : np.arange(6,10)})\nprint(df)\n# 1. 单列分组\n# 当被分组并应用汇聚的列，无法进行应用汇聚时，则直接丢弃(比如k2列为字符串,不能进行mean求平均值)\n# df.groupby('k1').mean()\n\n# 2.多列分组\n# df.groupby(['k1', 'k2']).mean()\n\n# 3.多列分组—去除分组索引\n## 在多列分组的情况下，新生成的数据表会有多层次化索引，有的时候我们不需要这些索引，而是要将他们变成新的数据列\n# df.groupby(['k1', 'k2'], as_index=False).mean()\n\n# 4.自定义分组\n# 如果我们不按照数据表中某列来分组，先自己定义分组的规则。这时，可以通过传入自定义列表传入groupby参数，按照列表数据规则进行分组\n# df.groupby(['A', 'A', 'A', 'B']).mean()\n# df.groupby(['1', '1', '2', '0']).mean()\n\n# 5.多列分组—求和\n# df.groupby(['1', '1', '2', '0']).sum()\n\n# 6.多列分组—最大值\n# df.groupby(['k1', 'k2']).max()\n\n# 7.多列分组—中位数\n# df.groupby(['k1', 'k2']).median()\ndf.groupby(['1', '1', '2', '1']).median()\n\n\n\n# 数据分组操作(3) 分组指定应用聚合列\n\n点击查看\n\n\"\"\"数据分组操作(3)  分组指定应用聚合列\"\"\"\n\ndf = pd.DataFrame({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', 'one', 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\n# 1.指定单列 (运行没好使)\n## 使用groupby()函数对DataFrame数据表进行分组时，可以指定方法应用和聚合的单列，并返回Series对象。series.groupby([“column_name”,”column_name”]).mean()\n# df['v1'].groupby(['k1', 'k2']).mean()\n\n# 1.2 指定单列—语法糖 (计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用)\n## 什么是语法糖:https://www.jianshu.com/p/777b10385524\ndf.groupby(['k1', 'k2'])['v1'].mean()\n\n# 2.指定多列 (运行没好使)\n# df[['v1','v2']].groupby(['k1', 'k2']).mean()\n\n# 2.1 指定多列—语法糖\ndf.groupby(['k1', 'k2'])['v1','v2'].mean()\n\n\n\n# 数据分组操作(4) 分组的迭代操作\n\n点击查看\n\n\"\"\"数据分组操作(4)  分组的迭代操作\"\"\"\n\ndf = pd.DataFrame({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', 'one', 'one'],'v1' : np.arange(4),'v2' : np.arange(6,10)})\n# print(df)\n\n# 对不同分组进行不同处理,对GroupBy对象进行迭代,在迭代中处理各个分组\n# 1.输出分组\n# for name, group in df.groupby('k1'):\n#     print(\"name:\" + name)\n#     print(group)\n\n# 2.\n# for [k1, k2],group in df.groupby(['k1', 'k2']):\n#     print(f'({k1}, {k2}):\\n{group}')\n\n# 3.可以将分组数据变成数据表字典,dict(list(GroupByObj)) \ngroupDict = dict(list(df.groupby('k1'))) # 先转列表再转字典\ngroupDict['a']\n\n\n\n# 数据分组操作(5) 对行索引名进行分组\n\n点击查看\n\n\"\"\"数据分组操作(5)  对行索引名进行分组\"\"\"\n\ndf = pd.DataFrame({ 'k1':['a', 'a', 'b', 'b'], 'k2':['one', 'two', 'one', 'one'], 'v1':np.arange(4), 'v2':np.arange(6,10)}, \n                index=['c1','cc2','cc3','c4'])\nprint(df)\n# 1.行索引函数分组\ndf.groupby(len).mean()\n\n# 2.行索引函数分组\ndf.index=['c1','cc2','cc3','c1'] # 重置索引\ndf.groupby(str).mean()\n# df\n\n\n\n# 数据分组操作(6) 聚合函数\n\n点击查看\n\n\"\"\"数据分组操作(6)  聚合函数\"\"\"\n\ndf = pd.DataFrame({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n# 1.非空值计数\ndf.groupby('k1').count()\n\n# 2. 分组乘积\n# df.iloc[3, 2] = np.nan # 将3,2设为NaN\n# df.groupby('k1').prod() # NaN不参与乘积\n\n# 3.分组方差和标准差\n# df.iloc[3, 2] = np.nan\n# df.groupby('k1').var() # 方差\n# df.groupby('k1').std() # 样本标准差 (numpy的是总体标准偏差???)\n\n# 4.分位数\n# df.iloc[3, 2] = np.nan\n# df.groupby(['k1', 'k2']).quantile(0.75)\n\n# 5.首尾值\n# df.iloc[3, 2] = np.nan\n# # df.groupby('k1').first()\n# df.groupby('k1').last()\n\n# 6.数据探索\n## 在数据分析的数据探索阶段，需要对数据有个整体的感知，如果按上面步骤一个个看的话比较麻烦。Pandas提供describe()函数，可以生成常用方法结果\ndf.iloc[3, 2] = np.nan\ndf.groupby('k1').describe()\n\n\n\n# 数据分组操作(7) 自定义聚合函数agg()\n\n点击查看\n\n\"\"\"数据分组操作(7)  自定义聚合函数agg()\"\"\"\n\ndf = pd.DataFrame({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\ndef my_fun(data):\n    return data.max() + data.min()\n\ndf.iloc[3, 2] = np.nan\n\n# 1.自定义函数\n# df.groupby('k1').agg(my_fun)\n\n# 2.自定义agg函数列表\n# df.groupby('k1').agg(['mean', 'max', 'min', my_fun])\n\n# 2.2 自定义agg函数列表 [指定应用结果的列名称(用元组)]\n# df.groupby('k1').agg([('平均值', 'mean'), ('最大值', 'max'), ('最小值', 'min'), (\"最大最小值之和\", my_fun)])\n\n# 2.3 自定义agg函数列表 [指定列名称(用元组) + 前缀add_prefix]\n## 定义新数据表列名时，在同一行中命名会出现相同的情况，容易混淆\ndf.groupby('k1').agg( my_fun ).add_prefix('x_')\n\n\n\n# 自定义聚合操作 分组转换与分组应用\n\n点击查看\n\n\"\"\"自定义聚合操作  分组转换与分组应用\"\"\"\ndf = pd.DataFrame({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\n# df.iloc[3,2] = np.nan\n\n# 1.transform()函数 如果我们需要将统计结果参照原表的shape,直接广播到列中\n# df.groupby('k1').transform(np.mean)\n# df.groupby('k1').mean()  # ?区别\n\n# 2.GroupBy对象的transform()函数，与agg()一样可以传入自定义函数\ndef my_fun(data):\n    return data.max() + data.min()\n\n# df.groupby(['k1', 'k2']).transform(my_fun)  # ????????????????????不好使\ndf.groupby('k1')['v1', 'v2'].transform(my_fun)\n\n# 3.agg和transform的区别\n## agg()函数 必须是可以汇聚的值（ aggregated value ）\n## transform()函数则可以传入普通的转换函数\n# def divide(df,n=2):\n#     return df/n\n\n# df.groupby('k1').agg(divide) # Exception: Must produce aggregated value\n# df.groupby(\"k1\")['v1','v2'].transform(divide)\n\n\n\n# 通用的apply方法\n\n点击查看\n\n\"\"\"\n通用的apply方法 可以是非汇聚函数\n1. 通常，agg聚合生成的表shape小于原表，而apply和transform组合的shape可以等于原表\n\"\"\"\n\n'''\n    agg和transform的局限\n    agg()函数需要传入的方法可以返回汇聚的值（ aggregated value ），transform()函数则可以是N:1的汇聚值，也可以是1对1的转换值。\n    如果是输入M到输出N的函数(M>N)，agg和transform都无法使用！比如: 取分组的前N个值\n'''\ndf = pd.DataFrame({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\ndef get_rows(df,n=2): \n    return df.iloc[:n,:]\n\n# df.groupby('k1')['v1','v2'].agg(get_rows) #  ValueError: Shape of passed values is (4, 2), indices imply (2, 2)\n# df.groupby(\"k1\")['v1','v2'].transform(get_rows) # IndexingError: ('Too many indexers', 'occurred at index v1')\n\n# 1.取分组前N个值的方法\n# df.groupby('k1')['v1','v2'].apply(get_rows,1)\n\n# 2.也可以用apply()取TopN个值\ndef topn(df, n=3, column='sort_column'):\n    return df.sort_values(by=column,ascending=False)[:n]\n\ndf.groupby(\"k1\")['v1','v2'].apply(topn,2,'v2')\n\n\n\n# 透视表与交叉表 透视表(Pivot Table)\n\n点击查看\n\n\"\"\" 透视表与交叉表  透视表(Pivot Table)\"\"\"\nimport pandas as pd\n'''\n透视表(pivot table)是各种电子表格程序和其他数据分析软件中一种常见的数据汇总工具。它根据一个或多个键对数据进行聚合，并根据行和列上得分组建将数据分配到各个矩形区域中。\n1. 在Python和pandas中，可以通过本章所介绍的groupby功能以及（能够利用层次化索引的）重塑运算制作透视表。\n2. DataFrame有一个pivot_table方法，此外还有一个顶级的pandas.pivot_table函数。除了能为groupby提供便利之外，pivot_table还可以添加分项小计（也叫margins\n'''\n\ndf = pd.DataFrame({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\n# DataFrame.pivot_table(Index, Columns, aggFunc(默认为np.mean), fill_value)\n# 1.如果只指定pivot_tabel()函数的index参数，不指定columns参数和fill_value参数，其结果和前面介绍的分组聚合结果一致。\n# df.pivot_table(index='k1') # 相当于df.groupby('k1').mean()\n\n# 2.指定输出的列\n# df.pivot_table(['v1', 'v2'], index='k1') # 相当于df.groupby('k1')['v1', 'v2'].mean()\n\n# 3.如果只指定pivot_tabel()函数的index参数，指定columns参数，就是将以列维度进行分组，其效果和指定两个分组行索引，再将返回的层次索引unstack() 结果一致\ndf.pivot_table(index='k1', columns='k2') # 相当于df.groupby(['k1', 'k2']).mean().unstack()\n\n\n\n# 透视表与交叉表 交叉表(Cross Table)\n\n点击查看\n\n\"\"\" 透视表与交叉表  交叉表(Cross Table)\"\"\"\nimport pandas as pd\n\n\"\"\"\n1. 交叉表(cross table) 是矩阵格式的一种表格，显示变量的（多变量）频率分布。\n2. 交叉表被广泛用于调查研究，商业智能，工程和科学研究。它们提供了两个变量之间的相互关系的基本画面，可以帮助他们发现它们之间的相互作用。\n3. 卡尔·皮尔逊（Karl Pearson）首先在“关于应变的理论及其关联理论与正常相关性”中使用了交叉表。\n4. 在pandas中，交叉表是一种特殊的透视表。\n\"\"\"\n# pd.crosstab(index, columns, margins[边际求和开关])\ndf = pd.DataFrame({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\ndef get_rows(df,n=2): \n    return df.iloc[:n,:]\n\ndf.iloc[3,2] = np.nan\n# pd.crosstab(df['k1'],df['k2'])\npd.crosstab(df['k1'],df['k2'],margins=True)\n\n\n\n# Seaborn(Pandas)可视化\n\n折线图\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.DataFrame(np.random.randn(10,3), columns = ['A','B','C'], index = np.arange(0,100,10))  \ndf.plot()\nplt.show() \n# df\n\n\n条形图\n\n点击查看\n\nfig, axes = plt.subplots(1,2)  \ndata = pd.Series(np.random.rand(7),index = list('abcdefg'))  \n#kind选择图表类型  'bar' 垂直条形图 \ndata.plot(kind = 'bar', ax = axes[0], color = 'b', alpha = 0.7) \n# 'barh' 水平条形图 \ndata.plot(kind = 'barh', ax = axes[1], color = 'b', alpha = 0.7)\nplt.show() \n\n\n直方图\n\n点击查看\n\nimport sklearn.datasets as skds\n\"\"\"直方图\"\"\"\n\n# iris = skds.load_iris()\n# df_iris = pd.DataFrame(iris.data,columns=iris.feature_names)\n# df_iris.hist('sepal length (cm)')\n# plt.show()\n\niris = skds.load_iris()\ndf_iris = pd.DataFrame(iris.data,columns=iris.feature_names)\ndf_iris.hist()\nplt.show()\n\n## --------------------------------------------\n\nfig, axes = plt.subplots(1,2)  \ndata = pd.Series(np.random.randn(100))  \ndata.hist(ax = axes[0], bins = 50)       #直方图  \ndata.plot(kind = 'kde', ax = axes[1])    #密度图  \nplt.show() \n\n\n散点图\n\n点击查看\n\niris = skds.load_iris()\ndf_iris = pd.DataFrame(iris.data,columns=iris.feature_names)\ndf_iris.plot(kind='scatter',x=\"sepal length (cm)\", y=\"sepal width (cm)\")\nplt.show()\n\n\nMatplotlib无疑是高度可定制的，但快速实施出吸引人的细节就变得有些复杂。Seaborn作为一个带着定制主题和高级界面控制的Matplotlib扩展包，能让绘图变得更轻松\n\n示例\n\n点击查看\n\n\"\"\"Seaborn可视化方法  (单变量分布)\"\"\"\nimport seaborn as sns \n\n\"\"\"最快速查看单变量分布无疑是使用distplot()函数。默认情况下，这将绘制一个直方图，并拟合出核密度估计(KDE)\"\"\"\nx = np.random.normal(size=100)\nsns.distplot(x)\nplt.show()\n\n# ---------------------------------\n\"\"\"Seaborn可视化方法  (直方图)\"\"\"\n\n\"\"\"\n直方图通过在数据的范围内切成数据片段，然后绘制每个数据片段中的观察次数，来表示整体数据的分布。\n我们删除密度曲线并添加了地毯图，每个观察点绘制一个小的垂直刻度\n\"\"\"\n\nx = np.random.normal(size=100)\nsns.distplot(x, kde=False, rug=True)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"Seaborn可视化方法  (核密度估计)\"\"\"\n\n\"\"\"Seaborn的displot()函数，通过设置参数，可以实现只显示核密度估计和地毯图\"\"\"\nx = np.random.normal(size=100)\nsns.distplot(x, hist=False, rug=True)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"Seaborn可视化方法  (散点双变量分布)\"\"\"\n\n# 随机生成两列，其均值为[0,1],协方差矩阵为[(1, 0.5), (0.5, 1)]的数组\n\nmean, cov = [0, 1], [(1, 0.5), (0.5, 1)]\ndata = np.random.multivariate_normal(mean, cov, 200)\ndf = pd.DataFrame(data, columns=[\"x\", \"y\"])\nsns.jointplot(x=\"x\", y=\"y\", data=df)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"Seaborn可视化方法  (成对关系图)\"\"\"\n\"\"\"\n要在数据集中绘制多个成对双变量分布，可以使用pairplot()函数。这将创建一个轴的矩阵，并显示DataFrame中每对列的关系。\n默认情况下，它也绘制每个变量在对角轴上的单变量。\n\"\"\"\n\nimport sklearn.datasets as skds\niris = skds.load_iris()\ndf_iris = pd.DataFrame(iris.data,columns=iris.feature_names)\nsns.pairplot(df_iris)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"Seaborn可视化方法  (线性回归线一)\"\"\"\n\n\"\"\"Seaborn的lmplot(data,x,y)函数，将data数据表中x列和y列数据，生成散点图，并绘制线性回归线。本示例使用tips数据集。\"\"\"\n# tips = sns.load_dataset(\"tips\")\ntips = pd.read_csv('./data/tips.csv')\nsns.lmplot(data=tips, x=\"total_bill\", y=\"tip\")\nplt.show()\n## ---------------------------------\n\n\"\"\"Seaborn可视化方法  (线性回归线二)\"\"\"\n\n\"\"\"Seaborn的jointplot()函数绘制双变量分布时，也可以绘制回归线。设置kind参数为“reg”。本示例使用tips数据集。效果如下\"\"\"\n\n# tips = sns.load_dataset(\"tips\")\ntips = pd.read_csv('./data/tips.csv')\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\")\nplt.show()\n# tips\n\n## ---------------------------------\n\n\"\"\"生成数据\"\"\"\nimport csv\nimport random\nimport datetime\n\nfilepath ='data/data.csv'\nwith open(filepath, 'w', encoding='utf-8') as fp:\n    #创建csv文件写入对象\n    wr = csv.writer(fp)\n    #写入表头\n    wr. writerow(['日期','销量'])\n    #生成模拟数据\n    startDate = datetime. date(2020, 1, 1)\n    #生成365个模拟数据，可以根据需要进行调整\n\n    for i in range (365):\n        #生成一个模拟数据，写入csv文件\n        amount = 300 + i*5 + random.randrange (100)\n        wr.writerow([str(startDate), amount] )\n        #下一天\n        startDate = startDate + datetime.timedelta (days=1)\n\"OK\"\n\n## ---------------------------------\n\n\"\"\"生成模拟数据\"\"\"\nimport numpy as np\nimport pandas as pd\n\n# 用含日期时间索引与标签的 NumPy 数组生成 DataFrame\ndates = pd.DataFrame(pd.date_range(\"20200101\", periods=365), columns=['日期'])\ndata = pd.DataFrame(np.random.randint(300, 600, dates.shape[0]), columns=['销量'])\ndf = dates.join(data)\n\nfilepath = 'data\\data0.csv'\ndf.to_csv(filepath, # sys.stdout, # 输出到控制台\n          na_rep='non', # 存储空值\n          index=False, # 不存储索引(index)\n          header=True, # 存储列名\n)\n\n## ---------------------------------\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 读取数据，丢弃缺失值\ndf = pd.read_csv('data\\\\data0.csv', encoding='utf-8')\ndf = df.dropna()\n# print(df['日期'])\n\n# 设置字体\nplt.rcParams['font.sans-serif']=['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n#生成营业额折线图\nplt.figure()\ndf.plot(x='日期')\n# plt.savefig('data\\\\test\\\\first.jpg')\n\n#按月统计，生成柱状图\nplt.figure()\ndf1 = df[:]\n# map()会根据提供的函数对指定序列做映射。第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表\n# lambda简化了函数定义的书写形式。使代码更为简洁，但是使用函数的定义方式更为直观，易理解。\n# def fun(x):\n#     return x[:x.rindex('-')]\n\ndf1['month'] = df1['日期'].map(lambda x:x[:x.rindex('-')]) # lambda x:x[:x.rindex('-')]\ndf1 = df1.groupby(by='month', as_index=False).sum()\ndf1.plot(x='month', kind='bar')\n# plt.savefig('data\\\\test\\\\second.jpg')\n\n# 查找涨幅最大的月份，写入文件 \nplt.figure()\ndf2 = df1.drop('month', axis=1).diff()\n# DataFrame.nlargest(self, n, columns, keep='first') 返回按列降序排列的前n行。以降序返回column中具有最大值的前n行。未指定的列也将返回，但不用于排序。\n# 此方法等效于 ，但性能更高。df.sort_values(columns, ascending=False).head(n)\nm = df2['销量'].nlargest(1).keys()[0]\nprint(f\"销量最高月份{df1.loc[m, 'month']}\")\nwith open('data\\\\test\\\\maxMonth.txt', 'w') as fp:\n    fp.write(df1.loc[m, 'month'])\n\n# 按季度统计，生成饼状图\nplt.figure()\none=df1[:3]['销量'].sum()\ntwo=df1[3:6]['销量'].sum()\nthree=df1[6:9]['销量'].sum()\nfour=df1[9:12]['销量'].sum()\nplt.pie([one, two, three, four], labels=['第一季度', '第二季度', '第三季度', '第四季度'])\n# plt.savefig('data\\\\test\\\\third.jpg')\n\nplt.show()\n\n\n\n\n# matplotlib可视化\n\n\n# 条形图\n\n# 条形图\n\n点击查看\n\n\"\"\"第一次作业  条形图\"\"\"\nimport  pymysql\nimport matplotlib.pyplot as plt\n# from matplotlib import font_manager\n \n##获取一个数据库连接，注意如果是UTF-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n#将元组数据存进列表中\ncity=[]\nneed=[]\nfor x in result:\n    city.append(x[0])\n    need.append(x[1])\n    \n# 一种设置字体的方式\n# my_font = font_manager.FontProperties(fname=\"D:\\software\\python\\Anaconda3\\Library\\MyFonts\\GeiTangBuDaoDan.ttf\")\n# 设置字体\nplt.rcParams['font.sans-serif']=['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 设置图形大小\nplt.figure(figsize=(12, 5), dpi=120)\n# 设置刻度字体大小\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\n#直方图\nplt.bar(range(len(need)), need, color='r', tick_label=city)\n\nplt.xlabel(\"城市名\", fontsize=20)\nplt.ylabel(\"数量\", fontsize=20)\nplt.title(\"城市职位需求图\", fontsize=20)\nfor  x,y in enumerate(need):\n    plt.text(x-0.4, y+0.4, '%s' % y)\nplt.show()\n\n\n# 条形图 bar()\n\n点击查看\n\n\"\"\"条形图 bar()\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 示例\n# plt.bar(np.arange(2,5),np.arange(1,4),\n#         label=\"zt example\") \n# plt.bar([1,2,3],[2,4,1],label=\"tz example\", color='g')\n# plt.xlabel(\"this is x\")\n# plt.ylabel(\"this is y\")\n# plt.title(\"this is bar\")\n# plt.legend()\n# plt.show()\n\n\"\"\"展示2017票房数据\"\"\"\n# 设置字体\nplt.rcParams['font.sans-serif'] = ['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig = plt.figure(figsize=(8, 4), dpi=200)\n\nmovie_name = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",]\nbox_office = [56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23]\ndf = pd.DataFrame( {\"电影名\":movie_name, \"票房(单位:亿)\":box_office} )\n# df\nx = range(df.shape[0]) # x轴的列表\ny = box_office\n\n# bar()绘制条形图,只能接受可迭代的数字对象\nplt.bar(x, y,\n    width = 0.4, # 默认0.8\n    color = 'orange',\n    tick_label = y,\n    label = '电影', # 为设置图例作准备\n    alpha = 0.9\n)\n# 通过设置xticks使数字与字符串对应\nplt.xticks(x, df.iloc[:, 0], rotation=90)\n# 设置描述信息\nplt.title(\"2017年电影票房展示\")\nplt.xlabel(df.columns[0])\nplt.ylabel(df.columns[1])\n# 显示图例\nplt.legend()\n    \nplt.show()\n\n\n# 水平条形图 barh()\n\n点击查看\n\n\"\"\"水平条形图 barh()\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\"\"\"展示2017票房数据\"\"\"\nmovie_name = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",]\nbox_office = [56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23]\ndf = pd.DataFrame( {\"电影名\":movie_name, \"票房(单位:亿)\":box_office} )\n# df\n\n# 设置字体\nplt.rcParams['font.sans-serif'] = ['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig, ax = plt.subplots(figsize=(20, 16), dpi=80)\n\nx = np.arange(df.shape[0]) # x轴的列表\ny = box_office\n\n# bar()绘制条形图,只能接受可迭代的数字对象\nplt.barh(x, y,\n    height = 0.4,\n    color = 'orange',\n    label = '电影', # 为设置图例作准备\n    alpha = 0.9,\n    align='center'\n)\n\n# plt.yticks(y, movie_name) # , rotation=90\nax.set_yticks(x)\nax.set_yticklabels(df.iloc[:, 0], minor=False, fontsize=16)\nax.invert_yaxis() # 标签读取自上而下labels read top-to-bottom\n# 设置描述信息\nax.set_title(\"2017年电影票房展示\", fontsize=20)\nax.set_xlabel(df.columns[1], fontsize=20)\nax.set_ylabel(df.columns[0], fontsize=20)\n# 显示图例\nax.legend()\n    \nplt.show()\n\n\n\n# 子图\n\n点击查看\n\n\"\"\"子图\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n##获取一个数据库连接，注意如果是UTF-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncol_result = cursor.description  # 获取查询结果的字段描述\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n# 设置字体\nplt.rcParams['font.sans-serif']=['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 设置图形大小\nplt.figure(figsize=(20, 10), dpi=120)\nfig, axes = plt.subplots(1, 2)\n\n# 用数据库查询到的数据创建DataFrame\n# print(col_result)\ndf = pd.DataFrame(result, columns=[col_result[0][0], col_result[1][0]])\n\n# 饼图\nslices = df.iloc[:, 1]\nactivities = df.iloc[:, 0]\naxes[0].pie(slices,labels=activities,\n        startangle=90, # 初始角度\n        shadow= True, # 阴影\n        textprops={'size': 'small'},\n#         colors=[], # 设置颜色\n#         radius=1.6, # 半径\n        explode=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05, 0), # 突出\n        autopct='%1.2f%%') # \n\n# 条形图\naxes[1].bar(df.iloc[:, 0], df.iloc[:, 1], color='pink')\n# axes[1].xt\n\nplt.title('城市职位需求图')\nplt.show()\n\n\n\n# 饼图\n\n点击查看\n\n\"\"\"第二次作业  饼图\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n##获取一个数据库连接，注意如果是UTF-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncol_result = cursor.description  # 获取查询结果的字段描述\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n# 设置字体\nplt.rcParams['font.sans-serif']=['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 设置图形大小\nplt.figure(figsize=(6, 4), dpi=120)\n\n# 用数据库查询到的数据创建DataFrame\n# print(col_result)\ndf = pd.DataFrame(result, columns=[col_result[0][0], col_result[1][0]])\n\n# 饼图\nslices = df.iloc[:, 1]\nactivities = df.iloc[:, 0]\nplt.pie(slices,labels=activities,\n        startangle=90, # 初始角度\n        shadow= True, # 阴影\n        textprops={'size': 'small'},\n#         colors=[], # 设置颜色\n#         radius=1.6, # 半径\n        explode=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05, 0), # 突出\n        autopct='%1.2f%%') # \n\nplt.title('城市职位需求图')\nplt.show()\n\n\n\n# 折线图(完整)\n\n点击查看\n\n\"\"\"折线图   (画出你和同桌在11-25岁谈过的女友数)  \"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 设置字体\nplt.rcParams['font.sans-serif'] = ['LiSu']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig = plt.figure('Figure Object 1', # 图形对象名称  窗口左上角显示\n    figsize=(8, 4), # 窗口大小\n    dpi=80, # 分辨率\n    facecolor = 'white',     # 背景色\n)\n\n# x轴和y轴\nx = range(11, 31)\ny_1 = [1, 0, 1, 1, 2, 4, 3, 2, 3, 4, 4, 5, 6, 5, 4, 3, 3, 1, 1, 1]\ny_2 = [1, 0, 3, 1, 2, 2, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nplt.plot(\n    x,\n    y_1,\n    # 折线样式\n    color='r',  # 设置线条颜色\n    linestyle='--',  # 线条风格\n    linewidth=1,  # 线条粗细\n    alpha=0.5,  # 透明度\n    label='自己',\n    # 6.折点样式设置\n    marker='o', # 折点形状\n    markersize='3', # 或 ms --折点大小\n    markerfacecolor='black', # 或 mfc --折点实心颜色\n)\n\nplt.plot(\n    x,\n    y_2,\n    color='b',  # 设置线条颜色\n    linestyle=':',  # 线条风格\n    linewidth=1,  # 线条粗细\n    alpha=0.5,  # 透明度\n    label='同桌',\n    # 折点样式设置\n    marker='*', # 折点形状\n    markersize='6', # 或 ms --折点大小\n    markerfacecolor='pink', # 或 mfc --折点实心颜色\n)\n\n# 8.标出最高点 (因为横纵坐标没有必然联系所以比较难整)\nzip1 = dict( zip(x, y_1) ) # 把横纵坐标合为一个字典\n# 找出最大值和下标\nfor key,value in zip1.items():\n    if(value == max(zip1.values())):\n        max_index1 = key\n        max_value1 = value\ndel zip1\nplt.plot(max_index1,max_value1,'ks')\ns = f\"({max_index1},{max_value1})\"\n# plt.annotate()函数用于标注文字\nplt.annotate(s, xytext=(max_index1,max_value1), xy=(max_index1,max_value1)) # 注释内容 注释文本的坐标点 被注释的坐标点，二维元组形如(x,y)\n####\nzip2 = dict( zip(x, y_2) ) # 把横纵坐标合为一个字典\n# 找出最大值和下标\nfor key,value in zip2.items():\n    if(value == max(zip2.values())):\n        max_index2 = key\n        max_value2 = value\ndel zip2\nplt.plot(max_index2,max_value2,'ks')\ns = f\"({max_index2},{max_value2})\"\n# plt.annotate()函数用于标注文字\nplt.annotate(s, xytext=(max_index2,max_value2), xy=(max_index2,max_value2))\n\n\n# 4.调整x和y轴刻度间距\n_xtick_labels = [\"{}岁\".format(i) for i in x]\nplt.xticks(x, _xtick_labels, rotation=45, fontsize=9)\nplt.yticks(range(0, 9))\n# 5.线条样式 颜色 透明度\n# 加网格 (透明度)\nplt.grid(alpha=0.5, linestyle='--', linewidth=1)\n\n# 3.描述信息(x轴[y轴.标题]代表什么)\nplt.xlabel('年龄')\nplt.ylabel('人数')\nplt.title(\"回忆青葱岁月\", fontsize=16)\n\nplt.legend(loc='best')\n\n# 2.保存到本地 (可设置格式(svg矢量图))\n# plt.savefig(\"data/xxx.svg\")\n\n# 7.图片加水印\ndef add_watermark(x, y):\n    fig.text(x, y, '寒川环宇', # text的位置,内容\n        fontsize=16, \n        color='gray',\n        ha='left', \n        va='top',\n        rotation=-45, #旋转角度\n        alpha=0.3,\n        bbox = dict(facecolor = \"#B0C4DE\", alpha = 0.05)) # 加框(框体颜色,透明度)\n    \nadd_watermark(0.5, 0.6)\nadd_watermark(0.5, 0.8)\nadd_watermark(0.2, 0.6)\nadd_watermark(0.2, 0.8)\nplt.show()\n",normalizedContent:"# 基础语法\n\n\n# numpy学习\n\n\n# ndarray类学习\n\n点击查看\n\n# numpy 参考手册 https://www.numpy.org.cn/reference/\n\"\"\"ndarray类学习 (存放同类型元素的多维数组)\"\"\"\nimport numpy as np\n\n\"\"\"\nndarray.ndim - 数组的轴（维度）的个数。在python世界中，维度的数量被称为rank。\nndarray.shape - 数组的维度。这是一个整数的元组，表示每个维度中数组的大小。对于有 n 行和 m 列的矩阵，shape 将是 (n,m)。因此，shape 元组的长度就是rank或维度的个数 ndim。\nndarray.size - 数组元素的总数。这等于 shape 的元素的乘积。\nndarray.dtype - 一个描述数组中元素类型的对象。可以使用标准的python类型创建或指定dtype。另外numpy提供它自己的类型。例如numpy.int32、numpy.int16和numpy.float64。\nndarray.itemsize - 数组中每个元素的字节大小。例如，元素为 float64 类型的数组的 itemsize 为8（=64/8），而 complex32 类型的数组的 itemsize 为4（=32/8）。它等于 ndarray.dtype.itemsize 。\nndarray.data - 该缓冲区包含数组的实际元素。通常，我们不需要使用此属性，因为我们将使用索引访问数组中的元素\n\"\"\"\n# order=\"c\" 行优先\n# arr1 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7]), offset=0, order=\"c\")\n# arr1\n\n# order=\"f\" 列优先\n# arr2 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7]), offset=0, order=\"f\")\n# arr2\n\n# offset=8 buffer中用于初始化数组的首个数据的偏移  (字节数的偏移 ndarray.itemsize为4 设置为8偏移两个值)\narr3 = np.ndarray(shape=(2, 3), dtype = int, buffer=np.array([1,2,3,4,5,6,7,8]), offset=8, order=\"c\")\n# arr3.itemsize\narr3\n\n\n\n# np.array方法\n\n点击查看\n\n\"\"\"\nnp.array只是一个便捷的函数,用来创建ndarray,\n它本身并不是一个类\n\"\"\"\nfrom numpy import *\n\narr4 = array(range(15)).reshape(3, 5)\n# arr4\n# print(arr4.t)\n# print(arr4.size)\n# print(arr4.itemsize)\n# print(arr4.ndim)\n# print(arr4.shape)\n# print(arr4.dtype)\n\n\"\"\"通过常规类型创建array\"\"\"\n# 1.通过tuple创建array\n# yuanzu = (4, 5, 6)\n# arr5 = array(yuanzu)\n# print(arr5)\n\n# 2.通过list创建array\n# pylist = [0, 1, 2]\n# arr6 = array(pylist)\n# print(arr6)\n\n# 3.构建多维的array\n# pylist2 = [4, 5, 6]\n# arr7 = array( [pylist, pylist2] )\n# print(\"多维数组:\\n\" + str(arr7))\n\n# 4.类型自动推断\n# arr8 = array( [1, 2, 3.3] )\n# print(arr8)\n# arr8 = array( [\"1\", 2, 3] )\n# print(arr8)\n\n# 5.明确数组类型\n# arr9 = array([1, 3, 6, 9], dtype=float32)\n# arr9\narr9 = array(['1', 3, 6, 9], dtype=ubyte)\narr9\n\n\n\n# numpy数组创建方法\n\n点击查看\n\n\"\"\"numpy数组创建方法\"\"\"\n# from numpy import *\n\n# 1. 全0数组\n# arr = zeros( (3, 4) ) # 二维全0数组\n# arr = zeros( (2,2,2) ) # 三维全0数组\n\n# 1.1 全1数组\n# arr = ones( (2, 3) )\n\n# 1.2 初始内容是随机的，取决于内存的状态\narr = empty( (2, 3) )\n\n# 1.2 全x数组\n# arr = full( (2, 3), 6 )\n\n# 1.3 根据步长创建数组arange(start, end, step)\n# arr = arange(0, 1, 0.1)\n\n# 2.等差数列\n# arr = linspace(0, 1, 10) # linspace(start, end, count, endpoint=true)\n# arr = linspace(0, 1, 10, endpoint=false)\n\n# 3.等比数列\n# arr = logspace(0, 10, 1, base=2) # logspace(start, end, count, base=10)\n\narr\n\n\n\n# 打印数组\n\n点击查看\n\n\"\"\"打印数组\"\"\"\n# import sys\n# 一维数组打印为行，将二维数据打印为矩阵，将三维数据打印为矩数组表\n# arr = arange(10000)\n\n# 如果数组太大而无法打印，numpy会自动跳过数组的中心部分并仅打印角点\n# arr.reshape(100, 100)\n# 禁用此行为并强制numpy打印整个数组 更改打印选项set_printoptions\n# set_printoptions(threshold=sys.maxsize)\n# arr.reshape(100, 100)\n\n\n\n# 基本操作 (数组元素的运算)\n\n点击查看\n\n\"\"\"基本操作 (数组元素的运算)\"\"\"\nimport numpy as np\n\na = np.array([10, 20, 30, 40, 50])\nb = np.array(np.arange(5))\nprint(\"%s%s\" % (\"数组a-数组b:\\t\",a - b)) # 数组相减\nprint(\"%s%s\" % (\"数组b的2次方:\\t\",b**2))\nprint(\"%s%s\" % (\"sin(a):\\t\", np.sin(a)))\nprint(\"%s%s\" % (\"数组a < 35\\t\",a < 35))\n\n\n\n# 基本操作 (矩阵乘积)\n\n点击查看\n\n\"\"\"基本操作 (矩阵乘积)\"\"\"\na = np.array( [[1,1], [0,1]] )\nb = np.array( [[2,0], [3,4]] )\n\nprint(\"矩阵乘积:\" + str(a @ b))\nprint(\"矩阵乘积:\" + str(a.dot(b)))\n\n\n\"\"\"\n某些操作（例如+=和 *=）会更直接更改被操作的矩阵数组而不会创建新矩阵数组\n\"\"\"\na *= 0\na += 3\nb = np.random.random( (2, 2) )\nprint(b)\n# a += b # 需要向上转换 typeerror: cannot cast ufunc add output from dtype('float64') to dtype('int32') with casting rule 'same_kind'\nb += a\nprint(\"b += a:\\n\" + str(b))\n\n\"\"\"一元操作\"\"\"\n# b.sum() # 所有元素的和\n# b.min() # 最小的元素\n# b.max() # 最大的元素\n\n# b.sum(axis=0) # sum of each column\n# b.min(axis=1) # min of each row\n# b.cumsum(axis=1) # 在每一行的累积 cumulative sum along each row\n\n\"\"\"\n通函数\nnumpy提供熟悉的数学函数，例如sin，cos和exp。在numpy中，这些被称为“通函数”（ufunc）。在numpy中，这些函数在数组上按元素进行运算，产生一个数组作为输出\n\"\"\"\n\n\n\n# 形状操纵\n\n点击查看\n\n\"\"\"形状操纵 0428\"\"\"\nimport numpy as np\n\n# 改变数组的形状\narr = np.floor(np.random.random( (3,4) ) * 10)\nprint(arr.shape)\nprint(arr)\n# arr.ravel() # returns the array, flattened\n# arr.t\n# arr.reshape(6, -2)\n\n# 将不同数组堆叠在一起\narr1 = np.array([ [[1,2], [3,4]], [[5,6], [7,8]] ])\narr2 = np.array([ [[10,20], [30,40]], [[50,60], [70,80]] ])\n# np.vstack( (arr1, arr2) ) # 沿第一轴[水平(按列顺序)]堆叠\n# np.row_stack( (arr1, arr2) )\n# np.hstack( (arr1, arr2) )   # 沿第二轴[垂直(按照行顺序)]堆叠\n# np.column_stack( (arr1, arr2) )\n## 在复杂的情况下，r_和 c_于通过沿一个轴堆叠数字来创建数组很有用。它们允许使用范围操作符(“：”)。\n# np.r_[1:6, 0, 4]\n# np.r_[arr1, arr2]\n# np.c_[arr1, arr2]\n\n# 复制堆叠  numpy.repeat(a, repeats, axis=none)\n# '''\n#     a(array_like): 输入数组。\n#     repeats(int or array of ints): 每个元素的重复次数。 重复播放以适合给定轴的形状\n#     axis(int, optional) 重复值所沿的轴。默认情况下，使用展平的输入数组，并返回展平的输出数组。\n# '''\n# np.repeat(a=3, repeats=4)\n# np.repeat(a=arr1, repeats=2)\n# np.repeat(a=arr1, repeats=2, axis=2)\n\n# '''title'''\n\n# 将一个数组拆分成几个较小的数组\n# np.hsplit(arr1, (2,2))\n# a = np.array([np.arange(1,13), np.arange(1,13)*10])\n# np.hsplit(a, 3) # 无论数组尺寸如何，数组始终沿第二轴分割\n# np.hsplit(a, (3, 6, 9)) # (第二个参数是切分的块??? 012 345 678 9-)\n# np.vsplit(a, 2) # 该阵列被始终沿第一轴线分裂不管阵列的尺寸\n# '''split split(array, splits,axis=1) 将数组拆分为大小相等的多个子数组\n#     numpy.array_split（ary，indexs_or_sections，axis = 0 ）\n#     array_split允许 indices_or_sections是整数，它不平分轴。对于应分为n个部分的长度为l的数组，它返回大小为l // n + 1的l％n个子数组，其余大小为l // n\n# '''\n# np.array_split(ary=arr1, indices_or_sections=2, axis= 2)\narr3 = np.array([arr, arr*10])\nprint(\"arr3:\\n\" + str(arr3))\n# np.split(ary=arr3, indices_or_sections=arr3.shape[0], axis=0)\n\n\n\n# 索引、切片和迭代\n\n点击查看\n\nimport numpy as np\n\"\"\"索引、切片和迭代\"\"\"\n'''\n一维的数组可以进行索引、切片和迭代操作的，就像 列表 和其他python序列类型一样。\n'''\narr = np.arange(12)**3\nprint(arr[5]) # 索引\nprint(arr[0:12:2]) # 切片\n# 迭代\nfor i in arr:\n    print(i, end=\" \")\n\n'''\n多维的数组每个轴可以有一个索引。这些索引以逗号分隔的元组给出：\n'''\narr = arr.reshape( (3,4) )\nprint(\"第三行第一个元素:\" + str(arr[2, 0])) # 索引\n\n# -1对应二维数组里的一维说的，但不包含最后一个一维数组；-2对应一维数组里的元素，不包含每个一维数组最后两个\nprint(arr[:-1,:-2]) # 切片\n# 迭代\nfor elem in arr.flat:\n    print(elem, end=\" \")\n    \narr\n\n\n\n# 深入:\n\n点击查看\n\n\"\"\"拷贝和视图\"\"\"\n# 完全不复制\n# 视图或浅拷贝\n# 深拷贝\n\"\"\"less基础 广播（broadcasting）规则\"\"\"\n\"\"\"花式索引和索引技巧\"\"\"\n# 使用索引数组进行索引\n# 使用布尔数组进行索引\nimport numpy as np\nimport matplotlib.pyplot as plt\ndef mandelbrot( h,w, maxit=20 ):\n    \"\"\"用布尔索引生成mandelbrot集的图像：\"\"\"\n    \"\"\"returns an image of the mandelbrot fractal of size (h,w).\"\"\"\n    y,x = np.ogrid[ -1.4:1.4:h*1j, -2:0.8:w*1j ]\n    c = x+y*1j\n    z = c\n    divtime = maxit + np.zeros(z.shape, dtype=int)\n\n    for i in range(maxit):\n     z = z**2 + c\n     diverge = z*np.conj(z) > 2**2            # who is diverging\n     div_now = diverge & (divtime==maxit)  # who is diverging now\n     divtime[div_now] = i                  # note when\n     z[diverge] = 2                        # avoid diverging too much\n\n    return divtime\nplt.imshow(mandelbrot(400,400))\nplt.show()\n\n# ix_()函数\n# 使用字符串建立索引\n\"\"\"线性代数 简单数组操作\"\"\"\n\"\"\"“自动”整形\"\"\"\n\"\"\"矢量堆叠\"\"\"\n\n\n\n# 深入: 直方图\n\n点击查看\n\n\"\"\"直方图\"\"\"\nimport numpy as np\nimport matplotlib.pyplot as plt\n# build a vector of 10000 normal deviates with variance 0.5^2 and mean 2\nmu, sigma = 2, 0.5\nv = np.random.normal(mu,sigma,10000)\n# plot a normalized histogram with 50 bins\nplt.hist(v, bins=50, density=1)       # matplotlib version (plot)\nplt.show()\n\n# compute the histogram with numpy and then plot it\n(n, bins) = np.histogram(v, bins=50, density=true)  # numpy version (no plot)\nplt.plot(.5*(bins[1:]+bins[:-1]), n)\nplt.show()\n\n\n\n# 附:创建一个3*3 的数组方法\n\n点击查看\n\nimport numpy as np\n\n# 创建一个3*3 的数组, 下列代码错误的是\n# a:np.arange(9).reshape(3,3)\n# b:np.eye(3)\n# c:np.random.random([3,3,3])\n# d:np.mat(\"1 2 3;4 5 6;7 8 9\")\n# 正确答案:c\n\n# arr = np.arange(9).reshape(3,3)\n# arr = np.eye(3) # 生成对角矩阵\narr = np.random.random([3,3,3])\n# arr = np.mat(\"1 2 3;4 5 6;7 8 9\")\n\nprint(arr.shape)\narr\n\n\n\n# pandas（两种数据结构学习）\n\n\n# 1.series(一维标记数组)学习\n\n点击查看\n\n\"\"\"pandas 简介:https://www.pypandas.cn/docs/getting_started/ \"\"\"\nimport pandas as pd\nimport numpy as np\n\n\"\"\"series(一维标记数组)学习\"\"\"\n\n# obj = pd.series([1, 3, 5, np.nan, 6, \"ai\"])  # 默认下标0123\nobj = pd.series([1, 2, 3, 4, 5], index=['d', 'b', 'a', 'c', 'e']) \n\n# obj\n# obj.values # 返回series的值 为ndarray类型\n# obj.index # 返回索引名称\n\n'''series索引'''\n# 1.类似numpy索引方式\n# obj[2:6:2]\n\n# 2.index名称索引\n# obj[\"a\"] # 单个\n# obj[ [\"a\", \"d\", \"e\"] ] # 索引多个值,需要传入名称列表\n# obj[\"a\":\"c\"] # 包括\"c\"\n\n# 3.通过布尔表达式索引\n# obj[obj>=3]\n\n'''series赋值'''\n# 1.单个值赋值\n# obj[2] = 9\n\n# 2.多个值赋值\n# obj[0:2] = [-9, -6]\n\n# 3.通过布尔表达式赋值\nobj[obj<3] = 0\n\nobj\n\n\n\n# 2.dataframe(二维标记数据结构)学习\n\n# 创建\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\"\"\"\n    dataframe( data, index, columns, dtype, copy)(二维标记数据结构)学习\n    1. 像series一样可以接收多种输入:lists、dicts、series和dataframe等\n    2.初始化对象时,除了数据还可以传index和columns这两个参数\n    附:可以把dataframe想象成一个电子表格，它由行名（index）、列名(columns)和数据(values)组成。\n\"\"\"\n\n# 1.根据字典新建dataframe\n# data = {\n#     'column_a':[1, 2, 3],\n#     'column_b':[4, 5, 6],\n#     'column_c':[7, 8, 9]\n# }\n# df = pd.dataframe(data, index=['r1', 'r2', 'r3'])\n\n# 1.2.根据嵌套字典新建dataframe\n# data = {\n#     'c1':{'r1':111, 'r2':122},\n#     'c2':{'r1':211, 'r2':222}\n# }\n# df = pd.dataframe(data)\n\n# 2. 根据列表创建dataframe\n# data = [\n#     [1111, 2222, 3333],\n#     [111, 222, 333],\n#     [11, 22, 33],\n#     [1, 2, 3]\n# ]\n# df = pd.dataframe(data, columns=['c1', 'c2', 'c3'], index=['r1', 'r2', 'r3', 'r4'])\n\n# 3. dataframe 和 ndarray 互操作\n# 3.1 用ndarray构造dataframe\nnarr = np.array([\n    [11, 22, 33, 44, 55], \n    [1.1, 2.2, 3.3, 4.4, 5.5]\n])\ndf = pd.dataframe(narr, columns=['c1', 'c2', 'c3', 'c4', 'c5'], index=['r1', 'r2'])\n# 3.2 用dataframe构造ndarray\n## narr2 = np.array(df)\n# narr2 = df.values\n# print(narr2)\n\n### end.输出\n# print(df.index)\n# print(df.columns)\n# print(df.values) # 返回值为ndarray类型\n# print(df.values.shape)\n# print(df.index.shape)\ndf\n\n\n# dataframe值索引\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\n\"\"\"dataframe值索引\"\"\"\n\n\ndata = [\n    [1111, 2222, 3333],\n    [111, 222, 333],\n    [11, 22, 33],\n    [1, 2, 3]\n]\ndf = pd.dataframe(data, columns=['c1', 'c2', 'c3'], index=['r1', 'r2', 'r3', 'r4'])\n\n# 1.列索引(dataframe[column_name],返回对应列的所有值)\n# df['c1']\n\n# 2. 行索引(dataframe.ix[index_name],返回对应行的所有值。返回值类型为series。)\n# df.ix['r1'] # 注意这里是中括号,不是函数??? (被弃用????)\n\n# 3.dataframe.loc[index_name，column_name],返回对应元素。\n# df.loc['r1'] # 行索引\n# df.loc[:, 'c1'] # 列索引\n# df.loc['r1', 'c1']\n# df.loc[ ['r1', 'r3'] ] # 返回值为dataframe。\n# df.loc['r1': 'r3', 'c2'] # 切片 包括起始和结束\n# df.loc[ df['c1']>100, ['c2'] ] # 有条件的返回布尔序列 + 指定列\n# df[df>100] # bool值的索引方法\n\n# 3.1 设定值 (实质上是给索引赋值??)\n# df.loc[df['c1']>100, ['c2'] ] = 2000\n# df\n\n# 4.dataframe.iloc[x，y],返回对应元素。\n    # 参数(整数 # df.iloc[0] # 整数  具有整数的切片对象,例如1:7  布尔数组  一个callable带有一个参数的函数（调用series或dataframe）)\n# df.iloc[0] # 整数\n# df.iloc[ [0, 1] ] # df.iloc[0] # 整数\n# df.iloc[ 0:3:2 ] # 切片对象\n# df.iloc[[true, false, true, true]] # 布尔掩码与索引的长度相同\n\n# df = pd.dataframe(data, columns=['c1', 'c2', 'c3'])\n# df.iloc[lambda x: x.index % 2 == 0]\n\n\n# 层次化索引与unstack\n\n点击查看\n\n\"\"\"层次化索引与unstack\"\"\"\n\"\"\"\n层次化索引可以在一个轴上拥有多个索引级别。也就是以低维度形式处理高维度数据。\nunstack()函数可以将层次化series转换成高维的dataframe。\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndata = pd.series(np.random.randn(10), index=[['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'd', 'd'], [1, 2, 3, 1, 2, 3, 1, 2, 2, 3]])\n# data # 两层索引\ndata.unstack()\n\n\n# dataframe堆叠\n\n点击查看\n\n\"\"\"dataframe堆叠 (shape相同)  [dataframe表有行和列标签，因此堆叠时shape可以不一致]\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf = pd.dataframe(np.array([[1,2,3],[4,5,6]]), index=['ⅰ', 'ⅱ'])\ndf2 = pd.dataframe(np.array([[10,20,30],[40,50,60]]), index=['ⅰ', 'ⅱ'])\n\n# concat([pd1,pd2],axis=0,ignore_index=false)\n# print( pd.concat([df, df2]) )\n# pd.concat([df, df2], ignore_index=false) # 纵向堆叠时，忽略索引名\npd.concat([df, df2], axis=1)# 横向堆叠\n\n# frame = pd.dataframe({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n# print('值排序1  :\\n',   frame.sort_index(by='b', axis=0))\n# frame\n\n\n# dataframe常用函数介绍(一) 重新索引(reindex)\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(一) 重新索引(reindex)\"\"\"\n\"\"\"\n    参数dataframe.reindex(self, \n                labels=none, index=none, columns=none, axis=none, \n                method=none, copy=true, level=none, fill_value=nan, limit=none, tolerance=none)\n\"\"\"\nimport pandas as pd\n\ndf = pd.dataframe(np.array([[1,2,3],[4,5,6]]), index=['ⅰ', 'ⅱ'], columns=['a', 'b', 'c'])\ndf.reindex(index=['ⅰ', 'ⅱ', 'ⅲ'], columns=['a', 'b', 'c', 'd'], fill_value=0 )\n\n\n# dataframe常用函数介绍(二) 丢弃值(drop)\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(二) 丢弃值(drop) [ⅰ, ⅱ, ⅲ, ⅳ, ⅴ, ⅵ, ⅶ, ⅷ, ⅸ, ⅹ]\"\"\"\n\"\"\"\n    参数dataframe.drop(self, labels=none, axis=0, index=none, \n    columns=none, level=none, inplace=false, errors='raise')\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.dataframe(np.array([[1,2,3],[4,5,6], [7,8,9], [np.nan,10,np.nan]]), \n                  index=['ⅰ', 'ⅱ', 'ⅲ', 'ⅳ'], columns=['a', 'b', 'c'])\n# df.drop(index='ⅲ', axis=0) # 删除行 (返回新对象)\n# df.drop(columns='b', axis=1) # 删除列 (返回新对象)\n# 参数 dataframe.dropna(self, axis=0, how='any', thresh=none, subset=none, inplace=false)\n# df.dropna() # 清除有空值(nan)的行\ndf.dropna(how='all') # 清除全为空的行(axis=1的列)\ndf.dropna(subset=['列名'],inplace=true)  # 某列为空删除这一行\n# df\n\n\n# dataframe常用函数介绍(三) 算术方法\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(三) 算术方法\"\"\"\n\"\"\"\n    参数:add(self, other, axis='columns', level=none, fill_value=none)\n    sub(self, other, axis='columns', level=none, fill_value=none)\n    div(self, other, axis='columns', level=none, fill_value=none)\n    sub(self, other, axis='columns', level=none, fill_value=none)\n\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf = pd.dataframe(np.arange(4).reshape((2,2)), columns=list('ab'))\ndf2 = pd.dataframe(np.arange(6).reshape((2,3)), columns=('ⅰ', 'ⅱ', 'ⅲ'))\n# df + df2\n# df.add(df2)\ndf.add(10)\n\n\n# dataframe常用函数介绍(四) 索引排序\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(四) 索引排序\"\"\"\n\"\"\"\n    dataframe.sort_index(self, axis=0, level=none, ascending=true, inplace=false, \n        kind='quicksort', na_position='last', sort_remaining=true, ignore_index: bool = false)\n\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.dataframe(np.array([[1,2,3], [7,8,9], [4,5,6], [np.nan,5.5,np.nan]]), \n                  index=['ⅲ', 'ⅳ', 'ⅰ', 'ⅱ'], columns=['b', 'a', 'c'])\n# print(df)\n# df.sort_index() # 按索引排序\n# df.sort_index(by=['a', 'b']) # 不推荐使用sort_index的参数，请使用.sort_values（by = ...）\n# df.sort_index(axis = 1, ascending=false) # 按照列索引名降序排序\ndf.sort_index(axis = 0, ascending=false)\n# df.sort_values(by=[ 'a']) # 按值排序\n\n\n# dataframe常用函数介绍(五) 描述和汇总统计(待补充)\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(五) 描述和汇总统计(补充)\"\"\"\nimport pandas as pd\n\ndf = pd.dataframe({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\ndf.cov() # 协方差计算方法，series需要通过参数传入\ndf.corr() # 相关系数计算方法，series需要通过参数传入\n\n\n# dataframe常用函数介绍(六) 缺失值填充\n\n点击查看\n\n\"\"\"dataframe常用函数介绍(六) 缺失值填充\"\"\"\nimport pandas as pd\nimport numpy as np\n\ndf = pd.dataframe(np.array([[1,2,3], [7,8,9], [4,5,6], [np.nan,5.5,np.nan]]), \n                  index=['ⅲ', 'ⅳ', 'ⅰ', 'ⅱ'], columns=['b', 'a', 'c'])\n# print(df)\n# df.fillna(0) # 全填为0\n# df.fillna({'b':666, 'c':999}) # 参数为字典类型 不同列填充不同值\ndf.fillna(df.mean()) # 列平均值填充列对应的nan值\n\n\n# pandas文件读取\n\n点击查看\n\n\"\"\"文件读取\"\"\"\nimport pandas as pd\n\n# filepath = 'data\\music.csv'\nfilepath = 'data\\sales-副本.csv' # 含中文的文件 65行\n\n# 1.read_csv方法\ndf = pd.read_csv(filepath, \n                 encoding='gbk', \n                 names=['发票id', '销售日期', '总金额', '支付金额', '收银员'], # 指定列名,不使用第一行作为列名\n                 skiprows=[0], # 忽略指定列\n#                  na_values=['null'], # 显示空值\n#                  nrows=12, # 文件大时 设置读取行\n#                  chunksize=4 # 每次读取4行\n                ) \n\n# 1.1使用chunksize=4参数,读取后的数据类型为textfilereader\n# for ele in df:\n#     print(ele)\n\n# 2.read_table方法\n# df = pd.read_table(filepath, sep=',', encoding='gbk')\n# print(\"dataframe的形状\" + str(df.shape))\ndf\n\n# df.fillna(\"空值\")\n\n\n# pandas文件写入\n\n点击查看\n\n\"\"\"文件写入\"\"\"\nimport pandas as pd\nimport numpy as np\n# import sys\n\ndf = pd.dataframe([\n    ['nan', 88, 66, 55, 39],\n    [53, 52, 86, 66, np.nan],\n    [21, 98, 68, 'null', 99]\n])\n# df\nfilepath = 'data\\pfile_test.csv'\ndf.to_csv(filepath, # sys.stdout, # 输出到控制台\n          na_rep='non', # 存储空值\n          sep='\\t', # 设置分隔符\n          index=false, # 不存储索引(index)\n          header=false, # 不存储列名\n#           columns=[0, 1] # 设置只保存 某些列\n         )\n\n\n# pandas合并xls文件\n\n点击查看\n\nimport pandas as pd\nimport os\n\nfile_path = \"d:\\\\software\\\\pythonprojects\\\\weibospider\\\\weibospider\\\\spiders\\\\data\\\\weibo\"\nfile_list = [f\"{file_path}\" + i for i in os.listdir(file_path)]'\n\nli=[]\nfor i in file_list:\n    li.append(pd.read_excel(i))\nwriter = pd.excelwriter(f'{file_path}\\微博.xlsx')\npd.concat(li).to_excel(writer,'sheet1',index=false)\n \nwriter.save()\n\n\n\n# pandas数据合并、清洗\n\n\n# merge函数 默认内连接\n\n点击查看\n\nimport pandas as pd\n\"\"\"merge函数 默认内连接\"\"\"\n\n\"\"\"1.内连接(默认) how = 'inner'\"\"\"\n# 1.1 按 相同列名 内连接\n# df1 = pd.dataframe({'key':['b','b','a','c'], 'data1':range(4)})\n# df2 = pd.dataframe({'key':['a','b','d'], 'data2':range(3)})\n# df3 = pd.merge(df1, df2, on = 'key', how = 'inner')\n\n# 1.2 没有同名列 (相当于把参数on= 变为 left_on 和 right_on两个参数)\ndf1 = pd.dataframe({'key1':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.dataframe({'key2':['a','b','d'], 'data1':range(3)})\ndf3 = pd.merge(df1, df2, left_on='key1', right_on='key2')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# 外连接\n\n# 外连接\n\n点击查看\n\nimport pandas as pd\n\n\"\"\" 2.外连接 \"\"\"\n''' 1.how  2.多列连接on=[] 3.区分相同列名suffixes= 4.索引名连接right_index=true'''\n# 2.1.1  how = 'outer'\ndf1 = pd.dataframe({'key': ['b', 'b', 'a', 'c'],'data1': range(4)})\ndf2 = pd.dataframe({'key': ['a', 'b', 'd'],'data2': range(3)})\ndf3 = pd.merge(df1,df2,how='outer')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# 多列连接on=[]\n\n点击查看\n\nimport pandas as pd\n\n# 2.1.2 多列连接on=[]\ndf1 = pd.dataframe({'k1': ['a', 'a', 'b'], 'k2': ['a', 'b', 'a'], 'lval': [1, 2, 3]})\ndf2 = pd.dataframe({'k1': ['a', 'a', 'b', 'b'], 'k2': ['a', 'a', 'a', 'b'], 'rval': [4, 5, 6, 7]})\ndf3 = pd.merge(df1, df2, how='outer',on= ['k1', 'k2'])\n\n# 2.1.3 非连接列有重名时指定后缀\n# df3 = pd.merge(df1, df2, how='outer',on='k1', suffixes=['_x', '_y'])\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# 左连接 how = 'left'\n\n点击查看\n\nimport pandas as pd\n\n# 2.2\ndf1 = pd.dataframe({'key':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.dataframe({'key':['a','b','d'], 'data2':range(3)})\n# 2.2 左连接 how = 'left'\ndf3 = pd.merge(df1, df2, on = 'key', how = 'left')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n# how = 'right'\n\n点击查看\n\nimport pandas as pd\n\n# 2.2\ndf1 = pd.dataframe({'key':['b','b','a','c'], 'data1':range(4)})\ndf2 = pd.dataframe({'key':['a','b','d'], 'data2':range(3)})\n\n# 2.3 右连接 how = 'right'\ndf3 = pd.merge(df1, df2, on = 'key', how = 'right')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# 用表的行索引名作为连接\n\n点击查看\n\nimport pandas as pd\n# 2.4.1 用表的行索引名作为连接\ndf1 = pd.dataframe({'key': ['a', 'b', 'a', 'c'],'value': range(4)})\ndf2 = pd.dataframe({'val': [4, 9]}, index=['a', 'b']) \ndf3 = pd.merge(df1, df2, left_on='key', right_index=true, how='outer')\ndf3 = pd.merge(df1, df2, left_on='key', right_index=true, how='outer')\n\n# print(f\"{df1}\\n{df2}\")\ndf3\n\n\n\n# join函数(为merge的特例) 默认外连接\n\n点击查看\n\nimport pandas as pd\n\"\"\"join函数(为merge的特例) 默认外连接\"\"\"\n\ndf1 = pd.dataframe({'key1': ['b', 'b', 'a', 'c'],'data1': range(4)})\ndf2 = pd.dataframe({'key2': ['a', 'b', 'd'],'data2': range(3)})\n\n# 两种方式相当\nprint(pd.merge(df1, df2,left_index=true, right_index=true))\ndf1.join(df2, how='inner')\n\n\n\n# combine_first函数 以一个为基准,另一个进行补充\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\n\n\n\"\"\"combine_first函数  以一个为基准,另一个进行补充\"\"\"\ndf1 = pd.dataframe(np.arange(6).reshape((2, 3)),index=['a','b'])\ndf2 = pd.dataframe(np.arange(6).reshape((3, 2)),index=['a','b','c'])\n\n# 体会两者的区别\nprint(df1.combine_first(df2)) # df1值为nan的位置，由df2来填充\ndf2.combine_first(df1) # 以df2为准，用df1补空\n\n\n\n# 待补充\n\n点击查看\n\n\"\"\"\npd.concat与np.concatenate对比\npd.concat与pd.merge与join\nconcat忽略索引\n\"\"\"\n\n\n\n# 数据清理与转换(一) 值替换\n\n点击查看\n\n\"\"\"数据清理与转换(一) 值替换\"\"\"\n\nimport numpy as np\nimport pandas as pd\n\"\"\"数据清理--值替换\"\"\"\n\n''' 1. df.fillna()方法[对nan值进行填充] '''\ndf =  pd.dataframe([[1,np.nan,2,0], [np.nan, np.nan, np.nan, np.nan,], [3, np.nan,5,6]])\nprint(df) # 打印原始值\n\n# 1.1 全部填充为0\n# df.fillna(0)\n\n# 1.2 填充为列平均值\n# df.fillna(df.mean())\n\n# 1.3 不同列采用不同填充\n# df.fillna({0:0.0, 1:1.1, 2:2.2, 3:3.3})\n\n''' \n2.df.replace()方法,对不同值(比如0, -1, nan)进行填充 \n    附:df.replace(np.nan, 0) 相当于 df.fillna(0)\n'''\n# 2.1 把多个值[np.nan, 0] 替换为 -1\n# df.replace([np.nan, 0], -1)\n\n# 2.2 把多个值 替换为 多个值\ndf.replace([np.nan, 0], [0, -1])\n\n\n\n# 数据清理与转换(二) 去重复值\n\n点击查看\n\n\"\"\"数据清理与转换(二) 去重复值\"\"\"\nimport numpy as np\nimport pandas as pd\n\ndf1 = pd.dataframe({'k1': ['a','a','b','c','c','c','a'], 'k2': [1, 1, 2, 3, 3, 4, 6]}) \n# print(df1)\n\n# 1 duplicated()函数 [找出重复记录]\n# df1.duplicated()\n# 2.1 drop_duplicates()函数 [直接剔除对应的重复记录]\n# df1.drop_duplicates()\n# 2.2以列为单位比较是否存在重复记录[默认行为单位]\ndf1.drop_duplicates(['k1', 'k2'])\n\n\n\n\n# 数据清理与转换(三) 索引重命名\n\n点击查看\n\n\"\"\"数据清理与转换(三) 索引重命名\"\"\"\nimport pandas as pd\n\n# 1.df.rename(index={},columns={})方法\ndf1 = pd.dataframe([[1111, 2222, 3333, 4444], [111, 222, 333, 444], [11, 22, 33, 44]])\n# print(df1)\n\ndf1.rename(index={0:'row_1', 1:'row_2', 2:'row_3'}, columns={0:'col_1', 1:'col_2', 2:'col_3', 3:'col_4'})\n\n\n\n# 数据清理与转换(四) 数据转换\n\n点击查看\n\n\"\"\"数据清理与转换(四) 数据转换\"\"\"\nimport pandas as pd\n\n'''函数转换 map(func)函数'''\n# 1. 替换fillna replace(见前面)\n# 2. map(func)函数 [内部值进行函数转换。如统一字符的大小写等]\ndf1 = pd.dataframe({\"course\":[\"chinese\", \"math\", \"english\", \"physics\" , \"chemistry\", \"biologic\"], \n                    \"score\":[96, 94, 92, 62, 45, 60]})\n# 2.1第一列转换为首字母大写\n# df1['course'] = df1['course'].map(str.title) # upper\n\n'''映射转换 map(func)函数'''\n# 1.根据字典的映射进行相应转换\ncourse = {\"chinese\":\"语文\", \"math\":\"数学\", \"english\":\"英语\", \"physics\":\"物理\", \"chemistry\":\"化学\", \"biologic\":\"生物\"}\ndf1['course'] = df1['course'].map(course)\n\ndf1\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 指定划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\nimport pandas as pd\nimport numpy as np\n\n\"\"\"\n    数值类型  1.连续值:一定区间可连续取值(比如天气的温度)  2.离散值:按一定顺序一一列举(比如'多云','晴天','雨天','阴天')\n    categoricals:  1.是 pandas 的一种数据类型,是由固定的且有限数量的离散变量组成的 2.不能排序(sort_by): 顺序是创建时手工设定的，是静态的\n\"\"\"\n\n'''指定划分边界  cut()函数[实现数据装箱bin(连续->离散)。返回一个categorical对象]'''\n# arr = np.arange(0, 100, 7)\narr = np.random.randint(0, 100, 18) # 生成在半开半闭区间[low,high)上离散均匀分布的整数值\nprint(f\"arr:{arr}\")\nbins = [0, 40, 80, 100]\ncats = pd.cut(arr, bins)\n# cats \nprint(f\"编号:{cats.codes}\") # 从0开始生成编号,不在范围内为-1\n\n# 把array转换为dataframe\ndf1 = pd.dataframe( arr.reshape(3, 6) )\nprint(f\"矩阵:\\n{df1}\")\n\ndf1[3] = pd.cut(df1[3], bins).values.codes\ndf1\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 平均划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\nimport pandas as pd\nimport numpy as np\n\n'''平均划分边界  cut()函数 可以通过数值平均等分(平均数)自动划分并装箱'''\narr = np.random.randint(0, 100, 18)\ncats = pd.cut(arr, 4)\n# print(f\"装箱后矩阵:\\n{cats.codes.reshape(3, 6)}\")\n\ndf1 = pd.dataframe( arr.reshape(3, 6) )\nprint(df1)\npd.dataframe( cats.codes.reshape(3, 6) )\n# cats\n\n\n\n# 数据清理与转换(五) 数据离散化和装箱 分位划分边界\n\n点击查看\n\n\"\"\"数据清理与转换(五) 数据离散化和装箱\"\"\"\n\nimport pandas as pd\nimport numpy as np\n\n'''分位划分边界  qcut(data,count) 使用中位数来划分数据并装箱'''\narr = np.random.randint(0, 100, 18)\ncats = pd.qcut(arr, 4)\n# print(f\"装箱后矩阵:\\n{cats.codes.reshape(3, 6)}\")\n\ndf1 = pd.dataframe( arr.reshape(3, 6) )\nprint(f\"随机矩阵:{df1}\")\nprint(f\"cats:{cats}\")\npd.dataframe( cats.codes.reshape(3, 6) )\n\n\n\n\n# 哑变量\n\n点击查看\n\n\"\"\"\n哑变量(可以提高运算速度) 哑变量(dummy variable)是指用0或1表示某个类别是否出现\n1. 有n种互斥属性时，哑变量需要引入n-1个变量，独热编码需要n个变量\n2. get_dummies(drop_first=true)为真正哑变量，默认的drop_first=false为独热编码\n\n\"\"\"\nimport pandas as pd\n\ndf1 = pd.dataframe({\"key\":['a', 'b', 'a', 'c']})\n# 独热编码\n# pd.get_dummies(df1['key'])\n\n# 哑变量\npd.get_dummies(df1['key'], drop_first=true)\n\n# 连接哑变量\n\n\n\n# 数据随机取样(排序)\n\n点击查看\n\n\"\"\"数据随机取样\"\"\"\nimport pandas as pd\nimport numpy as np\n\n# 1.随机排序\ndf1 = pd.dataframe({'k1': ['a','a','b','c','c','c'], 'k2': [1, 1, 2, 3, 3, 4]}) \n# sampler = np.random.permutation(6) # 生成随机序列\n# df1.take(sampler) # 以随机序列为行索引,重新排序后输出\n\n# 2.随机下采样 [随机排序后,取前n行]\nsampler = np.random.permutation(len(df1))[:3] # simpler = array([x, x, x])\n\n# 3.随机上采样 [样本较少时,扩大样本(),再取样]\n## 生成12个元素在0 - 6范围内的数组(正态)\n# sampler = np.random.randint(0, len(df1), size=2*len(df1))\n\ndf1.take(sampler)\n# sampler\n\n\n\n# 补充\n\n点击查看\n\n\"\"\"字符串操作\"\"\"\n\n# 打印内置方法和属性\n# dir(): 返回参数的属性、方法列表\n# dir(\"\")\n\n# 编码解码\n# \"你好\".encode()\nb'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd'.decode('utf-8')\n\n\n\"\"\"老师的代码\"\"\"\n\n# 前缀使用\ndf=pd.dataframe([[1,'a'],[2,'b'],[3,'c'],[1,'d'],[3,'e'],[2,'f']],columns=['lie1','lie2'])\nprint(df)\ndf1=pd.get_dummies(df['lie1'],prefix='lie1')\nprint(df1)\n\n'''\n一个对统计应用有用的秘诀是：结合get_dummies和cut之类的离散化函数\n'''\n#正态分布是个数值\ndata=np.random.rand(10)\nprint(data)\n# [0.01472476 0.21786879 0.80685543 0.33888554 0.28585739 0.03260082\n#  0.86698275 0.86326211 0.36818782 0.04061498]\n \n#设置面元\nbins=[0,0.2,0.4,0.6,0.8,1]\n \n#面元划分\nprint(pd.cut(data,bins))\n# [0.09044921 0.34034557 0.16417927 0.45625488 0.05030981 0.26397673\n#  0.93966121 0.17444847 0.19196159 0.48356917]\n# [(0.0, 0.2], (0.2, 0.4], (0.0, 0.2], (0.4, 0.6], (0.0, 0.2], (0.2, 0.4], (0.8, 1.0], (0.0, 0.2], (0.0, 0.2], (0.4, 0.6]]\n# categories (5, interval[float64]): [(0.0, 0.2] < (0.2, 0.4] < (0.4, 0.6] < (0.6, 0.8] < (0.8, 1.0]]\n#    (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]\n \n#哑变量\nprint(pd.get_dummies(pd.cut(data,bins)))\n\n\n\n# pandas聚合与分组\n\n\n# 数据分组操作(1) (groupby函数 & series分组)\n\n点击查看\n\n\"\"\"数据分组操作(1)  (groupby函数 & series分组)\"\"\"\nimport pandas as pd\nimport numpy as np\n\n# 1.groupy()函数返回一个groupby对象,此对象没有做任何计算，只生成符合分组条件的中间数据，当执行apply方法时才进行真正的计算\ndf = pd.dataframe({ 'k1':['a', 'a', 'b', 'b'], 'k2':['one', 'two', 'one', 'one'], 'v1':np.arange(4), 'v2':np.arange(6,10)})\n\n'''单列分组'''\n# grouped = df['v1'].groupby(df['k1'])\n\n'''多列分组 (多层次索引的series,可转化为datafeame)'''\ngrouped = df['v1'].groupby([df['k1'], df['k2']])\n\n# grouped # 显示groupby对象\n\nprint(df) # 打印df\n\n# groupby对象在执行apply方法时，才会进行真正的计算和组合\n## 如:在groupby对象上应用求平均的应用，并聚合输出一个新的series\n# grouped.mean()\npd.dataframe(grouped.mean()) # 多层索引series转化为dataframe\n\n\n\n# 数据分组操作(2) (datafrme分组)\n\n点击查看\n\n\"\"\"数据分组操作(2)  (datafrme分组)\"\"\"\n# np.array?? # help(np.array) # 查看方法详细信息\n\n# dataframe数据表对象，使用groupby()函数，指定分组的列，即可对数据表其它列进行应用和聚合\ndf = pd.dataframe({'k1' : ['a', 'a', 'b', 'b'], 'k2' : ['one', 'two', 'one', 'one'],'v1' : np.arange(4), 'v2' : np.arange(6,10)})\nprint(df)\n# 1. 单列分组\n# 当被分组并应用汇聚的列，无法进行应用汇聚时，则直接丢弃(比如k2列为字符串,不能进行mean求平均值)\n# df.groupby('k1').mean()\n\n# 2.多列分组\n# df.groupby(['k1', 'k2']).mean()\n\n# 3.多列分组—去除分组索引\n## 在多列分组的情况下，新生成的数据表会有多层次化索引，有的时候我们不需要这些索引，而是要将他们变成新的数据列\n# df.groupby(['k1', 'k2'], as_index=false).mean()\n\n# 4.自定义分组\n# 如果我们不按照数据表中某列来分组，先自己定义分组的规则。这时，可以通过传入自定义列表传入groupby参数，按照列表数据规则进行分组\n# df.groupby(['a', 'a', 'a', 'b']).mean()\n# df.groupby(['1', '1', '2', '0']).mean()\n\n# 5.多列分组—求和\n# df.groupby(['1', '1', '2', '0']).sum()\n\n# 6.多列分组—最大值\n# df.groupby(['k1', 'k2']).max()\n\n# 7.多列分组—中位数\n# df.groupby(['k1', 'k2']).median()\ndf.groupby(['1', '1', '2', '1']).median()\n\n\n\n# 数据分组操作(3) 分组指定应用聚合列\n\n点击查看\n\n\"\"\"数据分组操作(3)  分组指定应用聚合列\"\"\"\n\ndf = pd.dataframe({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', 'one', 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\n# 1.指定单列 (运行没好使)\n## 使用groupby()函数对dataframe数据表进行分组时，可以指定方法应用和聚合的单列，并返回series对象。series.groupby([“column_name”,”column_name”]).mean()\n# df['v1'].groupby(['k1', 'k2']).mean()\n\n# 1.2 指定单列—语法糖 (计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用)\n## 什么是语法糖:https://www.jianshu.com/p/777b10385524\ndf.groupby(['k1', 'k2'])['v1'].mean()\n\n# 2.指定多列 (运行没好使)\n# df[['v1','v2']].groupby(['k1', 'k2']).mean()\n\n# 2.1 指定多列—语法糖\ndf.groupby(['k1', 'k2'])['v1','v2'].mean()\n\n\n\n# 数据分组操作(4) 分组的迭代操作\n\n点击查看\n\n\"\"\"数据分组操作(4)  分组的迭代操作\"\"\"\n\ndf = pd.dataframe({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', 'one', 'one'],'v1' : np.arange(4),'v2' : np.arange(6,10)})\n# print(df)\n\n# 对不同分组进行不同处理,对groupby对象进行迭代,在迭代中处理各个分组\n# 1.输出分组\n# for name, group in df.groupby('k1'):\n#     print(\"name:\" + name)\n#     print(group)\n\n# 2.\n# for [k1, k2],group in df.groupby(['k1', 'k2']):\n#     print(f'({k1}, {k2}):\\n{group}')\n\n# 3.可以将分组数据变成数据表字典,dict(list(groupbyobj)) \ngroupdict = dict(list(df.groupby('k1'))) # 先转列表再转字典\ngroupdict['a']\n\n\n\n# 数据分组操作(5) 对行索引名进行分组\n\n点击查看\n\n\"\"\"数据分组操作(5)  对行索引名进行分组\"\"\"\n\ndf = pd.dataframe({ 'k1':['a', 'a', 'b', 'b'], 'k2':['one', 'two', 'one', 'one'], 'v1':np.arange(4), 'v2':np.arange(6,10)}, \n                index=['c1','cc2','cc3','c4'])\nprint(df)\n# 1.行索引函数分组\ndf.groupby(len).mean()\n\n# 2.行索引函数分组\ndf.index=['c1','cc2','cc3','c1'] # 重置索引\ndf.groupby(str).mean()\n# df\n\n\n\n# 数据分组操作(6) 聚合函数\n\n点击查看\n\n\"\"\"数据分组操作(6)  聚合函数\"\"\"\n\ndf = pd.dataframe({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n# 1.非空值计数\ndf.groupby('k1').count()\n\n# 2. 分组乘积\n# df.iloc[3, 2] = np.nan # 将3,2设为nan\n# df.groupby('k1').prod() # nan不参与乘积\n\n# 3.分组方差和标准差\n# df.iloc[3, 2] = np.nan\n# df.groupby('k1').var() # 方差\n# df.groupby('k1').std() # 样本标准差 (numpy的是总体标准偏差???)\n\n# 4.分位数\n# df.iloc[3, 2] = np.nan\n# df.groupby(['k1', 'k2']).quantile(0.75)\n\n# 5.首尾值\n# df.iloc[3, 2] = np.nan\n# # df.groupby('k1').first()\n# df.groupby('k1').last()\n\n# 6.数据探索\n## 在数据分析的数据探索阶段，需要对数据有个整体的感知，如果按上面步骤一个个看的话比较麻烦。pandas提供describe()函数，可以生成常用方法结果\ndf.iloc[3, 2] = np.nan\ndf.groupby('k1').describe()\n\n\n\n# 数据分组操作(7) 自定义聚合函数agg()\n\n点击查看\n\n\"\"\"数据分组操作(7)  自定义聚合函数agg()\"\"\"\n\ndf = pd.dataframe({'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\ndef my_fun(data):\n    return data.max() + data.min()\n\ndf.iloc[3, 2] = np.nan\n\n# 1.自定义函数\n# df.groupby('k1').agg(my_fun)\n\n# 2.自定义agg函数列表\n# df.groupby('k1').agg(['mean', 'max', 'min', my_fun])\n\n# 2.2 自定义agg函数列表 [指定应用结果的列名称(用元组)]\n# df.groupby('k1').agg([('平均值', 'mean'), ('最大值', 'max'), ('最小值', 'min'), (\"最大最小值之和\", my_fun)])\n\n# 2.3 自定义agg函数列表 [指定列名称(用元组) + 前缀add_prefix]\n## 定义新数据表列名时，在同一行中命名会出现相同的情况，容易混淆\ndf.groupby('k1').agg( my_fun ).add_prefix('x_')\n\n\n\n# 自定义聚合操作 分组转换与分组应用\n\n点击查看\n\n\"\"\"自定义聚合操作  分组转换与分组应用\"\"\"\ndf = pd.dataframe({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\nprint(df)\n\n# df.iloc[3,2] = np.nan\n\n# 1.transform()函数 如果我们需要将统计结果参照原表的shape,直接广播到列中\n# df.groupby('k1').transform(np.mean)\n# df.groupby('k1').mean()  # ?区别\n\n# 2.groupby对象的transform()函数，与agg()一样可以传入自定义函数\ndef my_fun(data):\n    return data.max() + data.min()\n\n# df.groupby(['k1', 'k2']).transform(my_fun)  # ????????????????????不好使\ndf.groupby('k1')['v1', 'v2'].transform(my_fun)\n\n# 3.agg和transform的区别\n## agg()函数 必须是可以汇聚的值（ aggregated value ）\n## transform()函数则可以传入普通的转换函数\n# def divide(df,n=2):\n#     return df/n\n\n# df.groupby('k1').agg(divide) # exception: must produce aggregated value\n# df.groupby(\"k1\")['v1','v2'].transform(divide)\n\n\n\n# 通用的apply方法\n\n点击查看\n\n\"\"\"\n通用的apply方法 可以是非汇聚函数\n1. 通常，agg聚合生成的表shape小于原表，而apply和transform组合的shape可以等于原表\n\"\"\"\n\n'''\n    agg和transform的局限\n    agg()函数需要传入的方法可以返回汇聚的值（ aggregated value ），transform()函数则可以是n:1的汇聚值，也可以是1对1的转换值。\n    如果是输入m到输出n的函数(m>n)，agg和transform都无法使用！比如: 取分组的前n个值\n'''\ndf = pd.dataframe({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\ndef get_rows(df,n=2): \n    return df.iloc[:n,:]\n\n# df.groupby('k1')['v1','v2'].agg(get_rows) #  valueerror: shape of passed values is (4, 2), indices imply (2, 2)\n# df.groupby(\"k1\")['v1','v2'].transform(get_rows) # indexingerror: ('too many indexers', 'occurred at index v1')\n\n# 1.取分组前n个值的方法\n# df.groupby('k1')['v1','v2'].apply(get_rows,1)\n\n# 2.也可以用apply()取topn个值\ndef topn(df, n=3, column='sort_column'):\n    return df.sort_values(by=column,ascending=false)[:n]\n\ndf.groupby(\"k1\")['v1','v2'].apply(topn,2,'v2')\n\n\n\n# 透视表与交叉表 透视表(pivot table)\n\n点击查看\n\n\"\"\" 透视表与交叉表  透视表(pivot table)\"\"\"\nimport pandas as pd\n'''\n透视表(pivot table)是各种电子表格程序和其他数据分析软件中一种常见的数据汇总工具。它根据一个或多个键对数据进行聚合，并根据行和列上得分组建将数据分配到各个矩形区域中。\n1. 在python和pandas中，可以通过本章所介绍的groupby功能以及（能够利用层次化索引的）重塑运算制作透视表。\n2. dataframe有一个pivot_table方法，此外还有一个顶级的pandas.pivot_table函数。除了能为groupby提供便利之外，pivot_table还可以添加分项小计（也叫margins\n'''\n\ndf = pd.dataframe({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\n# dataframe.pivot_table(index, columns, aggfunc(默认为np.mean), fill_value)\n# 1.如果只指定pivot_tabel()函数的index参数，不指定columns参数和fill_value参数，其结果和前面介绍的分组聚合结果一致。\n# df.pivot_table(index='k1') # 相当于df.groupby('k1').mean()\n\n# 2.指定输出的列\n# df.pivot_table(['v1', 'v2'], index='k1') # 相当于df.groupby('k1')['v1', 'v2'].mean()\n\n# 3.如果只指定pivot_tabel()函数的index参数，指定columns参数，就是将以列维度进行分组，其效果和指定两个分组行索引，再将返回的层次索引unstack() 结果一致\ndf.pivot_table(index='k1', columns='k2') # 相当于df.groupby(['k1', 'k2']).mean().unstack()\n\n\n\n# 透视表与交叉表 交叉表(cross table)\n\n点击查看\n\n\"\"\" 透视表与交叉表  交叉表(cross table)\"\"\"\nimport pandas as pd\n\n\"\"\"\n1. 交叉表(cross table) 是矩阵格式的一种表格，显示变量的（多变量）频率分布。\n2. 交叉表被广泛用于调查研究，商业智能，工程和科学研究。它们提供了两个变量之间的相互关系的基本画面，可以帮助他们发现它们之间的相互作用。\n3. 卡尔·皮尔逊（karl pearson）首先在“关于应变的理论及其关联理论与正常相关性”中使用了交叉表。\n4. 在pandas中，交叉表是一种特殊的透视表。\n\"\"\"\n# pd.crosstab(index, columns, margins[边际求和开关])\ndf = pd.dataframe({ 'k1' : ['a', 'a', 'b', 'b'],'k2' : ['one', 'two', np.nan, 'one'], 'v1' : np.arange(4),'v2' : np.arange(6,10)})\n\ndef get_rows(df,n=2): \n    return df.iloc[:n,:]\n\ndf.iloc[3,2] = np.nan\n# pd.crosstab(df['k1'],df['k2'])\npd.crosstab(df['k1'],df['k2'],margins=true)\n\n\n\n# seaborn(pandas)可视化\n\n折线图\n\n点击查看\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.dataframe(np.random.randn(10,3), columns = ['a','b','c'], index = np.arange(0,100,10))  \ndf.plot()\nplt.show() \n# df\n\n\n条形图\n\n点击查看\n\nfig, axes = plt.subplots(1,2)  \ndata = pd.series(np.random.rand(7),index = list('abcdefg'))  \n#kind选择图表类型  'bar' 垂直条形图 \ndata.plot(kind = 'bar', ax = axes[0], color = 'b', alpha = 0.7) \n# 'barh' 水平条形图 \ndata.plot(kind = 'barh', ax = axes[1], color = 'b', alpha = 0.7)\nplt.show() \n\n\n直方图\n\n点击查看\n\nimport sklearn.datasets as skds\n\"\"\"直方图\"\"\"\n\n# iris = skds.load_iris()\n# df_iris = pd.dataframe(iris.data,columns=iris.feature_names)\n# df_iris.hist('sepal length (cm)')\n# plt.show()\n\niris = skds.load_iris()\ndf_iris = pd.dataframe(iris.data,columns=iris.feature_names)\ndf_iris.hist()\nplt.show()\n\n## --------------------------------------------\n\nfig, axes = plt.subplots(1,2)  \ndata = pd.series(np.random.randn(100))  \ndata.hist(ax = axes[0], bins = 50)       #直方图  \ndata.plot(kind = 'kde', ax = axes[1])    #密度图  \nplt.show() \n\n\n散点图\n\n点击查看\n\niris = skds.load_iris()\ndf_iris = pd.dataframe(iris.data,columns=iris.feature_names)\ndf_iris.plot(kind='scatter',x=\"sepal length (cm)\", y=\"sepal width (cm)\")\nplt.show()\n\n\nmatplotlib无疑是高度可定制的，但快速实施出吸引人的细节就变得有些复杂。seaborn作为一个带着定制主题和高级界面控制的matplotlib扩展包，能让绘图变得更轻松\n\n示例\n\n点击查看\n\n\"\"\"seaborn可视化方法  (单变量分布)\"\"\"\nimport seaborn as sns \n\n\"\"\"最快速查看单变量分布无疑是使用distplot()函数。默认情况下，这将绘制一个直方图，并拟合出核密度估计(kde)\"\"\"\nx = np.random.normal(size=100)\nsns.distplot(x)\nplt.show()\n\n# ---------------------------------\n\"\"\"seaborn可视化方法  (直方图)\"\"\"\n\n\"\"\"\n直方图通过在数据的范围内切成数据片段，然后绘制每个数据片段中的观察次数，来表示整体数据的分布。\n我们删除密度曲线并添加了地毯图，每个观察点绘制一个小的垂直刻度\n\"\"\"\n\nx = np.random.normal(size=100)\nsns.distplot(x, kde=false, rug=true)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"seaborn可视化方法  (核密度估计)\"\"\"\n\n\"\"\"seaborn的displot()函数，通过设置参数，可以实现只显示核密度估计和地毯图\"\"\"\nx = np.random.normal(size=100)\nsns.distplot(x, hist=false, rug=true)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"seaborn可视化方法  (散点双变量分布)\"\"\"\n\n# 随机生成两列，其均值为[0,1],协方差矩阵为[(1, 0.5), (0.5, 1)]的数组\n\nmean, cov = [0, 1], [(1, 0.5), (0.5, 1)]\ndata = np.random.multivariate_normal(mean, cov, 200)\ndf = pd.dataframe(data, columns=[\"x\", \"y\"])\nsns.jointplot(x=\"x\", y=\"y\", data=df)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"seaborn可视化方法  (成对关系图)\"\"\"\n\"\"\"\n要在数据集中绘制多个成对双变量分布，可以使用pairplot()函数。这将创建一个轴的矩阵，并显示dataframe中每对列的关系。\n默认情况下，它也绘制每个变量在对角轴上的单变量。\n\"\"\"\n\nimport sklearn.datasets as skds\niris = skds.load_iris()\ndf_iris = pd.dataframe(iris.data,columns=iris.feature_names)\nsns.pairplot(df_iris)\nplt.show()\n\n## ---------------------------------\n\n\"\"\"seaborn可视化方法  (线性回归线一)\"\"\"\n\n\"\"\"seaborn的lmplot(data,x,y)函数，将data数据表中x列和y列数据，生成散点图，并绘制线性回归线。本示例使用tips数据集。\"\"\"\n# tips = sns.load_dataset(\"tips\")\ntips = pd.read_csv('./data/tips.csv')\nsns.lmplot(data=tips, x=\"total_bill\", y=\"tip\")\nplt.show()\n## ---------------------------------\n\n\"\"\"seaborn可视化方法  (线性回归线二)\"\"\"\n\n\"\"\"seaborn的jointplot()函数绘制双变量分布时，也可以绘制回归线。设置kind参数为“reg”。本示例使用tips数据集。效果如下\"\"\"\n\n# tips = sns.load_dataset(\"tips\")\ntips = pd.read_csv('./data/tips.csv')\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\")\nplt.show()\n# tips\n\n## ---------------------------------\n\n\"\"\"生成数据\"\"\"\nimport csv\nimport random\nimport datetime\n\nfilepath ='data/data.csv'\nwith open(filepath, 'w', encoding='utf-8') as fp:\n    #创建csv文件写入对象\n    wr = csv.writer(fp)\n    #写入表头\n    wr. writerow(['日期','销量'])\n    #生成模拟数据\n    startdate = datetime. date(2020, 1, 1)\n    #生成365个模拟数据，可以根据需要进行调整\n\n    for i in range (365):\n        #生成一个模拟数据，写入csv文件\n        amount = 300 + i*5 + random.randrange (100)\n        wr.writerow([str(startdate), amount] )\n        #下一天\n        startdate = startdate + datetime.timedelta (days=1)\n\"ok\"\n\n## ---------------------------------\n\n\"\"\"生成模拟数据\"\"\"\nimport numpy as np\nimport pandas as pd\n\n# 用含日期时间索引与标签的 numpy 数组生成 dataframe\ndates = pd.dataframe(pd.date_range(\"20200101\", periods=365), columns=['日期'])\ndata = pd.dataframe(np.random.randint(300, 600, dates.shape[0]), columns=['销量'])\ndf = dates.join(data)\n\nfilepath = 'data\\data0.csv'\ndf.to_csv(filepath, # sys.stdout, # 输出到控制台\n          na_rep='non', # 存储空值\n          index=false, # 不存储索引(index)\n          header=true, # 存储列名\n)\n\n## ---------------------------------\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 读取数据，丢弃缺失值\ndf = pd.read_csv('data\\\\data0.csv', encoding='utf-8')\ndf = df.dropna()\n# print(df['日期'])\n\n# 设置字体\nplt.rcparams['font.sans-serif']=['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n#生成营业额折线图\nplt.figure()\ndf.plot(x='日期')\n# plt.savefig('data\\\\test\\\\first.jpg')\n\n#按月统计，生成柱状图\nplt.figure()\ndf1 = df[:]\n# map()会根据提供的函数对指定序列做映射。第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表\n# lambda简化了函数定义的书写形式。使代码更为简洁，但是使用函数的定义方式更为直观，易理解。\n# def fun(x):\n#     return x[:x.rindex('-')]\n\ndf1['month'] = df1['日期'].map(lambda x:x[:x.rindex('-')]) # lambda x:x[:x.rindex('-')]\ndf1 = df1.groupby(by='month', as_index=false).sum()\ndf1.plot(x='month', kind='bar')\n# plt.savefig('data\\\\test\\\\second.jpg')\n\n# 查找涨幅最大的月份，写入文件 \nplt.figure()\ndf2 = df1.drop('month', axis=1).diff()\n# dataframe.nlargest(self, n, columns, keep='first') 返回按列降序排列的前n行。以降序返回column中具有最大值的前n行。未指定的列也将返回，但不用于排序。\n# 此方法等效于 ，但性能更高。df.sort_values(columns, ascending=false).head(n)\nm = df2['销量'].nlargest(1).keys()[0]\nprint(f\"销量最高月份{df1.loc[m, 'month']}\")\nwith open('data\\\\test\\\\maxmonth.txt', 'w') as fp:\n    fp.write(df1.loc[m, 'month'])\n\n# 按季度统计，生成饼状图\nplt.figure()\none=df1[:3]['销量'].sum()\ntwo=df1[3:6]['销量'].sum()\nthree=df1[6:9]['销量'].sum()\nfour=df1[9:12]['销量'].sum()\nplt.pie([one, two, three, four], labels=['第一季度', '第二季度', '第三季度', '第四季度'])\n# plt.savefig('data\\\\test\\\\third.jpg')\n\nplt.show()\n\n\n\n\n# matplotlib可视化\n\n\n# 条形图\n\n# 条形图\n\n点击查看\n\n\"\"\"第一次作业  条形图\"\"\"\nimport  pymysql\nimport matplotlib.pyplot as plt\n# from matplotlib import font_manager\n \n##获取一个数据库连接，注意如果是utf-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n#将元组数据存进列表中\ncity=[]\nneed=[]\nfor x in result:\n    city.append(x[0])\n    need.append(x[1])\n    \n# 一种设置字体的方式\n# my_font = font_manager.fontproperties(fname=\"d:\\software\\python\\anaconda3\\library\\myfonts\\geitangbudaodan.ttf\")\n# 设置字体\nplt.rcparams['font.sans-serif']=['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 设置图形大小\nplt.figure(figsize=(12, 5), dpi=120)\n# 设置刻度字体大小\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\n#直方图\nplt.bar(range(len(need)), need, color='r', tick_label=city)\n\nplt.xlabel(\"城市名\", fontsize=20)\nplt.ylabel(\"数量\", fontsize=20)\nplt.title(\"城市职位需求图\", fontsize=20)\nfor  x,y in enumerate(need):\n    plt.text(x-0.4, y+0.4, '%s' % y)\nplt.show()\n\n\n# 条形图 bar()\n\n点击查看\n\n\"\"\"条形图 bar()\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 示例\n# plt.bar(np.arange(2,5),np.arange(1,4),\n#         label=\"zt example\") \n# plt.bar([1,2,3],[2,4,1],label=\"tz example\", color='g')\n# plt.xlabel(\"this is x\")\n# plt.ylabel(\"this is y\")\n# plt.title(\"this is bar\")\n# plt.legend()\n# plt.show()\n\n\"\"\"展示2017票房数据\"\"\"\n# 设置字体\nplt.rcparams['font.sans-serif'] = ['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig = plt.figure(figsize=(8, 4), dpi=200)\n\nmovie_name = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",]\nbox_office = [56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23]\ndf = pd.dataframe( {\"电影名\":movie_name, \"票房(单位:亿)\":box_office} )\n# df\nx = range(df.shape[0]) # x轴的列表\ny = box_office\n\n# bar()绘制条形图,只能接受可迭代的数字对象\nplt.bar(x, y,\n    width = 0.4, # 默认0.8\n    color = 'orange',\n    tick_label = y,\n    label = '电影', # 为设置图例作准备\n    alpha = 0.9\n)\n# 通过设置xticks使数字与字符串对应\nplt.xticks(x, df.iloc[:, 0], rotation=90)\n# 设置描述信息\nplt.title(\"2017年电影票房展示\")\nplt.xlabel(df.columns[0])\nplt.ylabel(df.columns[1])\n# 显示图例\nplt.legend()\n    \nplt.show()\n\n\n# 水平条形图 barh()\n\n点击查看\n\n\"\"\"水平条形图 barh()\"\"\"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\"\"\"展示2017票房数据\"\"\"\nmovie_name = [\"战狼2\",\"速度与激情8\",\"功夫瑜伽\",\"西游伏妖篇\",\"变形金刚5：最后的骑士\",\"摔跤吧！爸爸\",\"加勒比海盗5：死无对证\",\"金刚：骷髅岛\",\"极限特工：终极回归\",\"生化危机6：终章\",\"乘风破浪\",\"神偷奶爸3\",\"智取威虎山\",\"大闹天竺\",\"金刚狼3：殊死一战\",\"蜘蛛侠：英雄归来\",\"悟空传\",\"银河护卫队2\",\"情圣\",\"新木乃伊\",]\nbox_office = [56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23]\ndf = pd.dataframe( {\"电影名\":movie_name, \"票房(单位:亿)\":box_office} )\n# df\n\n# 设置字体\nplt.rcparams['font.sans-serif'] = ['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig, ax = plt.subplots(figsize=(20, 16), dpi=80)\n\nx = np.arange(df.shape[0]) # x轴的列表\ny = box_office\n\n# bar()绘制条形图,只能接受可迭代的数字对象\nplt.barh(x, y,\n    height = 0.4,\n    color = 'orange',\n    label = '电影', # 为设置图例作准备\n    alpha = 0.9,\n    align='center'\n)\n\n# plt.yticks(y, movie_name) # , rotation=90\nax.set_yticks(x)\nax.set_yticklabels(df.iloc[:, 0], minor=false, fontsize=16)\nax.invert_yaxis() # 标签读取自上而下labels read top-to-bottom\n# 设置描述信息\nax.set_title(\"2017年电影票房展示\", fontsize=20)\nax.set_xlabel(df.columns[1], fontsize=20)\nax.set_ylabel(df.columns[0], fontsize=20)\n# 显示图例\nax.legend()\n    \nplt.show()\n\n\n\n# 子图\n\n点击查看\n\n\"\"\"子图\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n##获取一个数据库连接，注意如果是utf-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncol_result = cursor.description  # 获取查询结果的字段描述\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n# 设置字体\nplt.rcparams['font.sans-serif']=['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 设置图形大小\nplt.figure(figsize=(20, 10), dpi=120)\nfig, axes = plt.subplots(1, 2)\n\n# 用数据库查询到的数据创建dataframe\n# print(col_result)\ndf = pd.dataframe(result, columns=[col_result[0][0], col_result[1][0]])\n\n# 饼图\nslices = df.iloc[:, 1]\nactivities = df.iloc[:, 0]\naxes[0].pie(slices,labels=activities,\n        startangle=90, # 初始角度\n        shadow= true, # 阴影\n        textprops={'size': 'small'},\n#         colors=[], # 设置颜色\n#         radius=1.6, # 半径\n        explode=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05, 0), # 突出\n        autopct='%1.2f%%') # \n\n# 条形图\naxes[1].bar(df.iloc[:, 0], df.iloc[:, 1], color='pink')\n# axes[1].xt\n\nplt.title('城市职位需求图')\nplt.show()\n\n\n\n# 饼图\n\n点击查看\n\n\"\"\"第二次作业  饼图\"\"\"\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n##获取一个数据库连接，注意如果是utf-8类型的，需要制定数据库\ndb=pymysql.connect(host=\"127.0.0.1\",user='root',passwd=\"123456789\",port=3306,db=\"demo\",charset='utf8')\ncursor=db.cursor()#获取一个游标\nsql=\"select city,need from citys\"\ncursor.execute(sql)\nresult=cursor.fetchall() #result为元组\ncol_result = cursor.description  # 获取查询结果的字段描述\ncursor.close() #关闭游标\ndb.close() #关闭数据库\n \n# 设置字体\nplt.rcparams['font.sans-serif']=['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 设置图形大小\nplt.figure(figsize=(6, 4), dpi=120)\n\n# 用数据库查询到的数据创建dataframe\n# print(col_result)\ndf = pd.dataframe(result, columns=[col_result[0][0], col_result[1][0]])\n\n# 饼图\nslices = df.iloc[:, 1]\nactivities = df.iloc[:, 0]\nplt.pie(slices,labels=activities,\n        startangle=90, # 初始角度\n        shadow= true, # 阴影\n        textprops={'size': 'small'},\n#         colors=[], # 设置颜色\n#         radius=1.6, # 半径\n        explode=(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.05, 0), # 突出\n        autopct='%1.2f%%') # \n\nplt.title('城市职位需求图')\nplt.show()\n\n\n\n# 折线图(完整)\n\n点击查看\n\n\"\"\"折线图   (画出你和同桌在11-25岁谈过的女友数)  \"\"\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 设置字体\nplt.rcparams['font.sans-serif'] = ['lisu']\nplt.rcparams['axes.unicode_minus'] = false\n\n# 1.设置图片大小\n# 实例化figure并传递参数  dpi为每英寸像素点数\nfig = plt.figure('figure object 1', # 图形对象名称  窗口左上角显示\n    figsize=(8, 4), # 窗口大小\n    dpi=80, # 分辨率\n    facecolor = 'white',     # 背景色\n)\n\n# x轴和y轴\nx = range(11, 31)\ny_1 = [1, 0, 1, 1, 2, 4, 3, 2, 3, 4, 4, 5, 6, 5, 4, 3, 3, 1, 1, 1]\ny_2 = [1, 0, 3, 1, 2, 2, 3, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nplt.plot(\n    x,\n    y_1,\n    # 折线样式\n    color='r',  # 设置线条颜色\n    linestyle='--',  # 线条风格\n    linewidth=1,  # 线条粗细\n    alpha=0.5,  # 透明度\n    label='自己',\n    # 6.折点样式设置\n    marker='o', # 折点形状\n    markersize='3', # 或 ms --折点大小\n    markerfacecolor='black', # 或 mfc --折点实心颜色\n)\n\nplt.plot(\n    x,\n    y_2,\n    color='b',  # 设置线条颜色\n    linestyle=':',  # 线条风格\n    linewidth=1,  # 线条粗细\n    alpha=0.5,  # 透明度\n    label='同桌',\n    # 折点样式设置\n    marker='*', # 折点形状\n    markersize='6', # 或 ms --折点大小\n    markerfacecolor='pink', # 或 mfc --折点实心颜色\n)\n\n# 8.标出最高点 (因为横纵坐标没有必然联系所以比较难整)\nzip1 = dict( zip(x, y_1) ) # 把横纵坐标合为一个字典\n# 找出最大值和下标\nfor key,value in zip1.items():\n    if(value == max(zip1.values())):\n        max_index1 = key\n        max_value1 = value\ndel zip1\nplt.plot(max_index1,max_value1,'ks')\ns = f\"({max_index1},{max_value1})\"\n# plt.annotate()函数用于标注文字\nplt.annotate(s, xytext=(max_index1,max_value1), xy=(max_index1,max_value1)) # 注释内容 注释文本的坐标点 被注释的坐标点，二维元组形如(x,y)\n####\nzip2 = dict( zip(x, y_2) ) # 把横纵坐标合为一个字典\n# 找出最大值和下标\nfor key,value in zip2.items():\n    if(value == max(zip2.values())):\n        max_index2 = key\n        max_value2 = value\ndel zip2\nplt.plot(max_index2,max_value2,'ks')\ns = f\"({max_index2},{max_value2})\"\n# plt.annotate()函数用于标注文字\nplt.annotate(s, xytext=(max_index2,max_value2), xy=(max_index2,max_value2))\n\n\n# 4.调整x和y轴刻度间距\n_xtick_labels = [\"{}岁\".format(i) for i in x]\nplt.xticks(x, _xtick_labels, rotation=45, fontsize=9)\nplt.yticks(range(0, 9))\n# 5.线条样式 颜色 透明度\n# 加网格 (透明度)\nplt.grid(alpha=0.5, linestyle='--', linewidth=1)\n\n# 3.描述信息(x轴[y轴.标题]代表什么)\nplt.xlabel('年龄')\nplt.ylabel('人数')\nplt.title(\"回忆青葱岁月\", fontsize=16)\n\nplt.legend(loc='best')\n\n# 2.保存到本地 (可设置格式(svg矢量图))\n# plt.savefig(\"data/xxx.svg\")\n\n# 7.图片加水印\ndef add_watermark(x, y):\n    fig.text(x, y, '寒川环宇', # text的位置,内容\n        fontsize=16, \n        color='gray',\n        ha='left', \n        va='top',\n        rotation=-45, #旋转角度\n        alpha=0.3,\n        bbox = dict(facecolor = \"#b0c4de\", alpha = 0.05)) # 加框(框体颜色,透明度)\n    \nadd_watermark(0.5, 0.6)\nadd_watermark(0.5, 0.8)\nadd_watermark(0.2, 0.6)\nadd_watermark(0.2, 0.8)\nplt.show()\n",charsets:{cjk:!0},lastUpdated:"2022/05/03, 23:36:40",lastUpdatedTimestamp:16515922e5},{title:"Python爬虫",frontmatter:{title:"Python爬虫",date:"2024-01-11T09:28:56.000Z",permalink:"/pages/f799c7/"},regularPath:"/04.%E5%85%B6%E4%BB%96/01.Python/05.Python%E7%88%AC%E8%99%AB.html",relativePath:"04.其他/01.Python/05.Python爬虫.md",key:"v-547abcde",path:"/pages/f799c7/",headers:[{level:4,title:"琐碎代码",slug:"琐碎代码",normalizedTitle:"琐碎代码",charIndex:2},{level:5,title:"Url 编码解码",slug:"url-编码解码",normalizedTitle:"url 编码解码",charIndex:52},{level:5,title:"日期格式化",slug:"日期格式化",normalizedTitle:"日期格式化",charIndex:128},{level:5,title:"json 转字符串乱码解决",slug:"json-转字符串乱码解决",normalizedTitle:"json 转字符串乱码解决",charIndex:1074},{level:5,title:"使用 lxml 解析数据",slug:"使用-lxml-解析数据",normalizedTitle:"使用 lxml 解析数据",charIndex:1166},{level:4,title:"Requests",slug:"requests",normalizedTitle:"requests",charIndex:1979},{level:5,title:"requests 库请求结果显示中文",slug:"requests-库请求结果显示中文",normalizedTitle:"requests 库请求结果显示中文",charIndex:2033},{level:5,title:"requests 库携带文件对象参数",slug:"requests-库携带文件对象参数",normalizedTitle:"requests 库携带文件对象参数",charIndex:2111},{level:4,title:"Scrapy",slug:"scrapy",normalizedTitle:"scrapy",charIndex:2291},{level:5,title:"程序中主动退出爬虫",slug:"程序中主动退出爬虫",normalizedTitle:"程序中主动退出爬虫",charIndex:2343},{level:5,title:"代码中执行单个爬虫",slug:"代码中执行单个爬虫",normalizedTitle:"代码中执行单个爬虫",charIndex:2436},{level:5,title:"命令行中传参",slug:"命令行中传参",normalizedTitle:"命令行中传参",charIndex:2567},{level:5,title:"两个请求见传递参数",slug:"两个请求见传递参数",normalizedTitle:"两个请求见传递参数",charIndex:2849},{level:5,title:"发送请求并获取请求头中的Cookie",slug:"发送请求并获取请求头中的cookie",normalizedTitle:"发送请求并获取请求头中的cookie",charIndex:2981},{level:5,title:"PipeLine 存储 Item 数据到 Excel",slug:"pipeline-存储-item-数据到-excel",normalizedTitle:"pipeline 存储 item 数据到 excel",charIndex:3119},{level:5,title:"中间件 from_crawler 方法中各个阶段执行前绑定函数",slug:"中间件-from-crawler-方法中各个阶段执行前绑定函数",normalizedTitle:"中间件 from_crawler 方法中各个阶段执行前绑定函数",charIndex:3798},{level:5,title:"中间件（或spider）中重新发送请求",slug:"中间件-或spider-中重新发送请求",normalizedTitle:"中间件（或spider）中重新发送请求",charIndex:4148},{level:5,title:"中间件中处理异常",slug:"中间件中处理异常",normalizedTitle:"中间件中处理异常",charIndex:4328},{level:5,title:"ERROR：使用Rquests发请求可以，但是使用Scrapy不行",slug:"error-使用rquests发请求可以-但是使用scrapy不行",normalizedTitle:"error：使用rquests发请求可以，但是使用scrapy不行",charIndex:4859},{level:4,title:"Selenium",slug:"selenium",normalizedTitle:"selenium",charIndex:5123},{level:5,title:"Selenium Chrome 最新驱动下载地址",slug:"selenium-chrome-最新驱动下载地址",normalizedTitle:"selenium chrome 最新驱动下载地址",charIndex:5177},{level:5,title:"Selenium 去掉爬虫标识（与之前不同）",slug:"selenium-去掉爬虫标识-与之前不同",normalizedTitle:"selenium 去掉爬虫标识（与之前不同）",charIndex:5225},{level:5,title:"Selenium 设置请求头",slug:"selenium-设置请求头",normalizedTitle:"selenium 设置请求头",charIndex:5917},{level:5,title:"Selenium 设置页面超时时间",slug:"selenium-设置页面超时时间",normalizedTitle:"selenium 设置页面超时时间",charIndex:6079},{level:5,title:"Selenium 在 Linux（Centos7） 上使用",slug:"selenium-在-linux-centos7-上使用",normalizedTitle:"selenium 在 linux（centos7） 上使用",charIndex:6204},{level:5,title:"Selenium 获取请求头",slug:"selenium-获取请求头",normalizedTitle:"selenium 获取请求头",charIndex:6975},{level:5,title:"Selenium 获取Cookies",slug:"selenium-获取cookies",normalizedTitle:"selenium 获取cookies",charIndex:7269},{level:5,title:"Selenium 获取 jQuery 中 localStorage",slug:"selenium-获取-jquery-中-localstorage",normalizedTitle:"selenium 获取 jquery 中 localstorage",charIndex:7314},{level:5,title:"爬虫自测网站",slug:"爬虫自测网站",normalizedTitle:"爬虫自测网站",charIndex:7548},{level:4,title:"爬虫梳理",slug:"爬虫梳理",normalizedTitle:"爬虫梳理",charIndex:7617},{level:4,title:"加密解密函数",slug:"加密解密函数",normalizedTitle:"加密解密函数",charIndex:8197},{level:5,title:"ras 解密",slug:"ras-解密",normalizedTitle:"ras 解密",charIndex:8249},{level:5,title:"aes 解密（AES-CTR 模式，其他类似）",slug:"aes-解密-aes-ctr-模式-其他类似",normalizedTitle:"aes 解密（aes-ctr 模式，其他类似）",charIndex:8644},{level:5,title:"aes 加密（AES-ECB 模式）",slug:"aes-加密-aes-ecb-模式",normalizedTitle:"aes 加密（aes-ecb 模式）",charIndex:9203},{level:4,title:"附：代码示例",slug:"附-代码示例",normalizedTitle:"附：代码示例",charIndex:9591},{level:5,title:"爬虫代码",slug:"爬虫代码",normalizedTitle:"爬虫代码",charIndex:9643},{level:5,title:"中间件使用动态代理IP测试",slug:"中间件使用动态代理ip测试",normalizedTitle:"中间件使用动态代理ip测试",charIndex:12012},{level:5,title:"中间件使用Selenium发送请求 + 动态代理IP",slug:"中间件使用selenium发送请求-动态代理ip",normalizedTitle:"中间件使用selenium发送请求 + 动态代理ip",charIndex:14545}],headersStr:"琐碎代码 Url 编码解码 日期格式化 json 转字符串乱码解决 使用 lxml 解析数据 Requests requests 库请求结果显示中文 requests 库携带文件对象参数 Scrapy 程序中主动退出爬虫 代码中执行单个爬虫 命令行中传参 两个请求见传递参数 发送请求并获取请求头中的Cookie PipeLine 存储 Item 数据到 Excel 中间件 from_crawler 方法中各个阶段执行前绑定函数 中间件（或spider）中重新发送请求 中间件中处理异常 ERROR：使用Rquests发请求可以，但是使用Scrapy不行 Selenium Selenium Chrome 最新驱动下载地址 Selenium 去掉爬虫标识（与之前不同） Selenium 设置请求头 Selenium 设置页面超时时间 Selenium 在 Linux（Centos7） 上使用 Selenium 获取请求头 Selenium 获取Cookies Selenium 获取 jQuery 中 localStorage 爬虫自测网站 爬虫梳理 加密解密函数 ras 解密 aes 解密（AES-CTR 模式，其他类似） aes 加密（AES-ECB 模式） 附：代码示例 爬虫代码 中间件使用动态代理IP测试 中间件使用Selenium发送请求 + 动态代理IP",content:"# 琐碎代码\n\n----------------------------------------\n\n# Url 编码解码\n\n# url 编码\nurllib.parse.quote()\n# url 解码\nurllib.parse.unquote()\n\n\n# 日期格式化\n\n特殊字符串转日期\n\n# pip install python-dateutil\nimport datetime\nfrom dateutil import parser\n\ntime_string = \"Fri Jan 05 15:41:17 GMT+08:00 2024\"\ndt_object = parser.parse(time_string)\nprint(dt_object.strftime(\"%Y-%m-%d %H:%M:%S\"))\n# 转换为 UTC 时间\nprint(dt_object.astimezone(tz=datetime.timezone.utc))\n# 或者如果你想转换到本地时区（假设你的系统配置了正确的本地时区）\nprint(dt_object.astimezone())\n\n\n日期转带时区的字符串\n\nfrom datetime import datetime, timezone\nimport pytz\n\n# 获取当前时间（假设我们使用UTC时区作为示例，实际中你可能需要根据你的位置获取正确的时区）\nnow_utc = datetime.now(timezone.utc)\n\n# 将UTC时间转换为北京时间（GMT+08:00）\n# 注意：这里我们使用了pytz库来获取北京时间的时区对象\nbeijing_tz = pytz.timezone('Asia/Shanghai')\nnow_beijing = now_utc.astimezone(beijing_tz)\n\n# 格式化时间，但注意strftime()不支持直接添加时区名称，所以我们手动添加\n# '%A' - 星期几的全名\n# '%b' - 月份的简写名\n# '%d' - 月中的一天（01至31）\n# '%Y' - 年份\n# '%H:%M:%S' - 时:分:秒\n# 然后我们手动添加 'GMT+0800 (中国标准时间)'\nformatted_time = now_beijing.strftime(\"%a %b %d %Y %H:%M:%S\") + \" GMT+0800 (中国标准时间)\"\n\nprint(\"当前时间（格式化后）:\", formatted_time)\n\n\n# json 转字符串乱码解决\n\n# 确保输出的结果中不包含非ASCII字符\njson.dumps(response[\"result\"], ensure_ascii=False)\n\n\n# 使用 lxml 解析数据\n\ndata=\"\"\"\n<datastore>\n<recordset>\n<record><![CDATA[\n<div class=\"fyxx_lsbox\">\t<div class=\"btqz\"></div>\t<div class=\"fyxx_lsbox_r\">\t\t<a title=\"xxxxxxxxxxxxxxxxxxxxxx\" target=\"_blank\" href=\"/art/2024/1/12/art_1229682709_457018.html\">xxxxxxxxxxxxxxxxxxxxxx</a> <span>2024-01-12</span> </div></div>]]></record>\n</recordset>\n</datastore>\n\"\"\"\n\n# 方法一：工具直接解析（上述数据不太符合，但写法应如此）\nfrom xml.etree import ElementTree as ET\nroot = ET.fromstring(data)\nfor element in root.iter():\n   # 简单地访问.text属性，因为在大多数情况下解析器已经处理好CDATA了\n   if element.text:\n      print(element.text)\n\n# 方法二：字符串混合xpath处理\ndatastore = etree.HTML(data)\nfor row in datastore.xpath('//record'):\n   record = etree.tostring(row).replace(r'<record>', '').replace(r']]&gt;</record>', '')\n   record1 = etree.HTML(record)\n   print etree.tostring(record1)\n\"\"\"\n\n\n# Requests\n\n----------------------------------------\n\n# requests 库请求结果显示中文\n\n# 设置编码\nresponse.encoding='utf-8'\nprint(response.text)\n\n\n# requests 库携带文件对象参数\n\nresponse = requests.post(\n    url='http://xxx/captcha-ocr-yn/captcha',\n    files={'captcha': open(img_path, 'rb')},\n    data={'question': '请依次点击【工,确,海】'}\n)\n\n\n# Scrapy\n\n----------------------------------------\n\n# 程序中主动退出爬虫\n\n# scrapy框架中手动退出爬虫程序\nself.crawler.engine.close_spider(self, '验证码尝试三次不正确，退出爬虫')\n\n\n# 代码中执行单个爬虫\n\nfrom scrapy import cmdline\ncmdline.execute(\"scrapy crawl xxx -o ./data/xxx.csv -s LOG_FILE=./logs/xxx.log\".split())\n\n\n# 命令行中传参\n\n传入参数\n\ncmdline.execute(\"scrapy crawl jianyuSearch -a searchWord=xxx -a page=10\".split())\n\n\n爬虫中接收参数（Spider中增加）\n\ndef __init__(self, searchWord='', page=1,*args, **kwargs):\n  super(xxxSpider, self).__init__(*args, **kwargs)\n  self.searchWord = searchWord\n  self.page = page\n\n\n# 两个请求见传递参数\n\n# 第一个请求携带参数\nyield Request(url=url, callback=self.parse, meta={\"para1\": xxx})\n\n# parse 回调函数中获取参数\nresponse.meta['url']\n\n\n# 发送请求并获取请求头中的Cookie\n\nresponse = requests.get(url, headers=headers)\nself.cookies = requests.utils.dict_from_cookiejar(response.cookies)\n\n\n# PipeLine 存储 Item 数据到 Excel\n\nclass spiderNamePipeLine(object):\n    def open_spider(self,spider):\n        if spider.name in ['spiderName']:\n            self.field_list = [field_name for field_name, field_meta in spiderNameItems.fields.items()]\n            self.wb = openpyxl.Workbook()\n            self.ws = self.wb.active\n            self.ws.append(self.field_list)\n\n    def close_spider(self,spider):\n        if spider.name in ['spiderName']:\n            self.wb.save(\"test.xlsx\")\n\n    def process_item(self, item, spider):\n        if spider.name in ['spiderName']:\n            self.ws.append([item.get(field_name) for field_name in self.field_list])\n            return item\n\n\n# 中间件 from_crawler 方法中各个阶段执行前绑定函数\n\n@classmethod\ndef from_crawler(cls, crawler):\n    # This method is used by Scrapy to create your spiders.\n    s = cls()\n    crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n    # 绑定 spider_closed 信号的处理方法\n    crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)\n    return s\n\n\n# 中间件（或spider）中重新发送请求\n\nfrom scrapy.downloadermiddlewares.retry import get_retry_request\n\nreturn get_retry_request(request=request, spider=spider, reason='xxx')   # spider = self\n\n\n# 中间件中处理异常\n\n# 抛出异常\nraise IgnoreRequest(\"Filtered request: {}\".format(request))\nraise ValueError('403 response')\n\n# 处理异常\ndef process_exception(self, request, exception, spider):\n    if isinstance(exception, IgnoreRequest):\n        # 处理 IgnoreRequest 异常，例如记录日志、发送通知等\n        # 返回 None 表示异常已经被处理\n        return None\n    else:\n        # 重发请求\n        request.meta['dont_filter'] = True\n        request.meta['max_retry_times'] = 4   # 增加重试次数\n        return get_retry_request(request=request, spider=spider, reason='process_exception')\n\n\n# ERROR：使用Rquests发请求可以，但是使用Scrapy不行\n\n 1. 网站有请求头 Content-Length 的校验：Scrapy如果在header写死，发请求时会再增加一个 Content-Length（而不是替换原来的，Request应该是直接替换原来的），导致请求异常（400 Bad Request）。\n 2. 能不能用 headers[\"Content-Length\"] = len(urllib.parse.urlencode(params).encode('utf-8')) 计算请求长度？？？\n\n# Selenium\n\n----------------------------------------\n\n# Selenium Chrome 最新驱动下载地址\n\nChrome for Testing\n\n# Selenium 去掉爬虫标识（与之前不同）\n\noptions = webdriver.ChromeOptions()\noptions.add_argument(\"--disable-blink-features=AutomationControlled\")  # 将window.navigator.webdriver设置为false\nbrowser = webdriver.Chrome(options=options)\n\n\n#=============== 之前是这样，没好使？ =====================\noptions = webdriver.ChromeOptions()\n# selenium 不显示正在被测试软件控制\noptions.add_experimental_option('excludeSwitches', ['enable-automation'])\noptions.add_experimental_option('useAutomationExtension', False)\nbrowser = webdriver.Chrome(options=options)\n# 防止通过变量识别到 selenium\nbrowser.execute_cdp_cmd(\n    'Page.addScriptToEvaluateOnNewDocument',\n    {'source': 'Object.defineProperty(navigator, \"webdriver, {get: () => undefined})'}\n)\n\n\n# Selenium 设置请求头\n\nbrowser.execute_cdp_cmd(\"Network.enable\", {})\nbrowser.execute_cdp_cmd(\"Network.setExtraHTTPHeaders\", {\"headers\": {\"User-Agent\": \"browser1\"}})\n\n\n# Selenium 设置页面超时时间\n\n# 设置页面加载和js加载超时时间，超时立即报错，如下设置超时时间为x秒\nbrowser.set_page_load_timeout(10)\nbrowser.set_script_timeout(10)\n\n\n# Selenium 在 Linux（Centos7） 上使用\n\n# 1. 在普通用户没有问题\n# 2. 在 root 用户一直报错 selenium.common.exceptions.WebDriverException: Message: unknown error: DevToolsActivePort file doesn't exist\n#    1. headless 以下办法解决\noptions.add_argument('--no-sandbox')  # fix:DevToolsActivePort file doesn't exist\noptions.add_argument('--disable-gpu')  # fix:DevToolsActivePort file doesn't exist\noptions.add_argument('--disable-dev-shm-usage')  # fix:DevToolsActivePort file doesn't exist\noptions.add_argument('--remote-debugging-port=9222')  # fix:DevToolsActivePort file doesn't exist\n\n# 注：（卡一整天的问题）\n# 百度 linux 下 chrome 打开报错，有给出以下解决办法的。千万不要修改！！！要不 Selenium 执行报错！！！\n# 将`/usr/bin/google-chrome` 中 `exec -a \"$0\" \"$HERE/chrome\" \"$@\"` 修改为 `exec -a \"$0\" \"$HERE/chrome\" \"$@\" --user-data-dir --no-sandbox`\n\n\n# Selenium 获取请求头\n\n# pip install selenium-wire\n\nfrom seleniumwire import webdriver\n\ndriver = webdriver.Chrome()\ndriver.get('https://www.baidu.com')\nfor request in driver.requests:\n    print('请求headers：')\n    print(request.headers)\n    # print(request.response.headers)\n    break\ndriver.quit()\n\n\n# Selenium 获取Cookies\n\ndriver.get_cookies()\n\n\n# Selenium 获取 jQuery 中 localStorage\n\nlocalStorage：在HTML5中，新加入的一个l特性，这个特性主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题，localStorage中一般浏览器支持的是5M大小，这个在不同的浏览器中localStorage会有所不同\n\nlocal_storage = driver.execute_script(\"return window.localStorage;\")\n\n\n# 爬虫自测网站\n\n# 可以查看与正常访问相比有哪些参数不同，用于优化爬虫程序\nhttps://bot.sannysoft.com/\n\n\n# 爬虫梳理\n\n----------------------------------------\n\n 1.  Session 验证：\n     * 模拟登录后获取 Cookie 中，每次请求带上改 Cookie\n 2.  数据字母验证码： OCR 识别，后面请求每次带上验证码（有些需加密）\n 3.  IP封禁： 购买动态IP\n 4.  User-Agent验证：修改请求UA\n 5.  数据动态加载：\n     * 模拟接口请求，获取json数据\n     * Selenium 获取动态渲染后网站源码\n 6.  数据加密（理论上在网站都能找到key）\n     * base64 加密：无秘钥，直接解密\n     * 使用aes加密秘钥，再用ras加密正文\n 7.  Content-Length 验证：有些网站会验证请求头中的 Content-Length，要保证有且只有一个正确的长度\n 8.  通过 window.open('xxx'') 可获取跳转链接\n 9.  通过Referer的反扒爬虫\n 10. 针对 Selenium 的 find_element_by_* 方法的 click 事件监听\n\n * 第三方库：pyautogui 等\n\n分析思路\n\n> 使用浏览器 > 元素 > 事件监听器，排查执行的js 使用移动端链接 www -> m\n\n# 加密解密函数\n\n----------------------------------------\n\n# ras 解密\n\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Cipher import PKCS1_v1_5 as Cipher_pkcs1_v1_5\nimport base64\n\ndef rsa_decrypt(cipher_text, private_key):\n    decode_text = base64.b64decode(cipher_text)\n    cipher = Cipher_pkcs1_v1_5.new(RSA.importKey(private_key))  # 创建用于执行pkcs1_v1_5加密或解密的密码\n    decrypt_text = cipher.decrypt(decode_text, b\"rsa\")\n    return decrypt_text.decode(\"utf-8\")\n\n\n# aes 解密（AES-CTR 模式，其他类似）\n\nfrom Crypto.Cipher import AES\nfrom Crypto.Util import Counter\nimport base64\n\ndef decrypt_aes_ctr(encrypted_data, key, iv):\n   ciphertext = base64.b64decode(encrypted_data)\n    key = str.encode(key)\n    # 设置 AES-CTR 的计数器\n    ctr = Counter.new(128, initial_value=int.from_bytes(iv, byteorder='big'))\n    # 使用 AES-CTR 模式创建 AES 对象\n    aes = AES.new(key, AES.MODE_CTR, counter=ctr)\n    # 解密密文\n    decrypted_data = aes.decrypt(ciphertext)\n    # 将解密后的数据转换为文本\n    decrypted_text = decrypted_data.decode('utf-8')\n    return decrypted_text\n\n\n# aes 加密（AES-ECB 模式）\n\nfrom Crypto.Cipher import AES\n\ndef aes_encode(data, key):\n  global aes\n  while len(data) % 16 != 0:  # 补足字符串长度为16的倍数\n      data += (16 - len(data) % 16) * chr(16 - len(data) % 16)\n      data = str.encode(data)\n      aes = AES.new(str.encode(key), AES.MODE_ECB)  # 初始化加密器\n  return str(base64.encodebytes(aes.encrypt(data)), encoding='utf8').replace('\\n', '')  # 加密\n\n\n# 附：代码示例\n\n----------------------------------------\n\n# 爬虫代码\n\nfrom xxx.items import gpItems\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.http import Request\n\nimport logging\nimport base64\nfrom Crypto.Cipher import AES\n\nclass XXXSpider(CrawlSpider):\n\tname = 'XXX'\n\tallowed_domains = ['www.xxx.com']\n\n\t# key：数据接口地址   value：source type_code 一次爬取的页面数\n\tcategoryCodeDict = {\n\t\t'网址1{}': '描述1 ID1 1 3',  # 17页    15-31页\n\t\t'网址2{}': '描述2 ID2 1 6',  # 179页\n\t}\n\theaders = {\n\t}\n\n\tdef start_requests(self):\n\t\tfor key, value in self.categoryCodeDict.items():\n\t\t\tstart_page = int(value.split(' ')[2])\n\t\t\tpage = int(value.split(' ')[3])\n\t\t\tfor index in range(start_page, page):\n\t\t\t\turl = key.format(str(index))\n\t\t\t\tlogging.info('爬取总页数：{}  页面链接：{}'.format(page - 1, url))\n\t\t\t\tyield Request(url=url, headers=self.headers, method='POST', callback=self.parse, meta={'categoryCode': key, 'categoryText': value})\n\n\tdef parse(self, response):\n\t\tcategoryText1 = response.meta['categoryText'].split(' ')[0]\n\t\tcategoryText2 = response.meta['categoryText'].split(' ')[1]\n\n\t\trows = response.xpath('//ul[@class=\"article-list-a\"]/li')\n\t\tfor row in rows:\n\t\t\ti = gpItems()\n\t\t\ti['publishTime'] = row.xpath('div[1]/div[@class=\"list-times\"]/text()').extract_first().strip()\n\t\t\turl = row.xpath('div[1]/a/@href').extract_first().strip()\n\t\t\tccc = url.split('/')[-1].split('.')[0]\n\t\t\tddd = self.aes_encode(ccc, '公钥编码').replace('/', '^').replace(\"==\", \"\")\n\t\t\ti['url'] = url.replace(ccc, ddd)\n\t\t\ti['title'] = ''.join(row.xpath('div[1]/a/text()').extract()).strip()\n\t\t\tad_name = row.xpath('div[1]/a/label/text()').extract_first()\n\t\t\tif ad_name:\n\t\t\t\tad_name = ad_name.strip().replace('【', '').replace('】', '')\n\t\t\t\ti['ad_name'] = 'sss' if ad_name == 'bbb' else ad_name\n\t\t\telse:\n\t\t\t\ti['ad_name'] = 'xxx'\n\t\t\ti['source'] = categoryText1\n\t\t\ti['type_code'] = categoryText2\n\t\t\tyield Request(i['url'], headers=self.headers, meta={'item': i}, callback=self.parse_item)\n\n\tdef parse_item(self, response):\n\t\ti = response.meta['item']\n\t\ti['htmlcontent'] = response.xpath('//div[@class=\"class1111\"]').extract_first().strip()\n\t\treturn i\n\n\tdef aes_encode(self, data, key):\n\t\tglobal aes\n\t\twhile len(data) % 16 != 0:  # 补足字符串长度为16的倍数\n\t\t\tdata += (16 - len(data) % 16) * chr(16 - len(data) % 16)\n\t\t\tdata = str.encode(data)\n\t\t\taes = AES.new(str.encode(key), AES.MODE_ECB)  # 初始化加密器\n\t\treturn str(base64.encodebytes(aes.encrypt(data)), encoding='utf8').replace('\\n', '')  # 加密\n\n\n# 中间件使用动态代理IP测试\n\nclass AutotestDownloaderMiddleware(object):\n    delay_sec = [0.1, 0.2, 0.3, 0.4, 0.5]   # , 0.6, 0.7, 0.8, 0.9\n    proxy_ip_dict = {}\n    # 需要走代理的爬虫\n    spiders_list = ['XXX']\n\n    def spider_opened(self, spider):\n        # 初始化代理池\n        if spider.name in self.spiders_list:\n            while len(self.proxy_ip_dict) < 6:\n                time.sleep(5)\n                self.get_proxy()\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_request(self, request, spider):\n        if spider.name in self.spiders_list:\n            # time.sleep(random.choice(self.delay_sec))\n            proxy_ip = self.determine(int(time.time()*1000))\n            print('request.meta[\\'proxy\\'] = {proxy_ip}'.format(proxy_ip=proxy_ip))\n            print('proxy_ip_list：{}'.format(self.proxy_ip_dict))\n            request.meta['proxy'] = proxy_ip\n\n    def process_response(self, request, response, spider):\n        return response\n\n    def process_exception(self, request, exception, spider):\n        pass\n\n    def get_proxy(self, proxy_pop=''):\n        curtime = int(time.time()*1000)\n        api_url = '购买的动态IP接口'   # 返回值为 IP:PORT,可用时间(毫秒)\n        response = requests.get(api_url).text.strip()\n        proxy = 'http://' +response.split(',')[0]\n        mill = int(response.split(',')[1])\n        print('从api获取动态ip：{}'.format(response))\n        # self.proxy_ip_list.append((proxy, curtime + mill))\n        # 已经有,更新；没有,删除旧的,插入新的   proxy_pop为空字符串时初始化字典\n        if proxy_pop == '' or self.proxy_ip_dict.get(proxy) is not None:\n            pass\n        else:\n            print(\"==================删除ip======{}\".format(proxy_pop))\n            self.proxy_ip_dict.pop(proxy_pop)\n        self.proxy_ip_dict[proxy] = curtime + mill - 2000 # 2s预留时间差\n        # return (proxy, curtime + mill)\n        return proxy\n\n    def determine(self, curmill):\n        # 获取ip\n        item1 = random.choice(list(self.proxy_ip_dict.keys()))\n        print('可用时间：{}  当前时间：{}'.format(self.proxy_ip_dict[item1], curmill))\n        if self.proxy_ip_dict[item1] > curmill:\n            # 若可用，返回\n            # return tuple1[0]\n            return item1\n        else:\n            print(\"================== ip：{}  过期时间：{}  当前时间：{} ======\".format(item1, self.proxy_ip_dict[item1], int(time.time()*1000) ))\n            # 若不可用，从列表移除  重新获取\n            return self.get_proxy(item1)\n\n\n# 中间件使用Selenium发送请求 + 动态代理IP\n\nfrom selenium import webdriver\nfrom scrapy.downloadermiddlewares.retry import get_retry_request\nfrom scrapy.exceptions import IgnoreRequest\nimport pymysql\nfrom scrapy.utils.project import get_project_settings\nclass SeleniumDownloaderMiddleware(object):\n    # 需要走代理的爬虫\n    spiders_list = ['xxxx', 'xxxxxx']\n    proxy_ip_dict = {}  # key：代理ip  value：最大可用毫秒数 使用次数 错误次数（selenium中获取不到代理IP，故同一时间只能使用一个代理IP）\n    proxy = False    # 是否走代理\n    db = None\n    cursorSeq = None\n\n    def __init__(self):\n        self.browser = None\n\n    def spider_opened(self, spider):\n        if spider.name in self.spiders_list:\n            self.browser = self.create_chrome_driver()  # 创建浏览器对象\n            self.connect()  # 创建数据库连接\n            if self.proxy:\n                while len(self.proxy_ip_dict) == 0:   # 每次只有一个IP\n                    self.get_proxy()\n\n    def spider_closed(self, spider):\n        if spider.name in self.spiders_list:\n            if self.browser:   # 关闭浏览器连接\n                self.browser.close()\n            if self.cursorSeq or self.db:   # 关闭数据库连接\n                self.cursorSeq.close()\n                self.db.close()\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        # 绑定 spider_closed 信号的处理方法\n        crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)\n        return s\n\n    def process_request(self, request, spider):\n        if spider.name in self.spiders_list:\n            # 库中存在就不访问\n            if self.should_filter(request):\n                # 如果需要过滤，则抛出 IgnoreRequest 异常\n                raise IgnoreRequest(\"Filtered request: {}\".format(request))\n            if self.proxy:\n                self.preparatory_work(int(time.time()*1000))\n            self.browser.get(request.url)\n            # time.sleep(random.uniform(0.1, 0.5))\n            print(\"=\" * 100)\n            print(\"#########{}\".format(self.browser.current_url))\n            if len(self.browser.page_source) < 200:  # 空请求体或IP超过最大请求量\n                # <html lang=\"zh-CN\"><head><meta charset=\"UTF-8\"><title>too many request</title></head><body>IP超过最大请求量，详情参考<a href=\"http://www.data5u.com/help/article-54.html\">www.data5u.com</a></body></html>\n                # <html><head></head><body></body></html>\n                print(\"================= Empty response: {url} =============================\".format(url=self.browser.current_url))\n                print(self.browser.page_source)\n                raise ValueError('Empty response')\n            return HtmlResponse(url=request.url, body=self.browser.page_source, encoding=\"utf-8\",\n                                request=request)  # 然后把这个response对象返回给爬虫  self.browser.current_url\n\n    def process_response(self, request, response, spider):\n        if spider.name in self.spiders_list:\n            print(\"====================== process_response ====================================\")\n            print(response.status)\n            if self.proxy:\n                # 使用 next() 函数获取第一个键值对\n                first_key, first_value = next(iter(self.proxy_ip_dict.items()))\n                item_info = self.proxy_ip_dict[first_key].split(' ')\n                item_info[1] = str(int(item_info[1]) + 1)  # 使用次数+1\n                if response.status != 200:\n                    item_info[2] = str(int(item_info[2]) + 1)  # 错误次数+1\n                self.proxy_ip_dict[first_key] = ' '.join(item_info)\n        # 则返回原始的响应对象\n        return response\n\n    def process_exception(self, request, exception, spider):\n        if spider.name in self.spiders_list:\n            print(\"====================== process_exception ====================================\")\n            print(request.url)\n            print(exception)\n            if isinstance(exception, IgnoreRequest):\n                # 处理 IgnoreRequest 异常，例如记录日志、发送通知等\n                # 返回 None 表示异常已经被处理\n                return None\n            if self.proxy:\n                # 使用 next() 函数获取第一个键值对\n                first_key, first_value = next(iter(self.proxy_ip_dict.items()))\n                item_info = self.proxy_ip_dict[first_key].split(' ')\n                item_info[1] = str(int(item_info[1]) + 1)  # 使用次数+1\n                item_info[2] = str(int(item_info[2]) + 1)  # 错误次数+1\n                self.proxy_ip_dict[first_key] = ' '.join(item_info)\n            request.meta['dont_filter'] = True    # 可以不加，retry函数中会修改\n            request.meta['max_retry_times'] = 4   # 增加重试次数\n            return get_retry_request(request=request, spider=spider, reason='process_exception')\n        pass\n\n    #=========================================== 自定义函数 =====================================\n\n    def should_filter(self, request):\n        # 在这里编写过滤逻辑，根据请求的某些特征来判断是否需要过滤该请求\n        sqlexists = \"select count(1) from crawler_t_src_spider a where a.url= '\"+request.url+\"'\"\n        self.cursorSeq.execute(sqlexists)\n        num1 = self.cursorSeq.fetchone()\n        num = num1[0]\n        # 返回 True 表示需要过滤，返回 False 表示不需要过滤\n        if num == 0:\n            return False  # 示例中默认不过滤任何请求\n        else:\n            print(\"======================= 过滤请求 =={}=============================\".format(request.url))\n            return True\n\n    def connect(self):\n        settings = get_project_settings()\n        self.db = pymysql.connect(\n            host=settings['DB_HOST'],\n            port=settings['DB_PORT'],\n            user=settings['DB_USER'],\n            password=settings['DB_PASSWROD'],\n            db=settings['DB_NAME'],\n            charset=settings['DB_CHARSET']\n        )\n        self.cursorSeq = self.db.cursor()\n\n    def create_chrome_driver(self, headless=False, proxy_ip=None):\n        options = webdriver.ChromeOptions()\n        if headless:\n            options.add_argument('--headless')\n            options.add_argument('--no-sandbox')  # fix:DevToolsActivePort file doesn't exist\n            options.add_argument('--disable-gpu')  # fix:DevToolsActivePort file doesn't exist\n            options.add_argument('--disable-dev-shm-usage')  # fix:DevToolsActivePort file doesn't exist\n            options.add_argument('--remote-debugging-port=9222')  # fix:DevToolsActivePort file doesn't exist\n            # headless 模式请求头与正常不一致，需修改请求头\n            options.add_argument(f'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36')\n        else:\n            options.add_argument(\"--start-maximized\")\n        if proxy_ip: options.add_argument('--proxy-server={}'.format(proxy_ip))\n\n        options.add_argument(\"--disable-blink-features=AutomationControlled\")  # 将window.navigator.webdriver设置为false\n        options.add_experimental_option(\"prefs\", {\"profile.mamaged_default_content_settings.images\": 2})  # 不加载图片,加快访问速度\n        # selenium 不显示正在被测试软件控制\n        options.add_experimental_option('excludeSwitches', ['enable-automation'])\n        options.add_experimental_option('useAutomationExtension', False)\n        browser = webdriver.Chrome(options=options)\n        # 防止通过变量识别到 selenium\n        browser.execute_cdp_cmd(\n            'Page.addScriptToEvaluateOnNewDocument',\n            {'source': 'Object.defineProperty(navigator, \"webdriver, {get: () => undefined})'}\n        )\n\n        # browser.execute_cdp_cmd(\"Network.enable\", {})\n        # browser.execute_cdp_cmd(\"Network.setExtraHTTPHeaders\", {\"headers\": {\"User-Agent\": \"browser1\"}})\n\n        # 设置页面加载和js加载超时时间，超时立即报错，如下设置超时时间为x秒\n        browser.set_page_load_timeout(10)\n        browser.set_script_timeout(10)\n        time.sleep(2)\n        print(\"=========== 创建浏览器对象，代理IP为{} ================\".format(proxy_ip))\n        return browser\n\n    def get_proxy(self, proxy_pop=''):\n        api_url = '代理商API接口'\n        curtime, proxy, mill = None, None, None\n        for i in range(3):\n            if i > 0: time.sleep(3)\n            curtime = int(time.time()*1000)\n            response = requests.get(api_url).text.strip()\n            proxy = 'http://' + response.split(',')[0]\n            mill = int(response.split(',')[1])\n            if self.proxy_ip_dict.get(proxy) is None: break   # 获取到新的，跳出循环\n        # proxy_pop为空字符串时初始化字典\n        if proxy_pop == '':\n            self.proxy_ip_dict[proxy] = '{} 0 0'.format(curtime + mill)\n            if self.browser:\n                self.browser.close()\n            self.browser = self.create_chrome_driver(proxy_ip=proxy)\n        # IP已经存在,跳过\n        elif self.proxy_ip_dict.get(proxy) is not None:\n            pass\n        # 删除旧的,插入新的\n        else:\n            print(\"==================删除ip======{}\".format(proxy_pop))\n            self.proxy_ip_dict.pop(proxy_pop)\n            self.proxy_ip_dict[proxy] = '{} 0 0'.format(curtime + mill)\n            if self.browser:\n                self.browser.close()\n            self.browser = self.create_chrome_driver(proxy_ip=proxy)\n        return proxy\n\n    def preparatory_work(self, curmill):\n        proxy_ip = random.choice(list(self.proxy_ip_dict.keys()))\n        item_info = self.proxy_ip_dict[proxy_ip].split(' ')\n        print('可用时间（使用次数、错误次数）：{}  当前时间：{}'.format(self.proxy_ip_dict[proxy_ip], curmill))\n        if int(item_info[0]) > curmill and int(item_info[2]) == 0:  # and int(item_info[1]) < 10\n            return proxy_ip  # 若可用，返回\n        else:\n            print(\"================== ip：{}  过期时间：{}  当前时间：{} ======\".format(proxy_ip, item_info[0], int(time.time()*1000)))\n            return self.get_proxy(proxy_ip)   # 若不可用，从列表移除  重新获取\n",normalizedContent:"# 琐碎代码\n\n----------------------------------------\n\n# url 编码解码\n\n# url 编码\nurllib.parse.quote()\n# url 解码\nurllib.parse.unquote()\n\n\n# 日期格式化\n\n特殊字符串转日期\n\n# pip install python-dateutil\nimport datetime\nfrom dateutil import parser\n\ntime_string = \"fri jan 05 15:41:17 gmt+08:00 2024\"\ndt_object = parser.parse(time_string)\nprint(dt_object.strftime(\"%y-%m-%d %h:%m:%s\"))\n# 转换为 utc 时间\nprint(dt_object.astimezone(tz=datetime.timezone.utc))\n# 或者如果你想转换到本地时区（假设你的系统配置了正确的本地时区）\nprint(dt_object.astimezone())\n\n\n日期转带时区的字符串\n\nfrom datetime import datetime, timezone\nimport pytz\n\n# 获取当前时间（假设我们使用utc时区作为示例，实际中你可能需要根据你的位置获取正确的时区）\nnow_utc = datetime.now(timezone.utc)\n\n# 将utc时间转换为北京时间（gmt+08:00）\n# 注意：这里我们使用了pytz库来获取北京时间的时区对象\nbeijing_tz = pytz.timezone('asia/shanghai')\nnow_beijing = now_utc.astimezone(beijing_tz)\n\n# 格式化时间，但注意strftime()不支持直接添加时区名称，所以我们手动添加\n# '%a' - 星期几的全名\n# '%b' - 月份的简写名\n# '%d' - 月中的一天（01至31）\n# '%y' - 年份\n# '%h:%m:%s' - 时:分:秒\n# 然后我们手动添加 'gmt+0800 (中国标准时间)'\nformatted_time = now_beijing.strftime(\"%a %b %d %y %h:%m:%s\") + \" gmt+0800 (中国标准时间)\"\n\nprint(\"当前时间（格式化后）:\", formatted_time)\n\n\n# json 转字符串乱码解决\n\n# 确保输出的结果中不包含非ascii字符\njson.dumps(response[\"result\"], ensure_ascii=false)\n\n\n# 使用 lxml 解析数据\n\ndata=\"\"\"\n<datastore>\n<recordset>\n<record><![cdata[\n<div class=\"fyxx_lsbox\">\t<div class=\"btqz\"></div>\t<div class=\"fyxx_lsbox_r\">\t\t<a title=\"xxxxxxxxxxxxxxxxxxxxxx\" target=\"_blank\" href=\"/art/2024/1/12/art_1229682709_457018.html\">xxxxxxxxxxxxxxxxxxxxxx</a> <span>2024-01-12</span> </div></div>]]></record>\n</recordset>\n</datastore>\n\"\"\"\n\n# 方法一：工具直接解析（上述数据不太符合，但写法应如此）\nfrom xml.etree import elementtree as et\nroot = et.fromstring(data)\nfor element in root.iter():\n   # 简单地访问.text属性，因为在大多数情况下解析器已经处理好cdata了\n   if element.text:\n      print(element.text)\n\n# 方法二：字符串混合xpath处理\ndatastore = etree.html(data)\nfor row in datastore.xpath('//record'):\n   record = etree.tostring(row).replace(r'<record>', '').replace(r']]&gt;</record>', '')\n   record1 = etree.html(record)\n   print etree.tostring(record1)\n\"\"\"\n\n\n# requests\n\n----------------------------------------\n\n# requests 库请求结果显示中文\n\n# 设置编码\nresponse.encoding='utf-8'\nprint(response.text)\n\n\n# requests 库携带文件对象参数\n\nresponse = requests.post(\n    url='http://xxx/captcha-ocr-yn/captcha',\n    files={'captcha': open(img_path, 'rb')},\n    data={'question': '请依次点击【工,确,海】'}\n)\n\n\n# scrapy\n\n----------------------------------------\n\n# 程序中主动退出爬虫\n\n# scrapy框架中手动退出爬虫程序\nself.crawler.engine.close_spider(self, '验证码尝试三次不正确，退出爬虫')\n\n\n# 代码中执行单个爬虫\n\nfrom scrapy import cmdline\ncmdline.execute(\"scrapy crawl xxx -o ./data/xxx.csv -s log_file=./logs/xxx.log\".split())\n\n\n# 命令行中传参\n\n传入参数\n\ncmdline.execute(\"scrapy crawl jianyusearch -a searchword=xxx -a page=10\".split())\n\n\n爬虫中接收参数（spider中增加）\n\ndef __init__(self, searchword='', page=1,*args, **kwargs):\n  super(xxxspider, self).__init__(*args, **kwargs)\n  self.searchword = searchword\n  self.page = page\n\n\n# 两个请求见传递参数\n\n# 第一个请求携带参数\nyield request(url=url, callback=self.parse, meta={\"para1\": xxx})\n\n# parse 回调函数中获取参数\nresponse.meta['url']\n\n\n# 发送请求并获取请求头中的cookie\n\nresponse = requests.get(url, headers=headers)\nself.cookies = requests.utils.dict_from_cookiejar(response.cookies)\n\n\n# pipeline 存储 item 数据到 excel\n\nclass spidernamepipeline(object):\n    def open_spider(self,spider):\n        if spider.name in ['spidername']:\n            self.field_list = [field_name for field_name, field_meta in spidernameitems.fields.items()]\n            self.wb = openpyxl.workbook()\n            self.ws = self.wb.active\n            self.ws.append(self.field_list)\n\n    def close_spider(self,spider):\n        if spider.name in ['spidername']:\n            self.wb.save(\"test.xlsx\")\n\n    def process_item(self, item, spider):\n        if spider.name in ['spidername']:\n            self.ws.append([item.get(field_name) for field_name in self.field_list])\n            return item\n\n\n# 中间件 from_crawler 方法中各个阶段执行前绑定函数\n\n@classmethod\ndef from_crawler(cls, crawler):\n    # this method is used by scrapy to create your spiders.\n    s = cls()\n    crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n    # 绑定 spider_closed 信号的处理方法\n    crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)\n    return s\n\n\n# 中间件（或spider）中重新发送请求\n\nfrom scrapy.downloadermiddlewares.retry import get_retry_request\n\nreturn get_retry_request(request=request, spider=spider, reason='xxx')   # spider = self\n\n\n# 中间件中处理异常\n\n# 抛出异常\nraise ignorerequest(\"filtered request: {}\".format(request))\nraise valueerror('403 response')\n\n# 处理异常\ndef process_exception(self, request, exception, spider):\n    if isinstance(exception, ignorerequest):\n        # 处理 ignorerequest 异常，例如记录日志、发送通知等\n        # 返回 none 表示异常已经被处理\n        return none\n    else:\n        # 重发请求\n        request.meta['dont_filter'] = true\n        request.meta['max_retry_times'] = 4   # 增加重试次数\n        return get_retry_request(request=request, spider=spider, reason='process_exception')\n\n\n# error：使用rquests发请求可以，但是使用scrapy不行\n\n 1. 网站有请求头 content-length 的校验：scrapy如果在header写死，发请求时会再增加一个 content-length（而不是替换原来的，request应该是直接替换原来的），导致请求异常（400 bad request）。\n 2. 能不能用 headers[\"content-length\"] = len(urllib.parse.urlencode(params).encode('utf-8')) 计算请求长度？？？\n\n# selenium\n\n----------------------------------------\n\n# selenium chrome 最新驱动下载地址\n\nchrome for testing\n\n# selenium 去掉爬虫标识（与之前不同）\n\noptions = webdriver.chromeoptions()\noptions.add_argument(\"--disable-blink-features=automationcontrolled\")  # 将window.navigator.webdriver设置为false\nbrowser = webdriver.chrome(options=options)\n\n\n#=============== 之前是这样，没好使？ =====================\noptions = webdriver.chromeoptions()\n# selenium 不显示正在被测试软件控制\noptions.add_experimental_option('excludeswitches', ['enable-automation'])\noptions.add_experimental_option('useautomationextension', false)\nbrowser = webdriver.chrome(options=options)\n# 防止通过变量识别到 selenium\nbrowser.execute_cdp_cmd(\n    'page.addscripttoevaluateonnewdocument',\n    {'source': 'object.defineproperty(navigator, \"webdriver, {get: () => undefined})'}\n)\n\n\n# selenium 设置请求头\n\nbrowser.execute_cdp_cmd(\"network.enable\", {})\nbrowser.execute_cdp_cmd(\"network.setextrahttpheaders\", {\"headers\": {\"user-agent\": \"browser1\"}})\n\n\n# selenium 设置页面超时时间\n\n# 设置页面加载和js加载超时时间，超时立即报错，如下设置超时时间为x秒\nbrowser.set_page_load_timeout(10)\nbrowser.set_script_timeout(10)\n\n\n# selenium 在 linux（centos7） 上使用\n\n# 1. 在普通用户没有问题\n# 2. 在 root 用户一直报错 selenium.common.exceptions.webdriverexception: message: unknown error: devtoolsactiveport file doesn't exist\n#    1. headless 以下办法解决\noptions.add_argument('--no-sandbox')  # fix:devtoolsactiveport file doesn't exist\noptions.add_argument('--disable-gpu')  # fix:devtoolsactiveport file doesn't exist\noptions.add_argument('--disable-dev-shm-usage')  # fix:devtoolsactiveport file doesn't exist\noptions.add_argument('--remote-debugging-port=9222')  # fix:devtoolsactiveport file doesn't exist\n\n# 注：（卡一整天的问题）\n# 百度 linux 下 chrome 打开报错，有给出以下解决办法的。千万不要修改！！！要不 selenium 执行报错！！！\n# 将`/usr/bin/google-chrome` 中 `exec -a \"$0\" \"$here/chrome\" \"$@\"` 修改为 `exec -a \"$0\" \"$here/chrome\" \"$@\" --user-data-dir --no-sandbox`\n\n\n# selenium 获取请求头\n\n# pip install selenium-wire\n\nfrom seleniumwire import webdriver\n\ndriver = webdriver.chrome()\ndriver.get('https://www.baidu.com')\nfor request in driver.requests:\n    print('请求headers：')\n    print(request.headers)\n    # print(request.response.headers)\n    break\ndriver.quit()\n\n\n# selenium 获取cookies\n\ndriver.get_cookies()\n\n\n# selenium 获取 jquery 中 localstorage\n\nlocalstorage：在html5中，新加入的一个l特性，这个特性主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题，localstorage中一般浏览器支持的是5m大小，这个在不同的浏览器中localstorage会有所不同\n\nlocal_storage = driver.execute_script(\"return window.localstorage;\")\n\n\n# 爬虫自测网站\n\n# 可以查看与正常访问相比有哪些参数不同，用于优化爬虫程序\nhttps://bot.sannysoft.com/\n\n\n# 爬虫梳理\n\n----------------------------------------\n\n 1.  session 验证：\n     * 模拟登录后获取 cookie 中，每次请求带上改 cookie\n 2.  数据字母验证码： ocr 识别，后面请求每次带上验证码（有些需加密）\n 3.  ip封禁： 购买动态ip\n 4.  user-agent验证：修改请求ua\n 5.  数据动态加载：\n     * 模拟接口请求，获取json数据\n     * selenium 获取动态渲染后网站源码\n 6.  数据加密（理论上在网站都能找到key）\n     * base64 加密：无秘钥，直接解密\n     * 使用aes加密秘钥，再用ras加密正文\n 7.  content-length 验证：有些网站会验证请求头中的 content-length，要保证有且只有一个正确的长度\n 8.  通过 window.open('xxx'') 可获取跳转链接\n 9.  通过referer的反扒爬虫\n 10. 针对 selenium 的 find_element_by_* 方法的 click 事件监听\n\n * 第三方库：pyautogui 等\n\n分析思路\n\n> 使用浏览器 > 元素 > 事件监听器，排查执行的js 使用移动端链接 www -> m\n\n# 加密解密函数\n\n----------------------------------------\n\n# ras 解密\n\nfrom crypto.publickey import rsa\nfrom crypto.cipher import pkcs1_v1_5 as cipher_pkcs1_v1_5\nimport base64\n\ndef rsa_decrypt(cipher_text, private_key):\n    decode_text = base64.b64decode(cipher_text)\n    cipher = cipher_pkcs1_v1_5.new(rsa.importkey(private_key))  # 创建用于执行pkcs1_v1_5加密或解密的密码\n    decrypt_text = cipher.decrypt(decode_text, b\"rsa\")\n    return decrypt_text.decode(\"utf-8\")\n\n\n# aes 解密（aes-ctr 模式，其他类似）\n\nfrom crypto.cipher import aes\nfrom crypto.util import counter\nimport base64\n\ndef decrypt_aes_ctr(encrypted_data, key, iv):\n   ciphertext = base64.b64decode(encrypted_data)\n    key = str.encode(key)\n    # 设置 aes-ctr 的计数器\n    ctr = counter.new(128, initial_value=int.from_bytes(iv, byteorder='big'))\n    # 使用 aes-ctr 模式创建 aes 对象\n    aes = aes.new(key, aes.mode_ctr, counter=ctr)\n    # 解密密文\n    decrypted_data = aes.decrypt(ciphertext)\n    # 将解密后的数据转换为文本\n    decrypted_text = decrypted_data.decode('utf-8')\n    return decrypted_text\n\n\n# aes 加密（aes-ecb 模式）\n\nfrom crypto.cipher import aes\n\ndef aes_encode(data, key):\n  global aes\n  while len(data) % 16 != 0:  # 补足字符串长度为16的倍数\n      data += (16 - len(data) % 16) * chr(16 - len(data) % 16)\n      data = str.encode(data)\n      aes = aes.new(str.encode(key), aes.mode_ecb)  # 初始化加密器\n  return str(base64.encodebytes(aes.encrypt(data)), encoding='utf8').replace('\\n', '')  # 加密\n\n\n# 附：代码示例\n\n----------------------------------------\n\n# 爬虫代码\n\nfrom xxx.items import gpitems\nfrom scrapy.spiders import crawlspider, rule\nfrom scrapy.http import request\n\nimport logging\nimport base64\nfrom crypto.cipher import aes\n\nclass xxxspider(crawlspider):\n\tname = 'xxx'\n\tallowed_domains = ['www.xxx.com']\n\n\t# key：数据接口地址   value：source type_code 一次爬取的页面数\n\tcategorycodedict = {\n\t\t'网址1{}': '描述1 id1 1 3',  # 17页    15-31页\n\t\t'网址2{}': '描述2 id2 1 6',  # 179页\n\t}\n\theaders = {\n\t}\n\n\tdef start_requests(self):\n\t\tfor key, value in self.categorycodedict.items():\n\t\t\tstart_page = int(value.split(' ')[2])\n\t\t\tpage = int(value.split(' ')[3])\n\t\t\tfor index in range(start_page, page):\n\t\t\t\turl = key.format(str(index))\n\t\t\t\tlogging.info('爬取总页数：{}  页面链接：{}'.format(page - 1, url))\n\t\t\t\tyield request(url=url, headers=self.headers, method='post', callback=self.parse, meta={'categorycode': key, 'categorytext': value})\n\n\tdef parse(self, response):\n\t\tcategorytext1 = response.meta['categorytext'].split(' ')[0]\n\t\tcategorytext2 = response.meta['categorytext'].split(' ')[1]\n\n\t\trows = response.xpath('//ul[@class=\"article-list-a\"]/li')\n\t\tfor row in rows:\n\t\t\ti = gpitems()\n\t\t\ti['publishtime'] = row.xpath('div[1]/div[@class=\"list-times\"]/text()').extract_first().strip()\n\t\t\turl = row.xpath('div[1]/a/@href').extract_first().strip()\n\t\t\tccc = url.split('/')[-1].split('.')[0]\n\t\t\tddd = self.aes_encode(ccc, '公钥编码').replace('/', '^').replace(\"==\", \"\")\n\t\t\ti['url'] = url.replace(ccc, ddd)\n\t\t\ti['title'] = ''.join(row.xpath('div[1]/a/text()').extract()).strip()\n\t\t\tad_name = row.xpath('div[1]/a/label/text()').extract_first()\n\t\t\tif ad_name:\n\t\t\t\tad_name = ad_name.strip().replace('【', '').replace('】', '')\n\t\t\t\ti['ad_name'] = 'sss' if ad_name == 'bbb' else ad_name\n\t\t\telse:\n\t\t\t\ti['ad_name'] = 'xxx'\n\t\t\ti['source'] = categorytext1\n\t\t\ti['type_code'] = categorytext2\n\t\t\tyield request(i['url'], headers=self.headers, meta={'item': i}, callback=self.parse_item)\n\n\tdef parse_item(self, response):\n\t\ti = response.meta['item']\n\t\ti['htmlcontent'] = response.xpath('//div[@class=\"class1111\"]').extract_first().strip()\n\t\treturn i\n\n\tdef aes_encode(self, data, key):\n\t\tglobal aes\n\t\twhile len(data) % 16 != 0:  # 补足字符串长度为16的倍数\n\t\t\tdata += (16 - len(data) % 16) * chr(16 - len(data) % 16)\n\t\t\tdata = str.encode(data)\n\t\t\taes = aes.new(str.encode(key), aes.mode_ecb)  # 初始化加密器\n\t\treturn str(base64.encodebytes(aes.encrypt(data)), encoding='utf8').replace('\\n', '')  # 加密\n\n\n# 中间件使用动态代理ip测试\n\nclass autotestdownloadermiddleware(object):\n    delay_sec = [0.1, 0.2, 0.3, 0.4, 0.5]   # , 0.6, 0.7, 0.8, 0.9\n    proxy_ip_dict = {}\n    # 需要走代理的爬虫\n    spiders_list = ['xxx']\n\n    def spider_opened(self, spider):\n        # 初始化代理池\n        if spider.name in self.spiders_list:\n            while len(self.proxy_ip_dict) < 6:\n                time.sleep(5)\n                self.get_proxy()\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # this method is used by scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s\n\n    def process_request(self, request, spider):\n        if spider.name in self.spiders_list:\n            # time.sleep(random.choice(self.delay_sec))\n            proxy_ip = self.determine(int(time.time()*1000))\n            print('request.meta[\\'proxy\\'] = {proxy_ip}'.format(proxy_ip=proxy_ip))\n            print('proxy_ip_list：{}'.format(self.proxy_ip_dict))\n            request.meta['proxy'] = proxy_ip\n\n    def process_response(self, request, response, spider):\n        return response\n\n    def process_exception(self, request, exception, spider):\n        pass\n\n    def get_proxy(self, proxy_pop=''):\n        curtime = int(time.time()*1000)\n        api_url = '购买的动态ip接口'   # 返回值为 ip:port,可用时间(毫秒)\n        response = requests.get(api_url).text.strip()\n        proxy = 'http://' +response.split(',')[0]\n        mill = int(response.split(',')[1])\n        print('从api获取动态ip：{}'.format(response))\n        # self.proxy_ip_list.append((proxy, curtime + mill))\n        # 已经有,更新；没有,删除旧的,插入新的   proxy_pop为空字符串时初始化字典\n        if proxy_pop == '' or self.proxy_ip_dict.get(proxy) is not none:\n            pass\n        else:\n            print(\"==================删除ip======{}\".format(proxy_pop))\n            self.proxy_ip_dict.pop(proxy_pop)\n        self.proxy_ip_dict[proxy] = curtime + mill - 2000 # 2s预留时间差\n        # return (proxy, curtime + mill)\n        return proxy\n\n    def determine(self, curmill):\n        # 获取ip\n        item1 = random.choice(list(self.proxy_ip_dict.keys()))\n        print('可用时间：{}  当前时间：{}'.format(self.proxy_ip_dict[item1], curmill))\n        if self.proxy_ip_dict[item1] > curmill:\n            # 若可用，返回\n            # return tuple1[0]\n            return item1\n        else:\n            print(\"================== ip：{}  过期时间：{}  当前时间：{} ======\".format(item1, self.proxy_ip_dict[item1], int(time.time()*1000) ))\n            # 若不可用，从列表移除  重新获取\n            return self.get_proxy(item1)\n\n\n# 中间件使用selenium发送请求 + 动态代理ip\n\nfrom selenium import webdriver\nfrom scrapy.downloadermiddlewares.retry import get_retry_request\nfrom scrapy.exceptions import ignorerequest\nimport pymysql\nfrom scrapy.utils.project import get_project_settings\nclass seleniumdownloadermiddleware(object):\n    # 需要走代理的爬虫\n    spiders_list = ['xxxx', 'xxxxxx']\n    proxy_ip_dict = {}  # key：代理ip  value：最大可用毫秒数 使用次数 错误次数（selenium中获取不到代理ip，故同一时间只能使用一个代理ip）\n    proxy = false    # 是否走代理\n    db = none\n    cursorseq = none\n\n    def __init__(self):\n        self.browser = none\n\n    def spider_opened(self, spider):\n        if spider.name in self.spiders_list:\n            self.browser = self.create_chrome_driver()  # 创建浏览器对象\n            self.connect()  # 创建数据库连接\n            if self.proxy:\n                while len(self.proxy_ip_dict) == 0:   # 每次只有一个ip\n                    self.get_proxy()\n\n    def spider_closed(self, spider):\n        if spider.name in self.spiders_list:\n            if self.browser:   # 关闭浏览器连接\n                self.browser.close()\n            if self.cursorseq or self.db:   # 关闭数据库连接\n                self.cursorseq.close()\n                self.db.close()\n\n    @classmethod\n    def from_crawler(cls, crawler):\n        # this method is used by scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        # 绑定 spider_closed 信号的处理方法\n        crawler.signals.connect(s.spider_closed, signal=signals.spider_closed)\n        return s\n\n    def process_request(self, request, spider):\n        if spider.name in self.spiders_list:\n            # 库中存在就不访问\n            if self.should_filter(request):\n                # 如果需要过滤，则抛出 ignorerequest 异常\n                raise ignorerequest(\"filtered request: {}\".format(request))\n            if self.proxy:\n                self.preparatory_work(int(time.time()*1000))\n            self.browser.get(request.url)\n            # time.sleep(random.uniform(0.1, 0.5))\n            print(\"=\" * 100)\n            print(\"#########{}\".format(self.browser.current_url))\n            if len(self.browser.page_source) < 200:  # 空请求体或ip超过最大请求量\n                # <html lang=\"zh-cn\"><head><meta charset=\"utf-8\"><title>too many request</title></head><body>ip超过最大请求量，详情参考<a href=\"http://www.data5u.com/help/article-54.html\">www.data5u.com</a></body></html>\n                # <html><head></head><body></body></html>\n                print(\"================= empty response: {url} =============================\".format(url=self.browser.current_url))\n                print(self.browser.page_source)\n                raise valueerror('empty response')\n            return htmlresponse(url=request.url, body=self.browser.page_source, encoding=\"utf-8\",\n                                request=request)  # 然后把这个response对象返回给爬虫  self.browser.current_url\n\n    def process_response(self, request, response, spider):\n        if spider.name in self.spiders_list:\n            print(\"====================== process_response ====================================\")\n            print(response.status)\n            if self.proxy:\n                # 使用 next() 函数获取第一个键值对\n                first_key, first_value = next(iter(self.proxy_ip_dict.items()))\n                item_info = self.proxy_ip_dict[first_key].split(' ')\n                item_info[1] = str(int(item_info[1]) + 1)  # 使用次数+1\n                if response.status != 200:\n                    item_info[2] = str(int(item_info[2]) + 1)  # 错误次数+1\n                self.proxy_ip_dict[first_key] = ' '.join(item_info)\n        # 则返回原始的响应对象\n        return response\n\n    def process_exception(self, request, exception, spider):\n        if spider.name in self.spiders_list:\n            print(\"====================== process_exception ====================================\")\n            print(request.url)\n            print(exception)\n            if isinstance(exception, ignorerequest):\n                # 处理 ignorerequest 异常，例如记录日志、发送通知等\n                # 返回 none 表示异常已经被处理\n                return none\n            if self.proxy:\n                # 使用 next() 函数获取第一个键值对\n                first_key, first_value = next(iter(self.proxy_ip_dict.items()))\n                item_info = self.proxy_ip_dict[first_key].split(' ')\n                item_info[1] = str(int(item_info[1]) + 1)  # 使用次数+1\n                item_info[2] = str(int(item_info[2]) + 1)  # 错误次数+1\n                self.proxy_ip_dict[first_key] = ' '.join(item_info)\n            request.meta['dont_filter'] = true    # 可以不加，retry函数中会修改\n            request.meta['max_retry_times'] = 4   # 增加重试次数\n            return get_retry_request(request=request, spider=spider, reason='process_exception')\n        pass\n\n    #=========================================== 自定义函数 =====================================\n\n    def should_filter(self, request):\n        # 在这里编写过滤逻辑，根据请求的某些特征来判断是否需要过滤该请求\n        sqlexists = \"select count(1) from crawler_t_src_spider a where a.url= '\"+request.url+\"'\"\n        self.cursorseq.execute(sqlexists)\n        num1 = self.cursorseq.fetchone()\n        num = num1[0]\n        # 返回 true 表示需要过滤，返回 false 表示不需要过滤\n        if num == 0:\n            return false  # 示例中默认不过滤任何请求\n        else:\n            print(\"======================= 过滤请求 =={}=============================\".format(request.url))\n            return true\n\n    def connect(self):\n        settings = get_project_settings()\n        self.db = pymysql.connect(\n            host=settings['db_host'],\n            port=settings['db_port'],\n            user=settings['db_user'],\n            password=settings['db_passwrod'],\n            db=settings['db_name'],\n            charset=settings['db_charset']\n        )\n        self.cursorseq = self.db.cursor()\n\n    def create_chrome_driver(self, headless=false, proxy_ip=none):\n        options = webdriver.chromeoptions()\n        if headless:\n            options.add_argument('--headless')\n            options.add_argument('--no-sandbox')  # fix:devtoolsactiveport file doesn't exist\n            options.add_argument('--disable-gpu')  # fix:devtoolsactiveport file doesn't exist\n            options.add_argument('--disable-dev-shm-usage')  # fix:devtoolsactiveport file doesn't exist\n            options.add_argument('--remote-debugging-port=9222')  # fix:devtoolsactiveport file doesn't exist\n            # headless 模式请求头与正常不一致，需修改请求头\n            options.add_argument(f'user-agent=mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36 (khtml, like gecko) chrome/79.0.3945.79 safari/537.36')\n        else:\n            options.add_argument(\"--start-maximized\")\n        if proxy_ip: options.add_argument('--proxy-server={}'.format(proxy_ip))\n\n        options.add_argument(\"--disable-blink-features=automationcontrolled\")  # 将window.navigator.webdriver设置为false\n        options.add_experimental_option(\"prefs\", {\"profile.mamaged_default_content_settings.images\": 2})  # 不加载图片,加快访问速度\n        # selenium 不显示正在被测试软件控制\n        options.add_experimental_option('excludeswitches', ['enable-automation'])\n        options.add_experimental_option('useautomationextension', false)\n        browser = webdriver.chrome(options=options)\n        # 防止通过变量识别到 selenium\n        browser.execute_cdp_cmd(\n            'page.addscripttoevaluateonnewdocument',\n            {'source': 'object.defineproperty(navigator, \"webdriver, {get: () => undefined})'}\n        )\n\n        # browser.execute_cdp_cmd(\"network.enable\", {})\n        # browser.execute_cdp_cmd(\"network.setextrahttpheaders\", {\"headers\": {\"user-agent\": \"browser1\"}})\n\n        # 设置页面加载和js加载超时时间，超时立即报错，如下设置超时时间为x秒\n        browser.set_page_load_timeout(10)\n        browser.set_script_timeout(10)\n        time.sleep(2)\n        print(\"=========== 创建浏览器对象，代理ip为{} ================\".format(proxy_ip))\n        return browser\n\n    def get_proxy(self, proxy_pop=''):\n        api_url = '代理商api接口'\n        curtime, proxy, mill = none, none, none\n        for i in range(3):\n            if i > 0: time.sleep(3)\n            curtime = int(time.time()*1000)\n            response = requests.get(api_url).text.strip()\n            proxy = 'http://' + response.split(',')[0]\n            mill = int(response.split(',')[1])\n            if self.proxy_ip_dict.get(proxy) is none: break   # 获取到新的，跳出循环\n        # proxy_pop为空字符串时初始化字典\n        if proxy_pop == '':\n            self.proxy_ip_dict[proxy] = '{} 0 0'.format(curtime + mill)\n            if self.browser:\n                self.browser.close()\n            self.browser = self.create_chrome_driver(proxy_ip=proxy)\n        # ip已经存在,跳过\n        elif self.proxy_ip_dict.get(proxy) is not none:\n            pass\n        # 删除旧的,插入新的\n        else:\n            print(\"==================删除ip======{}\".format(proxy_pop))\n            self.proxy_ip_dict.pop(proxy_pop)\n            self.proxy_ip_dict[proxy] = '{} 0 0'.format(curtime + mill)\n            if self.browser:\n                self.browser.close()\n            self.browser = self.create_chrome_driver(proxy_ip=proxy)\n        return proxy\n\n    def preparatory_work(self, curmill):\n        proxy_ip = random.choice(list(self.proxy_ip_dict.keys()))\n        item_info = self.proxy_ip_dict[proxy_ip].split(' ')\n        print('可用时间（使用次数、错误次数）：{}  当前时间：{}'.format(self.proxy_ip_dict[proxy_ip], curmill))\n        if int(item_info[0]) > curmill and int(item_info[2]) == 0:  # and int(item_info[1]) < 10\n            return proxy_ip  # 若可用，返回\n        else:\n            print(\"================== ip：{}  过期时间：{}  当前时间：{} ======\".format(proxy_ip, item_info[0], int(time.time()*1000)))\n            return self.get_proxy(proxy_ip)   # 若不可用，从列表移除  重新获取\n",charsets:{cjk:!0},lastUpdated:"2024/12/26, 14:30:54",lastUpdatedTimestamp:1735194654e3},{title:"Shell基础",frontmatter:{title:"Shell基础",date:"2022-03-10T16:49:17.000Z",permalink:"/pages/5704cc/",categories:["其他","Shell"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/02.Shell/01.Shell%E5%9F%BA%E7%A1%80.html",relativePath:"04.其他/02.Shell/01.Shell基础.md",key:"v-6ece5467",path:"/pages/5704cc/",headers:[{level:2,title:"一、命令",slug:"一、命令",normalizedTitle:"一、命令",charIndex:14},{level:3,title:"1、搜索命令用法",slug:"_1、搜索命令用法",normalizedTitle:"1、搜索命令用法",charIndex:56},{level:3,title:"2、Linux命令分类",slug:"_2、linux命令分类",normalizedTitle:"2、linux命令分类",charIndex:69},{level:4,title:"文件传输",slug:"文件传输",normalizedTitle:"文件传输",charIndex:84},{level:4,title:"备份压缩",slug:"备份压缩",normalizedTitle:"备份压缩",charIndex:423},{level:4,title:"文件管理",slug:"文件管理",normalizedTitle:"文件管理",charIndex:1388},{level:4,title:"磁盘管理",slug:"磁盘管理",normalizedTitle:"磁盘管理",charIndex:1666},{level:4,title:"磁盘维护",slug:"磁盘维护",normalizedTitle:"磁盘维护",charIndex:1836},{level:4,title:"系统设置",slug:"系统设置",normalizedTitle:"系统设置",charIndex:2086},{level:4,title:"系统管理",slug:"系统管理",normalizedTitle:"系统管理",charIndex:2453},{level:4,title:"文本处理",slug:"文本处理",normalizedTitle:"文本处理",charIndex:2772},{level:4,title:"网络通讯",slug:"网络通讯",normalizedTitle:"网络通讯",charIndex:3018},{level:4,title:"设备管理",slug:"设备管理",normalizedTitle:"设备管理",charIndex:3442},{level:4,title:"电子邮件与新闻组",slug:"电子邮件与新闻组",normalizedTitle:"电子邮件与新闻组",charIndex:3490},{level:4,title:"其他命令",slug:"其他命令",normalizedTitle:"其他命令",charIndex:3703},{level:3,title:"博客",slug:"博客",normalizedTitle:"博客",charIndex:3717},{level:2,title:"二、shell脚本相关",slug:"二、shell脚本相关",normalizedTitle:"二、shell脚本相关",charIndex:3776},{level:3,title:"1、脚本格式",slug:"_1、脚本格式",normalizedTitle:"1、脚本格式",charIndex:3801},{level:3,title:"2、变量",slug:"_2、变量",normalizedTitle:"2、变量",charIndex:4174},{level:4,title:"变量类型",slug:"变量类型",normalizedTitle:"变量类型",charIndex:4182},{level:4,title:"定义变量",slug:"定义变量",normalizedTitle:"定义变量",charIndex:4408},{level:4,title:"参数扩展",slug:"参数扩展",normalizedTitle:"参数扩展",charIndex:4614},{level:4,title:"通配符",slug:"通配符",normalizedTitle:"通配符",charIndex:2979},{level:4,title:"数组",slug:"数组",normalizedTitle:"数组",charIndex:6207},{level:3,title:"3、特殊变量",slug:"_3、特殊变量",normalizedTitle:"3、特殊变量",charIndex:6335},{level:3,title:"4、if条件判断",slug:"_4、if条件判断",normalizedTitle:"4、if条件判断",charIndex:6843},{level:3,title:"5、流程控制",slug:"_5、流程控制",normalizedTitle:"5、流程控制",charIndex:8800},{level:4,title:"if判断",slug:"if判断",normalizedTitle:"if判断",charIndex:8810},{level:4,title:"case语法",slug:"case语法",normalizedTitle:"case语法",charIndex:8998},{level:4,title:"for循环",slug:"for循环",normalizedTitle:"for循环",charIndex:9185},{level:4,title:"while循环",slug:"while循环",normalizedTitle:"while循环",charIndex:9466},{level:4,title:"Until循环",slug:"until循环",normalizedTitle:"until循环",charIndex:9533},{level:3,title:"6、read读取控制台输入",slug:"_6、read读取控制台输入",normalizedTitle:"6、read读取控制台输入",charIndex:9583},{level:3,title:"7、函数",slug:"_7、函数",normalizedTitle:"7、函数",charIndex:9741},{level:4,title:"basename 截取文件名",slug:"basename-截取文件名",normalizedTitle:"basename 截取文件名",charIndex:9749},{level:4,title:"dirname 截取绝对路径",slug:"dirname-截取绝对路径",normalizedTitle:"dirname 截取绝对路径",charIndex:9933}],headersStr:"一、命令 1、搜索命令用法 2、Linux命令分类 文件传输 备份压缩 文件管理 磁盘管理 磁盘维护 系统设置 系统管理 文本处理 网络通讯 设备管理 电子邮件与新闻组 其他命令 博客 二、shell脚本相关 1、脚本格式 2、变量 变量类型 定义变量 参数扩展 通配符 数组 3、特殊变量 4、if条件判断 5、流程控制 if判断 case语法 for循环 while循环 Until循环 6、read读取控制台输入 7、函数 basename 截取文件名 dirname 截取绝对路径",content:'# shell基础\n\n\n# 一、命令\n\n详细用法请查看Linux命令大全搜索工具 v1.5.1.pdf\n\n\n# 1、搜索命令用法\n\n\n# 2、Linux命令分类\n\n# 文件传输\n\nbye、ftp、ftpcount、ftpshut、ftpwho、ncftp、tftp、uucico、uucp、uupick、uuto、scp\n\n点击查看\n\n实例\n\n 1. ftp： 使用ftp 127.0.0.1创建连接，输入用户名密码后连接成功，使用[m]get xxx、[m]put xxx上传下载文件，使用[m]delete删除远端文件，使用bye、exit、quit关闭连接\n 2. scp： 远程拷贝到本机：scp -r root@10.10.10.10:/opt/soft/mongodb /opt/soft/ 本机拷贝到远程：scp -r /opt/soft/mongodb root@10.10.10.10:/opt/soft/scptest\n\n# 备份压缩\n\nar、bunzip2、bzip2、bzip2recover、compress、cpio、dump、gunzip、gzexe、gzip、lha、restore、tar、unarj、unzip、zip、zipinfo\n\n点击查看\n\n实例\n\n 1. gz： 打包并压缩：tar -czf [目标文件名].tar.gz [原文件/目录名] 解压并解包：tar -zxvf xxx.tar.gz -C dirname（指定解压路径）\n    \n    > 注：c参数代表create（创建），x参数代表extract（解包），v参数代表verbose（详细信息），f参数代表filename（文件名），所以f后必须接文件名。\n\n 2. zip： 压缩：zip -qr [目标文件名].zip [原文件/目录名] 解压：unzip [原文件名].zip\n\n 3. bz2 打包并压缩： tar -jcvf [目标文件名].tar.bz2 [原文件名/目录名] 解压并解包： tar -jxvf [原文件名].tar.bz2 注：小写j代表用bzip2算法来压缩/解压\n\n 4. 7z 压缩：7z a [目标文件名].7z [原文件名/目录名] 解压：7z x [原文件名].7z\n\n 5. jar 压缩：jar -cvf [目标文件名].jar [原文件名/目录名] 解压：jar -xvf [原文件名].jar\n    \n    > 注：如果是打包的是Java类库，并且该类库中存在主类，那么需要写一个META-INF/MANIFEST.MF配置文件，内容如下：\n    > Manifest-Version: 1.0\n    > Created-By: 1.6.0_27 (Sun Microsystems Inc.)\n    > Main-class: the_name_of_the_main_class_should_be_put_here\n    > 然后用如下命令打包：jar -cvfm [目标文件名].jar META-INF/MANIFEST.MF [原文件名/目录名]，这样以后就能用“java -jar [文件名].jar”命令直接运行主类中的public static void main方法了。\n\n# 文件管理\n\ndiff、diffstat、file、find、git、gitview、ln、locate、lsattr、mattrib、mc、mcopy、mdel、mdir、mktemp、mmove、mread、mren、mshowfat、mtools、mtoolstest、mv、od、paste、patch、rcp、rhmask、rm、slocate、split、tee、tmpwatch、touch、umask、whereis、which、cat、chattr、chgrp、chmod、chown、cksum、cmp、cp、cut、indent\n\n# 磁盘管理\n\ncd、df、dirs、du、edquota、eject、lndir、ls、mcd、mdeltree、mdu、mkdir、mlabel、mmd、mmount、mrd、mzip、pwd、quota、quotacheck、quotaoff、quotaon、repquota、rmdir、rmt、stat、tree、umount\n\n# 磁盘维护\n\nbadblocks、cfdisk、dd、e2fsck、ext2ed、fdisk、fsck.ext2、fsck、fsck.minix、fsconf、hdparm、losetup、mbadblocks、mformat、mkbootdisk、mkdosfs、mke2fs、mkfs.ext2、mkfs、mkfs.minix、mkfs.msdos、mkinitrd、mkisofs、mkswap、mpartition、sfdisk、swapoff、swapon、symlinks、sync\n\n# 系统设置\n\nalias、apmd、aumix、bind、chkconfig、chroot、clock、crontab、declare、depmod、dircolors、dmesg、enable、eval、export、fbset、grpconv、grpunconv、hwclock、insmod、kbdconfig、lilo、liloconfig、lsmod、minfo、mkkickstart、modinfo、modprobe、mouseconfig、ntsysv、passwd、pwconv、pwunconv、rdate、resize、rmmod、rpm、set、setconsole、setenv、setup、sndconfig、SVGAText Mode、timeconfig、ulimit、unalias、unset\n\n# 系统管理\n\nadduser、chfn、chsh、date、exit、finger、free、fwhois、gitps、groupdel、groupmod、halt、id、kill、last、lastb、login、logname、logout、logrotate、newgrp、nice、procinfo、ps、pstree、reboot、renice、rlogin、rsh、rwho、screen、shutdown、sliplogin、su、sudo、suspend、swatch、tload、top、uname、useradd、userconf、userdel、usermod、vlock、w、who、whoami、whois\n\n# 文本处理\n\nawk、col、colrm、comm、csplit、ed、egrep、ex、fgrep、fmt、fold、grep、ispell、jed、joe、join、look、mtype、pico、rgrep、sed、sort、spell、tr、uniq、vi、wc\n\n点击查看\n\n实例\n\n 1. grep： 多行匹配：grep --color=auto -Pazo \'<div>\\s+</div>\' [文件名/通配符].txt （-z 为多行模式、-P 为 Perl 正则表达式）\n\n# 网络通讯\n\ndip、getty、mingetty、ppp-off、smbd(samba daemon)、telnet、uulog、uustat、uux、cu、dnsconf、efax、httpd、ip、ifconfig、mesg、minicom、nc、netconf、netconfig、netstat、ping、pppstats、samba、setserial、shapecfg(shaper configuration)、smbd(samba daemon)、statserial(status ofserial port)、talk、tcpdump、testparm(test parameter)、traceroute、tty(teletypewriter)、uuname、wall(write all)、write、ytalk、arpwatch、apachectl、smbclient(samba client)、pppsetup\n\n# 设备管理\n\ndumpkeys、loadkeys、MAKEDEV、rdev、setleds\n\n# 电子邮件与新闻组\n\narchive、ctlinnd、elm、getlist、inncheck、mail、mailconf、mailq、messages、metamail、mutt、nntpget、pine、slrn、X WINDOWS SYSTEM、reconfig、startx(start X Window)、Xconfigurator、XF86Setup、xlsatoms、xlsclients、xlsfonts\n\n# 其他命令\n\nyes\n\n\n# 博客\n\n博客链接：\n\n 1. Linux性能问题分析流程与性能优化思路\n 2. CentOS 7系统优化脚本\n\n\n# 二、shell脚本相关\n\nBash公共库\n\n\n# 1、脚本格式\n\n解析器\n\n使用 cat /etc/shells 来查看系统提供的Shell解析器。 使用 echo $SHELL 查看默认使用的解析器\n\n 1. 以#!/bin/bash开头(用来指定解析器)\n 2. 使用sh/bash + 脚本不需要执行权限，直接使用脚本绝对路径或相对路径需要执行权限。\n\n> 使用 bash(sh) x.sh 的方式执行脚本，是在当前shell中打开一个子shell来执行脚本\n> 使用 ./x.sh 或 source(.) x.sh 是在当前shell执行，这也是每次修改完环境变量/etc/profile文件后，要执行source /etc/profile 的原因\n> 在子shell执行和父shell执行的区别是：环境变量的继承关系，比如在子shell设置的环境变量，在父shell是不可见的\n\n\n# 2、变量\n\n# 变量类型\n\n 1. 局部变量：局部变量在脚本或命令中定义，仅在当前 shell 实例中有效，其他 shell 启动的程序不能访问局部变量；\n 2. 环境变量：所有的程序，包括 shell 启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候 shell 脚本也可以定义环境变量；\n 3. shell 变量：shell 变量是由 shell 程序设置的特殊变量。shell 变量中有一部分是环境变量，有一部分是局部变量。\n\n# 定义变量\n\n 1. 定义变量：变量=值 （中间不能有空格）\n 2. 使用变量 $变量 或 ${变量}\n 3. 撤销变量：unset 变量名\n 4. 声明局部变量：local 变量="xxx"\n 5. 声明只读变量：readonly 变量（不能unset）\n\n--       --\nglobal   作用域从定义到shell结束或者变量被删除\nlocal    作用域只在函数内部,函数参数是local的\n\n# 参数扩展\n\n 1. 去掉结尾的部分:\n    * ${var%pattern}: 去掉变量值末尾符合 pattern 的部分。例如，${filename%.*} 去掉文件名中的扩展名。\n    * ${var%%pattern}: 去掉变量值末尾符合 pattern 的最长部分。例如，${path%%/} 去掉路径末尾的所有斜杠。\n 2. 去掉开头的部分:\n    * ${var#pattern}: 去掉变量值开头符合 pattern 的部分。例如，${path#*/} 去掉路径开头的第一个斜杠。\n    * ${var##pattern}: 去掉变量值开头符合 pattern 的最长部分。例如，${path##*/} 去掉路径开头的所有目录部分，只留下文件名。\n 3. 替换内容:\n    * ${var/pattern/replacement}: 替换变量值中第一个匹配 pattern 的部分为 replacement。例如，${filename/.txt/.bak} 将 .txt 替换为 .bak。\n    * ${var//pattern/replacement}: 替换变量值中所有匹配 pattern 的部分为 replacement。\n 4. 默认值:\n    * ${var:-default}: 如果变量 var 未设置或为空，返回 default 的值。\n    * ${var:=default}: 如果变量 var 未设置或为空，将其设置为 default 的值，并返回该值。\n 5. 长度和子字符串:\n    * ${#var}: 变量 var 的长度。例如，${#filename} 返回文件名的长度。\n    * ${var:position:length}: 从变量 var 的 position 开始提取 length 个字符。例如，${filename:0:5} 提取文件名的前五个字符。\n\n# 通配符\n\n通配符               作用                                   示例\n*                 匹配零个或多个字符。                           例如，*.txt 匹配所有扩展名为 .txt 的文件。\n?                 匹配一个单一字符。                            例如，file?.txt 匹配 file1.txt、fileA.txt 等，但不匹配 file10.txt。\n[abc]             匹配方括号内的任意一个字符。                       例如，file[123].txt 匹配 file1.txt、file2.txt 和 file3.txt。\n[a-z]             匹配方括号内的字符范围。                         例如，file[a-z].txt 匹配 filea.txt、fileb.txt 到 filez.txt。\n{a,b}             匹配 {} 内的任意一个选项（用于文件名生成）。             例如，file{1,2}.txt 匹配 file1.txt 和 file2.txt。\n[!abc] 或 [^abc]   匹配不在方括号内的任何一个字符。                     例如，file[!1].txt 匹配 file2.txt、fileA.txt 等，但不匹配 file1.txt。\n**                匹配零个或多个目录（在 Bash 的 extglob 扩展中支持）。   例如，dir/** 匹配 dir 目录及其所有子目录和文件。\n\n# 数组\n\n 1. 定义数组：arr=(value0 value1 value2)\n 2. 使用数组：${数组名[下标]}\n 3. 获取元素：${arr[*]} 或 ${arr[@]}\n 4. 获取长度：${#arr[@]} 或 ${#arr[*]}\n\n\n# 3、特殊变量\n\n变量      含义\n$\'\\n\'   获取换行符\n$1~$n   添加到Shell的各参数值。$1是第1参数、$2是第2参数…十以上的参数需要用大括号包含${10}\nshift   位置参数可以用shift命令左移。比如shift\n        3表示原来的$4现在变成$1，原来的$5现在变成$2等等，原来的$1、$2、$3丢弃，$0不移动。不带参数的shift命令相当于shift\n        1。\n$$      Shell本身的PID（ProcessID）\n$!      Shell最后运行的后台Process的PID\n$?      最后运行的命令的结束代码（返回值）\n$-      使用Set命令设定的Flag一览\n$*      所有参数列表(所有参数看成一个整体)。如"$*"用「"」括起来的情况、以"$1 $2 … $n"的形式输出所有参数\n$@      所有参数列表(每个参数区分对待)。如"$@"用「"」括起来的情况、以"$1" "$2" … "$n" 的形式输出所有参数\n$#      添加到Shell的参数个数\n$0      Shell本身的文件名\n\n\n# 4、if条件判断\n\nIF条件只能为命令（或脚本）返回值（比如./test.sh），[命令等同于test命令\n\n条件        含义\n[]和test   在命令行里test expr和[ expr ]的效果相同(判断文件、判断字符串、判断整数)\n[[ ]]     内置在shell中的一个命令（支持字符串的模式匹配、逻辑组合可以不使用test的-a,-o而使用&&\n-eq       【数值比较】测试两个整数是否相等\n-ne       【数值比较】测试两个整数是否不等\n-gt       【数值比较】测试一个数是否大于另一个数\n-lt       【数值比较】测试一个数是否小于另一个数\n-ge       【数值比较】大于或等于\n-le       【数值比较】小于或等于\n逻辑关系      命令间的逻辑关系, 逻辑与：&& , 逻辑或：\n=         【字符串比较】等于 两边要有空格\n!=        【字符串比较】不等\n>         【字符串比较】大于\n<         【字符串比较】小于\n-z        【字符串比较】string 字符是否为空，空着真，非空为假\n-n        【字符串比较】string 字符串是否为不空（长度非0），空为假 非空为真（if [ -n "" ]）\n-e        【文件测试】file 文件是否存在\n-f        【文件测试】file 是否为普通文件（if [ -f "" ]）\n-d        【文件测试】file 是否为目录（if [ -d "" ]）\n-r        【文件测试】file 文件对当前用户是否可读\n-w        【文件测试】file 文件对当前用户是否可写\n-x        【文件测试】file 文件对当前用户是都可执行\n-z        【文件测试】是否为空 为空则为真\n-a        【文件测试】是否不空\n-s        【文件测试】文件存在且至少有一个字符时为真\n-c        【文件测试】文件存在且为字符型特殊文件时为真\n-b        【文件测试】文件存在且为块特殊文件时为真\n-r        【文件权限】有读的权限(read)\n-w        【文件权限】有写的权限(write)\n-x        【文件权限】有执行的权限(execute)\n=~        正则匹配 if [[ $line =~ ^java.library.path=(.*)$ ]]\n\n[] 和 [[]]的区别\n\n> 注意：使用[]和[[]]的时候不要吝啬空格，每一项两边都要有空格，[[ 1 == 2 ]]的结果为“假”，但[[ 1==2 ]]的结果为“真”！\n\n> 1.首先，尽管很相似，但是从概念上讲，二者是不同层次的东西。"[["，是关键字，许多shell(如ash bsh)并不支持这种方式。ksh, bash(据说从2.02起引入对[[的支持)等支持。"["是一条命令， 与test等价，大多数shell都支持。在现代的大多数sh实现中，"["与"test"是内部(builtin)命令，换句话说执行"test"/"["时不会调用/some/path/to/test这样的外部命令(如果有这样的命令的话)。\n\n> 2.[[]]结构比Bash版本的[]更通用。在[[和]]之间的所有的字符都不会被文件扩展或是标记分割，但是会有参数引用和命令替换。 用[[ ... ]]测试结构比用[ ... ]更能防止脚本里的许多逻辑错误。比如说，&&,||,<和>操作符能在一个[[]]测试里通过，但在[]结构会发生错误。\n\n> 3.(( ))结构扩展并计算一个算术表达式的值。如果表达式值为0，会返回1或假作为退出状态码。一个非零值的表达式返回一个0或真作为退出状态码。这个结构和先前test命令及[]结构的讨论刚好相反。\n\n> 4.[ ... ]为shell命令，所以在其中的表达式应是它的命令行参数，所以串比较操作符">" 与"<"必须转义，否则就变成IO改向操作符了(请参看上面2中的例子)。在[[中"<"与">"不需转义； 由于"[["是关键字，不会做命令行扩展，因而相对的语法就稍严格些。例如 在[ ... ]中可以用引号括起操作符，因为在做命令行扩展时会去掉这些引号，而在[[ ... ]]则不允许这样做。\n\n> 5.[[ ... ]]进行算术扩展，而[ ... ]不做\n\n> 6.[[ ... && ... && ... ]] 和 [ ... -a ... -a ...] 不一样，[[ ]] 是逻辑短路操作，而 [ ] 不会进行逻辑短路\n\n\n# 5、流程控制\n\n# if判断\n\n> 注意: 1.if后要有空格 2.条件前后要有空格\n\n 1. 单分支\n\nif [ 条件判断 ]; then\n  # 程序\nfi \n# 或者\nif [  ]\nthen\n  # 程序    \nfi\n\n\n 2. 多分支\n\nif [ 条件判断 ]\nthen\n  # 程序\nelif [ 条件判断 ]\nthen\n  # 程序\nelse\n  # 程序    \nfi\n\n\n# case语法\n\n> 注意: 1. case行尾必须为单词in 2. 每个模式匹配必须以\')\'结束 3. \';;\'表示命令序列结束(同java的break)\n\ncase $变量 in\n"值1")\n  # 变量的值等于值1, 则执行\n  ;;\n"值2")\n  # 变量的值等于值2, 则执行\n  ;;\n*)\n  # 变量的值都不是以上的值, 则执行\n  ;;\nesac\n\n\n# for循环\n\n# for (( 初始值;循环控制条件;变量变化 ))\nfor (( i = 0; i < n; i++ )); do\n    \ndone\n\n# 或者\n\n# for 变量 in 值1 值2 值3...\nfor i in {1..5} ; do\n    \ndone\n\n\n> $* 和 $@ 的区别:\n> \n> \n>  1. 不被双引号("")包含时: 都以$1 $2...$n形式输出\n>     \n>  2. 被双引号("")包含时: $*将所有参数看做整体"$1 $2...$n"    $@将各个参数分开"$1" "$2"..."$n"\n\n# while循环\n\nwhile [ 条件判断 ]; do\n    # 程序；可使用 break 或 continue\ndone\n\n\n# Until循环\n\nuntil condition\ndo\n    command\ndone\n\n\n\n# 6、read读取控制台输入\n\nread [选项] [参数]\n# 选项 -p: 指定读取时提示符   -t: 指定读取等待时间(s秒),不加默认一直等待\n# 参数 指定读取时的变量名\n\n#!/bin/bash\nread -t 3 -p "3s内输入名称: " username\necho $username\n\n\n\n# 7、函数\n\n# basename 截取文件名\n\n# 语法\nbasename [string/pathname] [suffix]    # 删掉所有前缀包含最后一个\'/\'(若指定suffix,则将其删掉), 将字符串显示\n\n# 示例\n[banana@hadoop10 MyLog]$ basename /home/banana/MyLog/test.sh  .sh\ntest\n\n\n# dirname 截取绝对路径\n\ndirname 文件绝对路径\n\n# 示例\n[banana@hadoop10 MyLog]$ dirname /home/banana/MyLog/test.sh       \n/home/banana/MyLog\n\n\n\n# 自定义函数\n\n> 注意:\n> \n> \n>  1. 使用时应该先声明函数, 再调用(shell脚本逐行执行)\n>     \n>  2. 返回值: 可以用$?获取返回值, 若不加, 为最后一个命令的运行结果\n\n# 声明\n[function] funname[()]\n{\n  Action;\n  [return int(0-255);]\n}\n\n# 调用\nfunname para1\n',normalizedContent:'# shell基础\n\n\n# 一、命令\n\n详细用法请查看linux命令大全搜索工具 v1.5.1.pdf\n\n\n# 1、搜索命令用法\n\n\n# 2、linux命令分类\n\n# 文件传输\n\nbye、ftp、ftpcount、ftpshut、ftpwho、ncftp、tftp、uucico、uucp、uupick、uuto、scp\n\n点击查看\n\n实例\n\n 1. ftp： 使用ftp 127.0.0.1创建连接，输入用户名密码后连接成功，使用[m]get xxx、[m]put xxx上传下载文件，使用[m]delete删除远端文件，使用bye、exit、quit关闭连接\n 2. scp： 远程拷贝到本机：scp -r root@10.10.10.10:/opt/soft/mongodb /opt/soft/ 本机拷贝到远程：scp -r /opt/soft/mongodb root@10.10.10.10:/opt/soft/scptest\n\n# 备份压缩\n\nar、bunzip2、bzip2、bzip2recover、compress、cpio、dump、gunzip、gzexe、gzip、lha、restore、tar、unarj、unzip、zip、zipinfo\n\n点击查看\n\n实例\n\n 1. gz： 打包并压缩：tar -czf [目标文件名].tar.gz [原文件/目录名] 解压并解包：tar -zxvf xxx.tar.gz -c dirname（指定解压路径）\n    \n    > 注：c参数代表create（创建），x参数代表extract（解包），v参数代表verbose（详细信息），f参数代表filename（文件名），所以f后必须接文件名。\n\n 2. zip： 压缩：zip -qr [目标文件名].zip [原文件/目录名] 解压：unzip [原文件名].zip\n\n 3. bz2 打包并压缩： tar -jcvf [目标文件名].tar.bz2 [原文件名/目录名] 解压并解包： tar -jxvf [原文件名].tar.bz2 注：小写j代表用bzip2算法来压缩/解压\n\n 4. 7z 压缩：7z a [目标文件名].7z [原文件名/目录名] 解压：7z x [原文件名].7z\n\n 5. jar 压缩：jar -cvf [目标文件名].jar [原文件名/目录名] 解压：jar -xvf [原文件名].jar\n    \n    > 注：如果是打包的是java类库，并且该类库中存在主类，那么需要写一个meta-inf/manifest.mf配置文件，内容如下：\n    > manifest-version: 1.0\n    > created-by: 1.6.0_27 (sun microsystems inc.)\n    > main-class: the_name_of_the_main_class_should_be_put_here\n    > 然后用如下命令打包：jar -cvfm [目标文件名].jar meta-inf/manifest.mf [原文件名/目录名]，这样以后就能用“java -jar [文件名].jar”命令直接运行主类中的public static void main方法了。\n\n# 文件管理\n\ndiff、diffstat、file、find、git、gitview、ln、locate、lsattr、mattrib、mc、mcopy、mdel、mdir、mktemp、mmove、mread、mren、mshowfat、mtools、mtoolstest、mv、od、paste、patch、rcp、rhmask、rm、slocate、split、tee、tmpwatch、touch、umask、whereis、which、cat、chattr、chgrp、chmod、chown、cksum、cmp、cp、cut、indent\n\n# 磁盘管理\n\ncd、df、dirs、du、edquota、eject、lndir、ls、mcd、mdeltree、mdu、mkdir、mlabel、mmd、mmount、mrd、mzip、pwd、quota、quotacheck、quotaoff、quotaon、repquota、rmdir、rmt、stat、tree、umount\n\n# 磁盘维护\n\nbadblocks、cfdisk、dd、e2fsck、ext2ed、fdisk、fsck.ext2、fsck、fsck.minix、fsconf、hdparm、losetup、mbadblocks、mformat、mkbootdisk、mkdosfs、mke2fs、mkfs.ext2、mkfs、mkfs.minix、mkfs.msdos、mkinitrd、mkisofs、mkswap、mpartition、sfdisk、swapoff、swapon、symlinks、sync\n\n# 系统设置\n\nalias、apmd、aumix、bind、chkconfig、chroot、clock、crontab、declare、depmod、dircolors、dmesg、enable、eval、export、fbset、grpconv、grpunconv、hwclock、insmod、kbdconfig、lilo、liloconfig、lsmod、minfo、mkkickstart、modinfo、modprobe、mouseconfig、ntsysv、passwd、pwconv、pwunconv、rdate、resize、rmmod、rpm、set、setconsole、setenv、setup、sndconfig、svgatext mode、timeconfig、ulimit、unalias、unset\n\n# 系统管理\n\nadduser、chfn、chsh、date、exit、finger、free、fwhois、gitps、groupdel、groupmod、halt、id、kill、last、lastb、login、logname、logout、logrotate、newgrp、nice、procinfo、ps、pstree、reboot、renice、rlogin、rsh、rwho、screen、shutdown、sliplogin、su、sudo、suspend、swatch、tload、top、uname、useradd、userconf、userdel、usermod、vlock、w、who、whoami、whois\n\n# 文本处理\n\nawk、col、colrm、comm、csplit、ed、egrep、ex、fgrep、fmt、fold、grep、ispell、jed、joe、join、look、mtype、pico、rgrep、sed、sort、spell、tr、uniq、vi、wc\n\n点击查看\n\n实例\n\n 1. grep： 多行匹配：grep --color=auto -pazo \'<div>\\s+</div>\' [文件名/通配符].txt （-z 为多行模式、-p 为 perl 正则表达式）\n\n# 网络通讯\n\ndip、getty、mingetty、ppp-off、smbd(samba daemon)、telnet、uulog、uustat、uux、cu、dnsconf、efax、httpd、ip、ifconfig、mesg、minicom、nc、netconf、netconfig、netstat、ping、pppstats、samba、setserial、shapecfg(shaper configuration)、smbd(samba daemon)、statserial(status ofserial port)、talk、tcpdump、testparm(test parameter)、traceroute、tty(teletypewriter)、uuname、wall(write all)、write、ytalk、arpwatch、apachectl、smbclient(samba client)、pppsetup\n\n# 设备管理\n\ndumpkeys、loadkeys、makedev、rdev、setleds\n\n# 电子邮件与新闻组\n\narchive、ctlinnd、elm、getlist、inncheck、mail、mailconf、mailq、messages、metamail、mutt、nntpget、pine、slrn、x windows system、reconfig、startx(start x window)、xconfigurator、xf86setup、xlsatoms、xlsclients、xlsfonts\n\n# 其他命令\n\nyes\n\n\n# 博客\n\n博客链接：\n\n 1. linux性能问题分析流程与性能优化思路\n 2. centos 7系统优化脚本\n\n\n# 二、shell脚本相关\n\nbash公共库\n\n\n# 1、脚本格式\n\n解析器\n\n使用 cat /etc/shells 来查看系统提供的shell解析器。 使用 echo $shell 查看默认使用的解析器\n\n 1. 以#!/bin/bash开头(用来指定解析器)\n 2. 使用sh/bash + 脚本不需要执行权限，直接使用脚本绝对路径或相对路径需要执行权限。\n\n> 使用 bash(sh) x.sh 的方式执行脚本，是在当前shell中打开一个子shell来执行脚本\n> 使用 ./x.sh 或 source(.) x.sh 是在当前shell执行，这也是每次修改完环境变量/etc/profile文件后，要执行source /etc/profile 的原因\n> 在子shell执行和父shell执行的区别是：环境变量的继承关系，比如在子shell设置的环境变量，在父shell是不可见的\n\n\n# 2、变量\n\n# 变量类型\n\n 1. 局部变量：局部变量在脚本或命令中定义，仅在当前 shell 实例中有效，其他 shell 启动的程序不能访问局部变量；\n 2. 环境变量：所有的程序，包括 shell 启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候 shell 脚本也可以定义环境变量；\n 3. shell 变量：shell 变量是由 shell 程序设置的特殊变量。shell 变量中有一部分是环境变量，有一部分是局部变量。\n\n# 定义变量\n\n 1. 定义变量：变量=值 （中间不能有空格）\n 2. 使用变量 $变量 或 ${变量}\n 3. 撤销变量：unset 变量名\n 4. 声明局部变量：local 变量="xxx"\n 5. 声明只读变量：readonly 变量（不能unset）\n\n--       --\nglobal   作用域从定义到shell结束或者变量被删除\nlocal    作用域只在函数内部,函数参数是local的\n\n# 参数扩展\n\n 1. 去掉结尾的部分:\n    * ${var%pattern}: 去掉变量值末尾符合 pattern 的部分。例如，${filename%.*} 去掉文件名中的扩展名。\n    * ${var%%pattern}: 去掉变量值末尾符合 pattern 的最长部分。例如，${path%%/} 去掉路径末尾的所有斜杠。\n 2. 去掉开头的部分:\n    * ${var#pattern}: 去掉变量值开头符合 pattern 的部分。例如，${path#*/} 去掉路径开头的第一个斜杠。\n    * ${var##pattern}: 去掉变量值开头符合 pattern 的最长部分。例如，${path##*/} 去掉路径开头的所有目录部分，只留下文件名。\n 3. 替换内容:\n    * ${var/pattern/replacement}: 替换变量值中第一个匹配 pattern 的部分为 replacement。例如，${filename/.txt/.bak} 将 .txt 替换为 .bak。\n    * ${var//pattern/replacement}: 替换变量值中所有匹配 pattern 的部分为 replacement。\n 4. 默认值:\n    * ${var:-default}: 如果变量 var 未设置或为空，返回 default 的值。\n    * ${var:=default}: 如果变量 var 未设置或为空，将其设置为 default 的值，并返回该值。\n 5. 长度和子字符串:\n    * ${#var}: 变量 var 的长度。例如，${#filename} 返回文件名的长度。\n    * ${var:position:length}: 从变量 var 的 position 开始提取 length 个字符。例如，${filename:0:5} 提取文件名的前五个字符。\n\n# 通配符\n\n通配符               作用                                   示例\n*                 匹配零个或多个字符。                           例如，*.txt 匹配所有扩展名为 .txt 的文件。\n?                 匹配一个单一字符。                            例如，file?.txt 匹配 file1.txt、filea.txt 等，但不匹配 file10.txt。\n[abc]             匹配方括号内的任意一个字符。                       例如，file[123].txt 匹配 file1.txt、file2.txt 和 file3.txt。\n[a-z]             匹配方括号内的字符范围。                         例如，file[a-z].txt 匹配 filea.txt、fileb.txt 到 filez.txt。\n{a,b}             匹配 {} 内的任意一个选项（用于文件名生成）。             例如，file{1,2}.txt 匹配 file1.txt 和 file2.txt。\n[!abc] 或 [^abc]   匹配不在方括号内的任何一个字符。                     例如，file[!1].txt 匹配 file2.txt、filea.txt 等，但不匹配 file1.txt。\n**                匹配零个或多个目录（在 bash 的 extglob 扩展中支持）。   例如，dir/** 匹配 dir 目录及其所有子目录和文件。\n\n# 数组\n\n 1. 定义数组：arr=(value0 value1 value2)\n 2. 使用数组：${数组名[下标]}\n 3. 获取元素：${arr[*]} 或 ${arr[@]}\n 4. 获取长度：${#arr[@]} 或 ${#arr[*]}\n\n\n# 3、特殊变量\n\n变量      含义\n$\'\\n\'   获取换行符\n$1~$n   添加到shell的各参数值。$1是第1参数、$2是第2参数…十以上的参数需要用大括号包含${10}\nshift   位置参数可以用shift命令左移。比如shift\n        3表示原来的$4现在变成$1，原来的$5现在变成$2等等，原来的$1、$2、$3丢弃，$0不移动。不带参数的shift命令相当于shift\n        1。\n$$      shell本身的pid（processid）\n$!      shell最后运行的后台process的pid\n$?      最后运行的命令的结束代码（返回值）\n$-      使用set命令设定的flag一览\n$*      所有参数列表(所有参数看成一个整体)。如"$*"用「"」括起来的情况、以"$1 $2 … $n"的形式输出所有参数\n$@      所有参数列表(每个参数区分对待)。如"$@"用「"」括起来的情况、以"$1" "$2" … "$n" 的形式输出所有参数\n$#      添加到shell的参数个数\n$0      shell本身的文件名\n\n\n# 4、if条件判断\n\nif条件只能为命令（或脚本）返回值（比如./test.sh），[命令等同于test命令\n\n条件        含义\n[]和test   在命令行里test expr和[ expr ]的效果相同(判断文件、判断字符串、判断整数)\n[[ ]]     内置在shell中的一个命令（支持字符串的模式匹配、逻辑组合可以不使用test的-a,-o而使用&&\n-eq       【数值比较】测试两个整数是否相等\n-ne       【数值比较】测试两个整数是否不等\n-gt       【数值比较】测试一个数是否大于另一个数\n-lt       【数值比较】测试一个数是否小于另一个数\n-ge       【数值比较】大于或等于\n-le       【数值比较】小于或等于\n逻辑关系      命令间的逻辑关系, 逻辑与：&& , 逻辑或：\n=         【字符串比较】等于 两边要有空格\n!=        【字符串比较】不等\n>         【字符串比较】大于\n<         【字符串比较】小于\n-z        【字符串比较】string 字符是否为空，空着真，非空为假\n-n        【字符串比较】string 字符串是否为不空（长度非0），空为假 非空为真（if [ -n "" ]）\n-e        【文件测试】file 文件是否存在\n-f        【文件测试】file 是否为普通文件（if [ -f "" ]）\n-d        【文件测试】file 是否为目录（if [ -d "" ]）\n-r        【文件测试】file 文件对当前用户是否可读\n-w        【文件测试】file 文件对当前用户是否可写\n-x        【文件测试】file 文件对当前用户是都可执行\n-z        【文件测试】是否为空 为空则为真\n-a        【文件测试】是否不空\n-s        【文件测试】文件存在且至少有一个字符时为真\n-c        【文件测试】文件存在且为字符型特殊文件时为真\n-b        【文件测试】文件存在且为块特殊文件时为真\n-r        【文件权限】有读的权限(read)\n-w        【文件权限】有写的权限(write)\n-x        【文件权限】有执行的权限(execute)\n=~        正则匹配 if [[ $line =~ ^java.library.path=(.*)$ ]]\n\n[] 和 [[]]的区别\n\n> 注意：使用[]和[[]]的时候不要吝啬空格，每一项两边都要有空格，[[ 1 == 2 ]]的结果为“假”，但[[ 1==2 ]]的结果为“真”！\n\n> 1.首先，尽管很相似，但是从概念上讲，二者是不同层次的东西。"[["，是关键字，许多shell(如ash bsh)并不支持这种方式。ksh, bash(据说从2.02起引入对[[的支持)等支持。"["是一条命令， 与test等价，大多数shell都支持。在现代的大多数sh实现中，"["与"test"是内部(builtin)命令，换句话说执行"test"/"["时不会调用/some/path/to/test这样的外部命令(如果有这样的命令的话)。\n\n> 2.[[]]结构比bash版本的[]更通用。在[[和]]之间的所有的字符都不会被文件扩展或是标记分割，但是会有参数引用和命令替换。 用[[ ... ]]测试结构比用[ ... ]更能防止脚本里的许多逻辑错误。比如说，&&,||,<和>操作符能在一个[[]]测试里通过，但在[]结构会发生错误。\n\n> 3.(( ))结构扩展并计算一个算术表达式的值。如果表达式值为0，会返回1或假作为退出状态码。一个非零值的表达式返回一个0或真作为退出状态码。这个结构和先前test命令及[]结构的讨论刚好相反。\n\n> 4.[ ... ]为shell命令，所以在其中的表达式应是它的命令行参数，所以串比较操作符">" 与"<"必须转义，否则就变成io改向操作符了(请参看上面2中的例子)。在[[中"<"与">"不需转义； 由于"[["是关键字，不会做命令行扩展，因而相对的语法就稍严格些。例如 在[ ... ]中可以用引号括起操作符，因为在做命令行扩展时会去掉这些引号，而在[[ ... ]]则不允许这样做。\n\n> 5.[[ ... ]]进行算术扩展，而[ ... ]不做\n\n> 6.[[ ... && ... && ... ]] 和 [ ... -a ... -a ...] 不一样，[[ ]] 是逻辑短路操作，而 [ ] 不会进行逻辑短路\n\n\n# 5、流程控制\n\n# if判断\n\n> 注意: 1.if后要有空格 2.条件前后要有空格\n\n 1. 单分支\n\nif [ 条件判断 ]; then\n  # 程序\nfi \n# 或者\nif [  ]\nthen\n  # 程序    \nfi\n\n\n 2. 多分支\n\nif [ 条件判断 ]\nthen\n  # 程序\nelif [ 条件判断 ]\nthen\n  # 程序\nelse\n  # 程序    \nfi\n\n\n# case语法\n\n> 注意: 1. case行尾必须为单词in 2. 每个模式匹配必须以\')\'结束 3. \';;\'表示命令序列结束(同java的break)\n\ncase $变量 in\n"值1")\n  # 变量的值等于值1, 则执行\n  ;;\n"值2")\n  # 变量的值等于值2, 则执行\n  ;;\n*)\n  # 变量的值都不是以上的值, 则执行\n  ;;\nesac\n\n\n# for循环\n\n# for (( 初始值;循环控制条件;变量变化 ))\nfor (( i = 0; i < n; i++ )); do\n    \ndone\n\n# 或者\n\n# for 变量 in 值1 值2 值3...\nfor i in {1..5} ; do\n    \ndone\n\n\n> $* 和 $@ 的区别:\n> \n> \n>  1. 不被双引号("")包含时: 都以$1 $2...$n形式输出\n>     \n>  2. 被双引号("")包含时: $*将所有参数看做整体"$1 $2...$n"    $@将各个参数分开"$1" "$2"..."$n"\n\n# while循环\n\nwhile [ 条件判断 ]; do\n    # 程序；可使用 break 或 continue\ndone\n\n\n# until循环\n\nuntil condition\ndo\n    command\ndone\n\n\n\n# 6、read读取控制台输入\n\nread [选项] [参数]\n# 选项 -p: 指定读取时提示符   -t: 指定读取等待时间(s秒),不加默认一直等待\n# 参数 指定读取时的变量名\n\n#!/bin/bash\nread -t 3 -p "3s内输入名称: " username\necho $username\n\n\n\n# 7、函数\n\n# basename 截取文件名\n\n# 语法\nbasename [string/pathname] [suffix]    # 删掉所有前缀包含最后一个\'/\'(若指定suffix,则将其删掉), 将字符串显示\n\n# 示例\n[banana@hadoop10 mylog]$ basename /home/banana/mylog/test.sh  .sh\ntest\n\n\n# dirname 截取绝对路径\n\ndirname 文件绝对路径\n\n# 示例\n[banana@hadoop10 mylog]$ dirname /home/banana/mylog/test.sh       \n/home/banana/mylog\n\n\n\n# 自定义函数\n\n> 注意:\n> \n> \n>  1. 使用时应该先声明函数, 再调用(shell脚本逐行执行)\n>     \n>  2. 返回值: 可以用$?获取返回值, 若不加, 为最后一个命令的运行结果\n\n# 声明\n[function] funname[()]\n{\n  action;\n  [return int(0-255);]\n}\n\n# 调用\nfunname para1\n',charsets:{cjk:!0},lastUpdated:"2024/08/01, 16:20:18",lastUpdatedTimestamp:1722500418e3},{title:"Shell命令行",frontmatter:{title:"Shell命令行",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/5765cc/",categories:["其他","Shell"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/02.Shell/02.Shell%E5%B0%8F%E5%B7%A5%E5%85%B7.html",relativePath:"04.其他/02.Shell/02.Shell小工具.md",key:"v-e244ce58",path:"/pages/5765cc/",headers:[{level:2,title:"常用命令",slug:"常用命令",normalizedTitle:"常用命令",charIndex:2},{level:4,title:"批量移动指定文件",slug:"批量移动指定文件",normalizedTitle:"批量移动指定文件",charIndex:10},{level:4,title:"批量移动/拷贝文件",slug:"批量移动-拷贝文件",normalizedTitle:"批量移动/拷贝文件",charIndex:123},{level:4,title:"批量杀死进程",slug:"批量杀死进程",normalizedTitle:"批量杀死进程",charIndex:273},{level:4,title:"查看目录大小",slug:"查看目录大小",normalizedTitle:"查看目录大小",charIndex:343},{level:2,title:"工具",slug:"工具",normalizedTitle:"工具",charIndex:465},{level:3,title:"日志处理",slug:"日志处理",normalizedTitle:"日志处理",charIndex:514},{level:3,title:"集群脚本",slug:"集群脚本",normalizedTitle:"集群脚本",charIndex:1655},{level:3,title:"服务器搭建(tomcat)",slug:"服务器搭建-tomcat",normalizedTitle:"服务器搭建(tomcat)",charIndex:3595},{level:3,title:"sed替换json文件",slug:"sed替换json文件",normalizedTitle:"sed替换json文件",charIndex:4888},{level:3,title:"awk按某一列把文件分成多个文件",slug:"awk按某一列把文件分成多个文件",normalizedTitle:"awk按某一列把文件分成多个文件",charIndex:6568},{level:3,title:"替换文本内容(sed替换的文本不能有命令分隔符)",slug:"替换文本内容-sed替换的文本不能有命令分隔符",normalizedTitle:"替换文本内容(sed替换的文本不能有命令分隔符)",charIndex:6887},{level:3,title:"计算时间",slug:"计算时间",normalizedTitle:"计算时间",charIndex:7759}],headersStr:"常用命令 批量移动指定文件 批量移动/拷贝文件 批量杀死进程 查看目录大小 工具 日志处理 集群脚本 服务器搭建(tomcat) sed替换json文件 awk按某一列把文件分成多个文件 替换文本内容(sed替换的文本不能有命令分隔符) 计算时间",content:'# 常用命令\n\n# 批量移动指定文件\n\n将文件粘贴到 selected.txt 中，使用 Unix 换行符号\n\nfor file in $(cat selected.txt); do mv "$file" selected/; done\n\n\n# 批量移动/拷贝文件\n\n# （递归）查找aaa目录下所有jpg、pdf、png文件，并拷贝到bbb目录\nfind ./aaa -type f \\( -iname \'*.jpg\' -o -iname \'*.pdf\' -o -iname \'*.png\' \\) -exec cp {} bbb \\;\n\n\n# 批量杀死进程\n\nps -ef|grep java|grep -v grep|awk \'{print $2}\'|xargs kill\n\n\n# 查看目录大小\n\n# 查看当前目录及下级目录大小，按大小排序\ndu -h --max-depth=1 . | sort -hr\n# 查看当前目录下所有文件和目录的详细大小\ndu -ah --max-depth=1 | sort -hr\n\n\n\n# 工具\n\n----------------------------------------\n\n\n# 日志处理\n\n#!/bin/bash\nset -e\n\nif [ ! -n "$1" ];then\n        pre_date=`date -d "-1 day now" +%Y-%m-%d`\nelse\n        pre_date=`date -d "$1" +%Y-%m-%d`\nfi\necho "===============处理日志的日期为========================="$pre_date\n\n\nparent_dir=`date -d "$pre_date" +%Y-%m`\npath="/pp/pp-etl-1.0/log/$parent_dir/$pre_date"\nreg1="进度[0-9]{3,}\\.[0-9]{2}%"\nreg2=".*([0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}).*\\[INFO\\] ([a-z|A-Z]+)，(.*_V1).*插入([0-9]+).*更新([0-9]+).*进度([0-9]{3,}\\.[0-9]{2})%.*更新至([0-9]{4}-[0-9]{2}-[0-9]{2})。"\nfile="/home/xxx/tag.sql"\n\n\n# 判断目录存不存在\necho "=========日志路径为 $path=========="\nif [ ! -d "$path" ];then\n\techo "该日期目录不存在，退出程序..."\n\texit 1\nfi\n\nif [ `ls $path/custom*.log|wc -l` -eq 0 ];then\n\techo "没有需要的日志文件，退出程序..."\n\texit 1\nelse\n\tgrep -E $reg1 "$path/"custom*.log | sed -E "s#$reg2#insert into xxx(xx, xx, xx, xx, xx, xx, xx) values(\'\\1\',\'\\2\',\'\\3\',\\4,\\5,\\6,\'\\7\');#g" > "$file"\nfi\n\n# 判断文件是否存在\nif [ ! -f "$file" ];then\n\texit 1\nfi\n# 双引号替换为单引号\nsed -i "s/\\"/\'/g" "$file"\n\n# 取文件名 -Djava.security.egd=file:/dev/random \njava -Dfile=tag.sql -jar xxx.jar\nif [ $? -ne 0 ];then\n\techo "执行失败,退出..."\nelse\n\t#rm -f "$file"\n\techo "执行成功，退出..."\nfi\n\n\n\n# 集群脚本\n\n启动集群\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nsource /etc/profile\necho ===================集群开始启动====================\necho -------------------启动zk节点---------------------\nfor((host=101; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/zookeeper-3.5.7/bin/zkServer.sh start\'\ndone\necho -------------------启动dfs集群-------------\nssh $user@hadoop101 \'/soft/module/hadoop-2.9.2/sbin/start-dfs.sh\'\necho -------------------启动hbase集群-----------\nssh $user@hadoop100 \'/soft/module/hbase/bin/start-hbase.sh\'\necho -------------------启动hbase备份master--------------\nssh $user@hadoop101 \'/soft/module/hbase/bin/hbase-daemon.sh start master\'\n\n\n停止集群\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nsource /etc/profile\necho ===================集群开始关闭====================\necho -------------------关闭hbase备份master--------------\nssh $user@hadoop101 \'/soft/module/hbase/bin/hbase-daemon.sh stop master\'\necho -------------------关闭hbase集群-----------\nssh $user@hadoop100 \'/soft/module/hbase/bin/stop-hbase.sh\'\necho -------------------关闭dfs集群-------------\nssh $user@hadoop101 \'/soft/module/hadoop-2.9.2/sbin/stop-dfs.sh\'\necho -------------------关闭zk节点---------------------\nfor((host=101; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/zookeeper-3.5.7/bin/zkServer.sh stop\'\ndone\n\n\njps查看进程\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nfor((host=100; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/jdk1.8.0_161/bin/jps\'\ndone\n\n\n提示\n\nshell脚本执行的过程中，登录shell 和非登录shell 读取的环境配置文件不同。 登录shell 会读取 /etc/profile, ~/.bash_profile,~/.bash_login ,~/.profile等文件，而非登录shell 读取的脚本有 /etc/bashrc 和 ~/.bashrc ，像java，path 这些环境变量读取不到。 解决方法： 1.将/etc/profile文件写入 ~/.bashrc ;cat /etc/profile >~/.bashrc 2.把profile的配置信息echo到.bashrc中echo \'source /etc/profile\' >> ~/.bashrc\n\n\n# 服务器搭建(tomcat)\n\n环境变量\n\n## java\nJAVA_HOME=/soft/jdk1.8.0_161\nCLASSPATH=%JAVA_HOME%/lib:%JAVA_HOME%/jre/lib\nPATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin\n\n## maven\nexport MAVEN_HOME=/soft/apache-maven-3.6.3\nexport PATH=$MAVEN_HOME/bin:$PATH\n\n## tomcat\nCATALINA_HOME=/soft/apache-tomcat-9.0.41\n\n\ntomcat\n\nsh startup.sh（启动tomcat命令）\n关闭tomcat命令：\nsh /usr/local/tomcat7/bin/shutdown.sh\n\nps -ef|grep java\n查询端口是否有进程守护用如下命令grep对应端口，如8088为端口号\n例：netstat -nalp|grep 8080\n\n#停止firewall\nsystemctl stop firewalld.service \n \n#开启firewall\nsystemctl start firewalld.service\n \n#禁止firewall开机启动\nsystemctl disable firewalld.service \n \n#查看默认防火墙状态（关闭后显示not running，开启后显示running）\nfirewall-cmd --state\n\n开放指定端口\nfirewall-cmd --zone=public --add-port=8080/tcp --permanent\n 命令含义：\n--zone #作用域\n--add-port=1935/tcp  #添加端口，格式为：端口/通讯协议\n--permanent  #永久生效，没有此参数重启后失效\n\n可以通过"netstat -anp" 来查看哪些端口被打开\n然后可以通过"lsof -i:$PORT"查看应用该端口的程序（$PORT指对应的端口号）。或者你也可以查看文件/etc/services，从里面可以找出端口所对应的服务。\n\n\nLinux Tomcat启动慢\n\n方案1：通过rng-tools自动补充熵池（推荐）\n\n安装rng服务并启动，然后修改它的配置文件\nyum install rng-tools -y\nsystemctl start rngd\ncp /usr/lib/systemd/system/rngd.service /etc/systemd/system\ncd /etc/systemd/system/\n\nvim rngd.service \n将 ExecStart=/sbin/rngd -f 改为 ExecStart=/sbin/rngd -f -r /dev/urandom\n重新加载后，再重启服务\nsystemctl daemon-reload  \nsystemctl restart rngd\n\n\n\n# sed替换json文件\n\n##########准备参数########################\nfilename=`cat "json.properties"|grep \'filename\'|awk -F \'==\' \'{print $2}\'`          #字段文件名\nparameter_name=`cat "json.properties"|grep \'parameter_name\'|awk -F \'==\' \'{print $2}\'`     #分区参数\nmysql_col=`cat "json.properties"|grep \'mysql_col\'|awk -F \'==\' \'{print $2}\'`             #mysql对应字段名\nhdfs_table=`cat "json.properties"|grep \'hdfs_table\'|awk -F \'==\' \'{print $2}\'`                   #hdfs表名\nmysql_table=`cat "json.properties"|grep \'mysql_table\'|awk -F \'==\' \'{print $2}\'`                 #mysql对应表名\nhdfs_path=`cat "json.properties"|grep \'hdfs_path\'|awk -F \'==\' \'{print $2}\'`\n\necho "$filename===$parameter_name===$mysql_col===$hdfs_table===$mysql_table===${hdfs_path}"\n\n########拼接字符串####################\nsh create_column.sh $filename $parameter_name $mysql_col #"字段文件名" "分区参数" "mysql分区字段"\nfilename="hdfs_mysql_${hdfs_table}.json"\n########替换文件#########################\ncp "template.json" "json/${filename}"\ncd json\nsed -i "s#hdfscolumns#$(cat \'../hdfscolumn\')#g" $filename\nsed -i "s#mysqlcolumns#$(cat \'../mysqlcolumn\')#g" $filename\nsed -i "s#hdfspath#${hdfs_path}#g" $filename\nsed -i "s#mysqltablename#${mysql_table}#g" $filename\nsed -i "s#parameter_name#${parameter_name}#g" $filename\nsed -i "s#mysqlcol#${mysql_col}#g" $filename\ncd -\n\n\nrm -f "hdfscolumn"\nrm -f "mysqlcolumn"\nfor i in $(cat $1)\ndo\n        array=(${i//|/ })\n        #`echo ${array[0]}\n        # echo ${array[1]}\n        echo -n "{\\"index\\" : \\"${array[0]}\\",\\"type\\" : \\"${array[1]}\\"}," >> hdfscolumn\n\n        echo -n "\\"${array[2]}\\"," >> mysqlcolumn\ndone\n\necho -n "{\\"value\\" : \\"$2\\",\\"type\\" : \\"string\\"}" >> hdfscolumn\n\necho -n "\\"$3\\"" >> mysqlcolumn\n\n\n\n# awk按某一列把文件分成多个文件\n\nsed \'s/\\t/\\x01/g\' "data.csv" > "new_data.txt"\nfor idate in 2020-12-08 2020-12-07\ndo\n    awk \'BEGIN{FS="\\\\\\x01";var="\'${idate}\'";re="^\'${idate}\'"} $3~re{print $1"\\t"$2"\\t"$3>var".txt"}\' new_data.csv\n    # hdfs dfs -put\ndone\n\n\n# awk 获取某列长度大于20的行(筛选)\nawk -F, \'{if(length($1)>20) print $0}\'  xxx.csv\n\n\n\n# 替换文本内容(sed替换的文本不能有命令分隔符)\n\nfor i in $(cat filename.txt)\ndo\n        array=(${i//,/ })\n        #`echo ${array[0]}\n        # echo ${array[1]}\n        cp template.sh 1216/${array[1]}\n        sed -i "s#httpsed#${array[0]}#g" 1216/${array[1]}\ndone\n\n##\nfor filename in $(cat "filename.txt")\ndo\n    #echo $filename\n    filename_temp=${filename/"dwa"/"cio"}\n    echo $filename_temp\n    mv $filename $filename_temp\n    sed -i \'s/dwa/cio/g\' $filename_temp\ndone\n\n##\nfor CLASSIFY_DESC in 1002 1003 1004 1005 1006 1007 1008 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 3001 3002 3003 3004 3007 3008 3009 3010 3011 4002 4003 4004 4005 4006 4007\ndo\n   filename1="cio_cp_ctyun_website_index_day_1001_1.0.0.0.sql"\n   filename2=${filename1/1001/"${CLASSIFY_DESC}"}\n   echo $filename2\n   cp ${filename1} ${filename2}\n   sed -i s/CLASSIFY_DESC/"${CLASSIFY_DESC}"/g ${filename2} \ndone\n\n\n\n# 计算时间\n\ninput_date_time=$(date -d "2020-10-23 03:48:25" \'+%Y-%m-%d %H:%M:%S\')\nMONTH_ID=${input_date_time:0:7}\nPRE_MONTH_ID=$(date -d "${MONTH_ID}-01  -1 month" +%Y-%m)\n\nPRE_2MONTH_ID=$(date -d "${MONTH_ID}-01  -2 month" +%Y-%m)\nPRE_3MONTH_ID=$(date -d "${MONTH_ID}-01  -3 month" +%Y-%m)\nPRE_4MONTH_ID=$(date -d "${MONTH_ID}-01  -4 month" +%Y-%m)\nPRE_5MONTH_ID=$(date -d "${MONTH_ID}-01  -5 month" +%Y-%m)\nNEXT_MONTH=$(date -d "${MONTH_ID}-01  +1 month" +%Y-%m)\nLAST_DAY_MONTH=$(date -d "${NEXT_MONTH}-01 -1 days" +%Y-%m-%d)\nFIRST_DAY_MONTH=$(date -d "${MONTH_ID}-01" +%Y-%m-%d)\nFIRST_DAY_PRE_MONTH=$(date -d "${MONTH_ID}-01  -1 month" +%Y-%m-%d)\nFIRST_DAY_PRE_2MONTH=$(date -d "${MONTH_ID}-01  -2 month" +%Y-%m-%d)\nFIRST_DAY_PRE_3MONTH=$(date -d "${MONTH_ID}-01  -3 month" +%Y-%m-%d)\nFIRST_DAY_PRE_4MONTH=$(date -d "${MONTH_ID}-01  -4 month" +%Y-%m-%d)\n\necho "PRE_MONTH_ID : ${PRE_MONTH_ID}"\necho "PRE_2MONTH_ID : ${PRE_2MONTH_ID}"\necho "PRE_3MONTH_ID : ${PRE_3MONTH_ID}"\necho "PRE_4MONTH_ID : ${PRE_4MONTH_ID}"\necho "PRE_5MONTH_ID : ${PRE_5MONTH_ID}"\necho "LAST_DAY_MONTH : ${LAST_DAY_MONTH}"\necho "FIRST_DAY_MONTH : ${FIRST_DAY_MONTH}"\necho "FIRST_DAY_PRE_MONTH : ${FIRST_DAY_PRE_MONTH}"\necho "FIRST_DAY_PRE_2MONTH : ${FIRST_DAY_PRE_2MONTH}"\necho "FIRST_DAY_PRE_3MONTH : ${FIRST_DAY_PRE_3MONTH}"\necho "FIRST_DAY_PRE_4MONTH : ${FIRST_DAY_PRE_4MONTH}"\n',normalizedContent:'# 常用命令\n\n# 批量移动指定文件\n\n将文件粘贴到 selected.txt 中，使用 unix 换行符号\n\nfor file in $(cat selected.txt); do mv "$file" selected/; done\n\n\n# 批量移动/拷贝文件\n\n# （递归）查找aaa目录下所有jpg、pdf、png文件，并拷贝到bbb目录\nfind ./aaa -type f \\( -iname \'*.jpg\' -o -iname \'*.pdf\' -o -iname \'*.png\' \\) -exec cp {} bbb \\;\n\n\n# 批量杀死进程\n\nps -ef|grep java|grep -v grep|awk \'{print $2}\'|xargs kill\n\n\n# 查看目录大小\n\n# 查看当前目录及下级目录大小，按大小排序\ndu -h --max-depth=1 . | sort -hr\n# 查看当前目录下所有文件和目录的详细大小\ndu -ah --max-depth=1 | sort -hr\n\n\n\n# 工具\n\n----------------------------------------\n\n\n# 日志处理\n\n#!/bin/bash\nset -e\n\nif [ ! -n "$1" ];then\n        pre_date=`date -d "-1 day now" +%y-%m-%d`\nelse\n        pre_date=`date -d "$1" +%y-%m-%d`\nfi\necho "===============处理日志的日期为========================="$pre_date\n\n\nparent_dir=`date -d "$pre_date" +%y-%m`\npath="/pp/pp-etl-1.0/log/$parent_dir/$pre_date"\nreg1="进度[0-9]{3,}\\.[0-9]{2}%"\nreg2=".*([0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}).*\\[info\\] ([a-z|a-z]+)，(.*_v1).*插入([0-9]+).*更新([0-9]+).*进度([0-9]{3,}\\.[0-9]{2})%.*更新至([0-9]{4}-[0-9]{2}-[0-9]{2})。"\nfile="/home/xxx/tag.sql"\n\n\n# 判断目录存不存在\necho "=========日志路径为 $path=========="\nif [ ! -d "$path" ];then\n\techo "该日期目录不存在，退出程序..."\n\texit 1\nfi\n\nif [ `ls $path/custom*.log|wc -l` -eq 0 ];then\n\techo "没有需要的日志文件，退出程序..."\n\texit 1\nelse\n\tgrep -e $reg1 "$path/"custom*.log | sed -e "s#$reg2#insert into xxx(xx, xx, xx, xx, xx, xx, xx) values(\'\\1\',\'\\2\',\'\\3\',\\4,\\5,\\6,\'\\7\');#g" > "$file"\nfi\n\n# 判断文件是否存在\nif [ ! -f "$file" ];then\n\texit 1\nfi\n# 双引号替换为单引号\nsed -i "s/\\"/\'/g" "$file"\n\n# 取文件名 -djava.security.egd=file:/dev/random \njava -dfile=tag.sql -jar xxx.jar\nif [ $? -ne 0 ];then\n\techo "执行失败,退出..."\nelse\n\t#rm -f "$file"\n\techo "执行成功，退出..."\nfi\n\n\n\n# 集群脚本\n\n启动集群\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nsource /etc/profile\necho ===================集群开始启动====================\necho -------------------启动zk节点---------------------\nfor((host=101; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/zookeeper-3.5.7/bin/zkserver.sh start\'\ndone\necho -------------------启动dfs集群-------------\nssh $user@hadoop101 \'/soft/module/hadoop-2.9.2/sbin/start-dfs.sh\'\necho -------------------启动hbase集群-----------\nssh $user@hadoop100 \'/soft/module/hbase/bin/start-hbase.sh\'\necho -------------------启动hbase备份master--------------\nssh $user@hadoop101 \'/soft/module/hbase/bin/hbase-daemon.sh start master\'\n\n\n停止集群\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nsource /etc/profile\necho ===================集群开始关闭====================\necho -------------------关闭hbase备份master--------------\nssh $user@hadoop101 \'/soft/module/hbase/bin/hbase-daemon.sh stop master\'\necho -------------------关闭hbase集群-----------\nssh $user@hadoop100 \'/soft/module/hbase/bin/stop-hbase.sh\'\necho -------------------关闭dfs集群-------------\nssh $user@hadoop101 \'/soft/module/hadoop-2.9.2/sbin/stop-dfs.sh\'\necho -------------------关闭zk节点---------------------\nfor((host=101; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/zookeeper-3.5.7/bin/zkserver.sh stop\'\ndone\n\n\njps查看进程\n\n#!/bin/bash\n# 获取当前用户名称\nuser=`whoami`\nfor((host=100; host<=103; host++)); do\n        echo ------------------- hadoop$host --------------\n        ssh $user@hadoop$host \'/soft/module/jdk1.8.0_161/bin/jps\'\ndone\n\n\n提示\n\nshell脚本执行的过程中，登录shell 和非登录shell 读取的环境配置文件不同。 登录shell 会读取 /etc/profile, ~/.bash_profile,~/.bash_login ,~/.profile等文件，而非登录shell 读取的脚本有 /etc/bashrc 和 ~/.bashrc ，像java，path 这些环境变量读取不到。 解决方法： 1.将/etc/profile文件写入 ~/.bashrc ;cat /etc/profile >~/.bashrc 2.把profile的配置信息echo到.bashrc中echo \'source /etc/profile\' >> ~/.bashrc\n\n\n# 服务器搭建(tomcat)\n\n环境变量\n\n## java\njava_home=/soft/jdk1.8.0_161\nclasspath=%java_home%/lib:%java_home%/jre/lib\npath=$path:$java_home/bin:$java_home/jre/bin\n\n## maven\nexport maven_home=/soft/apache-maven-3.6.3\nexport path=$maven_home/bin:$path\n\n## tomcat\ncatalina_home=/soft/apache-tomcat-9.0.41\n\n\ntomcat\n\nsh startup.sh（启动tomcat命令）\n关闭tomcat命令：\nsh /usr/local/tomcat7/bin/shutdown.sh\n\nps -ef|grep java\n查询端口是否有进程守护用如下命令grep对应端口，如8088为端口号\n例：netstat -nalp|grep 8080\n\n#停止firewall\nsystemctl stop firewalld.service \n \n#开启firewall\nsystemctl start firewalld.service\n \n#禁止firewall开机启动\nsystemctl disable firewalld.service \n \n#查看默认防火墙状态（关闭后显示not running，开启后显示running）\nfirewall-cmd --state\n\n开放指定端口\nfirewall-cmd --zone=public --add-port=8080/tcp --permanent\n 命令含义：\n--zone #作用域\n--add-port=1935/tcp  #添加端口，格式为：端口/通讯协议\n--permanent  #永久生效，没有此参数重启后失效\n\n可以通过"netstat -anp" 来查看哪些端口被打开\n然后可以通过"lsof -i:$port"查看应用该端口的程序（$port指对应的端口号）。或者你也可以查看文件/etc/services，从里面可以找出端口所对应的服务。\n\n\nlinux tomcat启动慢\n\n方案1：通过rng-tools自动补充熵池（推荐）\n\n安装rng服务并启动，然后修改它的配置文件\nyum install rng-tools -y\nsystemctl start rngd\ncp /usr/lib/systemd/system/rngd.service /etc/systemd/system\ncd /etc/systemd/system/\n\nvim rngd.service \n将 execstart=/sbin/rngd -f 改为 execstart=/sbin/rngd -f -r /dev/urandom\n重新加载后，再重启服务\nsystemctl daemon-reload  \nsystemctl restart rngd\n\n\n\n# sed替换json文件\n\n##########准备参数########################\nfilename=`cat "json.properties"|grep \'filename\'|awk -f \'==\' \'{print $2}\'`          #字段文件名\nparameter_name=`cat "json.properties"|grep \'parameter_name\'|awk -f \'==\' \'{print $2}\'`     #分区参数\nmysql_col=`cat "json.properties"|grep \'mysql_col\'|awk -f \'==\' \'{print $2}\'`             #mysql对应字段名\nhdfs_table=`cat "json.properties"|grep \'hdfs_table\'|awk -f \'==\' \'{print $2}\'`                   #hdfs表名\nmysql_table=`cat "json.properties"|grep \'mysql_table\'|awk -f \'==\' \'{print $2}\'`                 #mysql对应表名\nhdfs_path=`cat "json.properties"|grep \'hdfs_path\'|awk -f \'==\' \'{print $2}\'`\n\necho "$filename===$parameter_name===$mysql_col===$hdfs_table===$mysql_table===${hdfs_path}"\n\n########拼接字符串####################\nsh create_column.sh $filename $parameter_name $mysql_col #"字段文件名" "分区参数" "mysql分区字段"\nfilename="hdfs_mysql_${hdfs_table}.json"\n########替换文件#########################\ncp "template.json" "json/${filename}"\ncd json\nsed -i "s#hdfscolumns#$(cat \'../hdfscolumn\')#g" $filename\nsed -i "s#mysqlcolumns#$(cat \'../mysqlcolumn\')#g" $filename\nsed -i "s#hdfspath#${hdfs_path}#g" $filename\nsed -i "s#mysqltablename#${mysql_table}#g" $filename\nsed -i "s#parameter_name#${parameter_name}#g" $filename\nsed -i "s#mysqlcol#${mysql_col}#g" $filename\ncd -\n\n\nrm -f "hdfscolumn"\nrm -f "mysqlcolumn"\nfor i in $(cat $1)\ndo\n        array=(${i//|/ })\n        #`echo ${array[0]}\n        # echo ${array[1]}\n        echo -n "{\\"index\\" : \\"${array[0]}\\",\\"type\\" : \\"${array[1]}\\"}," >> hdfscolumn\n\n        echo -n "\\"${array[2]}\\"," >> mysqlcolumn\ndone\n\necho -n "{\\"value\\" : \\"$2\\",\\"type\\" : \\"string\\"}" >> hdfscolumn\n\necho -n "\\"$3\\"" >> mysqlcolumn\n\n\n\n# awk按某一列把文件分成多个文件\n\nsed \'s/\\t/\\x01/g\' "data.csv" > "new_data.txt"\nfor idate in 2020-12-08 2020-12-07\ndo\n    awk \'begin{fs="\\\\\\x01";var="\'${idate}\'";re="^\'${idate}\'"} $3~re{print $1"\\t"$2"\\t"$3>var".txt"}\' new_data.csv\n    # hdfs dfs -put\ndone\n\n\n# awk 获取某列长度大于20的行(筛选)\nawk -f, \'{if(length($1)>20) print $0}\'  xxx.csv\n\n\n\n# 替换文本内容(sed替换的文本不能有命令分隔符)\n\nfor i in $(cat filename.txt)\ndo\n        array=(${i//,/ })\n        #`echo ${array[0]}\n        # echo ${array[1]}\n        cp template.sh 1216/${array[1]}\n        sed -i "s#httpsed#${array[0]}#g" 1216/${array[1]}\ndone\n\n##\nfor filename in $(cat "filename.txt")\ndo\n    #echo $filename\n    filename_temp=${filename/"dwa"/"cio"}\n    echo $filename_temp\n    mv $filename $filename_temp\n    sed -i \'s/dwa/cio/g\' $filename_temp\ndone\n\n##\nfor classify_desc in 1002 1003 1004 1005 1006 1007 1008 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 3001 3002 3003 3004 3007 3008 3009 3010 3011 4002 4003 4004 4005 4006 4007\ndo\n   filename1="cio_cp_ctyun_website_index_day_1001_1.0.0.0.sql"\n   filename2=${filename1/1001/"${classify_desc}"}\n   echo $filename2\n   cp ${filename1} ${filename2}\n   sed -i s/classify_desc/"${classify_desc}"/g ${filename2} \ndone\n\n\n\n# 计算时间\n\ninput_date_time=$(date -d "2020-10-23 03:48:25" \'+%y-%m-%d %h:%m:%s\')\nmonth_id=${input_date_time:0:7}\npre_month_id=$(date -d "${month_id}-01  -1 month" +%y-%m)\n\npre_2month_id=$(date -d "${month_id}-01  -2 month" +%y-%m)\npre_3month_id=$(date -d "${month_id}-01  -3 month" +%y-%m)\npre_4month_id=$(date -d "${month_id}-01  -4 month" +%y-%m)\npre_5month_id=$(date -d "${month_id}-01  -5 month" +%y-%m)\nnext_month=$(date -d "${month_id}-01  +1 month" +%y-%m)\nlast_day_month=$(date -d "${next_month}-01 -1 days" +%y-%m-%d)\nfirst_day_month=$(date -d "${month_id}-01" +%y-%m-%d)\nfirst_day_pre_month=$(date -d "${month_id}-01  -1 month" +%y-%m-%d)\nfirst_day_pre_2month=$(date -d "${month_id}-01  -2 month" +%y-%m-%d)\nfirst_day_pre_3month=$(date -d "${month_id}-01  -3 month" +%y-%m-%d)\nfirst_day_pre_4month=$(date -d "${month_id}-01  -4 month" +%y-%m-%d)\n\necho "pre_month_id : ${pre_month_id}"\necho "pre_2month_id : ${pre_2month_id}"\necho "pre_3month_id : ${pre_3month_id}"\necho "pre_4month_id : ${pre_4month_id}"\necho "pre_5month_id : ${pre_5month_id}"\necho "last_day_month : ${last_day_month}"\necho "first_day_month : ${first_day_month}"\necho "first_day_pre_month : ${first_day_pre_month}"\necho "first_day_pre_2month : ${first_day_pre_2month}"\necho "first_day_pre_3month : ${first_day_pre_3month}"\necho "first_day_pre_4month : ${first_day_pre_4month}"\n',charsets:{cjk:!0},lastUpdated:"2025/06/27, 12:02:59",lastUpdatedTimestamp:1750996979e3},{title:"语法学习",frontmatter:{title:"语法学习",date:"2022-03-02T11:06:24.000Z",permalink:"/pages/c917bd/",categories:["其他","Scala"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/03.Scala/01.%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0.html",relativePath:"04.其他/03.Scala/01.语法学习.md",key:"v-412d7d01",path:"/pages/c917bd/",headers:[{level:2,title:"Scala中,一切皆为对象",slug:"scala中-一切皆为对象",normalizedTitle:"scala中,一切皆为对象",charIndex:2},{level:2,title:"需要注意的",slug:"需要注意的",normalizedTitle:"需要注意的",charIndex:20},{level:2,title:"运算符",slug:"运算符",normalizedTitle:"运算符",charIndex:460},{level:2,title:"字符串函数",slug:"字符串函数",normalizedTitle:"字符串函数",charIndex:648},{level:2,title:"流程控制语句",slug:"流程控制语句",normalizedTitle:"流程控制语句",charIndex:700},{level:2,title:"方法和函数",slug:"方法和函数",normalizedTitle:"方法和函数",charIndex:2562},{level:3,title:"1.普通方法",slug:"_1-普通方法",normalizedTitle:"1.普通方法",charIndex:2614},{level:3,title:"2.递归方法",slug:"_2-递归方法",normalizedTitle:"2.递归方法",charIndex:2939},{level:3,title:"3.带默认参数的方法",slug:"_3-带默认参数的方法",normalizedTitle:"3.带默认参数的方法",charIndex:3129},{level:3,title:"4.可变长参数的方法",slug:"_4-可变长参数的方法",normalizedTitle:"4.可变长参数的方法",charIndex:3254},{level:3,title:"5.匿名函数",slug:"_5-匿名函数",normalizedTitle:"5.匿名函数",charIndex:3537},{level:3,title:"6.嵌套函数",slug:"_6-嵌套函数",normalizedTitle:"6.嵌套函数",charIndex:3653},{level:3,title:"7.偏应用函数",slug:"_7-偏应用函数",normalizedTitle:"7.偏应用函数",charIndex:3813},{level:3,title:"8.高阶函数",slug:"_8-高阶函数",normalizedTitle:"8.高阶函数",charIndex:4196},{level:3,title:"9.柯里化函数",slug:"_9-柯里化函数",normalizedTitle:"9.柯里化函数",charIndex:5725},{level:2,title:"数组",slug:"数组",normalizedTitle:"数组",charIndex:421},{level:2,title:"元组",slug:"元组",normalizedTitle:"元组",charIndex:157},{level:2,title:"链表List",slug:"链表list",normalizedTitle:"链表list",charIndex:8277},{level:2,title:"Map",slug:"map",normalizedTitle:"map",charIndex:448},{level:2,title:"Set",slug:"set",normalizedTitle:"set",charIndex:10179},{level:2,title:"类继承和伴生对象",slug:"类继承和伴生对象",normalizedTitle:"类继承和伴生对象",charIndex:12935},{level:2,title:"模式匹配和样例类",slug:"模式匹配和样例类",normalizedTitle:"模式匹配和样例类",charIndex:14252},{level:2,title:"Scala 下划线(_) 用法汇总",slug:"scala-下划线-用法汇总",normalizedTitle:"scala 下划线(_) 用法汇总",charIndex:16406},{level:3,title:"1.导包时的通配符",slug:"_1-导包时的通配符",normalizedTitle:"1.导包时的通配符",charIndex:16470},{level:3,title:"2.Scala类中成员变量初始化",slug:"_2-scala类中成员变量初始化",normalizedTitle:"2.scala类中成员变量初始化",charIndex:16533},{level:3,title:"3.类型通配符",slug:"_3-类型通配符",normalizedTitle:"3.类型通配符",charIndex:16623},{level:3,title:"4.可变参数",slug:"_4-可变参数",normalizedTitle:"4.可变参数",charIndex:16939},{level:3,title:"5.模式匹配",slug:"_5-模式匹配",normalizedTitle:"5.模式匹配",charIndex:17307},{level:3,title:"6.将函数赋给变量",slug:"_6-将函数赋给变量",normalizedTitle:"6.将函数赋给变量",charIndex:18103},{level:3,title:"7.访问Tuple元素",slug:"_7-访问tuple元素",normalizedTitle:"7.访问tuple元素",charIndex:18268},{level:3,title:"8.参数展开",slug:"_8-参数展开",normalizedTitle:"8.参数展开",charIndex:18347},{level:3,title:"9.其它用法——简化函数",slug:"_9-其它用法-简化函数",normalizedTitle:"9.其它用法——简化函数",charIndex:18628}],headersStr:"Scala中,一切皆为对象 需要注意的 运算符 字符串函数 流程控制语句 方法和函数 1.普通方法 2.递归方法 3.带默认参数的方法 4.可变长参数的方法 5.匿名函数 6.嵌套函数 7.偏应用函数 8.高阶函数 9.柯里化函数 数组 元组 链表List Map Set 类继承和伴生对象 模式匹配和样例类 Scala 下划线(_) 用法汇总 1.导包时的通配符 2.Scala类中成员变量初始化 3.类型通配符 4.可变参数 5.模式匹配 6.将函数赋给变量 7.访问Tuple元素 8.参数展开 9.其它用法——简化函数",content:'# Scala中,一切皆为对象\n\n\n# 需要注意的\n\n----------------------------------------\n\n * 定义多个变量 var (i,j,temp) = (1, 0, 0)\n * 记住: 除了循环都没有返回值,其余都有返回值\n * 函数化编程: 函数即参数\n\n//例如 (遍历元组)\ntuple22.productIterator.foreach(i => print(i + " "))\n\n\n * break语句\n\n// 创建 Breaks 对象\nval loop = new Breaks;\n// 在 breakable 中循环\nloop.breakable{\n    // 循环\n    for(...){\n       ....\n       // 循环中断\n       loop.break;\n   }\n}\n\n\n * foreach和迭代器的区别\n\nforeach遍历元素类型相同的 (例如 数组) 迭代器用来遍历元素类型不同的 (例如 元组. Map集合?)\n\n\n# 运算符\n\n----------------------------------------\n\nobject MyScala{\n    def main(args:ArrayString]){\n        val num:Int = 195\n        println(s"${num<<2}\\r${num>>2}\\r${num>>>2}")\n    }\n}\n\n\n\n# 字符串函数\n\n----------------------------------------\n\n\n# 流程控制语句\n\n----------------------------------------\n\npackage com.hrbu.nscala\n\nimport scala.io.StdIn\n\nobject ControlStatement {\n  \n  def test1(): Any = {\n    val in = StdIn.readLine("请输入: ")\n    //用if实现java三元表达式\n    println(if(in.isInstanceOf[Int]) in.toString() else "字符串:" + in )\n    \n    return if(in.isInstanceOf[Int]) in.toString() else in\n  }\n  \n  def test2():Any = {\n    print("请输入:")\n    val in = StdIn.readInt()\n    return if(in.isInstanceOf[Int]){\n      println("类型正确")\n    } else{\n      println("类型不正确")\n    }\n    \n  }\n  \n  /*\n   * 2.to and until\n   */\n  def test3{\n    val r1 = 1 to 10\n    val r2 = 1 until 10\n    val r3 = 1 to (10,2)\t\t// a.步长\n    println(r1 + "\\n" + r2 + "\\n" + r3)\n  }\n    \n\n    /*\n     * 3.循环语句\n     * a.for\n     */\n  def test4{\n    for (i <- 1 to 4) {\n      println(i)\n    }\n  \n      //乘法表\n      /*for(i<- 1 until 10){\n        for(j<- 1 until 10){\n          if(i>=j){\n            print(s"$i * $j=" + i*j + "\\t")\n          }\n          if(i==j){\n            println()\n          }\n        }\n      }*/\n      //简化\n      /*for(i<- 1 until 10;j<- 1 until 10){\n          if(i>=j){\n            print(s"$i * $j=" + i*j + "\\t")\n          }\n          if(i==j){\n            println()\n          }\n      }*/\n    }\n    /**\n     * while\n     * do...while\n     */\n    def test5{\n      var b: Int = 0\n      while (b < 10) {\n        println(s"第$b 次求婚") //r 注意$b后一定有空格\n        b += 1\n      }\n    }\n\n    /**\n     * 4.yield关键字：记住每次迭代中的有关值，并逐一存入到一个数组\n     * 5.循环过滤 （遍历数组）\n     */\n    def test6{\n      val result = for { i <- 1 to 100 if (i > 50) if (i % 5 == 0) } yield i\n      //val result = for(i<- 1 to 100 if(i>50) if(i%5==0)) yield i\n      println(result)\n    }\n  \n  def main(args: Array[String]): Unit = {\n    println("test1返回: " + test1())\n    \n    println("test2返回值: " + test2())\n    \n    println("println语句返回值:" + println("nicai"))\n    \n  }\n}\n\n\n\n# 方法和函数\n\n----------------------------------------\n\n\n# 1.普通方法\n\ndef 方法名 (参数:参数类型):方法返回值={函数体}\n\ndef max1(a:Int,b:Int):Int={\n      if(a>b){\n        return a\n      } else{\n        println("b>a")\n        return b\n      }\n    }\nprintln("max1=" + max1(b=69, a=35))\n/*****简化上面的方法**方法体如果可以一行搞定，可去掉{}*****/\ndef max1_1(a:Int,b:Int) = if(a>b) a else b\nprintln("max1.1=" + max1_1(12, 9))\n\n\n\n# 2.递归方法\n\n递归方法要显式的指定函数的返回值类型\n\ndef factorial(num:Int):Int = {\n      if(num == 1){\n        1\n      } else {\n        num * factorial(num-1)\n      }\n    }\nprintln(s"5的阶乘为:  ${factorial(5)}")\n\n\n\n# 3.带默认参数的方法\n\ndef max3(a:Int=69, b:Int=66) = if (a>b) a else b\nprintln("max3= " + max3())\nprintln("max3= " + max3(b=100))\n\n\n\n# 4.可变长参数的方法\n\ndef showStr(str:String*){\n  for(elem <- str){\n    print(elem)\n  }\n}\nshowStr("Hello", " ", "Scala", "\\r");\nshowStr("长河落日东都城", ",", "铁马戍边将军坟", "。", "尽诛宵小天策义", ",", "长枪独守大唐魂", "。", "\\n")\n/***************方法简化**************/\ndef showStr(str:String*) = str.foreach(print)\n\n\n\n# 5.匿名函数\n\n"=>"就是匿名函数，多用于方法的参数为函数时，常用匿名函数\n\ndef max5() = (a:Int, b:Int)=>if (a>b) a else b\nprintln(max5()(11, 22))\n\n\n\n# 6.嵌套函数\n\ndef value6(num:Int):Int={\n  def factorial6(a:Int):Int = if(a == 1) 1 else a * factorial6(a - 1)\n  factorial6(num)\n}\nprintln("5的阶乘为: " + value6(5))\n\n\n\n# 7.偏应用函数\n\n某些情况下,方法中参数非常多，调用非常频繁，每次调用只有固定的一个参数变化，其它都不变，可以定义偏应用函数简化\n\n//先定义一个普通函数\ndef showLogs(date:Date, log:String) = {\n  println(s"date = $date\\tlog = $log")\n}\nval date: Date = new Date();    //注意:这里是scala变量\nshowLogs(date, "balabala")      //普通函数调用\nshowLogs(date, "hahahaha")\n\n//定义偏应用函数\ndef showLogs7 = showLogs(date:Date, _:String)\nshowLogs7("123456789")\nshowLogs7("987654321")\n\n\n\n# 8.高阶函数\n\n/**a.参数是函数的方法*/\n/*def fun8_1(a:Int,b:Int)={\n  a+b\n}*/\n\n/*def fun8_a(f:(Int,Int)=>Int,s:String) : String={\n  val i:Int = f(100,200)\n  i+"#" +s\n}\nval result1 = fun8_a((a:Int,b:Int)=>{a*b},"Scala")\nprintln(result1)*/\n\n/**b.返回值是函数的方法*/\n/*def fun8_b(s:String):(String,String)=>String={      //显示声明返回值(或最后一行写为fun _)\n  \n  def fun(s1:String,s2:String):String={\n    s1 + " " + s2 + " " +s\n  }\n  fun        //r 当返回值时不加括号\n}\n\nprintln(fun8_b("!!!")("Hello","Scala"))*/\n\n/**c.返回值和参数都是函数的方法*/\n/*def fun8_c(f:(Int,Int)=>Int):(String,String)=>String={\n  val fInt = f(1,2)\n  \n  def fun8(s1:String,s2:String):String={\n    s1 + " " + s2 + fInt.toString()\n  }\n  \n  fun9\n}\n\nprintln("返回值参数都是函数：" + fun9_c((a,b)=>{a+b})("Hello", "Scala"))*/\n\n\n1.方法的参数是函数\n\n/*a.参数是函数*/\ndef pet(pName:String, pAttack:Int): String = {\n  (s"宠物名字: ${pName}\\t宠物攻击力: ${pAttack}")\n}\ndef hero(fun:(String, Int) => String, heroName:String) = {\n  println(s"英雄名字: ${heroName}\\t${fun("龙狼王", 10000)}")\n}\nhero(pet, "琴帝")\n\n\n2.方法的返回是函数\n\n/*b.返回值为参数*/\ndef hero2(heroName:String, heroAttack:Int) : (String, Int) => String = {\n  def getMessage(pName:String, pAttack:Int) : String = {\n    (s"英雄名字: ${heroName}\\t宠物名字: ${pName}\\t攻击力: ${heroAttack + pAttack}")\n  }\n  getMessage      //注意 当返回值不加()\n}\nprintln(hero2("酒神", 10000)("阴阳冕", 8000))\n\n\n3.方法的参数和返回值都是函数\n\ndef hoFun(f:(Int,Int)=>Int):(String,String)=>String={\n  val fInt = f(1,2)\n  def fun(s1:String,s2:String):String={\n    s1 + " " + s2 + fInt.toString()\n  }\n  fun\n}\nprintln("返回值参数都是函数：" + hoFun((a,b)=>{a+b})("Hello", "Scala"))\n\n\n\n# 9.柯里化函数\n\n返回值是函数的方法的简化\n\ndef fun9(a:Int, b:Int)(c:Int, d:Int) = a + b + c + d\nprintln(fun9(250,50)(100,120))\n\n\n\n# 数组\n\n----------------------------------------\n\n/*\n   * 1.第一种定义方式\n   */\n  def ImmutableArray1{\n    val arr = Array[String]("Hello", "Scala", "Hello", "World");\n    arr.foreach(println)\n  }\n  \n  /*\n   * 2.第二种定义方式\n   */\n  def ImmutableArray2{\n    val arr = new Array[String](3);\n    arr(0) = "你好"\n    arr(1) = "世界"\n    arr(2) = "!!!"\n    //arr(3) = ""  //java.lang.ArrayIndexOutOfBoundsException\n    arr.foreach(print)\n  }\n  \n  /*\n   * 3.关于数组连接 fill方法\n   */\n  def ImmutableArray3{\n    val arr1 = Array[String]("aaa", "bbb", "ccc")\n    val arr2 = Array[String]("333", "666", "999")\n//    println(arr1.contains(arr2))\n    Array.concat(arr1, arr2).foreach(print)\n    println()\n    \n    val arr3 = Array.fill(6)("Scala")\n    arr3.foreach(print)\n  }\n  /*\n   * 4.二维数组\n   */\n  def ImmutableArray4{\n    val arr = new Array[Array[String]](3)\n    arr(0) = Array[String]("Hello", "World", "!!!")\n    arr(1) = Array[String]("Hello", "Scala")\n    arr(2) = Array[String]("Hello", "Array", "EOF")\n    for(arrTemp <- arr; str <- arrTemp){\n      print(str + "  ")\n    }\n  }\n  /*\n   * 5.可变数组   类似 java 的 ArrayList\n   */\n  def MutableArray{\n    var arr = ArrayBuffer[String]("111", "222")\n    arr.foreach(i => print(i + " "))\n//    arr.+:("+:")\n    arr.+=("+=")      //数组末插入\n    arr.+=:("+=:")    //数组首插入\n//    arr.++("++")\n//    arr.++:("++:")\n//    arr.++=(Array("...", "***"))       //用++=操作符追加任何集合\n    println()\n    arr.foreach(i => print(i + " "))\n    \n    arr.append("aaa", "bbb", "ccc")    //追加元素\n    println()\n    arr.foreach(i => print(i + " "))\n  }\n\n\n\n# 元组\n\n----------------------------------------\n\n拉链\n\npackage com.hrbu.scala\n\n/**\n * 元组\n */\nobject Scala10_Tuple {\n  def main(args: Array[String]): Unit = {\n    \n    //注意:tuple最多支持22个参数\n    /**1.创建*/\n    //val tuple = new Tuple1(1)\n    val tuple2 = Tuple2("zhangsan",2)\n    val tuple3 = Tuple3(1,2,3)\n    //val tuple4 = (1,2,3,4)\n    //val tuple18 = Tuple18(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18)\n    val tuple22 = new Tuple22(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22)\n    \n    //使用\n    /*println(tuple2._1 + "\\t"+tuple2._2)\n    val t = Tuple2((1,2),("zhangsan","lisi"))\n    println(t._1._2)*/\n    \n    \n    /***2.遍历*/\n    val tupleIterator = tuple22.productIterator\n    while(tupleIterator.hasNext){\n      println(tupleIterator.next())\n    }\n\n    /**\n     * 方法\n     */\n    //翻转，只针对二元组\n    println(tuple2.swap)\n    \n    //toString\n    println(tuple3.toString())\n\n    \n  }\n} \n\n\n\n# 链表List\n\n----------------------------------------\n\n和Java里不同，Scala中List一定是以链表方式实现的。Java中的List概念对应Scala中的Seq。 链表的特征：元素有先后之分，适合逐个访问\n\npackage com.hrbu.scala\n\nimport scala.collection.mutable.ListBuffer\n\nobject Scala7_List {\n  def main(args: Array[String]): Unit = {\n    \n    val list1 = List[Int](7,9,1,2,3,4,5,6)\n    /*for(i<-list1){\n      print(i + " ")\n    }*/\n    //list1.foreach(print)\n    /*for(i<-0 until list1.count(x=>true)){\n      print(list1(i) + " ")\n    }\n    println()*/\n    \n    /*val countList1 = list1.count(x=>x>=3)\n    println(countList1)*/\n    \n    /***********重要方法****************/\n    val list2 = List("hello world","hello scala","hello spark")\n    // 1.过滤：filter方法\n    //print(list1.filter(x=>x>=6).toString())\n    /*val list_ = list1.filter(x=>x>=6)\n    list_.foreach(println)*/\n    \n    // 2.对元素操作：map方法\n    /*val list2_  = list2.map(x=>x.split(" "))\n    for(i<-list2_;j<-i){\n      println(j)\n    }*/\n    \n    // 3.扁平化操作(压扁压平，先map再flat)：flatMap方法\n    val list2_ = list2.flatMap(x=>x.split(" "))\n    for(elem<-list2_){\n      println(elem)\n    }\n    \n    \n    /**不可变数组***/\n    /**可变数组*/\n    /*val list = ListBuffer[String]("hello","scala")\n    list.+=("aaa","bbb")\n    list.foreach(println(_))*/\n  }\n}\n\n\n\n# Map\n\n----------------------------------------\n\n/*\n* map练习 \n*/\ndef testMap{\nval map1 = Map (\n  1 -> "hello",\n  "2" -> "scala",\n  (3, "kugou")\n)\n\nprintln(map1.get("2"))\nprintln(map1.get(3))\n// 1.若没有值,赋值为getOrElse传的值\nprintln(map1.get("key").getOrElse("no value"))\n\n/****2.遍历map*******/\n//2.1 foreach 遍历\nprintln("1.foreach 遍历:")\nmap1.foreach(\n    f => println("key=" + f._1 + "\\tvalue=" + f._2)\n)\n//2.2 每次获取其中一个元组\nprintln("每次获取其中一个元组:")\nfor(elem <- map1){\n  println("key:" + elem._1 + "\\tvalue:" + elem._2)\n}\n//2.3 每次循环直接解析元组（析构）\nprintln("每次循环直接解析元组:")\nfor((key,value) <- map1){\n  println(s"key:$key\\tvalue:$value")\n}\n\n/****3.遍历key*****/\nprintln("遍历key:")\n// 1.map.keys为迭代器类型  2.keySet为Set类型\nval keyIterable = map1.keys\nfor(elem<-keyIterable){\n  println("key:" + elem + "\\tvalue:" + map1.get(elem).get)\n}\n\n/****4.遍历value****/\nprintln("遍历value")\nval valueIterable = map1.values\nfor(elem <- valueIterable){\n  println("value:" + elem)\n}\n//    valueIterable.foreach { \n//      value => println("value: " + value)\n//    }\n  \n/*****5.合并map 合并时将相同key的value替换\t********/\nval map2 = Map[Int,String](\n    (1,"hi"),\n    (2,"你好"),  //此处2为Int,上面是String\n    (3,"世界"),\n    (4,"酷狗")\n)\nprintln("map1加入到map2中")\nmap1.++(map2).foreach(println)      //map1加入到map2中\nprintln("map2加入到map1中")\nmap1.++:(map2).foreach(println)    //map2加入到map1中\n\n/****6.可变map*****/\nvar map3 = scala.collection.mutable.Map(\n    "天策" -> "长河落日东都城，铁马戍边将军坟。尽诸宵小天策义，长枪独守大唐魂。", \n    "万花" -> "春兰秋菊夏清风，三星望月挂夜空。不求独避风雨外，只笑桃源非梦中。", \n    "纯阳" -> "昆仑玄境山外山，乾坤阴阳有洞天。只问真君何处有，不向江湖寻剑仙。",\n    "七秀" -> "西子湖畔西子情，楼外楼中雨霖铃。画廊绣舫霓裳舞，小桥流水叶娉婷。",\n    "少林" -> "古刹紫竹禅钟鸣，降妖伏魔江湖行。佛音亦有豪情意，天下武功出少林！", \n    "藏剑" -> "秀水灵山隐剑踪，不闻江湖铸青锋。逍遥此身君子意，一壶温酒向长空。", \n    "五毒" -> "蛇蝎为伴蛛为邻，千蝶绕笛蛊无形。世人皆惧断肠物，不见最毒在人心。",\n    "唐门" -> "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。",\n    "苍云" -> "雪覆胡关摧冷草，风扬朔漠起狼烟。刃端百死何辞战，碧血成书白马篇。",\n    "丐帮" -> "搅动君山五十州，风尘几历尽翩遥。散罢千金未束手，餐风吞酒不寂寥。",\n    "长歌" -> "儒门有志羁风雨，失鹿山河散若星。千古文人侠客梦，肯将碧血写丹青。",\n    "霸刀" -> "寥落尘寰数十载，何曾开眼论豪英。刀光起处鲸吞海，誓将浮名敬死生。"\n)\n/*删除元素*/\n//map3.-=("唐门")\nmap3.remove("唐门")\n//map3.foreach(f => println(f._1 + ":" + f._2))\n/*增加元素*/\n//map3.+=("唐门" -> "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。")\nmap3.put("唐门", "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。")\n/*修改value*/\nmap3("苍云") = "歌起征思芦管怨，透穿玄甲朔风寒。黄泉作酒酬兄弟，战尽狂沙血未干。"\nmap3.foreach(f => println(f._1 + ":" + f._2))\n\n/*\n * 7.重要方法\n * filter:过滤，留下符合条件的记录\n * count:统计符合条件的记录数\n * contains：map中是否包含某个key\n * exist：符合条件的记录存在不存在\n */\n}\n\n\n\n# Set\n\n----------------------------------------\n\npackage com.hrbu.scala\n\nimport scala.collection.mutable.Set\n\n\nobject Scala8_Set {\n  def main(args: Array[String]): Unit = {\n    \n    // set无重复元素 \n    /*val set1 = Set("hello","scala","hello","world")\n    set1.foreach(println)*/\n    \n    val set2 = Set("hello","world","scala","spark")\n    val set3 = Set("hello","world","!!!","???","///")\n    /***********重要方法**************/\n    //1.求交集\n    /*val set_ = set2.intersect(set3)\n    for(elem<-set_){\n      println(elem)\n    }*/\n    \n    //2.求差集\n    /*val set_ = set2.diff(set3)\n    for(elem<-set_){\n      println(elem)\n    }*/\n    \n    //3.求是否是子集\n    //println(set2.subsetOf(set3))\n    \n    //4.max.min\n    //println(set2.min)\n    \n    //5.转成数组\n    /*val set_ = set2.toList\n    set_.foreach(println)\n    println(set_)*/\n    \n    //6.转成字符串\n    val strSet = set2.mkString("+")\n    println(strSet)\n    \n    \n    /*********可变长****************/\n    val set4 = Set[String]("aaa","bbb")\n    set4.add("ccc")\n    set4.+=("elem1")\n    set4.foreach(println)\n  }\n} \n\n\n\n# 类继承和伴生对象\n\n----------------------------------------\n\nStudent.scala\n\npackage com.hrbu.nscala\n//子类  可继承父类的私有成员\nclass Student(name:String, age:Int, height:Int, weight:Double) extends Persion(name, age) {\n  //println("Student的构造方法")\n  \n  val id = Student.getNumber()\n  val info = Student.info\n  override def sayMessage():String = {\n    s"$id\\t${super.sayMessage()}\\t$height\\t$weight\\t$info" \n  }\n}\n//父类\nclass Persion(name:String, age:Int) {\n  private var height:Int = _\n  private var weight:Double = _\n  //println("Persion的构造方法")\n  \n  def sayMessage(): String = {\n    s"$name\\t$age"\n    //s"name= $name\\tage= $age\\theight= $height\\tweight= $weight"\n  }\n}\n//伴生对象  类似于静态类\nobject Student {\n  private var lastnumber:Int = 0\n  private var info:String = _\n  def apply(in:String) = {\n    info = in\n  }\n  def getNumber():Int = {\n    lastnumber += 1\n    lastnumber\n  }\n}\n\n\nTest.scala\n\npackage com.hrbu.nscala\n\nobject Test {\n  def main(args: Array[String]): Unit = {\n    val persion = new Persion("a", 24)\n    println(persion.sayMessage())\n    \n    Student.apply("我们都是好孩子,最最善良的孩子")\n    val stu = Array[Student](\n        new Student("aaa", 22, 170, 65),\n        new Student("bbb", 25, 180, 75),\n        new Student("ccc", 24, 175, 73)\n    )\n    stu.foreach(f => println(f.sayMessage()))\n    //println(stu(0).sayMessage())\n  }\n}\n\n\n\n# 模式匹配和样例类\n\n----------------------------------------\n\npackage com.hrbu.nscala\n\nimport scala.util.Random\n\nobject MatchAndClass {\n  /**\n   * 0.模式匹配和样例类\n   */\n  \n  \n  \n  /**\n   * _.模式匹配\n   * 1.模式匹配不仅可以匹配值还可以匹配类型\n * 2.从上到下顺序匹配，如果匹配到则不再往下匹配\n * 3.都匹配不上时，会匹配到case _ ,相当于default\n   */\n  def matchTest(x:Any):Unit = {\n    x match {\n      case a:Int => println("参数为Int类型")\n      case 1 => println("值为 1")        //匹配不到\n      case 2 => println("值为 2")\n      case b:String => println("参数为字符串类型")\n      case _ => print("未匹配到")\n    }\n  }\n  \n  /**\n   * _.偏函数\n   * 1.如果一个方法中没有match 只有case，这个函数可以定义成PartialFunction偏函数。\n   * 2.偏函数定义时，不能使用括号传参，默认定义PartialFunction中传入一个值，匹配上了对应的case,返回一个值\n   */\n  //PartialFunction的一个实例 [参数类型, 返回值类型]\n  def myTest: PartialFunction[String, Any] = {\n    case "Hello" => "Hello"\n    case "World" => println("World")\n    case "Scala" => "Scala"\n    case _ => "未匹配到"\n  }\n  def myTest2(num:Int) :String = num match {\n    case 1 => "First"\n    case 2 => "Second"\n    case 3 => "Third"\n    case _ => "未匹配到"\n  }\n  \n  /**\n   * _. 样例类\n   * 1.概念\n   * \t1.1使用了case关键字的类定义就是样例类(case classes)，样例类是种特殊的类\n   * \t1.2实现了类构造参数的getter方法（构造参数默认被声明为val），当构造参数是声明为var类型的，它将帮你实现setter和getter方法\n   * \t1.3 case class是多例的，后面要跟构造参数，case object是单例的\n   * 2.注意\n   * \t2.1 样例类默认帮你实现了toString,equals，copy和hashCode等方法\n   * \t2.2 样例类可以new, 也可以不用new\n   */\n  def classDemo(){\n    val arr = Array(new Stu("曹雪阳", 32), People)\n    arr(Random.nextInt(arr.length)) match {\n      case Stu(name, age) =>{\n        println(s"姓名:$name\\t年龄:$age")\n      }\n      case People => {\n        println("People类")\n      }\n    }\n  }\n  \n  /**\n   * Option类型用样例类来表示可能存在或也可能不存在的值(Option的子类有Some和None)\n   */\n  def optionTest(x:String) = {\n    val map = Map{\n      "天策" -> "长河落日东都城，铁马戍边将军坟。尽诸宵小天策义，长枪独守大唐魂。"\n    }\n    //类似getOrElse()方法\n    map.get(x) match{\n      case Some(s) => s\n      case None => "?"\n    }\n  }\n  \n  def main(args: Array[String]): Unit = {\n    //1.模式匹配\n//    matchTest(1)\n    \n    //2.偏函数\n//    myTest("World")\n//    println(myTest("Scala"))\n//    println(myTest2(1))\n    \n    //3.样例类\n    classDemo()\n    \n    //option\n    println(optionTest("天策"))\n    println(optionTest("万花"))\n  }\n}\n\n\n\n# Scala 下划线(_) 用法汇总\n\n----------------------------------------\n\n\n# 1.导包时的通配符\n\nimport java.util._\n\n\n类似Java的 import java.util.*\n\n\n# 2.Scala类中成员变量初始化\n\nclass Foo{\n    //String类型的默认值为null 不适合局部变量\n    var s: String = _\n}\n\n\n\n# 3.类型通配符\n\nJava的泛型系统有一个通配符类型，例如List，任意的List类型都是List的子类型，如果我们想编写一个可以打印所有List类型元素的方法，可以如下声明：\n\npublic static void printList(List<?> list){\n    for(Object elem: list){\n        System.out.println(elem + " ");\n    }\n}\n\n\n对应的Scala版本为：\n\ndef printList(list: List[_]): Unit ={\n   list.foreach(elem => println(elem + " "))\n}\n\n\n\n# 4.可变参数\n\nJava声明可变参数如下：\n\npublic static void printArgs(String ... args){\n    for(Object elem: args){\n        System.out.println(elem + " ");\n    }\n}\n\n\n调用方法如下：\n\n//传入两个参数\nprintArgs("a", "b");\n//也可以传入一个数组\nprintArgs(new String[]{"a", "b"});\n\n\n在Java中可以直接将数组传给printArgs方法，但是在Scala中，你必须要明确的告诉编译器，你是想将集合作为一个独立的参数传进去，还是想将集合的元素传进去。如果是后者则要借助下划线：\n\nprintArgs(List("a", "b"): _*)\n\n\n\n# 5.模式匹配\n\n\ndef matchTest(x: Int): String = x match {\n     case 1 => "one"\n     case 2 => "two"\n     case _ => "anything other than one and two"\n }\n\n expr match {\n     case List(1,_,_) => " a list with three element and the first element is 1"\n     case List(_*)  => " a list with zero or more elements "\n     case Map[_,_] => " matches a map with any key type and any value type "\n     case _ =>\n }\n\n List(1,2,3,4,5).foreach(print(_))\n // Doing the same without underscore: \n List(1,2,3,4,5).foreach( a => print(a))\n\n\n在Scala中，在一个object中非私有变量的getter和 setter方法会被隐式定义好，getter方法名和变量名相同，我们可以使用_=自定义setter name，更好的控制赋值\n\nclass Test {\n    private var a = 0\n    def age = a\n    def age_=(n:Int) = {\n            require(n>0)\n            a = n\n    }\n}\n\n\nUsage:\n\nval t = new Test\nt.age = 5\nprintln(t.age)\n\n\n\n# 6.将函数赋给变量\n\n如果尝试将函数直接赋值给一个变量，这个函数会被直接调用，并将调用的结果赋值给变量，如果在函数名称后面加上_，那么赋值的是函数体本身\n\nclass Test {\n    def fun = {\n        // Some code\n    }\n    val funLike = fun _\n}\n\n\n\n# 7.访问Tuple元素\n\nval t = (1, 2, (7, 9))\nprintln(t._1, t._2, t._3._1, t._3._2)\n\n\n\n# 8.参数展开\n\ndef getConnectionProps = {\n    ( Config.getHost, Config.getPort, Config.getSommElse, Config.getSommElsePartTwo )\n}\n\n\n如果客户端需要拿到所有连接参数\n\nval ( host, port, sommEsle, someElsePartTwo ) = getConnectionProps\n\n\n如果仅仅需要拿到host和port\n\nval ( host, port, _, _ ) = getConnectionProps\n\n\n\n# 9.其它用法——简化函数\n\nval nums = List(1,2,3,4,5,6,7,8,9,10)\n\nnums.filter (_ % 2 == 0)\nnums.reduce (_ + _)\nnums.exists(_ > 5)\nnums.takeWhile(_ < 8)\n\n\n参考链接',normalizedContent:'# scala中,一切皆为对象\n\n\n# 需要注意的\n\n----------------------------------------\n\n * 定义多个变量 var (i,j,temp) = (1, 0, 0)\n * 记住: 除了循环都没有返回值,其余都有返回值\n * 函数化编程: 函数即参数\n\n//例如 (遍历元组)\ntuple22.productiterator.foreach(i => print(i + " "))\n\n\n * break语句\n\n// 创建 breaks 对象\nval loop = new breaks;\n// 在 breakable 中循环\nloop.breakable{\n    // 循环\n    for(...){\n       ....\n       // 循环中断\n       loop.break;\n   }\n}\n\n\n * foreach和迭代器的区别\n\nforeach遍历元素类型相同的 (例如 数组) 迭代器用来遍历元素类型不同的 (例如 元组. map集合?)\n\n\n# 运算符\n\n----------------------------------------\n\nobject myscala{\n    def main(args:arraystring]){\n        val num:int = 195\n        println(s"${num<<2}\\r${num>>2}\\r${num>>>2}")\n    }\n}\n\n\n\n# 字符串函数\n\n----------------------------------------\n\n\n# 流程控制语句\n\n----------------------------------------\n\npackage com.hrbu.nscala\n\nimport scala.io.stdin\n\nobject controlstatement {\n  \n  def test1(): any = {\n    val in = stdin.readline("请输入: ")\n    //用if实现java三元表达式\n    println(if(in.isinstanceof[int]) in.tostring() else "字符串:" + in )\n    \n    return if(in.isinstanceof[int]) in.tostring() else in\n  }\n  \n  def test2():any = {\n    print("请输入:")\n    val in = stdin.readint()\n    return if(in.isinstanceof[int]){\n      println("类型正确")\n    } else{\n      println("类型不正确")\n    }\n    \n  }\n  \n  /*\n   * 2.to and until\n   */\n  def test3{\n    val r1 = 1 to 10\n    val r2 = 1 until 10\n    val r3 = 1 to (10,2)\t\t// a.步长\n    println(r1 + "\\n" + r2 + "\\n" + r3)\n  }\n    \n\n    /*\n     * 3.循环语句\n     * a.for\n     */\n  def test4{\n    for (i <- 1 to 4) {\n      println(i)\n    }\n  \n      //乘法表\n      /*for(i<- 1 until 10){\n        for(j<- 1 until 10){\n          if(i>=j){\n            print(s"$i * $j=" + i*j + "\\t")\n          }\n          if(i==j){\n            println()\n          }\n        }\n      }*/\n      //简化\n      /*for(i<- 1 until 10;j<- 1 until 10){\n          if(i>=j){\n            print(s"$i * $j=" + i*j + "\\t")\n          }\n          if(i==j){\n            println()\n          }\n      }*/\n    }\n    /**\n     * while\n     * do...while\n     */\n    def test5{\n      var b: int = 0\n      while (b < 10) {\n        println(s"第$b 次求婚") //r 注意$b后一定有空格\n        b += 1\n      }\n    }\n\n    /**\n     * 4.yield关键字：记住每次迭代中的有关值，并逐一存入到一个数组\n     * 5.循环过滤 （遍历数组）\n     */\n    def test6{\n      val result = for { i <- 1 to 100 if (i > 50) if (i % 5 == 0) } yield i\n      //val result = for(i<- 1 to 100 if(i>50) if(i%5==0)) yield i\n      println(result)\n    }\n  \n  def main(args: array[string]): unit = {\n    println("test1返回: " + test1())\n    \n    println("test2返回值: " + test2())\n    \n    println("println语句返回值:" + println("nicai"))\n    \n  }\n}\n\n\n\n# 方法和函数\n\n----------------------------------------\n\n\n# 1.普通方法\n\ndef 方法名 (参数:参数类型):方法返回值={函数体}\n\ndef max1(a:int,b:int):int={\n      if(a>b){\n        return a\n      } else{\n        println("b>a")\n        return b\n      }\n    }\nprintln("max1=" + max1(b=69, a=35))\n/*****简化上面的方法**方法体如果可以一行搞定，可去掉{}*****/\ndef max1_1(a:int,b:int) = if(a>b) a else b\nprintln("max1.1=" + max1_1(12, 9))\n\n\n\n# 2.递归方法\n\n递归方法要显式的指定函数的返回值类型\n\ndef factorial(num:int):int = {\n      if(num == 1){\n        1\n      } else {\n        num * factorial(num-1)\n      }\n    }\nprintln(s"5的阶乘为:  ${factorial(5)}")\n\n\n\n# 3.带默认参数的方法\n\ndef max3(a:int=69, b:int=66) = if (a>b) a else b\nprintln("max3= " + max3())\nprintln("max3= " + max3(b=100))\n\n\n\n# 4.可变长参数的方法\n\ndef showstr(str:string*){\n  for(elem <- str){\n    print(elem)\n  }\n}\nshowstr("hello", " ", "scala", "\\r");\nshowstr("长河落日东都城", ",", "铁马戍边将军坟", "。", "尽诛宵小天策义", ",", "长枪独守大唐魂", "。", "\\n")\n/***************方法简化**************/\ndef showstr(str:string*) = str.foreach(print)\n\n\n\n# 5.匿名函数\n\n"=>"就是匿名函数，多用于方法的参数为函数时，常用匿名函数\n\ndef max5() = (a:int, b:int)=>if (a>b) a else b\nprintln(max5()(11, 22))\n\n\n\n# 6.嵌套函数\n\ndef value6(num:int):int={\n  def factorial6(a:int):int = if(a == 1) 1 else a * factorial6(a - 1)\n  factorial6(num)\n}\nprintln("5的阶乘为: " + value6(5))\n\n\n\n# 7.偏应用函数\n\n某些情况下,方法中参数非常多，调用非常频繁，每次调用只有固定的一个参数变化，其它都不变，可以定义偏应用函数简化\n\n//先定义一个普通函数\ndef showlogs(date:date, log:string) = {\n  println(s"date = $date\\tlog = $log")\n}\nval date: date = new date();    //注意:这里是scala变量\nshowlogs(date, "balabala")      //普通函数调用\nshowlogs(date, "hahahaha")\n\n//定义偏应用函数\ndef showlogs7 = showlogs(date:date, _:string)\nshowlogs7("123456789")\nshowlogs7("987654321")\n\n\n\n# 8.高阶函数\n\n/**a.参数是函数的方法*/\n/*def fun8_1(a:int,b:int)={\n  a+b\n}*/\n\n/*def fun8_a(f:(int,int)=>int,s:string) : string={\n  val i:int = f(100,200)\n  i+"#" +s\n}\nval result1 = fun8_a((a:int,b:int)=>{a*b},"scala")\nprintln(result1)*/\n\n/**b.返回值是函数的方法*/\n/*def fun8_b(s:string):(string,string)=>string={      //显示声明返回值(或最后一行写为fun _)\n  \n  def fun(s1:string,s2:string):string={\n    s1 + " " + s2 + " " +s\n  }\n  fun        //r 当返回值时不加括号\n}\n\nprintln(fun8_b("!!!")("hello","scala"))*/\n\n/**c.返回值和参数都是函数的方法*/\n/*def fun8_c(f:(int,int)=>int):(string,string)=>string={\n  val fint = f(1,2)\n  \n  def fun8(s1:string,s2:string):string={\n    s1 + " " + s2 + fint.tostring()\n  }\n  \n  fun9\n}\n\nprintln("返回值参数都是函数：" + fun9_c((a,b)=>{a+b})("hello", "scala"))*/\n\n\n1.方法的参数是函数\n\n/*a.参数是函数*/\ndef pet(pname:string, pattack:int): string = {\n  (s"宠物名字: ${pname}\\t宠物攻击力: ${pattack}")\n}\ndef hero(fun:(string, int) => string, heroname:string) = {\n  println(s"英雄名字: ${heroname}\\t${fun("龙狼王", 10000)}")\n}\nhero(pet, "琴帝")\n\n\n2.方法的返回是函数\n\n/*b.返回值为参数*/\ndef hero2(heroname:string, heroattack:int) : (string, int) => string = {\n  def getmessage(pname:string, pattack:int) : string = {\n    (s"英雄名字: ${heroname}\\t宠物名字: ${pname}\\t攻击力: ${heroattack + pattack}")\n  }\n  getmessage      //注意 当返回值不加()\n}\nprintln(hero2("酒神", 10000)("阴阳冕", 8000))\n\n\n3.方法的参数和返回值都是函数\n\ndef hofun(f:(int,int)=>int):(string,string)=>string={\n  val fint = f(1,2)\n  def fun(s1:string,s2:string):string={\n    s1 + " " + s2 + fint.tostring()\n  }\n  fun\n}\nprintln("返回值参数都是函数：" + hofun((a,b)=>{a+b})("hello", "scala"))\n\n\n\n# 9.柯里化函数\n\n返回值是函数的方法的简化\n\ndef fun9(a:int, b:int)(c:int, d:int) = a + b + c + d\nprintln(fun9(250,50)(100,120))\n\n\n\n# 数组\n\n----------------------------------------\n\n/*\n   * 1.第一种定义方式\n   */\n  def immutablearray1{\n    val arr = array[string]("hello", "scala", "hello", "world");\n    arr.foreach(println)\n  }\n  \n  /*\n   * 2.第二种定义方式\n   */\n  def immutablearray2{\n    val arr = new array[string](3);\n    arr(0) = "你好"\n    arr(1) = "世界"\n    arr(2) = "!!!"\n    //arr(3) = ""  //java.lang.arrayindexoutofboundsexception\n    arr.foreach(print)\n  }\n  \n  /*\n   * 3.关于数组连接 fill方法\n   */\n  def immutablearray3{\n    val arr1 = array[string]("aaa", "bbb", "ccc")\n    val arr2 = array[string]("333", "666", "999")\n//    println(arr1.contains(arr2))\n    array.concat(arr1, arr2).foreach(print)\n    println()\n    \n    val arr3 = array.fill(6)("scala")\n    arr3.foreach(print)\n  }\n  /*\n   * 4.二维数组\n   */\n  def immutablearray4{\n    val arr = new array[array[string]](3)\n    arr(0) = array[string]("hello", "world", "!!!")\n    arr(1) = array[string]("hello", "scala")\n    arr(2) = array[string]("hello", "array", "eof")\n    for(arrtemp <- arr; str <- arrtemp){\n      print(str + "  ")\n    }\n  }\n  /*\n   * 5.可变数组   类似 java 的 arraylist\n   */\n  def mutablearray{\n    var arr = arraybuffer[string]("111", "222")\n    arr.foreach(i => print(i + " "))\n//    arr.+:("+:")\n    arr.+=("+=")      //数组末插入\n    arr.+=:("+=:")    //数组首插入\n//    arr.++("++")\n//    arr.++:("++:")\n//    arr.++=(array("...", "***"))       //用++=操作符追加任何集合\n    println()\n    arr.foreach(i => print(i + " "))\n    \n    arr.append("aaa", "bbb", "ccc")    //追加元素\n    println()\n    arr.foreach(i => print(i + " "))\n  }\n\n\n\n# 元组\n\n----------------------------------------\n\n拉链\n\npackage com.hrbu.scala\n\n/**\n * 元组\n */\nobject scala10_tuple {\n  def main(args: array[string]): unit = {\n    \n    //注意:tuple最多支持22个参数\n    /**1.创建*/\n    //val tuple = new tuple1(1)\n    val tuple2 = tuple2("zhangsan",2)\n    val tuple3 = tuple3(1,2,3)\n    //val tuple4 = (1,2,3,4)\n    //val tuple18 = tuple18(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18)\n    val tuple22 = new tuple22(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22)\n    \n    //使用\n    /*println(tuple2._1 + "\\t"+tuple2._2)\n    val t = tuple2((1,2),("zhangsan","lisi"))\n    println(t._1._2)*/\n    \n    \n    /***2.遍历*/\n    val tupleiterator = tuple22.productiterator\n    while(tupleiterator.hasnext){\n      println(tupleiterator.next())\n    }\n\n    /**\n     * 方法\n     */\n    //翻转，只针对二元组\n    println(tuple2.swap)\n    \n    //tostring\n    println(tuple3.tostring())\n\n    \n  }\n} \n\n\n\n# 链表list\n\n----------------------------------------\n\n和java里不同，scala中list一定是以链表方式实现的。java中的list概念对应scala中的seq。 链表的特征：元素有先后之分，适合逐个访问\n\npackage com.hrbu.scala\n\nimport scala.collection.mutable.listbuffer\n\nobject scala7_list {\n  def main(args: array[string]): unit = {\n    \n    val list1 = list[int](7,9,1,2,3,4,5,6)\n    /*for(i<-list1){\n      print(i + " ")\n    }*/\n    //list1.foreach(print)\n    /*for(i<-0 until list1.count(x=>true)){\n      print(list1(i) + " ")\n    }\n    println()*/\n    \n    /*val countlist1 = list1.count(x=>x>=3)\n    println(countlist1)*/\n    \n    /***********重要方法****************/\n    val list2 = list("hello world","hello scala","hello spark")\n    // 1.过滤：filter方法\n    //print(list1.filter(x=>x>=6).tostring())\n    /*val list_ = list1.filter(x=>x>=6)\n    list_.foreach(println)*/\n    \n    // 2.对元素操作：map方法\n    /*val list2_  = list2.map(x=>x.split(" "))\n    for(i<-list2_;j<-i){\n      println(j)\n    }*/\n    \n    // 3.扁平化操作(压扁压平，先map再flat)：flatmap方法\n    val list2_ = list2.flatmap(x=>x.split(" "))\n    for(elem<-list2_){\n      println(elem)\n    }\n    \n    \n    /**不可变数组***/\n    /**可变数组*/\n    /*val list = listbuffer[string]("hello","scala")\n    list.+=("aaa","bbb")\n    list.foreach(println(_))*/\n  }\n}\n\n\n\n# map\n\n----------------------------------------\n\n/*\n* map练习 \n*/\ndef testmap{\nval map1 = map (\n  1 -> "hello",\n  "2" -> "scala",\n  (3, "kugou")\n)\n\nprintln(map1.get("2"))\nprintln(map1.get(3))\n// 1.若没有值,赋值为getorelse传的值\nprintln(map1.get("key").getorelse("no value"))\n\n/****2.遍历map*******/\n//2.1 foreach 遍历\nprintln("1.foreach 遍历:")\nmap1.foreach(\n    f => println("key=" + f._1 + "\\tvalue=" + f._2)\n)\n//2.2 每次获取其中一个元组\nprintln("每次获取其中一个元组:")\nfor(elem <- map1){\n  println("key:" + elem._1 + "\\tvalue:" + elem._2)\n}\n//2.3 每次循环直接解析元组（析构）\nprintln("每次循环直接解析元组:")\nfor((key,value) <- map1){\n  println(s"key:$key\\tvalue:$value")\n}\n\n/****3.遍历key*****/\nprintln("遍历key:")\n// 1.map.keys为迭代器类型  2.keyset为set类型\nval keyiterable = map1.keys\nfor(elem<-keyiterable){\n  println("key:" + elem + "\\tvalue:" + map1.get(elem).get)\n}\n\n/****4.遍历value****/\nprintln("遍历value")\nval valueiterable = map1.values\nfor(elem <- valueiterable){\n  println("value:" + elem)\n}\n//    valueiterable.foreach { \n//      value => println("value: " + value)\n//    }\n  \n/*****5.合并map 合并时将相同key的value替换\t********/\nval map2 = map[int,string](\n    (1,"hi"),\n    (2,"你好"),  //此处2为int,上面是string\n    (3,"世界"),\n    (4,"酷狗")\n)\nprintln("map1加入到map2中")\nmap1.++(map2).foreach(println)      //map1加入到map2中\nprintln("map2加入到map1中")\nmap1.++:(map2).foreach(println)    //map2加入到map1中\n\n/****6.可变map*****/\nvar map3 = scala.collection.mutable.map(\n    "天策" -> "长河落日东都城，铁马戍边将军坟。尽诸宵小天策义，长枪独守大唐魂。", \n    "万花" -> "春兰秋菊夏清风，三星望月挂夜空。不求独避风雨外，只笑桃源非梦中。", \n    "纯阳" -> "昆仑玄境山外山，乾坤阴阳有洞天。只问真君何处有，不向江湖寻剑仙。",\n    "七秀" -> "西子湖畔西子情，楼外楼中雨霖铃。画廊绣舫霓裳舞，小桥流水叶娉婷。",\n    "少林" -> "古刹紫竹禅钟鸣，降妖伏魔江湖行。佛音亦有豪情意，天下武功出少林！", \n    "藏剑" -> "秀水灵山隐剑踪，不闻江湖铸青锋。逍遥此身君子意，一壶温酒向长空。", \n    "五毒" -> "蛇蝎为伴蛛为邻，千蝶绕笛蛊无形。世人皆惧断肠物，不见最毒在人心。",\n    "唐门" -> "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。",\n    "苍云" -> "雪覆胡关摧冷草，风扬朔漠起狼烟。刃端百死何辞战，碧血成书白马篇。",\n    "丐帮" -> "搅动君山五十州，风尘几历尽翩遥。散罢千金未束手，餐风吞酒不寂寥。",\n    "长歌" -> "儒门有志羁风雨，失鹿山河散若星。千古文人侠客梦，肯将碧血写丹青。",\n    "霸刀" -> "寥落尘寰数十载，何曾开眼论豪英。刀光起处鲸吞海，誓将浮名敬死生。"\n)\n/*删除元素*/\n//map3.-=("唐门")\nmap3.remove("唐门")\n//map3.foreach(f => println(f._1 + ":" + f._2))\n/*增加元素*/\n//map3.+=("唐门" -> "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。")\nmap3.put("唐门", "蜀中世家纷争事，暗起云涌逍九天。针翎钉棘十指牵，暴雨飞星乾坤颠。")\n/*修改value*/\nmap3("苍云") = "歌起征思芦管怨，透穿玄甲朔风寒。黄泉作酒酬兄弟，战尽狂沙血未干。"\nmap3.foreach(f => println(f._1 + ":" + f._2))\n\n/*\n * 7.重要方法\n * filter:过滤，留下符合条件的记录\n * count:统计符合条件的记录数\n * contains：map中是否包含某个key\n * exist：符合条件的记录存在不存在\n */\n}\n\n\n\n# set\n\n----------------------------------------\n\npackage com.hrbu.scala\n\nimport scala.collection.mutable.set\n\n\nobject scala8_set {\n  def main(args: array[string]): unit = {\n    \n    // set无重复元素 \n    /*val set1 = set("hello","scala","hello","world")\n    set1.foreach(println)*/\n    \n    val set2 = set("hello","world","scala","spark")\n    val set3 = set("hello","world","!!!","???","///")\n    /***********重要方法**************/\n    //1.求交集\n    /*val set_ = set2.intersect(set3)\n    for(elem<-set_){\n      println(elem)\n    }*/\n    \n    //2.求差集\n    /*val set_ = set2.diff(set3)\n    for(elem<-set_){\n      println(elem)\n    }*/\n    \n    //3.求是否是子集\n    //println(set2.subsetof(set3))\n    \n    //4.max.min\n    //println(set2.min)\n    \n    //5.转成数组\n    /*val set_ = set2.tolist\n    set_.foreach(println)\n    println(set_)*/\n    \n    //6.转成字符串\n    val strset = set2.mkstring("+")\n    println(strset)\n    \n    \n    /*********可变长****************/\n    val set4 = set[string]("aaa","bbb")\n    set4.add("ccc")\n    set4.+=("elem1")\n    set4.foreach(println)\n  }\n} \n\n\n\n# 类继承和伴生对象\n\n----------------------------------------\n\nstudent.scala\n\npackage com.hrbu.nscala\n//子类  可继承父类的私有成员\nclass student(name:string, age:int, height:int, weight:double) extends persion(name, age) {\n  //println("student的构造方法")\n  \n  val id = student.getnumber()\n  val info = student.info\n  override def saymessage():string = {\n    s"$id\\t${super.saymessage()}\\t$height\\t$weight\\t$info" \n  }\n}\n//父类\nclass persion(name:string, age:int) {\n  private var height:int = _\n  private var weight:double = _\n  //println("persion的构造方法")\n  \n  def saymessage(): string = {\n    s"$name\\t$age"\n    //s"name= $name\\tage= $age\\theight= $height\\tweight= $weight"\n  }\n}\n//伴生对象  类似于静态类\nobject student {\n  private var lastnumber:int = 0\n  private var info:string = _\n  def apply(in:string) = {\n    info = in\n  }\n  def getnumber():int = {\n    lastnumber += 1\n    lastnumber\n  }\n}\n\n\ntest.scala\n\npackage com.hrbu.nscala\n\nobject test {\n  def main(args: array[string]): unit = {\n    val persion = new persion("a", 24)\n    println(persion.saymessage())\n    \n    student.apply("我们都是好孩子,最最善良的孩子")\n    val stu = array[student](\n        new student("aaa", 22, 170, 65),\n        new student("bbb", 25, 180, 75),\n        new student("ccc", 24, 175, 73)\n    )\n    stu.foreach(f => println(f.saymessage()))\n    //println(stu(0).saymessage())\n  }\n}\n\n\n\n# 模式匹配和样例类\n\n----------------------------------------\n\npackage com.hrbu.nscala\n\nimport scala.util.random\n\nobject matchandclass {\n  /**\n   * 0.模式匹配和样例类\n   */\n  \n  \n  \n  /**\n   * _.模式匹配\n   * 1.模式匹配不仅可以匹配值还可以匹配类型\n * 2.从上到下顺序匹配，如果匹配到则不再往下匹配\n * 3.都匹配不上时，会匹配到case _ ,相当于default\n   */\n  def matchtest(x:any):unit = {\n    x match {\n      case a:int => println("参数为int类型")\n      case 1 => println("值为 1")        //匹配不到\n      case 2 => println("值为 2")\n      case b:string => println("参数为字符串类型")\n      case _ => print("未匹配到")\n    }\n  }\n  \n  /**\n   * _.偏函数\n   * 1.如果一个方法中没有match 只有case，这个函数可以定义成partialfunction偏函数。\n   * 2.偏函数定义时，不能使用括号传参，默认定义partialfunction中传入一个值，匹配上了对应的case,返回一个值\n   */\n  //partialfunction的一个实例 [参数类型, 返回值类型]\n  def mytest: partialfunction[string, any] = {\n    case "hello" => "hello"\n    case "world" => println("world")\n    case "scala" => "scala"\n    case _ => "未匹配到"\n  }\n  def mytest2(num:int) :string = num match {\n    case 1 => "first"\n    case 2 => "second"\n    case 3 => "third"\n    case _ => "未匹配到"\n  }\n  \n  /**\n   * _. 样例类\n   * 1.概念\n   * \t1.1使用了case关键字的类定义就是样例类(case classes)，样例类是种特殊的类\n   * \t1.2实现了类构造参数的getter方法（构造参数默认被声明为val），当构造参数是声明为var类型的，它将帮你实现setter和getter方法\n   * \t1.3 case class是多例的，后面要跟构造参数，case object是单例的\n   * 2.注意\n   * \t2.1 样例类默认帮你实现了tostring,equals，copy和hashcode等方法\n   * \t2.2 样例类可以new, 也可以不用new\n   */\n  def classdemo(){\n    val arr = array(new stu("曹雪阳", 32), people)\n    arr(random.nextint(arr.length)) match {\n      case stu(name, age) =>{\n        println(s"姓名:$name\\t年龄:$age")\n      }\n      case people => {\n        println("people类")\n      }\n    }\n  }\n  \n  /**\n   * option类型用样例类来表示可能存在或也可能不存在的值(option的子类有some和none)\n   */\n  def optiontest(x:string) = {\n    val map = map{\n      "天策" -> "长河落日东都城，铁马戍边将军坟。尽诸宵小天策义，长枪独守大唐魂。"\n    }\n    //类似getorelse()方法\n    map.get(x) match{\n      case some(s) => s\n      case none => "?"\n    }\n  }\n  \n  def main(args: array[string]): unit = {\n    //1.模式匹配\n//    matchtest(1)\n    \n    //2.偏函数\n//    mytest("world")\n//    println(mytest("scala"))\n//    println(mytest2(1))\n    \n    //3.样例类\n    classdemo()\n    \n    //option\n    println(optiontest("天策"))\n    println(optiontest("万花"))\n  }\n}\n\n\n\n# scala 下划线(_) 用法汇总\n\n----------------------------------------\n\n\n# 1.导包时的通配符\n\nimport java.util._\n\n\n类似java的 import java.util.*\n\n\n# 2.scala类中成员变量初始化\n\nclass foo{\n    //string类型的默认值为null 不适合局部变量\n    var s: string = _\n}\n\n\n\n# 3.类型通配符\n\njava的泛型系统有一个通配符类型，例如list，任意的list类型都是list的子类型，如果我们想编写一个可以打印所有list类型元素的方法，可以如下声明：\n\npublic static void printlist(list<?> list){\n    for(object elem: list){\n        system.out.println(elem + " ");\n    }\n}\n\n\n对应的scala版本为：\n\ndef printlist(list: list[_]): unit ={\n   list.foreach(elem => println(elem + " "))\n}\n\n\n\n# 4.可变参数\n\njava声明可变参数如下：\n\npublic static void printargs(string ... args){\n    for(object elem: args){\n        system.out.println(elem + " ");\n    }\n}\n\n\n调用方法如下：\n\n//传入两个参数\nprintargs("a", "b");\n//也可以传入一个数组\nprintargs(new string[]{"a", "b"});\n\n\n在java中可以直接将数组传给printargs方法，但是在scala中，你必须要明确的告诉编译器，你是想将集合作为一个独立的参数传进去，还是想将集合的元素传进去。如果是后者则要借助下划线：\n\nprintargs(list("a", "b"): _*)\n\n\n\n# 5.模式匹配\n\n\ndef matchtest(x: int): string = x match {\n     case 1 => "one"\n     case 2 => "two"\n     case _ => "anything other than one and two"\n }\n\n expr match {\n     case list(1,_,_) => " a list with three element and the first element is 1"\n     case list(_*)  => " a list with zero or more elements "\n     case map[_,_] => " matches a map with any key type and any value type "\n     case _ =>\n }\n\n list(1,2,3,4,5).foreach(print(_))\n // doing the same without underscore: \n list(1,2,3,4,5).foreach( a => print(a))\n\n\n在scala中，在一个object中非私有变量的getter和 setter方法会被隐式定义好，getter方法名和变量名相同，我们可以使用_=自定义setter name，更好的控制赋值\n\nclass test {\n    private var a = 0\n    def age = a\n    def age_=(n:int) = {\n            require(n>0)\n            a = n\n    }\n}\n\n\nusage:\n\nval t = new test\nt.age = 5\nprintln(t.age)\n\n\n\n# 6.将函数赋给变量\n\n如果尝试将函数直接赋值给一个变量，这个函数会被直接调用，并将调用的结果赋值给变量，如果在函数名称后面加上_，那么赋值的是函数体本身\n\nclass test {\n    def fun = {\n        // some code\n    }\n    val funlike = fun _\n}\n\n\n\n# 7.访问tuple元素\n\nval t = (1, 2, (7, 9))\nprintln(t._1, t._2, t._3._1, t._3._2)\n\n\n\n# 8.参数展开\n\ndef getconnectionprops = {\n    ( config.gethost, config.getport, config.getsommelse, config.getsommelseparttwo )\n}\n\n\n如果客户端需要拿到所有连接参数\n\nval ( host, port, sommesle, someelseparttwo ) = getconnectionprops\n\n\n如果仅仅需要拿到host和port\n\nval ( host, port, _, _ ) = getconnectionprops\n\n\n\n# 9.其它用法——简化函数\n\nval nums = list(1,2,3,4,5,6,7,8,9,10)\n\nnums.filter (_ % 2 == 0)\nnums.reduce (_ + _)\nnums.exists(_ > 5)\nnums.takewhile(_ < 8)\n\n\n参考链接',charsets:{cjk:!0},lastUpdated:"2022/07/14, 17:53:55",lastUpdatedTimestamp:1657792435e3},{title:"正则基础",frontmatter:{title:"正则基础",date:"2022-02-27T15:35:17.000Z",permalink:"/pages/e4e158/",categories:["其他","正则表达式"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/04.%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/01.%E6%AD%A3%E5%88%99%E5%9F%BA%E7%A1%80.html",relativePath:"04.其他/04.正则表达式/01.正则基础.md",key:"v-0499277d",path:"/pages/e4e158/",headers:[{level:2,title:"历史",slug:"历史",normalizedTitle:"历史",charIndex:2},{level:2,title:"POSIX规范",slug:"posix规范",normalizedTitle:"posix规范",charIndex:296},{level:3,title:"POSIX字符组",slug:"posix字符组",normalizedTitle:"posix字符组",charIndex:1448},{level:3,title:"Unicode处理",slug:"unicode处理",normalizedTitle:"unicode处理",charIndex:2697},{level:2,title:"优先级",slug:"优先级",normalizedTitle:"优先级",charIndex:4829},{level:2,title:"语系对正规表示法的影响",slug:"语系对正规表示法的影响",normalizedTitle:"语系对正规表示法的影响",charIndex:4947},{level:2,title:"正则表达式基本语法",slug:"正则表达式基本语法",normalizedTitle:"正则表达式基本语法",charIndex:5689},{level:2,title:"反向引用",slug:"反向引用",normalizedTitle:"反向引用",charIndex:928},{level:2,title:"匹配中文",slug:"匹配中文",normalizedTitle:"匹配中文",charIndex:9833}],headersStr:"历史 POSIX规范 POSIX字符组 Unicode处理 优先级 语系对正规表示法的影响 正则表达式基本语法 反向引用 匹配中文",content:"# 历史\n\n----------------------------------------\n\n最初的正则表达式出现于理论计算机科学的自动控制理论和形式化语言理论中。在这些领域中有对计算（自动控制）的模型和对形式化语言描述与分类的研究。\n\n1940年，沃伦·麦卡洛克与沃尔特·皮茨将神经系统中的神经元描述成小而简单的自动控制元。\n\n1950年代，数学家斯蒂芬·科尔·克莱尼利用称之为“正则集合”的数学符号来描述此模型。肯·汤普逊将此符号系统引入编辑器QED，随后是Unix上的编辑器ed，并最终引入grep。自此以后，正则表达式被广泛地应用于各种Unix或类Unix系统的工具中。正则表达式的POSIX规范，分为基本型正则表达式（Basic Regular Expression，BRE）和扩展型正则表达式（Extended Regular Express，ERE）两大流派。在兼容POSIX的UNIX系统上，grep和egrep之类的工具都遵循POSIX规范，一些数据库系统中的正则表达式也匹配POSIX规范。grep、vi、sed都属于BRE，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义。egrep、awk则属于ERE，元字符不用转译\n\nPerl的正则表达式源自于Henry Spencer于1986年1月19日发布的regex，它已经演化成了PCRE（Perl兼容正则表达式，Perl Compatible Regular Expressions），一个由Philip Hazel开发的，为很多现代工具所使用的库。\n\n来源：维基百科\n\n\n# POSIX规范\n\n----------------------------------------\n\nPOSIX的全称是Portable Operating System Interface for unix. 分为BRE(基本型正则表达式)和ERE(扩展型正则表达式)两大流派。\n\nBRE流派\n\nLinux下的vi、grep、sed工具属于BRE这一派，BRE中元字符(、)、{、}必须转义之后才具有特殊意义，比如a{1,2}才能匹配字符串a或aa。\n\nBRE不支持+、?量词，多选结构和反向引用\\1、\\2。\n\nGNU对BRE做了扩展，使之支持+、?、|，但使用时需转义。也支持\\1、\\2之类的反向引用。\n\nERE流派\n\nLinux下的egrep、awk属于ERE流派。这一流派中使用元字符时不用转义，支持量词等。\n\n现在的BRE和ERE的主要差异是元字符是否需转义。\n\n正则表达式特性               BRES           ERES\n点号、^、$、[...]、[^...]   √              √\n“任意数目”量词              *              *\n+ 和 ? 量词                             +、?\n区间量词                  \\{min, max\\}   {min, max}\n分组                    \\(...\\)        (...)\n量词可否作用于括号             √              √\n反向引用                  \\1到\\9          \n多选结构                                 √\n\n原文链接\n\n\n# POSIX字符组\n\nPOSIX字符组     说明                    ASCII环境                             UNICODE环境\n[:alnum:]    字母字符和数字字符             [a-zA-Z0-9]                         [\\p{L&}\\p{Nd}]\n[:alpha:]    字母                    [a-zA-Z]                            \\p{L&}\n[:ascii:]    ASCII字符               [\\x00-\\x7F]                         \\p{InBasicLatin}\n[:blank:]    空格字符和制表符              [ \\t]                               [\\p{Zs}\\t]\n[:cntrl:]    控制字符                  [\\x00-\\x1F\\x7F]                     \\p{Cc}\n[:digit:]    数字字符                  [0-9]                               \\p{Nd}\n[:graph:]    空白字符之外的字符             [\\x21-\\x7E]                         [^\\p{Z}\\p{C}]\n[:lower:]    小写字母字符                [a-z]                               \\p{Ll}\n[:print:]    类似[:graph:]，但包括空白字符   [\\x20-\\x7E]                         \\P{C}\n[:punct:]    标点符号                  [][!\"#$%&'()*+,./:;<=>?@\\^_{|}~-]   [\\p{P}\\p{S}]\n[:space:]    空白字符                  [\\t\\r\\n\\v\\f]                        [\\p{Z}\\t\\r\\n\\v\\f]\n[:upper:]    大写字母字符                [A-Z]                               \\p{Lu}\n[:word:]     字母字符                  [A-Za-z0-9_]                        [\\p{L}\\p{N}\\p{Pc}]\n[:xdigit:]   十六进制字符                [A-Fa-f0-9]                         [A-Fa-f0-9]\n\n\n# Unicode处理\n\n在.NET、Java、JavaScript、Python的正则表达式中，可以用\\uXXXX表示一个Unicode字符，其中XXXX为四位16进制数字。\n\nUnicode字符的三种性质：\n\n * Unicode Property：字符属于标点、空格、字母等等。每个Unicode字符只能属于唯一Unicode Property。.NET、Java、PHP和Ruby等语言支持。具体分类为：\n   * 字符\\p{L}\n     * \\p{Ll}或\\p{Lowercase_Letter}：小写字符（必须有大写的形式）。\n     * \\p{Lu}或\\p{Uppercase_Letter}：大写字符（必须有小写的形式）。\n     * \\p{Lt}或\\p{Titlecase_Letter}：全词首字母大写的字符。\n     * \\p{L&}或\\p{Cased_Letter}：存在大小写形式的字符（Ll, Lu, Lt的组合）。\n     * \\p{Lm}或\\p{Modifier_Letter}：音标修饰字符。\n     * \\p{Lo}或\\p{Other_Letter}：不具有大小写的字符或字形。\n   * 附加符号\\p{M}\n     * \\p{Mn}或\\p{Non_Spacing_Mark}：与其他字符结合，不额外占用空间的字符，例如日耳曼语元音变音。\n     * \\p{Mc}或\\p{Spacing_Combining_Mark}：与其他字符结合，额外占用空间的字符，例如马拉雅拉姆文#元音字母及附标)。\n     * \\p{Me}或\\p{Enclosing_Mark}：包含其他字符的字符，例如圆圈、方块。\n   * 分隔符\\p{Z}\n     * \\p{Zs}或\\p{Space_Separator}：不可见的空格，但占据空间。\n     * \\p{Zl}或\\p{Line_Separator}：分隔线字符U+2028。\n     * \\p{Zp}或\\p{Paragraph_Separator}：分段字符U+2029。\n   * 符号\\p{S}\n     * \\p{Sm}或\\p{Math_Symbol}：数学符号。\n     * \\p{Sc}或\\p{Currency_Symbol}：通货符号。\n     * \\p{Sk}或\\p{Modifier_Symbol}：组合为其他字符的符号。\n     * \\p{So}或\\p{Other_Symbol}：其他符号。\n   * 数值字符\\p{N}\n     * \\p{Nd}或\\p{Decimal_Digit_Number}：所有文本中的数字0至9字符，不含形意符号)。\n     * \\p{Nl}或\\p{Letter_Number}：看起来像字母的符号，包含罗马数字。\n     * \\p{No}或\\p{Other_Number}：上角标或下角标数字，或者其他不属于0至9的数字。不含形意符号。\n   * 标点符号\\p{P}\n     * \\p{Pd}或\\p{Dash_Punctuation}：任何种类的连字号或连接号。\n     * \\p{Ps}或\\p{Open_Punctuation}：任何种类开括号。\n     * \\p{Pe}或\\p{Close_Punctuation}：任何种类闭括号。\n     * \\p{Pi}或\\p{Initial_Punctuation}：任何种类开引号。\n     * \\p{Pf}或\\p{Final_Punctuation}：任何种类闭引号。\n     * \\p{Pc}或\\p{Connector_Punctuation}：连接词的标点符号，如下划线。\n     * \\p{Po}或\\p{Other_Punctuation}：其他标点符号。\n   * 其它符号\\p{C}（包括不可见控制字符与未用码位）\n     * \\p{Cc}或\\p{Control}：ASCII或Latin-1控制字符0x00-0x1F与0x7F-0x9F。\n     * \\p{Cf}或\\p{Format}：不可见的格式化指示字符。\n     * \\p{Co}或\\p{Private_Use}：私用码位。\n     * \\p{Cs}或\\p{Surrogate}：UTF-16编码的代理对的一半。\n     * \\p{Cn}或\\p{Unassigned}：未被使用的码位。\n * Unicode Block：按照编码区间划分Unicode字符，每个Unicode Block中的字符编码属于一个编码区间。例如Java语言\\p{ InCJK_Compatibility_Ideographs }，.NET语言\\p{IsCJK_Compatibility_Ideographs}。\n * Unicode Script：按照字符所属的书写系统来划分Unicode字符。PHP和Ruby（版本不低于1.9）支持Unicode Script。例如\\p{Han}表示汉字（中文字符）。\n\n这三种Unicode性质对应的字符组补集是将开头的\\p改为\\P，其它不变。\n\n\n# 优先级\n\n优先权   符号\n最高    \\\n高     ()、(?:)、(?=)、[]\n中     *、+、?、{n}、{n,}、{n,m}\n低     ^、$、中介字符\n次最低   串接，即相邻字符连接在一起\n最低    |\n\n\n# 语系对正规表示法的影响\n\n既然正规表示法是处理字符串的一种表示方式，那么对字符排序有影响的语系数据就会对正规表示法的结果有影响！\n\n为什么语系的数据会影响到正规表示法的输出结果呢？我们在第零章计算器概论的文字编码系统里面谈到，文件其实记录的仅有 0 与 1，我们看到的字符文字与数字都是透过编码表转换来的。由于不同语系的编码数据并不相同，所以就会造成数据撷取结果的差异了。 举例来说，在英文大小写的编码顺序中，zh_TW.big5 及 C 这两种语系的输出结果分别如下： \n\n * LANG=C 时：0 1 2 3 4 ... A B C D ... Z a b c d ...z\n * LANG=zh_TW 时：0 1 2 3 4 ... a A b B c C d D ... z Z\n\n上面的顺序是编码的顺序，我们可以很清楚的发现这两种语系明显就是不一样！如果你想要撷取大写字符而使用 [A-Z] 时， 会发现 LANG=C 确实可以仅捉到大写字符 (因为是连续的) ，但是如果LANG=zh_TW.big5 时，就会发现到， 连同小写的 b-z 也会被撷取出来！因为就编码的顺序来看，big5 语系可以撷取到『 A b B c C ... z Z 』这一堆字符哩！ 所以，使用正规表示法时，需要特别留意当时环境的语系为何， 否则可能会发现与别人不相同的撷取结果喔！\n\n由于一般我们在练习正规表示法时，使用的是兼容于 POSIX 的标准，因此就使用『 C 』这个语系！ 因此，底下的很多练习都是使用『 LANG=C 』这个语系数据来进行的喔！ 另外，为了要避免这样编码所造成的英文与数字的撷取问题，因此有些特殊的符号我们得要了解一下的！ 这些符号主要有底下这些意义：\n\n\n# 正则表达式基本语法\n\n----------------------------------------\n\n字符             描述\n\\              将下一个字符标记为一个特殊字符（File Format Escape，清单见本表）、或一个原义字符（Identity\n               Escape，有^$()*+?.[\\{|共计12个）、或一个向后引用（backreferences）、或一个八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配一个换行符。序列“\\\\”匹配“\\”而“\\(”则匹配“(”。\n^              匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。\n$              匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。\n*              匹配前面的子表达式零次或多次。例如，zo*能匹配“z”、“zo”以及“zoo”。*等价于{0,}。\n+              匹配前面的子表达式一次或多次。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。\n?              匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“does”中的“do”和“does”。?等价于{0,1}。\n{n}            n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。\n{n,}           n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。\n{n,m}          m和n均为非负整数，其中n<=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。\n?              非贪心量化（Non-greedy\n               quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串“oooo”，“o+?”将匹配单个“o”，而“o+”将匹配所有“o”。\n.              匹配除“\\r”“\\n”之外的任何单个字符。要匹配包括“\\r”“\\n”在内的任何字符，请使用像“(.|\\r|\\n)”的模式。\n(pattern)      匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“\\(”或“\\)”。可带数量后缀。\n(?:pattern)    匹配pattern但不获取匹配的子字符串（shy\n               groups），也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。\n(?=pattern)    正向肯定预查（look ahead positive\n               assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。\n(?!pattern)    正向否定预查（negative\n               assert），在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始\n(?<=pattern)   反向（look\n               behind）肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?<=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。\n(?<!pattern)   反向否定预查，与正向否定预查类似，只是方向相反。例如“(?<!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。\nx|y            没有包围在()里，其范围是整个正则表达式。例如，“z|food”能匹配“z”或“food”。“(?:z|f)ood”则匹配“zood”或“food”。\n[xyz]          字符集合（character\n               class）。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。特殊字符仅有反斜线\\保持特殊含义，用于转义字符。其它特殊字符如星号、加号、各种括号等均作为普通字符。脱字符^如果出现在首位则表示负值字符集合；如果出现在字符串中间就仅作为普通字符。连字符\n               -\n               如果出现在字符串中间表示字符范围描述；如果如果出现在首位（或末尾）则仅作为普通字符。右方括号应转义出现，也可以作为首位字符出现。\n[^xyz]         排除型字符集合（negated character\n               classes）。匹配未列出的任意字符。例如，“[^abc]”可以匹配“plain”中的“plin”。\n[a-z]          字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。\n[^a-z]         排除型的字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。\n[:name:]       增加命名字符类（named character class）。只能用于方括号表达式。\n[=elt=]        增加当前locale下排序（collate）等价于字符“elt”的元素。例如，[=a=]可能会增加ä、á、à、ă、ắ、ằ、ẵ、ẳ、â、ấ、ầ、ẫ、ẩ、ǎ、å、ǻ、ä、ǟ、ã、ȧ、ǡ、ą、ā、ả、ȁ、ȃ、ạ、ặ、ậ、ḁ、ⱥ、ᶏ、ɐ、ɑ\n               。只能用于方括号表达式。\n[.elt.]        增加排序元素（collation\n               element）elt到表达式中。这是因为某些排序元素由多个字符组成。例如，29个字母表的西班牙语，\n               \"CH\"作为单个字母排在字母C之后，因此会产生如此排序“cinco, credo,\n               chispa”。只能用于方括号表达式。\n\\b             匹配一个单词边界，也就是指单词和空格间的位置。例如，“er\\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”。\n\\B             匹配非单词边界。“er\\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。\n\\cx            匹配由x指明的控制字符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。控制字符的值等于x的值最低5比特（即对3210进制的余数）。例如，\\cM匹配一个Control-M或回车符。\\ca等效于\\u0001,\n               \\cb等效于\\u0002, 等等…\n\\d             匹配一个数字字符。等价于[0-9]。注意Unicode正则表达式会匹配全角数字字符。\n\\D             匹配一个非数字字符。等价于[^0-9]。\n\\f             匹配一个换页符。等价于\\x0c和\\cL。\n\\n             匹配一个换行符。等价于\\x0a和\\cJ。\n\\r             匹配一个回车符。等价于\\x0d和\\cM。\n\\s             匹配任何空白字符，包括空格、制表符、换页符等等。等价于[\\f\\n\\r\\t\\v]。注意Unicode正则表达式会匹配全角空格符。\n\\S             匹配任何非空白字符。等价于[^ \\f\\n\\r\\t\\v]。\n\\t             匹配一个制表符。等价于\\x09和\\cI。\n\\v             匹配一个垂直制表符。等价于\\x0b和\\cK。\n\\w             匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9_]”。注意Unicode正则表达式会匹配中文字符。\n\\W             匹配任何非单词字符。等价于“[^A-Za-z0-9_]”。\n\\xnn           十六进制转义字符序列。匹配两个十六进制数字nn表示的字符。例如，“\\x41”匹配“A”。“\\x041”则等价于“\\x04&1”。正则表达式中可以使用ASCII编码。.\n\\num           向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture\n               group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9（命名字符类BRE与grep最多只能向后引用到9；Visual\n               C++的regex库最多只能向后引用到31；ECMAScript不限向后引用的上限）。例如：“(.)\\1”匹配两个连续的相同字符。\n\\n             标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。\n\\nm            3位八进制数字，标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm。\n\\nml           如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。\n\\un            Unicode转义字符序列。其中n是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配著作权符号（©）。\n\n\n# 反向引用\n\n-- 1. 单个正则内使用\n^\\d{4}([-/])\\d{2}\\1\\d{2}$\n-- 2. 提取后续使用\ngrep -E $reg1 \"$path/\"custom*.log | sed -E \"s#$reg2#insert into xxx(xx, xx, xx, xx, xx, xx, xx) values('\\1','\\2','\\3',\\4,\\5,\\6,'\\7');#g\" > \"$file\"\n\n\n\n# 匹配中文\n\n----------------------------------------\n\n参考链接：https://www.cnblogs.com/animalize/p/5432864.html\n\n以下是比较全面的汉字Unicode分布，参考Unicode 10.0标准（2017年6月发布）：\n\n区块            范围                                                 实际汉字个数/备注          正则式\nCJK统一汉字       4E00-62FF, 6300-77FF,7800-8CFF, 8D00-9FFF          20,971常见           [\\u4E00-\\u9FFF] 或[一-鿆]\nCJK统一汉字扩展A区   3400-4DBF                                          6,582罕见            [\\u3400-\\u4DBF]\nCJK统一汉字扩展B区   20000-215FF, 21600-230FF,23100-245FF,              42,711罕见，历史        [\\U00020000-\\U0002A6DF]\n              24600-260FF,26100-275FF, 27600-290FF,29100-2A6DF\nCJK统一汉字扩展C区   2A700-2B73F                                        4,149罕见，历史         [\\U0002A700-\\U0002B73F]\nCJK统一汉字扩展D区   2B740–2B81F                                        222不常见，仍在使用        [\\U0002B740-\\U0002B81F]\nCJK统一汉字扩展E区   2B820–2CEAF                                        5,762罕见，历史         [\\U0002B820-\\U0002CEAF]\nCJK统一汉字扩展F区   2CEB0-2EBEF                                        7,473罕见，历史         [\\U0002CEB0-\\U0002EBEF]\nCJK兼容汉字       F900–FAFF                                          472重复、可统一变体、公司定义   [\\uF900-\\uFAFF]\nCJK兼容汉字增补     2F800-2FA1F                                        542可统一变体           [\\U0002F800-\\U0002FA1F]\n\n★如果想表示最普遍的汉字\n\n用：[\\u4E00-\\u9FFF] 或 [一-鿆] 共有20950个汉字，包括了常用简体字和繁体字，镕等字。 基本就是GBK的所有（21003个）汉字。也包括了BIG5的所有（13053个）繁体汉字。 一般情况下这个就够用了。\n\n> 说明：仅仅未包括出现在GBK里的CJK兼容汉字的21个汉字：郎凉秊裏隣兀嗀﨎﨏﨑﨓﨔礼﨟蘒﨡﨣﨤﨧﨨﨩 CJK兼容汉字用于转码处理，日常中是用不到的，所以不包括也没什么问题。 注意此凉非彼凉，兀也不是常用的那个，虽然用眼睛看是一样的，参见 http://www.zhihu.com/question/20697984\n\n★如果想表示BMP之内的汉字\n\n也就是Unicode值<=0xFFFF之内的所有汉字，用：[\\u4E00-\\u9FFF\\u3400-\\u4DBF\\uF900-\\uFAFF]，这个包含但不限于GBK定义的汉字，共有28025个汉字。\n\n> 说明：和上面相比，主要是多了CJK统一汉字扩展A区，这是1999年收录到Unicode 3.0标准里的6,582个汉字。 CJK统一汉字扩展A区，包括了东亚各地区（陆港台日韩新越）的汉字，有很多康熙字典的繁体字。\n\n★ 如果想尽可能表示所有的汉字\n\n用：[\\u4E00-\\u9FFF\\u3400-\\u4DBF\\uF900-\\uFAFF\\U00020000-U0002EBEF]这个包含上表的所有88342个汉字\n\n> 说明： 1, 以上正则表达式不会匹配（英文、汉字的）标点符号，不会匹配韩国拼音字、日本假名。 2, 会匹配一些日本、韩国独有的汉字。 3, 包含了一些没有汉字的空位置，这通常不碍事。 4, \\u及\\U的正则语法在Python 3.5上测试通过。 有些正则表达式引擎不认\\uFFFF和\\UFFFFFFFF这样的语法，可以换成\\x{FFFF}试一下；有些不支持BMP之外的范围，这就没办法处理CJK统一汉字扩展B~E区了，如notepad++。",normalizedContent:"# 历史\n\n----------------------------------------\n\n最初的正则表达式出现于理论计算机科学的自动控制理论和形式化语言理论中。在这些领域中有对计算（自动控制）的模型和对形式化语言描述与分类的研究。\n\n1940年，沃伦·麦卡洛克与沃尔特·皮茨将神经系统中的神经元描述成小而简单的自动控制元。\n\n1950年代，数学家斯蒂芬·科尔·克莱尼利用称之为“正则集合”的数学符号来描述此模型。肯·汤普逊将此符号系统引入编辑器qed，随后是unix上的编辑器ed，并最终引入grep。自此以后，正则表达式被广泛地应用于各种unix或类unix系统的工具中。正则表达式的posix规范，分为基本型正则表达式（basic regular expression，bre）和扩展型正则表达式（extended regular express，ere）两大流派。在兼容posix的unix系统上，grep和egrep之类的工具都遵循posix规范，一些数据库系统中的正则表达式也匹配posix规范。grep、vi、sed都属于bre，是历史最早的正则表达式，因此元字符必须转译之后才具有特殊含义。egrep、awk则属于ere，元字符不用转译\n\nperl的正则表达式源自于henry spencer于1986年1月19日发布的regex，它已经演化成了pcre（perl兼容正则表达式，perl compatible regular expressions），一个由philip hazel开发的，为很多现代工具所使用的库。\n\n来源：维基百科\n\n\n# posix规范\n\n----------------------------------------\n\nposix的全称是portable operating system interface for unix. 分为bre(基本型正则表达式)和ere(扩展型正则表达式)两大流派。\n\nbre流派\n\nlinux下的vi、grep、sed工具属于bre这一派，bre中元字符(、)、{、}必须转义之后才具有特殊意义，比如a{1,2}才能匹配字符串a或aa。\n\nbre不支持+、?量词，多选结构和反向引用\\1、\\2。\n\ngnu对bre做了扩展，使之支持+、?、|，但使用时需转义。也支持\\1、\\2之类的反向引用。\n\nere流派\n\nlinux下的egrep、awk属于ere流派。这一流派中使用元字符时不用转义，支持量词等。\n\n现在的bre和ere的主要差异是元字符是否需转义。\n\n正则表达式特性               bres           eres\n点号、^、$、[...]、[^...]   √              √\n“任意数目”量词              *              *\n+ 和 ? 量词                             +、?\n区间量词                  \\{min, max\\}   {min, max}\n分组                    \\(...\\)        (...)\n量词可否作用于括号             √              √\n反向引用                  \\1到\\9          \n多选结构                                 √\n\n原文链接\n\n\n# posix字符组\n\nposix字符组     说明                    ascii环境                             unicode环境\n[:alnum:]    字母字符和数字字符             [a-za-z0-9]                         [\\p{l&}\\p{nd}]\n[:alpha:]    字母                    [a-za-z]                            \\p{l&}\n[:ascii:]    ascii字符               [\\x00-\\x7f]                         \\p{inbasiclatin}\n[:blank:]    空格字符和制表符              [ \\t]                               [\\p{zs}\\t]\n[:cntrl:]    控制字符                  [\\x00-\\x1f\\x7f]                     \\p{cc}\n[:digit:]    数字字符                  [0-9]                               \\p{nd}\n[:graph:]    空白字符之外的字符             [\\x21-\\x7e]                         [^\\p{z}\\p{c}]\n[:lower:]    小写字母字符                [a-z]                               \\p{ll}\n[:print:]    类似[:graph:]，但包括空白字符   [\\x20-\\x7e]                         \\p{c}\n[:punct:]    标点符号                  [][!\"#$%&'()*+,./:;<=>?@\\^_{|}~-]   [\\p{p}\\p{s}]\n[:space:]    空白字符                  [\\t\\r\\n\\v\\f]                        [\\p{z}\\t\\r\\n\\v\\f]\n[:upper:]    大写字母字符                [a-z]                               \\p{lu}\n[:word:]     字母字符                  [a-za-z0-9_]                        [\\p{l}\\p{n}\\p{pc}]\n[:xdigit:]   十六进制字符                [a-fa-f0-9]                         [a-fa-f0-9]\n\n\n# unicode处理\n\n在.net、java、javascript、python的正则表达式中，可以用\\uxxxx表示一个unicode字符，其中xxxx为四位16进制数字。\n\nunicode字符的三种性质：\n\n * unicode property：字符属于标点、空格、字母等等。每个unicode字符只能属于唯一unicode property。.net、java、php和ruby等语言支持。具体分类为：\n   * 字符\\p{l}\n     * \\p{ll}或\\p{lowercase_letter}：小写字符（必须有大写的形式）。\n     * \\p{lu}或\\p{uppercase_letter}：大写字符（必须有小写的形式）。\n     * \\p{lt}或\\p{titlecase_letter}：全词首字母大写的字符。\n     * \\p{l&}或\\p{cased_letter}：存在大小写形式的字符（ll, lu, lt的组合）。\n     * \\p{lm}或\\p{modifier_letter}：音标修饰字符。\n     * \\p{lo}或\\p{other_letter}：不具有大小写的字符或字形。\n   * 附加符号\\p{m}\n     * \\p{mn}或\\p{non_spacing_mark}：与其他字符结合，不额外占用空间的字符，例如日耳曼语元音变音。\n     * \\p{mc}或\\p{spacing_combining_mark}：与其他字符结合，额外占用空间的字符，例如马拉雅拉姆文#元音字母及附标)。\n     * \\p{me}或\\p{enclosing_mark}：包含其他字符的字符，例如圆圈、方块。\n   * 分隔符\\p{z}\n     * \\p{zs}或\\p{space_separator}：不可见的空格，但占据空间。\n     * \\p{zl}或\\p{line_separator}：分隔线字符u+2028。\n     * \\p{zp}或\\p{paragraph_separator}：分段字符u+2029。\n   * 符号\\p{s}\n     * \\p{sm}或\\p{math_symbol}：数学符号。\n     * \\p{sc}或\\p{currency_symbol}：通货符号。\n     * \\p{sk}或\\p{modifier_symbol}：组合为其他字符的符号。\n     * \\p{so}或\\p{other_symbol}：其他符号。\n   * 数值字符\\p{n}\n     * \\p{nd}或\\p{decimal_digit_number}：所有文本中的数字0至9字符，不含形意符号)。\n     * \\p{nl}或\\p{letter_number}：看起来像字母的符号，包含罗马数字。\n     * \\p{no}或\\p{other_number}：上角标或下角标数字，或者其他不属于0至9的数字。不含形意符号。\n   * 标点符号\\p{p}\n     * \\p{pd}或\\p{dash_punctuation}：任何种类的连字号或连接号。\n     * \\p{ps}或\\p{open_punctuation}：任何种类开括号。\n     * \\p{pe}或\\p{close_punctuation}：任何种类闭括号。\n     * \\p{pi}或\\p{initial_punctuation}：任何种类开引号。\n     * \\p{pf}或\\p{final_punctuation}：任何种类闭引号。\n     * \\p{pc}或\\p{connector_punctuation}：连接词的标点符号，如下划线。\n     * \\p{po}或\\p{other_punctuation}：其他标点符号。\n   * 其它符号\\p{c}（包括不可见控制字符与未用码位）\n     * \\p{cc}或\\p{control}：ascii或latin-1控制字符0x00-0x1f与0x7f-0x9f。\n     * \\p{cf}或\\p{format}：不可见的格式化指示字符。\n     * \\p{co}或\\p{private_use}：私用码位。\n     * \\p{cs}或\\p{surrogate}：utf-16编码的代理对的一半。\n     * \\p{cn}或\\p{unassigned}：未被使用的码位。\n * unicode block：按照编码区间划分unicode字符，每个unicode block中的字符编码属于一个编码区间。例如java语言\\p{ incjk_compatibility_ideographs }，.net语言\\p{iscjk_compatibility_ideographs}。\n * unicode script：按照字符所属的书写系统来划分unicode字符。php和ruby（版本不低于1.9）支持unicode script。例如\\p{han}表示汉字（中文字符）。\n\n这三种unicode性质对应的字符组补集是将开头的\\p改为\\p，其它不变。\n\n\n# 优先级\n\n优先权   符号\n最高    \\\n高     ()、(?:)、(?=)、[]\n中     *、+、?、{n}、{n,}、{n,m}\n低     ^、$、中介字符\n次最低   串接，即相邻字符连接在一起\n最低    |\n\n\n# 语系对正规表示法的影响\n\n既然正规表示法是处理字符串的一种表示方式，那么对字符排序有影响的语系数据就会对正规表示法的结果有影响！\n\n为什么语系的数据会影响到正规表示法的输出结果呢？我们在第零章计算器概论的文字编码系统里面谈到，文件其实记录的仅有 0 与 1，我们看到的字符文字与数字都是透过编码表转换来的。由于不同语系的编码数据并不相同，所以就会造成数据撷取结果的差异了。 举例来说，在英文大小写的编码顺序中，zh_tw.big5 及 c 这两种语系的输出结果分别如下： \n\n * lang=c 时：0 1 2 3 4 ... a b c d ... z a b c d ...z\n * lang=zh_tw 时：0 1 2 3 4 ... a a b b c c d d ... z z\n\n上面的顺序是编码的顺序，我们可以很清楚的发现这两种语系明显就是不一样！如果你想要撷取大写字符而使用 [a-z] 时， 会发现 lang=c 确实可以仅捉到大写字符 (因为是连续的) ，但是如果lang=zh_tw.big5 时，就会发现到， 连同小写的 b-z 也会被撷取出来！因为就编码的顺序来看，big5 语系可以撷取到『 a b b c c ... z z 』这一堆字符哩！ 所以，使用正规表示法时，需要特别留意当时环境的语系为何， 否则可能会发现与别人不相同的撷取结果喔！\n\n由于一般我们在练习正规表示法时，使用的是兼容于 posix 的标准，因此就使用『 c 』这个语系！ 因此，底下的很多练习都是使用『 lang=c 』这个语系数据来进行的喔！ 另外，为了要避免这样编码所造成的英文与数字的撷取问题，因此有些特殊的符号我们得要了解一下的！ 这些符号主要有底下这些意义：\n\n\n# 正则表达式基本语法\n\n----------------------------------------\n\n字符             描述\n\\              将下一个字符标记为一个特殊字符（file format escape，清单见本表）、或一个原义字符（identity\n               escape，有^$()*+?.[\\{|共计12个）、或一个向后引用（backreferences）、或一个八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配一个换行符。序列“\\\\”匹配“\\”而“\\(”则匹配“(”。\n^              匹配输入字符串的开始位置。如果设置了regexp对象的multiline属性，^也匹配“\\n”或“\\r”之后的位置。\n$              匹配输入字符串的结束位置。如果设置了regexp对象的multiline属性，$也匹配“\\n”或“\\r”之前的位置。\n*              匹配前面的子表达式零次或多次。例如，zo*能匹配“z”、“zo”以及“zoo”。*等价于{0,}。\n+              匹配前面的子表达式一次或多次。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。\n?              匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“does”中的“do”和“does”。?等价于{0,1}。\n{n}            n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“bob”中的“o”，但是能匹配“food”中的两个o。\n{n,}           n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。\n{n,m}          m和n均为非负整数，其中n<=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。\n?              非贪心量化（non-greedy\n               quantifiers）：当该字符紧跟在任何一个其他重复修饰符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串“oooo”，“o+?”将匹配单个“o”，而“o+”将匹配所有“o”。\n.              匹配除“\\r”“\\n”之外的任何单个字符。要匹配包括“\\r”“\\n”在内的任何字符，请使用像“(.|\\r|\\n)”的模式。\n(pattern)      匹配pattern并获取这一匹配的子字符串。该子字符串用于向后引用。所获取的匹配可以从产生的matches集合得到，在vbscript中使用submatches集合，在jscript中则使用$0…$9属性。要匹配圆括号字符，请使用“\\(”或“\\)”。可带数量后缀。\n(?:pattern)    匹配pattern但不获取匹配的子字符串（shy\n               groups），也就是说这是一个非获取匹配，不存储匹配的子字符串用于向后引用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。\n(?=pattern)    正向肯定预查（look ahead positive\n               assert），在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，“windows(?=95|98|nt|2000)”能匹配“windows2000”中的“windows”，但不能匹配“windows3.1”中的“windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。\n(?!pattern)    正向否定预查（negative\n               assert），在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如“windows(?!95|98|nt|2000)”能匹配“windows3.1”中的“windows”，但不能匹配“windows2000”中的“windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始\n(?<=pattern)   反向（look\n               behind）肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?<=95|98|nt|2000)windows”能匹配“2000windows”中的“windows”，但不能匹配“3.1windows”中的“windows”。\n(?<!pattern)   反向否定预查，与正向否定预查类似，只是方向相反。例如“(?<!95|98|nt|2000)windows”能匹配“3.1windows”中的“windows”，但不能匹配“2000windows”中的“windows”。\nx|y            没有包围在()里，其范围是整个正则表达式。例如，“z|food”能匹配“z”或“food”。“(?:z|f)ood”则匹配“zood”或“food”。\n[xyz]          字符集合（character\n               class）。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。特殊字符仅有反斜线\\保持特殊含义，用于转义字符。其它特殊字符如星号、加号、各种括号等均作为普通字符。脱字符^如果出现在首位则表示负值字符集合；如果出现在字符串中间就仅作为普通字符。连字符\n               -\n               如果出现在字符串中间表示字符范围描述；如果如果出现在首位（或末尾）则仅作为普通字符。右方括号应转义出现，也可以作为首位字符出现。\n[^xyz]         排除型字符集合（negated character\n               classes）。匹配未列出的任意字符。例如，“[^abc]”可以匹配“plain”中的“plin”。\n[a-z]          字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。\n[^a-z]         排除型的字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。\n[:name:]       增加命名字符类（named character class）。只能用于方括号表达式。\n[=elt=]        增加当前locale下排序（collate）等价于字符“elt”的元素。例如，[=a=]可能会增加a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、a、ⱥ、ᶏ、ɐ、ɑ\n               。只能用于方括号表达式。\n[.elt.]        增加排序元素（collation\n               element）elt到表达式中。这是因为某些排序元素由多个字符组成。例如，29个字母表的西班牙语，\n               \"ch\"作为单个字母排在字母c之后，因此会产生如此排序“cinco, credo,\n               chispa”。只能用于方括号表达式。\n\\b             匹配一个单词边界，也就是指单词和空格间的位置。例如，“er\\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”。\n\\b             匹配非单词边界。“er\\b”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。\n\\cx            匹配由x指明的控制字符。x的值必须为a-z或a-z之一。否则，将c视为一个原义的“c”字符。控制字符的值等于x的值最低5比特（即对3210进制的余数）。例如，\\cm匹配一个control-m或回车符。\\ca等效于\\u0001,\n               \\cb等效于\\u0002, 等等…\n\\d             匹配一个数字字符。等价于[0-9]。注意unicode正则表达式会匹配全角数字字符。\n\\d             匹配一个非数字字符。等价于[^0-9]。\n\\f             匹配一个换页符。等价于\\x0c和\\cl。\n\\n             匹配一个换行符。等价于\\x0a和\\cj。\n\\r             匹配一个回车符。等价于\\x0d和\\cm。\n\\s             匹配任何空白字符，包括空格、制表符、换页符等等。等价于[\\f\\n\\r\\t\\v]。注意unicode正则表达式会匹配全角空格符。\n\\s             匹配任何非空白字符。等价于[^ \\f\\n\\r\\t\\v]。\n\\t             匹配一个制表符。等价于\\x09和\\ci。\n\\v             匹配一个垂直制表符。等价于\\x0b和\\ck。\n\\w             匹配包括下划线的任何单词字符。等价于“[a-za-z0-9_]”。注意unicode正则表达式会匹配中文字符。\n\\w             匹配任何非单词字符。等价于“[^a-za-z0-9_]”。\n\\xnn           十六进制转义字符序列。匹配两个十六进制数字nn表示的字符。例如，“\\x41”匹配“a”。“\\x041”则等价于“\\x04&1”。正则表达式中可以使用ascii编码。.\n\\num           向后引用（back-reference）一个子字符串（substring），该子字符串与正则表达式的第num个用括号围起来的捕捉群（capture\n               group）子表达式（subexpression）匹配。其中num是从1开始的十进制正整数，其上限可能是9（命名字符类bre与grep最多只能向后引用到9；visual\n               c++的regex库最多只能向后引用到31；ecmascript不限向后引用的上限）。例如：“(.)\\1”匹配两个连续的相同字符。\n\\n             标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。\n\\nm            3位八进制数字，标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm。\n\\nml           如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。\n\\un            unicode转义字符序列。其中n是一个用四个十六进制数字表示的unicode字符。例如，\\u00a9匹配著作权符号（©）。\n\n\n# 反向引用\n\n-- 1. 单个正则内使用\n^\\d{4}([-/])\\d{2}\\1\\d{2}$\n-- 2. 提取后续使用\ngrep -e $reg1 \"$path/\"custom*.log | sed -e \"s#$reg2#insert into xxx(xx, xx, xx, xx, xx, xx, xx) values('\\1','\\2','\\3',\\4,\\5,\\6,'\\7');#g\" > \"$file\"\n\n\n\n# 匹配中文\n\n----------------------------------------\n\n参考链接：https://www.cnblogs.com/animalize/p/5432864.html\n\n以下是比较全面的汉字unicode分布，参考unicode 10.0标准（2017年6月发布）：\n\n区块            范围                                                 实际汉字个数/备注          正则式\ncjk统一汉字       4e00-62ff, 6300-77ff,7800-8cff, 8d00-9fff          20,971常见           [\\u4e00-\\u9fff] 或[一-鿆]\ncjk统一汉字扩展a区   3400-4dbf                                          6,582罕见            [\\u3400-\\u4dbf]\ncjk统一汉字扩展b区   20000-215ff, 21600-230ff,23100-245ff,              42,711罕见，历史        [\\u00020000-\\u0002a6df]\n              24600-260ff,26100-275ff, 27600-290ff,29100-2a6df\ncjk统一汉字扩展c区   2a700-2b73f                                        4,149罕见，历史         [\\u0002a700-\\u0002b73f]\ncjk统一汉字扩展d区   2b740–2b81f                                        222不常见，仍在使用        [\\u0002b740-\\u0002b81f]\ncjk统一汉字扩展e区   2b820–2ceaf                                        5,762罕见，历史         [\\u0002b820-\\u0002ceaf]\ncjk统一汉字扩展f区   2ceb0-2ebef                                        7,473罕见，历史         [\\u0002ceb0-\\u0002ebef]\ncjk兼容汉字       f900–faff                                          472重复、可统一变体、公司定义   [\\uf900-\\ufaff]\ncjk兼容汉字增补     2f800-2fa1f                                        542可统一变体           [\\u0002f800-\\u0002fa1f]\n\n★如果想表示最普遍的汉字\n\n用：[\\u4e00-\\u9fff] 或 [一-鿆] 共有20950个汉字，包括了常用简体字和繁体字，镕等字。 基本就是gbk的所有（21003个）汉字。也包括了big5的所有（13053个）繁体汉字。 一般情况下这个就够用了。\n\n> 说明：仅仅未包括出现在gbk里的cjk兼容汉字的21个汉字：郎凉秊裏隣兀嗀﨎﨏﨑﨓﨔礼﨟蘒﨡﨣﨤﨧﨨﨩 cjk兼容汉字用于转码处理，日常中是用不到的，所以不包括也没什么问题。 注意此凉非彼凉，兀也不是常用的那个，虽然用眼睛看是一样的，参见 http://www.zhihu.com/question/20697984\n\n★如果想表示bmp之内的汉字\n\n也就是unicode值<=0xffff之内的所有汉字，用：[\\u4e00-\\u9fff\\u3400-\\u4dbf\\uf900-\\ufaff]，这个包含但不限于gbk定义的汉字，共有28025个汉字。\n\n> 说明：和上面相比，主要是多了cjk统一汉字扩展a区，这是1999年收录到unicode 3.0标准里的6,582个汉字。 cjk统一汉字扩展a区，包括了东亚各地区（陆港台日韩新越）的汉字，有很多康熙字典的繁体字。\n\n★ 如果想尽可能表示所有的汉字\n\n用：[\\u4e00-\\u9fff\\u3400-\\u4dbf\\uf900-\\ufaff\\u00020000-u0002ebef]这个包含上表的所有88342个汉字\n\n> 说明： 1, 以上正则表达式不会匹配（英文、汉字的）标点符号，不会匹配韩国拼音字、日本假名。 2, 会匹配一些日本、韩国独有的汉字。 3, 包含了一些没有汉字的空位置，这通常不碍事。 4, \\u及\\u的正则语法在python 3.5上测试通过。 有些正则表达式引擎不认\\uffff和\\uffffffff这样的语法，可以换成\\x{ffff}试一下；有些不支持bmp之外的范围，这就没办法处理cjk统一汉字扩展b~e区了，如notepad++。",charsets:{cjk:!0},lastUpdated:"2025/04/18, 12:12:36",lastUpdatedTimestamp:1744949556e3},{title:"摘录",frontmatter:{title:"摘录",date:"2022-03-02T17:42:54.000Z",permalink:"/pages/AXI4oJ/",categories:["其他","摘录"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/100.%E6%91%98%E5%BD%95/01.%E6%91%98%E5%BD%95.html",relativePath:"04.其他/100.摘录/01.摘录.md",key:"v-00f00e91",path:"/pages/AXI4oJ/",headers:[{level:2,title:"一、摘录",slug:"一、摘录",normalizedTitle:"一、摘录",charIndex:216},{level:2,title:"二、每天一遍，快乐再见",slug:"二、每天一遍-快乐再见",normalizedTitle:"二、每天一遍，快乐再见",charIndex:1455}],headersStr:"一、摘录 二、每天一遍，快乐再见",content:'----------------------------------------\n\n本来无一物，何处染尘埃\n\n----------------------------------------\n\n黑神话 · 悟空\n\n别有世间曾未见，一行一步，一花新。\n愿你历经九九八十一难，归来仍是那只石头憨憨。\n黑夜给了我火眼金睛， 我要用它，看穿宿命。\n\n----------------------------------------\n\n\n# 一、摘录\n\n  人终将被年少不可得之物困其一生。\n\n  正常的社会并不是黑白分明、非此即彼的，有时善与善也会发生冲突。\n\n  人真正能影响的人少之又少，那些被你影响的人，只是片刻的感动。\n\n  人要接受自己的有限性，人的逻辑、理性、阅读都是有限的，整个人就是在偏见之中。人这一生就是在走出偏见。\n\n  人生中最大的痛苦,就是你知道什么是对的,但却永远做出的是错误的选择,知道和做到这个巨大的鸿沟,你永远无法跨越。\n\n  人生不能太过圆满，求而不得未必是遗憾。因为，人要接受事与愿违啊，我们太有限了，我们只能做我们觉得是对的事，然后接受结果。误解是人生常态，理解才是稀缺的例外。\n\n  人生啊充满着挑战，有很多有形无形的考试。很多时候呢，我们只能尽力而为，但是结果要选择角度，因为人生唯一确定的就是不确定的人生。在每一个人生的重要关头，我们只需要尽力而为，不留遗憾。\n\n  行路难，不再水，不在山，只在人情反复间。\n\n  你要在这里真正地高歌猛进和一败涂地过，要在这里和什么人的命运紧紧纠缠过，要一踏入这里的机场车站就被巨大的回忆和期望充满，要经过这里四季的和煦温柔暴烈残酷，才有资格说，自己属于这个城市。我曾在这里，不顾一切地活着。\n\n----------------------------------------\n\n  每个人的心里都有一团火，路过的人只能看到烟。但是总有一个人，总有那么一个人能看到这火，然后走过来陪我一起。\n\n  海上月是天上月，眼前人是心上人。\n  向来心是看客心，奈何人是剧中人。\n\n  习惯会使我们双手伶俐而头脑笨拙。\n\n  傻瓜才在年轻的时候不做傻事，羡慕别人有故事。\n\n  慧极必伤，情深不寿，强极则辱，谦谦君子，温润如玉。\n\n  当你面前有一座不可逾越的围墙时，你只有不断的尝试跳起，不然，你永远也看不到，墙那边的天空\n\n  一个医生不会因为病人的疾病太过严重而不去医治他，修复师也是。\n\n  人们常常说永远不要在饿的时候逛超市，你会买不需要的东西，你的生活也是如此，永远不要在孤独的时候开启一段感情，你可能会遇见错误的人，仔细想一下，因为当你无助的时候，你会抓住任何你想要的东西，而不是真正需要的。我希望大家都能找到自己真正需要的。\n\n  若能澄心净耳听，万籁俱寂亦是韵。\n\n  晨光起于白塔尖顶，终将铺满阴霾之地。\n\n  别和往事过不去，因为它已经过去；别和现实过不去，因为你还要过下去。\n\n  无人问津也好，技不如人也罢，你都要试着安静下来，去做自己该做的事，而不是让内心烦躁、焦虑，毁掉你本就不多的热情和定力！\n\n  这个世界上第一快乐的人，是不需要对别人负责的人，第二快乐的人，就是从不回头看的人。遗憾谁没有呢？人往往都是快死的时候，才发现人生最大的遗憾，就是一直在遗憾过去的遗憾。遗憾在电影里是主角崛起的前戏，在生活里是让人沉沦的毒药。\n\n----------------------------------------\n\n\n# 二、每天一遍，快乐再见\n\n<iframe src="https://b23.tv/EKLZ6NM" width="100%" height="600" frameborder="0" scrolling="No" leftmargin="0" topmargin="0"></iframe>\n',normalizedContent:'----------------------------------------\n\n本来无一物，何处染尘埃\n\n----------------------------------------\n\n黑神话 · 悟空\n\n别有世间曾未见，一行一步，一花新。\n愿你历经九九八十一难，归来仍是那只石头憨憨。\n黑夜给了我火眼金睛， 我要用它，看穿宿命。\n\n----------------------------------------\n\n\n# 一、摘录\n\n  人终将被年少不可得之物困其一生。\n\n  正常的社会并不是黑白分明、非此即彼的，有时善与善也会发生冲突。\n\n  人真正能影响的人少之又少，那些被你影响的人，只是片刻的感动。\n\n  人要接受自己的有限性，人的逻辑、理性、阅读都是有限的，整个人就是在偏见之中。人这一生就是在走出偏见。\n\n  人生中最大的痛苦,就是你知道什么是对的,但却永远做出的是错误的选择,知道和做到这个巨大的鸿沟,你永远无法跨越。\n\n  人生不能太过圆满，求而不得未必是遗憾。因为，人要接受事与愿违啊，我们太有限了，我们只能做我们觉得是对的事，然后接受结果。误解是人生常态，理解才是稀缺的例外。\n\n  人生啊充满着挑战，有很多有形无形的考试。很多时候呢，我们只能尽力而为，但是结果要选择角度，因为人生唯一确定的就是不确定的人生。在每一个人生的重要关头，我们只需要尽力而为，不留遗憾。\n\n  行路难，不再水，不在山，只在人情反复间。\n\n  你要在这里真正地高歌猛进和一败涂地过，要在这里和什么人的命运紧紧纠缠过，要一踏入这里的机场车站就被巨大的回忆和期望充满，要经过这里四季的和煦温柔暴烈残酷，才有资格说，自己属于这个城市。我曾在这里，不顾一切地活着。\n\n----------------------------------------\n\n  每个人的心里都有一团火，路过的人只能看到烟。但是总有一个人，总有那么一个人能看到这火，然后走过来陪我一起。\n\n  海上月是天上月，眼前人是心上人。\n  向来心是看客心，奈何人是剧中人。\n\n  习惯会使我们双手伶俐而头脑笨拙。\n\n  傻瓜才在年轻的时候不做傻事，羡慕别人有故事。\n\n  慧极必伤，情深不寿，强极则辱，谦谦君子，温润如玉。\n\n  当你面前有一座不可逾越的围墙时，你只有不断的尝试跳起，不然，你永远也看不到，墙那边的天空\n\n  一个医生不会因为病人的疾病太过严重而不去医治他，修复师也是。\n\n  人们常常说永远不要在饿的时候逛超市，你会买不需要的东西，你的生活也是如此，永远不要在孤独的时候开启一段感情，你可能会遇见错误的人，仔细想一下，因为当你无助的时候，你会抓住任何你想要的东西，而不是真正需要的。我希望大家都能找到自己真正需要的。\n\n  若能澄心净耳听，万籁俱寂亦是韵。\n\n  晨光起于白塔尖顶，终将铺满阴霾之地。\n\n  别和往事过不去，因为它已经过去；别和现实过不去，因为你还要过下去。\n\n  无人问津也好，技不如人也罢，你都要试着安静下来，去做自己该做的事，而不是让内心烦躁、焦虑，毁掉你本就不多的热情和定力！\n\n  这个世界上第一快乐的人，是不需要对别人负责的人，第二快乐的人，就是从不回头看的人。遗憾谁没有呢？人往往都是快死的时候，才发现人生最大的遗憾，就是一直在遗憾过去的遗憾。遗憾在电影里是主角崛起的前戏，在生活里是让人沉沦的毒药。\n\n----------------------------------------\n\n\n# 二、每天一遍，快乐再见\n\n<iframe src="https://b23.tv/eklz6nm" width="100%" height="600" frameborder="0" scrolling="no" leftmargin="0" topmargin="0"></iframe>\n',charsets:{cjk:!0},lastUpdated:"2024/02/19, 14:31:28",lastUpdatedTimestamp:1708324288e3},{title:"前端相关",frontmatter:{title:"前端相关",date:"2022-02-28T10:14:49.000Z",permalink:"/pages/gxfmrs/",categories:["其他","前端"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/06.%E5%89%8D%E7%AB%AF/01.%E5%89%8D%E7%AB%AF%E7%9B%B8%E5%85%B3.html",relativePath:"04.其他/06.前端/01.前端相关.md",key:"v-48901c43",path:"/pages/gxfmrs/",headers:[{level:3,title:"jQuery获取后台Model的值",slug:"jquery获取后台model的值",normalizedTitle:"jquery获取后台model的值",charIndex:2},{level:3,title:"杂记",slug:"杂记",normalizedTitle:"杂记",charIndex:173},{level:4,title:"1.js 获取元素(父节点,子节点,兄弟节点)",slug:"_1-js-获取元素-父节点-子节点-兄弟节点",normalizedTitle:"1.js 获取元素(父节点,子节点,兄弟节点)",charIndex:179},{level:4,title:"2.jq链式语法优点和加载函数",slug:"_2-jq链式语法优点和加载函数",normalizedTitle:"2.jq链式语法优点和加载函数",charIndex:506},{level:4,title:"3.一些常用方法",slug:"_3-一些常用方法",normalizedTitle:"3.一些常用方法",charIndex:741},{level:4,title:"4.ul调用某一列",slug:"_4-ul调用某一列",normalizedTitle:"4.ul调用某一列",charIndex:1286},{level:4,title:"5.前后台交互时",slug:"_5-前后台交互时",normalizedTitle:"5.前后台交互时",charIndex:1350},{level:4,title:"6.jquery 获取元素(父节点,子节点,兄弟节点)",slug:"_6-jquery-获取元素-父节点-子节点-兄弟节点",normalizedTitle:"6.jquery 获取元素(父节点,子节点,兄弟节点)",charIndex:1448},{level:4,title:"7.列表元素筛选",slug:"_7-列表元素筛选",normalizedTitle:"7.列表元素筛选",charIndex:2023},{level:4,title:"8.jQuery 层次选择器",slug:"_8-jquery-层次选择器",normalizedTitle:"8.jquery 层次选择器",charIndex:2293},{level:3,title:"HTTP",slug:"http",normalizedTitle:"http",charIndex:2770},{level:4,title:"消息结构",slug:"消息结构",normalizedTitle:"消息结构",charIndex:2778},{level:4,title:"请求方法",slug:"请求方法",normalizedTitle:"请求方法",charIndex:2935},{level:4,title:"响应头",slug:"响应头",normalizedTitle:"响应头",charIndex:3468},{level:4,title:"状态码",slug:"状态码",normalizedTitle:"状态码",charIndex:5745}],headersStr:"jQuery获取后台Model的值 杂记 1.js 获取元素(父节点,子节点,兄弟节点) 2.jq链式语法优点和加载函数 3.一些常用方法 4.ul调用某一列 5.前后台交互时 6.jquery 获取元素(父节点,子节点,兄弟节点) 7.列表元素筛选 8.jQuery 层次选择器 HTTP 消息结构 请求方法 响应头 状态码",content:'# jQuery获取后台Model的值\n\n<script th:inline="javascript">\n    $(function () {\n        let topics = [[${topics}]]\n        console.log(topics)\n    })\n<\/script>\n\n\n来自thymeleaf文档\n\n\n# 杂记\n\n# 1.js 获取元素(父节点,子节点,兄弟节点)\n\nvar test = document.getElementById("test");\n　　var parent = test.parentNode; // 父节点\n　　var chils = test.childNodes; // 全部子节点\n　　var first = test.firstChild; // 第一个子节点\n　　var last = test.lastChile; // 最后一个子节点　\n　　var previous = test.previousSibling; // 上一个兄弟节点\n　　var next = test.nextSibling; // 下一个兄弟节点\n\n\n\n# 2.jq链式语法优点和加载函数\n\n节约JS代码;所返回的都是同一个对象,可以提高代码的效率.(jquery的设计哲学是Write less, do more)\n\n$(document).ready(function(){});\n$(function(){\n    console.log();\n})\n(两个函数的效果等同)\n\n\n<script src="./js/login.js"><\/script>    放在</body>之前\n在构建完DOM树后自动执行\n\n\n# 3.一些常用方法\n\n.attr()        //方法设置或返回被选元素的属性值    $("img").attr("width","180");\n.addClass("")    //向被选元素添加一个或多个类\n.removeClass("")    //从被选元素移除一个或多个类\n.append()            //在被选元素的结尾插入指定内容\n.html()            //返回或设置被选元素的内容\n事件\n.click()            //单击\n.mouseenter()        //鼠标指针进入（穿过）元素时\n.mouseleave()                    //鼠标指针离开元素\n.mousedown()        //鼠标指针移动到元素上方，并按下鼠标按键\n.mouseup()            //在元素上放松鼠标按钮\n.focus()            //元素获得焦点\n.change()            //元素的值发生改变\n动画\n.hide()               //hide() 方法隐藏被选元素\n.show()               //显示隐藏的被选元素\n\n\n# 4.ul调用某一列\n\n$(".payment li").eq(1).on("click", function(){})\n\n\n# 5.前后台交互时\n\nalert(data);     显示为Object  已经取到数据\nvar b = JSON.stringify(data);\t\t//把Object对象显示为字符串\n\n\n# 6.jquery 获取元素(父节点,子节点,兄弟节点)\n\n$("#test1").parent(); // 父节点\n$("#test1").parents(); // 全部父节点\n$("#test1").parents(".mui-content");\n$("#test").children(); // 全部子节点\n$("#test").children("#test1");\n$("#test").contents(); // 返回#test里面的所有内容，包括节点和文本\n$("#test").contents("#test1");\n$("#test1").prev();  // 上一个兄弟节点\n$("#test1").prevAll(); // 之前所有兄弟节点\n$("#test1").next(); // 下一个兄弟节点\n$("#test1").nextAll(); // 之后所有兄弟节点\n$("#test1").siblings(); // 所有兄弟节点\n$("#test1").siblings("#test2");\n$("#test").find("#test1");\n\n\n举个小栗子\n\n$(".name1").parent().parent().children().children(".name3").val()\n\n\n# 7.列表元素筛选\n\n// 以下方法都返回一个新的jQuery对象，他们包含筛选到的元素\n$("ul li").eq(1); // 选取ul li中匹配的索引顺序为1的元素(也就是第2个li元素)\n$("ul li").first(); // 选取ul li中匹配的第一个元素\n$("ul li").last(); // 选取ul li中匹配的最后一个元素\n$("ul li").slice(1, 4); // 选取第2 ~ 4个元素\n$("ul li").filter(":even"); // 选取ul li中所有奇数顺序的元素\n\n\n# 8.jQuery 层次选择器\n\n$("div span") 选取<div>里的所有<span>元素\n$("div >span") 选取<div>元素下元素名是<span>的子元素\n$("#one +div") 选取id为one的元素的下一个<div>同辈元素    等同于$(#one).next("div")\n$("#one~div") 选取id为one的元素的元素后面的所有<div>同辈元素    等同于$(#one).nextAll("div")\n$(#one).siblings("div") 获取id为one的元素的所有<div>同辈元素（不管前后）\n$(#one).prev("div") 获取id为one的元素的前面紧邻的同辈<div>元素\n\n所以 获取元素范围大小顺序依次为：\n$(#one).siblings("div")>$("#one~div")>$("#one +div")  或是\n$(#one).siblings("div")>$(#one).nextAll("div")>$(#one).next("div")\n\n\n\n# HTTP\n\n# 消息结构\n\n 1. 客户端请求 客户端发送一个HTTP请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，下图给出了请求报文的一般格式。\n\n 2. 服务器响应 HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。\n\n# 请求方法\n\nHTTP1.0 定义了三种请求方法： GET, POST 和 HEAD 方法。\nHTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。\n\n序号   方法        描述\n1    GET       请求指定的页面信息，并返回实体主体。\n2    HEAD      类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头\n3    POST      向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST\n               请求可能会导致新的资源的建立和/或已有资源的修改。\n4    PUT       从客户端向服务器传送的数据取代指定的文档的内容。\n5    DELETE    \n6    CONNECT   HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。\n7    OPTIONS   允许客户端查看服务器的性能。\n8    TRACE     回显服务器收到的请求，主要用于测试或诊断。\n9    PATCH     是对 PUT 方法的补充，用来对已知资源进行局部更新 。\n\n# 响应头\n\nHTTP请求头提供了关于请求，响应或者其他的发送实体的信息。\n\n应答头                说明\nAllow              服务器支持哪些请求方法（如GET、POST等）。\nContent-Encoding   文档的编码（Encode）方法。只有在解码之后才可以得到Content-Type头指定的内容类型。利用gzip压缩文档能够显著地减少HTML文档的下载时间。Java的GZIPOutputStream可以很方便地进行gzip压缩，但只有Unix上的Netscape和Windows上的IE\n                   4、IE\n                   5才支持它。因此，Servlet应该通过查看Accept-Encoding头（即request.getHeader("Accept-Encoding")）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的HTML页面，为其他浏览器返回普通页面。\nContent-Length     表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入\n                   ByteArrayOutputStream，完成后查看其大小，然后把该值放入Content-Length头，最后通过byteArrayStream.writeTo(response.getOutputStream()发送内容。\nContent-Type       表示后面的文档属于什么MIME类型。Servlet默认为text/plain，但通常需要显式地指定为text/html。由于经常要设置Content-Type，因此HttpServletResponse提供了一个专用的方法setContentType。\nDate               当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。\nExpires            应该在什么时候认为文档已经过期，从而不再缓存它？\nLast-Modified      文档的最后改动时间。客户可以通过If-Modified-Since请求头提供一个日期，该请求将被视为一个条件GET，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（Not\n                   Modified）状态。Last-Modified也可用setDateHeader方法来设置。\nLocation           表示客户应当到哪里去提取文档。Location通常不是直接设置的，而是通过HttpServletResponse的sendRedirect方法，该方法同时设置状态代码为302。\nRefresh            表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过setHeader("Refresh",\n                   "5; URL=http://host/path")让浏览器读取指定的页面。\n                   注意这种功能通常是通过设置HTML页面HEAD区的＜META HTTP-EQUIV="Refresh"\n                   CONTENT="5;URL=http://host/path"＞实现，这是因为，自动刷新或重定向对于那些不能使用CGI或Servlet的HTML编写者十分重要。但是，对于Servlet来说，直接设置Refresh头更加方便。\n                   注意Refresh的意义是"N秒之后刷新本页面或访问指定页面"，而不是"每隔N秒刷新本页面或访问指定页面"。因此，连续刷新要求每次都发送一个Refresh头，而发送204状态代码则可以阻止浏览器继续刷新，不管是使用Refresh头还是＜META\n                   HTTP-EQUIV="Refresh" ...＞。\n                   注意Refresh头不属于HTTP 1.1正式规范的一部分，而是一个扩展，但Netscape和IE都支持它。\nServer             服务器名字。Servlet一般不设置这个值，而是由Web服务器自己设置。\nSet-Cookie         设置和页面关联的Cookie。Servlet不应使用response.setHeader("Set-Cookie",\n                   ...)，而是应使用HttpServletResponse提供的专用方法addCookie。参见下文有关Cookie设置的讨论。\nWWW-Authenticate   客户应该在Authorization头中提供什么类型的授权信息？在包含401（Unauthorized）状态行的应答中这个头是必需的。例如，response.setHeader("WWW-Authenticate",\n                   "BASIC realm=＼"executives＼"")。\n                   注意Servlet一般不进行这方面的处理，而是让Web服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。\n\n# 状态码\n\n当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 HTTP 状态码的信息头（server header）用以响应浏览器的请求。\n\n状态码分类\n\n分类    分类描述\n1**   信息，服务器收到请求，需要请求者继续执行操作\n2**   成功，操作被成功接收并处理\n3**   重定向，需要进一步的操作以完成请求\n4**   客户端错误，请求包含语法错误或无法完成请求\n5**   服务器错误，服务器在处理请求的过程中发生了错误\n\nHTTP状态码列表(标红的为常用)\n\n状态码   状态码英文名称                           中文描述\n100   Continue                          继续。客户端应继续其请求\n101   Switching Protocols               切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议\n200   OK                                请求成功。一般用于GET与POST请求\n201   Created                           已创建。成功请求并创建了新的资源\n202   Accepted                          已接受。已经接受请求，但未处理完成\n203   Non-Authoritative Information     非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本\n204   No Content                        无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档\n205   Reset Content                     重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域\n206   Partial Content                   部分内容。服务器成功处理了部分GET请求\n300   Multiple Choices                  多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择\n301   Moved Permanently                 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替\n302   Found                             临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI\n303   See Other                         查看其它地址。与301类似。使用GET和POST请求查看\n304   Not Modified                      未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源\n305   Use Proxy                         使用代理。所请求的资源必须通过代理访问\n306   Unused                            已经被废弃的HTTP状态码\n307   Temporary Redirect                临时重定向。与302类似。使用GET请求重定向\n400   Bad Request                       客户端请求的语法错误，服务器无法理解\n401   Unauthorized                      请求要求用户的身份认证\n402   Payment Required                  保留，将来使用\n403   Forbidden                         服务器理解请求客户端的请求，但是拒绝执行此请求\n404   Not Found                         服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面\n405   Method Not Allowed                客户端请求中的方法被禁止\n406   Not Acceptable                    服务器无法根据客户端请求的内容特性完成请求\n407   Proxy Authentication Required     请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权\n408   Request Time-out                  服务器等待客户端发送的请求时间过长，超时\n409   Conflict                          服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突\n410   Gone                              客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置\n411   Length Required                   服务器无法处理客户端发送的不带Content-Length的请求信息\n412   Precondition Failed               客户端请求信息的先决条件错误\n413   Request Entity Too Large          由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息\n414   Request-URI Too Large             请求的URI过长（URI通常为网址），服务器无法处理\n415   Unsupported Media Type            服务器无法处理请求附带的媒体格式\n416   Requested range not satisfiable   客户端请求的范围无效\n417   Expectation Failed                服务器无法满足Expect的请求头信息\n500   Internal Server Error             服务器内部错误，无法完成请求\n501   Not Implemented                   服务器不支持请求的功能，无法完成请求\n502   Bad Gateway                       作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应\n503   Service Unavailable               由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中\n504   Gateway Time-out                  充当网关或代理的服务器，未及时从远端服务器获取请求\n505   HTTP Version not supported        服务器不支持请求的HTTP协议的版本，无法完成处理',normalizedContent:'# jquery获取后台model的值\n\n<script th:inline="javascript">\n    $(function () {\n        let topics = [[${topics}]]\n        console.log(topics)\n    })\n<\/script>\n\n\n来自thymeleaf文档\n\n\n# 杂记\n\n# 1.js 获取元素(父节点,子节点,兄弟节点)\n\nvar test = document.getelementbyid("test");\n　　var parent = test.parentnode; // 父节点\n　　var chils = test.childnodes; // 全部子节点\n　　var first = test.firstchild; // 第一个子节点\n　　var last = test.lastchile; // 最后一个子节点　\n　　var previous = test.previoussibling; // 上一个兄弟节点\n　　var next = test.nextsibling; // 下一个兄弟节点\n\n\n\n# 2.jq链式语法优点和加载函数\n\n节约js代码;所返回的都是同一个对象,可以提高代码的效率.(jquery的设计哲学是write less, do more)\n\n$(document).ready(function(){});\n$(function(){\n    console.log();\n})\n(两个函数的效果等同)\n\n\n<script src="./js/login.js"><\/script>    放在</body>之前\n在构建完dom树后自动执行\n\n\n# 3.一些常用方法\n\n.attr()        //方法设置或返回被选元素的属性值    $("img").attr("width","180");\n.addclass("")    //向被选元素添加一个或多个类\n.removeclass("")    //从被选元素移除一个或多个类\n.append()            //在被选元素的结尾插入指定内容\n.html()            //返回或设置被选元素的内容\n事件\n.click()            //单击\n.mouseenter()        //鼠标指针进入（穿过）元素时\n.mouseleave()                    //鼠标指针离开元素\n.mousedown()        //鼠标指针移动到元素上方，并按下鼠标按键\n.mouseup()            //在元素上放松鼠标按钮\n.focus()            //元素获得焦点\n.change()            //元素的值发生改变\n动画\n.hide()               //hide() 方法隐藏被选元素\n.show()               //显示隐藏的被选元素\n\n\n# 4.ul调用某一列\n\n$(".payment li").eq(1).on("click", function(){})\n\n\n# 5.前后台交互时\n\nalert(data);     显示为object  已经取到数据\nvar b = json.stringify(data);\t\t//把object对象显示为字符串\n\n\n# 6.jquery 获取元素(父节点,子节点,兄弟节点)\n\n$("#test1").parent(); // 父节点\n$("#test1").parents(); // 全部父节点\n$("#test1").parents(".mui-content");\n$("#test").children(); // 全部子节点\n$("#test").children("#test1");\n$("#test").contents(); // 返回#test里面的所有内容，包括节点和文本\n$("#test").contents("#test1");\n$("#test1").prev();  // 上一个兄弟节点\n$("#test1").prevall(); // 之前所有兄弟节点\n$("#test1").next(); // 下一个兄弟节点\n$("#test1").nextall(); // 之后所有兄弟节点\n$("#test1").siblings(); // 所有兄弟节点\n$("#test1").siblings("#test2");\n$("#test").find("#test1");\n\n\n举个小栗子\n\n$(".name1").parent().parent().children().children(".name3").val()\n\n\n# 7.列表元素筛选\n\n// 以下方法都返回一个新的jquery对象，他们包含筛选到的元素\n$("ul li").eq(1); // 选取ul li中匹配的索引顺序为1的元素(也就是第2个li元素)\n$("ul li").first(); // 选取ul li中匹配的第一个元素\n$("ul li").last(); // 选取ul li中匹配的最后一个元素\n$("ul li").slice(1, 4); // 选取第2 ~ 4个元素\n$("ul li").filter(":even"); // 选取ul li中所有奇数顺序的元素\n\n\n# 8.jquery 层次选择器\n\n$("div span") 选取<div>里的所有<span>元素\n$("div >span") 选取<div>元素下元素名是<span>的子元素\n$("#one +div") 选取id为one的元素的下一个<div>同辈元素    等同于$(#one).next("div")\n$("#one~div") 选取id为one的元素的元素后面的所有<div>同辈元素    等同于$(#one).nextall("div")\n$(#one).siblings("div") 获取id为one的元素的所有<div>同辈元素（不管前后）\n$(#one).prev("div") 获取id为one的元素的前面紧邻的同辈<div>元素\n\n所以 获取元素范围大小顺序依次为：\n$(#one).siblings("div")>$("#one~div")>$("#one +div")  或是\n$(#one).siblings("div")>$(#one).nextall("div")>$(#one).next("div")\n\n\n\n# http\n\n# 消息结构\n\n 1. 客户端请求 客户端发送一个http请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，下图给出了请求报文的一般格式。\n\n 2. 服务器响应 http响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。\n\n# 请求方法\n\nhttp1.0 定义了三种请求方法： get, post 和 head 方法。\nhttp1.1 新增了六种请求方法：options、put、patch、delete、trace 和 connect 方法。\n\n序号   方法        描述\n1    get       请求指定的页面信息，并返回实体主体。\n2    head      类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头\n3    post      向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。post\n               请求可能会导致新的资源的建立和/或已有资源的修改。\n4    put       从客户端向服务器传送的数据取代指定的文档的内容。\n5    delete    \n6    connect   http/1.1 协议中预留给能够将连接改为管道方式的代理服务器。\n7    options   允许客户端查看服务器的性能。\n8    trace     回显服务器收到的请求，主要用于测试或诊断。\n9    patch     是对 put 方法的补充，用来对已知资源进行局部更新 。\n\n# 响应头\n\nhttp请求头提供了关于请求，响应或者其他的发送实体的信息。\n\n应答头                说明\nallow              服务器支持哪些请求方法（如get、post等）。\ncontent-encoding   文档的编码（encode）方法。只有在解码之后才可以得到content-type头指定的内容类型。利用gzip压缩文档能够显著地减少html文档的下载时间。java的gzipoutputstream可以很方便地进行gzip压缩，但只有unix上的netscape和windows上的ie\n                   4、ie\n                   5才支持它。因此，servlet应该通过查看accept-encoding头（即request.getheader("accept-encoding")）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的html页面，为其他浏览器返回普通页面。\ncontent-length     表示内容长度。只有当浏览器使用持久http连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入\n                   bytearrayoutputstream，完成后查看其大小，然后把该值放入content-length头，最后通过bytearraystream.writeto(response.getoutputstream()发送内容。\ncontent-type       表示后面的文档属于什么mime类型。servlet默认为text/plain，但通常需要显式地指定为text/html。由于经常要设置content-type，因此httpservletresponse提供了一个专用的方法setcontenttype。\ndate               当前的gmt时间。你可以用setdateheader来设置这个头以避免转换时间格式的麻烦。\nexpires            应该在什么时候认为文档已经过期，从而不再缓存它？\nlast-modified      文档的最后改动时间。客户可以通过if-modified-since请求头提供一个日期，该请求将被视为一个条件get，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（not\n                   modified）状态。last-modified也可用setdateheader方法来设置。\nlocation           表示客户应当到哪里去提取文档。location通常不是直接设置的，而是通过httpservletresponse的sendredirect方法，该方法同时设置状态代码为302。\nrefresh            表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过setheader("refresh",\n                   "5; url=http://host/path")让浏览器读取指定的页面。\n                   注意这种功能通常是通过设置html页面head区的＜meta http-equiv="refresh"\n                   content="5;url=http://host/path"＞实现，这是因为，自动刷新或重定向对于那些不能使用cgi或servlet的html编写者十分重要。但是，对于servlet来说，直接设置refresh头更加方便。\n                   注意refresh的意义是"n秒之后刷新本页面或访问指定页面"，而不是"每隔n秒刷新本页面或访问指定页面"。因此，连续刷新要求每次都发送一个refresh头，而发送204状态代码则可以阻止浏览器继续刷新，不管是使用refresh头还是＜meta\n                   http-equiv="refresh" ...＞。\n                   注意refresh头不属于http 1.1正式规范的一部分，而是一个扩展，但netscape和ie都支持它。\nserver             服务器名字。servlet一般不设置这个值，而是由web服务器自己设置。\nset-cookie         设置和页面关联的cookie。servlet不应使用response.setheader("set-cookie",\n                   ...)，而是应使用httpservletresponse提供的专用方法addcookie。参见下文有关cookie设置的讨论。\nwww-authenticate   客户应该在authorization头中提供什么类型的授权信息？在包含401（unauthorized）状态行的应答中这个头是必需的。例如，response.setheader("www-authenticate",\n                   "basic realm=＼"executives＼"")。\n                   注意servlet一般不进行这方面的处理，而是让web服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。\n\n# 状态码\n\n当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含 http 状态码的信息头（server header）用以响应浏览器的请求。\n\n状态码分类\n\n分类    分类描述\n1**   信息，服务器收到请求，需要请求者继续执行操作\n2**   成功，操作被成功接收并处理\n3**   重定向，需要进一步的操作以完成请求\n4**   客户端错误，请求包含语法错误或无法完成请求\n5**   服务器错误，服务器在处理请求的过程中发生了错误\n\nhttp状态码列表(标红的为常用)\n\n状态码   状态码英文名称                           中文描述\n100   continue                          继续。客户端应继续其请求\n101   switching protocols               切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到http的新版本协议\n200   ok                                请求成功。一般用于get与post请求\n201   created                           已创建。成功请求并创建了新的资源\n202   accepted                          已接受。已经接受请求，但未处理完成\n203   non-authoritative information     非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本\n204   no content                        无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档\n205   reset content                     重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域\n206   partial content                   部分内容。服务器成功处理了部分get请求\n300   multiple choices                  多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择\n301   moved permanently                 永久移动。请求的资源已被永久的移动到新uri，返回信息会包括新的uri，浏览器会自动定向到新uri。今后任何新的请求都应使用新的uri代替\n302   found                             临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有uri\n303   see other                         查看其它地址。与301类似。使用get和post请求查看\n304   not modified                      未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源\n305   use proxy                         使用代理。所请求的资源必须通过代理访问\n306   unused                            已经被废弃的http状态码\n307   temporary redirect                临时重定向。与302类似。使用get请求重定向\n400   bad request                       客户端请求的语法错误，服务器无法理解\n401   unauthorized                      请求要求用户的身份认证\n402   payment required                  保留，将来使用\n403   forbidden                         服务器理解请求客户端的请求，但是拒绝执行此请求\n404   not found                         服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面\n405   method not allowed                客户端请求中的方法被禁止\n406   not acceptable                    服务器无法根据客户端请求的内容特性完成请求\n407   proxy authentication required     请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权\n408   request time-out                  服务器等待客户端发送的请求时间过长，超时\n409   conflict                          服务器完成客户端的 put 请求时可能返回此代码，服务器处理请求时发生了冲突\n410   gone                              客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置\n411   length required                   服务器无法处理客户端发送的不带content-length的请求信息\n412   precondition failed               客户端请求信息的先决条件错误\n413   request entity too large          由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个retry-after的响应信息\n414   request-uri too large             请求的uri过长（uri通常为网址），服务器无法处理\n415   unsupported media type            服务器无法处理请求附带的媒体格式\n416   requested range not satisfiable   客户端请求的范围无效\n417   expectation failed                服务器无法满足expect的请求头信息\n500   internal server error             服务器内部错误，无法完成请求\n501   not implemented                   服务器不支持请求的功能，无法完成请求\n502   bad gateway                       作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应\n503   service unavailable               由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的retry-after头信息中\n504   gateway time-out                  充当网关或代理的服务器，未及时从远端服务器获取请求\n505   http version not supported        服务器不支持请求的http协议的版本，无法完成处理',charsets:{cjk:!0},lastUpdated:"2022/05/05, 11:44:37",lastUpdatedTimestamp:1651722277e3},{title:"资料",frontmatter:{title:"资料",date:"2022-04-17T23:03:43.000Z",permalink:"/pages/e6d5cb/",categories:["其他"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/98.%E8%B5%84%E6%96%99/98.%E8%B5%84%E6%96%99.html",relativePath:"04.其他/98.资料/98.资料.md",key:"v-68f50c4e",path:"/pages/e6d5cb/",headers:[{level:2,title:"1. 基础",slug:"_1-基础",normalizedTitle:"1. 基础",charIndex:2},{level:3,title:"Java",slug:"java",normalizedTitle:"java",charIndex:12},{level:3,title:"基础",slug:"基础",normalizedTitle:"基础",charIndex:5},{level:2,title:"2. 大数据",slug:"_2-大数据",normalizedTitle:"2. 大数据",charIndex:220},{level:3,title:"Hadoop",slug:"hadoop",normalizedTitle:"hadoop",charIndex:231},{level:3,title:"Kafka",slug:"kafka",normalizedTitle:"kafka",charIndex:428},{level:3,title:"HBase",slug:"hbase",normalizedTitle:"hbase",charIndex:472},{level:3,title:"Spark",slug:"spark",normalizedTitle:"spark",charIndex:516},{level:3,title:"Flink",slug:"flink",normalizedTitle:"flink",charIndex:647},{level:3,title:"HIVE",slug:"hive",normalizedTitle:"hive",charIndex:778},{level:3,title:"数仓、数湖",slug:"数仓、数湖",normalizedTitle:"数仓、数湖",charIndex:871},{level:3,title:"DataX",slug:"datax",normalizedTitle:"datax",charIndex:1068},{level:3,title:"Azkaban",slug:"azkaban",normalizedTitle:"azkaban",charIndex:1106},{level:3,title:"机器学习",slug:"机器学习",normalizedTitle:"机器学习",charIndex:1144},{level:2,title:"3. 数据库和SQL",slug:"_3-数据库和sql",normalizedTitle:"3. 数据库和sql",charIndex:1204},{level:3,title:"SQL",slug:"sql",normalizedTitle:"sql",charIndex:832},{level:2,title:"4. 其他",slug:"_4-其他",normalizedTitle:"4. 其他",charIndex:1338},{level:3,title:"Shell",slug:"shell",normalizedTitle:"shell",charIndex:1348},{level:3,title:"正则表达式",slug:"正则表达式",normalizedTitle:"正则表达式",charIndex:1572}],headersStr:"1. 基础 Java 基础 2. 大数据 Hadoop Kafka HBase Spark Flink HIVE 数仓、数湖 DataX Azkaban 机器学习 3. 数据库和SQL SQL 4. 其他 Shell 正则表达式",content:"# 1. 基础\n\n\n# Java\n\n网盘\n\n资料\n\n * 五分钟学大数据-Java知识点复习\n\n书\n\n * 《深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）》-周志明(2019)\n\n面试题\n\n * 五分钟学大数据-Java基础面试题\n * 五分钟学大数据-JVM面试专题及答案\n\n\n# 基础\n\n网盘\n\n资料\n\n * 五分钟学大数据-操作系统篇\n * 五分钟学大数据-数据结构与算法篇\n * 五分钟学大数据-计算机网络篇\n\n\n# 2. 大数据\n\n\n# Hadoop\n\n网盘\n\n书\n\n * 《大数据之路阿里巴巴大数据实践》\n * 《大数据技术架构手册（公众号：进击吧大数据编制）》\n\n----------------------------------------\n\n资料\n\n * 五分钟学大数据-Hadoop企业级调优手册\n * 五分钟学大数据-Hadoop知识体系吐血宝典\n\n面试题\n\n * 五分钟学大数据-2022最新大数据面试宝典\n\n\n# Kafka\n\n网盘\n\n资料\n\n * 五分钟学大数据-Kafka知识体系吐血总结\n\n\n# HBase\n\n网盘\n\n资料\n\n * 五分钟学大数据-HBase知识体系吐血总结\n\n\n# Spark\n\n网盘\n\n资料\n\n * 尚硅谷-大数据技术之Spark性能调优与故障处理（1.1）\n * 五分钟学大数据-Spark知识体系吐血总结\n * 五分钟学大数据-Spark数据倾斜及解决方案\n\n面试题\n\n * 五分钟学大数据-Spark面试八股文\n\n\n# Flink\n\n网盘\n\n书\n\n * 《Apache Flink（阿里出品）》\n\n资料\n\n * 五分钟学大数据-Flink知识体系保姆级总结\n * 尚硅谷-大数据技术之Flink内核（1.12）V1.0\n\n面试题\n\n * 五分钟学大数据-Fink面试八股文\n\n\n# HIVE\n\n网盘\n\n资料\n\n * 五分钟学大数据-Hive知识体系保姆级总结\n * 五分钟学大数据-HiveSQL执行计划详解\n * 五分钟学大数据-最强HiveSQL开发指南\n\n\n# 数仓、数湖\n\n网盘\n\n书\n\n * 《数据仓库工具箱 维度建模权威指南 第3版》\n\n资料\n\n * 3万字38页《数据仓库知识体系》\n * 五分钟学大数据-大厂实时数仓建设案例\n * 五分钟学大数据-数据湖知识体系总结\n * 五分钟学大数据-最强数仓建设保姆级教程\n * 五分钟学大数据-最强最全面数仓建设规范指南（强烈推荐）\n * 五分钟学大数据-美团数据平台及数仓建设实践（全网独发）\n\n\n# DataX\n\n网盘\n\n资料\n\n * 尚硅谷-大数据技术之DataX\n\n\n# Azkaban\n\n网盘\n\n * 尚硅谷-大数据技术之Azkaban\n\n\n# 机器学习\n\n网盘\n\n书\n\n * 《周志华-机器学习》（西瓜书）\n * 《自然语言处理》\n * 《精通特征工程》\n\n\n# 3. 数据库和SQL\n\n\n# SQL\n\n网盘\n\n书\n\n * 《SQL进阶教程》高清中文版\n * 《MySQL实战45讲》\n * 《MySQL必知必会》\n * 《Oracle从入门到精通》\n\n面试题\n\n * 五分钟学大数据-最强最全面的大数据SQL面试题和答案\n\n\n# 4. 其他\n\n\n# Shell\n\n网盘\n\n资料\n\n * 尚硅谷-高级技术之Linux(CentOS7.9)\n * 尚硅谷-高级技术之Shell\n\n书\n\n * 《Linux命令大全搜索工具 v1.5.1.pdf》\n * 《Linux命令行与shell脚本编程大全第3版》\n * 《The Linux Command Line中文版》\n * 《Linux从入门到精通》\n * 《鸟哥的Linux私房菜》\n\n面试题\n\n * 五分钟学大数据-Linux面试专题及答案\n\n\n# 正则表达式\n\n书\n\n网盘\n\n * 《精通正则表达式第三版（美）佛瑞德》",normalizedContent:"# 1. 基础\n\n\n# java\n\n网盘\n\n资料\n\n * 五分钟学大数据-java知识点复习\n\n书\n\n * 《深入理解java虚拟机：jvm高级特性与最佳实践（第3版）》-周志明(2019)\n\n面试题\n\n * 五分钟学大数据-java基础面试题\n * 五分钟学大数据-jvm面试专题及答案\n\n\n# 基础\n\n网盘\n\n资料\n\n * 五分钟学大数据-操作系统篇\n * 五分钟学大数据-数据结构与算法篇\n * 五分钟学大数据-计算机网络篇\n\n\n# 2. 大数据\n\n\n# hadoop\n\n网盘\n\n书\n\n * 《大数据之路阿里巴巴大数据实践》\n * 《大数据技术架构手册（公众号：进击吧大数据编制）》\n\n----------------------------------------\n\n资料\n\n * 五分钟学大数据-hadoop企业级调优手册\n * 五分钟学大数据-hadoop知识体系吐血宝典\n\n面试题\n\n * 五分钟学大数据-2022最新大数据面试宝典\n\n\n# kafka\n\n网盘\n\n资料\n\n * 五分钟学大数据-kafka知识体系吐血总结\n\n\n# hbase\n\n网盘\n\n资料\n\n * 五分钟学大数据-hbase知识体系吐血总结\n\n\n# spark\n\n网盘\n\n资料\n\n * 尚硅谷-大数据技术之spark性能调优与故障处理（1.1）\n * 五分钟学大数据-spark知识体系吐血总结\n * 五分钟学大数据-spark数据倾斜及解决方案\n\n面试题\n\n * 五分钟学大数据-spark面试八股文\n\n\n# flink\n\n网盘\n\n书\n\n * 《apache flink（阿里出品）》\n\n资料\n\n * 五分钟学大数据-flink知识体系保姆级总结\n * 尚硅谷-大数据技术之flink内核（1.12）v1.0\n\n面试题\n\n * 五分钟学大数据-fink面试八股文\n\n\n# hive\n\n网盘\n\n资料\n\n * 五分钟学大数据-hive知识体系保姆级总结\n * 五分钟学大数据-hivesql执行计划详解\n * 五分钟学大数据-最强hivesql开发指南\n\n\n# 数仓、数湖\n\n网盘\n\n书\n\n * 《数据仓库工具箱 维度建模权威指南 第3版》\n\n资料\n\n * 3万字38页《数据仓库知识体系》\n * 五分钟学大数据-大厂实时数仓建设案例\n * 五分钟学大数据-数据湖知识体系总结\n * 五分钟学大数据-最强数仓建设保姆级教程\n * 五分钟学大数据-最强最全面数仓建设规范指南（强烈推荐）\n * 五分钟学大数据-美团数据平台及数仓建设实践（全网独发）\n\n\n# datax\n\n网盘\n\n资料\n\n * 尚硅谷-大数据技术之datax\n\n\n# azkaban\n\n网盘\n\n * 尚硅谷-大数据技术之azkaban\n\n\n# 机器学习\n\n网盘\n\n书\n\n * 《周志华-机器学习》（西瓜书）\n * 《自然语言处理》\n * 《精通特征工程》\n\n\n# 3. 数据库和sql\n\n\n# sql\n\n网盘\n\n书\n\n * 《sql进阶教程》高清中文版\n * 《mysql实战45讲》\n * 《mysql必知必会》\n * 《oracle从入门到精通》\n\n面试题\n\n * 五分钟学大数据-最强最全面的大数据sql面试题和答案\n\n\n# 4. 其他\n\n\n# shell\n\n网盘\n\n资料\n\n * 尚硅谷-高级技术之linux(centos7.9)\n * 尚硅谷-高级技术之shell\n\n书\n\n * 《linux命令大全搜索工具 v1.5.1.pdf》\n * 《linux命令行与shell脚本编程大全第3版》\n * 《the linux command line中文版》\n * 《linux从入门到精通》\n * 《鸟哥的linux私房菜》\n\n面试题\n\n * 五分钟学大数据-linux面试专题及答案\n\n\n# 正则表达式\n\n书\n\n网盘\n\n * 《精通正则表达式第三版（美）佛瑞德》",charsets:{cjk:!0},lastUpdated:"2022/05/03, 23:07:48",lastUpdatedTimestamp:1651590468e3},{title:"常用工具或网站",frontmatter:{title:"常用工具或网站",date:"2022-03-02T17:42:54.000Z",permalink:"/pages/414e9c/",categories:["其他","杂记"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/99.%E6%9D%82%E8%AE%B0/01.%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E6%88%96%E7%BD%91%E7%AB%99.html",relativePath:"04.其他/99.杂记/01.常用工具或网站.md",key:"v-5e6eb6cd",path:"/pages/414e9c/",headers:[{level:2,title:"工具或网站",slug:"工具或网站",normalizedTitle:"工具或网站",charIndex:2},{level:3,title:"在线工具",slug:"在线工具",normalizedTitle:"在线工具",charIndex:12},{level:3,title:"jar包下载",slug:"jar包下载",normalizedTitle:"jar包下载",charIndex:154},{level:3,title:"数据库通用客户端工具",slug:"数据库通用客户端工具",normalizedTitle:"数据库通用客户端工具",charIndex:437},{level:3,title:"自动化部署",slug:"自动化部署",normalizedTitle:"自动化部署",charIndex:668},{level:3,title:"接口测试",slug:"接口测试",normalizedTitle:"接口测试",charIndex:897},{level:3,title:"元数据管理",slug:"元数据管理",normalizedTitle:"元数据管理",charIndex:1471},{level:3,title:"资源下载",slug:"资源下载",normalizedTitle:"资源下载",charIndex:2482},{level:3,title:"学习网站",slug:"学习网站",normalizedTitle:"学习网站",charIndex:2869},{level:3,title:"云盘",slug:"云盘",normalizedTitle:"云盘",charIndex:3238},{level:3,title:"源码网站",slug:"源码网站",normalizedTitle:"源码网站",charIndex:3709},{level:3,title:"大数据3D可视化",slug:"大数据3d可视化",normalizedTitle:"大数据3d可视化",charIndex:4215},{level:3,title:"笔记",slug:"笔记",normalizedTitle:"笔记",charIndex:4357},{level:3,title:"作图",slug:"作图",normalizedTitle:"作图",charIndex:4957},{level:3,title:"科学",slug:"科学",normalizedTitle:"科学",charIndex:5504},{level:3,title:"电脑必备工具",slug:"电脑必备工具",normalizedTitle:"电脑必备工具",charIndex:5796},{level:3,title:"电脑常用收费工具",slug:"电脑常用收费工具",normalizedTitle:"电脑常用收费工具",charIndex:8797}],headersStr:"工具或网站 在线工具 jar包下载 数据库通用客户端工具 自动化部署 接口测试 元数据管理 资源下载 学习网站 云盘 源码网站 大数据3D可视化 笔记 作图 科学 电脑必备工具 电脑常用收费工具",content:"# 工具或网站\n\n\n# 在线工具\n\n阿里云在线小工具\n\nnull\n\n- name: 阿里云在线小工具\n  desc: \n  link: https://developer.aliyun.com/skills/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# jar包下载\n\n阿里云\n\n下载几乎所有jar包\n\nmaven中央仓库\n\n下载jar包\n\n- name: 阿里云\n  desc: 下载几乎所有jar包\n  link: https://developer.aliyun.com/mvn/guide\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: maven中央仓库\n  desc: 下载jar包\n  link: https://mvnrepository.com/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n# 数据库通用客户端工具\n\ndbeaver\n\n免费的多平台数据库工具，为开发人员，数据库管理员，分析师和所有需要与数据库工作的人。支持所有流行的数据库。\n\n- name: dbeaver\n  desc: 免费的多平台数据库工具，为开发人员，数据库管理员，分析师和所有需要与数据库工作的人。支持所有流行的数据库。\n  link: https://dbeaver.io/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 自动化部署\n\nJenkins\n\nJava语言开发，用于监控持续重复的工作，包括：持续的软件版本发布/测试项目，监控外部调用执行的工作。\n\n- name: Jenkins\n  desc: Java语言开发，用于监控持续重复的工作，包括：持续的软件版本发布/测试项目，监控外部调用执行的工作。\n  link: http://www.jenkins.org.cn/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 接口测试\n\nApifox\n\nAPI 文档、API 调试、API Mock、API 自动化测试（Postman + Swagger + Mock + JMeter）\n\nEolink\n\nEolink 是国内起步较早的API全生命周期管理平台。产品能力覆盖API开发-运维-开放交易，实现API研发管理、API快速测试、API自动化测试、API监控、API微服务网关、API对外开放等企业深度场景。\n\n- name: Apifox\n  desc: API 文档、API 调试、API Mock、API 自动化测试（Postman + Swagger + Mock + JMeter）\n  link: https://www.apifox.cn/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: Eolink\n  desc: Eolink 是国内起步较早的API全生命周期管理平台。产品能力覆盖API开发-运维-开放交易，实现API研发管理、API快速测试、API自动化测试、API监控、API微服务网关、API对外开放等企业深度场景。\n  link: https://www.eolink.com/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n# 元数据管理\n\nApache Atlas\n\n元数据管理和数据治理平台，是Hadoop社区为解决Hadoop生态系统的元数据治理问题而产生的开源项目，它为Hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心能力。\n\nSQLFlow\n\nSQLFlow是一个可视化的在线处理SQL对象依赖关系的工具，只需要上传你的SQL脚本，它可以自动分析SQL里的数据对象，包括database、schema、table、view、column、procedure、function、trigger等等，并且能够分析这些数据对象之间的依赖关系，并将这些依赖关系可视化展现出来。\n\nPDManer\n\nPDManer元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具\n\n- name: Apache Atlas\n  desc: 元数据管理和数据治理平台，是Hadoop社区为解决Hadoop生态系统的元数据治理问题而产生的开源项目，它为Hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心能力。\n  link: https://atlas.apache.org/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: SQLFlow\n  desc: SQLFlow是一个可视化的在线处理SQL对象依赖关系的工具，只需要上传你的SQL脚本，它可以自动分析SQL里的数据对象，包括database、schema、table、view、column、procedure、function、trigger等等，并且能够分析这些数据对象之间的依赖关系，并将这些依赖关系可视化展现出来。\n  link: https://github.com/sql-machine-learning/sqlflow\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: PDManer\n  desc: PDManer元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具\n  link: https://gitee.com/robergroup/pdmaner\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 资源下载\n\n华为云镜像\n\n华为开源镜像站(Mirrors)是由华为云提供的开源组件、开源操作系统及开源DevOps工具镜像站\n\nmacwk\n\n解决mac0S下软件难的问题，让你简单又粗暴的下载软件\n\n- name: 华为云镜像\n  desc: 华为开源镜像站(Mirrors)是由华为云提供的开源组件、开源操作系统及开源DevOps工具镜像站\n  link: https://mirrors.huaweicloud.com/home\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: macwk\n  desc: 解决mac0S下软件难的问题，让你简单又粗暴的下载软件\n  link: https://macwk.com/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n# 学习网站\n\n哔哩哔哩\n\nbilibili\n\n菜鸟教程\n\n编程知识\n\nITPUB技术论坛\n\n我是描述\n\n- name: 哔哩哔哩\n  desc: bilibili\n  link: https://www.bilibili.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: 菜鸟教程\n  desc: 编程知识\n  link: https://www.runoob.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: ITPUB技术论坛\n  desc: 我是描述\n  link: http://www.itpub.net/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 云盘\n\n蓝奏云\n\n我是描述\n\n百度网盘\n\n我是描述\n\n腾讯微云\n\n我是描述\n\n阿里网盘\n\n我是描述\n\n- name: 蓝奏云\n  desc: 我是描述\n  link: https://www.lanzous.com\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: 百度网盘\n  desc: 我是描述\n  link: https://pan.baidu.com\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: 腾讯微云\n  desc: 我是描述\n  link: https://www.weiyun.com/disk\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: 阿里网盘\n  desc: 我是描述\n  link: https://www.aliyundrive.com/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n\n# 源码网站\n\n码云Gitee\n\n我是描述\n\nGithub\n\n我是描述\n\n源码之家\n\n我是描述\n\nAxureShop\n\nAxureShop产品原型网（付费）\n\n- name: 码云Gitee\n  desc: 我是描述\n  link: https://gitee.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Github\n  desc: 我是描述\n  link: https://github.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: 源码之家\n  desc: 我是描述\n  link: https://www.mycodes.net\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: AxureShop\n  desc: AxureShop产品原型网（付费）\n  link: http://demo.axureshop.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 大数据3D可视化\n\nThingJs\n\n我是描述\n\n- name: ThingJs\n  desc: 我是描述\n  link:  http://www.thingjs.com/guide/\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n# 笔记\n\nObsidian\n\n知识整理工具（双向链接）\n\n- name: Obsidian\n  desc: 知识整理工具（双向链接）\n  link: https://obsidian.md/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n有道云笔记\n\n我是描述\n\n印象笔记\n\n我是描述\n\n博客园\n\n我是描述\n\nCSDN\n\n我是描述\n\n- name: 有道云笔记\n  desc: 我是描述\n  link:  http://note.youdao.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: 印象笔记\n  desc: 我是描述\n  link: https://www.yinxiang.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: 博客园\n  desc: 我是描述\n  link: https://www.cnblogs.com\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: CSDN\n  desc: 我是描述\n  link: https://www.csdn.net\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 作图\n\n百度脑图\n\n我是描述\n\nProcessOn\n\n我是描述\n\n在线思维导图(模板)\n\n我是描述\n\n软件\n\nVisio、StarUML、谷歌浏览器插件Gliffy、Balsamiq Mockups 3\n\n- name: 百度脑图\n  desc: 我是描述\n  link:  https://naotu.baidu.com\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: ProcessOn\n  desc: 我是描述\n  link: https://www.processon.com\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: 在线思维导图(模板)\n  desc: 我是描述\n  link: https://mm.edrawsoft.cn\n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n- name: 软件\n  desc: Visio、StarUML、谷歌浏览器插件Gliffy、Balsamiq Mockups 3\n  link: \n  bgColor: '#F0DFB1'\n  textColor: '#2A3344'\n\n\n\n# 科学\n\nAnycast\n\n我是描述\n\nPigcha\n\n我是描述\n\n- name: Anycast\n  desc: 我是描述\n  link:  http://s.anyjs2.com/share/mfekij | http://www.d1kuai.com/#/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Pigcha\n  desc: 我是描述\n  link: https://github.com/pigpigchacha\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 电脑必备工具\n\nSublime Text\n\n最好用的文本编辑器之一\n\nObsidian\n\n这款免费灵活的应用程序可以让你随心所欲地思考。\n\nTrafficMonitor\n\n一个用于显示当前网速、CPU及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。\n\nListary\n\nWindows 革命性的文件搜索工具。Listary 使得查找文件和启动应用程序变得异常迅速，无论是对普通用户还是高级用户都是如此！\n\nQuicker\n\n您的指尖工具箱\n\nmemreduct\n\n轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。\n\nF.lux\n\nF.lux 使你的电脑屏幕看起来像你所在的房间，始终如此。当太阳落山时，它使你的电脑看起来像室内灯光。早晨，它又使事物看起来像阳光\n\nKeyFreeze\n\nKeyFreeze 是一款免费的 Windows 应用程序，它可以在不 “锁定” 屏幕的情况下锁定您的键盘和鼠标。这样您的孩子就可以安全地观看动画片，或者与他们的祖父母进行视频聊天，并随心所欲地敲击键盘。\n\nPDManer\n\nPDManer元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具，相对于PowerDesigner，他具备界面简洁美观，操作简单，上手容易等特点。支持Windows,Mac,Linux等操作系统，也能够支持国产操作系统\n\nFiddler\n\nFiddler是一个http协议调试代理工具。\n\nSnipaste\n\n截图、贴图工具\n\nWinRAR\n\n压缩工具\n\n图吧工具箱\n\n图吧工具箱，是开源、免费、绿色、纯净的硬件检测工具合集，专为所有计算机硬件极客、DIY爱好者、各路大神及小白制作。集成大量常见硬件检测、评分工具，一键下载、方便使用。\n\nFolcolor\n\n给你的 Windows 文件夹涂色可以帮助你整理和提高工作效率。你的文件夹可以通过颜色立即识别，而不是需要停下来阅读标签。\n\n- name: Sublime Text\n  desc: 最好用的文本编辑器之一\n  link: https://www.sublimetext.com/\n  link2: https://sublimetext.p2hp.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Obsidian\n  desc: 这款免费灵活的应用程序可以让你随心所欲地思考。\n  link: https://obsidian.md/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: TrafficMonitor\n  desc: 一个用于显示当前网速、CPU及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。\n  link: https://github.com/zhongyang219/TrafficMonitor\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Listary\n  desc: Windows 革命性的文件搜索工具。Listary 使得查找文件和启动应用程序变得异常迅速，无论是对普通用户还是高级用户都是如此！\n  link: https://www.listary.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Quicker\n  desc: 您的指尖工具箱\n  link: https://getquicker.net/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: memreduct\n  desc: 轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。\n  link: https://github.com/henrypp/memreduct\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: F.lux\n  desc: F.lux 使你的电脑屏幕看起来像你所在的房间，始终如此。当太阳落山时，它使你的电脑看起来像室内灯光。早晨，它又使事物看起来像阳光\n  link: https://justgetflux.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: KeyFreeze\n  desc: KeyFreeze 是一款免费的 Windows 应用程序，它可以在不 “锁定” 屏幕的情况下锁定您的键盘和鼠标。这样您的孩子就可以安全地观看动画片，或者与他们的祖父母进行视频聊天，并随心所欲地敲击键盘。\n  link: https://www.keyfreeze.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: PDManer\n  desc: PDManer元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具，相对于PowerDesigner，他具备界面简洁美观，操作简单，上手容易等特点。支持Windows,Mac,Linux等操作系统，也能够支持国产操作系统\n  link: https://gitee.com/robergroup/pdmaner\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Fiddler\n  desc: Fiddler是一个http协议调试代理工具。\n  link: https://www.fiddler.net.cn/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Snipaste\n  desc: 截图、贴图工具\n  link: https://www.snipaste.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: WinRAR\n  desc: 压缩工具\n  link: https://www.winrar.com.cn/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: 图吧工具箱\n  desc: 图吧工具箱，是开源、免费、绿色、纯净的硬件检测工具合集，专为所有计算机硬件极客、DIY爱好者、各路大神及小白制作。集成大量常见硬件检测、评分工具，一键下载、方便使用。\n  link: https://www.tbtool.cn/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Folcolor\n  desc: 给你的 Windows 文件夹涂色可以帮助你整理和提高工作效率。你的文件夹可以通过颜色立即识别，而不是需要停下来阅读标签。\n  link: http://www.folcolor.com/\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n\n\n\n# 电脑常用收费工具\n\nWallpaper Engine\n\n基于Steam平台的壁纸软件\n\nBeyond Compare\n\nBeyond Compare 是数据比较的专业选择。比较文件夹、文本文件、图像和表格。高效审查差异并自信地合并更改。\n\nSecureCRT\n\n适用于 Windows、macOS 和 Linux 的 SecureCRT 客户端为计算专业人员提供了坚实的终端仿真。\n\nInternet Download Manager\n\n互联网下载管理器 (IDM) 是一种下载加速器，可将下载速度提高多达 8 倍，用于恢复、组织和安排下载。\n\nMyDockFinder\n\nMyDockFinder是一款系统快速启动和控制查看系统功能的软件。可以拖拽添加自己喜好的程序或文件，拖拽直接使用程序打开文件，基于WinUI使用GPU渲染，流畅的动画效果，贝塞尔曲线圆角模糊，可以调节模糊强度。管理系统所有窗口的最小化动画。\n\n- name: Wallpaper Engine\n  desc: 基于Steam平台的壁纸软件\n  link: https://www.wallpaperengine.io/zh-hans\n  bgColor: '#DFEEE7'\n  textColor: '#2A3344'\n- name: Beyond Compare\n  desc: Beyond Compare 是数据比较的专业选择。比较文件夹、文本文件、图像和表格。高效审查差异并自信地合并更改。\n  link: https://bcompare.cn/\n  bgColor: '#DFEEE7'\n  textColor: '#D98765'\n- name: SecureCRT\n  desc: 适用于 Windows、macOS 和 Linux 的 SecureCRT 客户端为计算专业人员提供了坚实的终端仿真。\n  link: https://www.vandyke.com/products/securecrt/\n  bgColor: '#DFEEE7'\n  textColor: '#D98765'\n- name: Internet Download Manager\n  desc: 互联网下载管理器 (IDM) 是一种下载加速器，可将下载速度提高多达 8 倍，用于恢复、组织和安排下载。\n  link: https://www.internetdownloadmanager.com/\n  bgColor: '#DFEEE7'\n  textColor: '#D98765'\n- name: MyDockFinder\n  desc: MyDockFinder是一款系统快速启动和控制查看系统功能的软件。可以拖拽添加自己喜好的程序或文件，拖拽直接使用程序打开文件，基于WinUI使用GPU渲染，流畅的动画效果，贝塞尔曲线圆角模糊，可以调节模糊强度。管理系统所有窗口的最小化动画。\n  link: https://www.mydockfinder.com/\n  bgColor: '#DFEEE7'\n  textColor: '#D98765'\n",normalizedContent:"# 工具或网站\n\n\n# 在线工具\n\n阿里云在线小工具\n\nnull\n\n- name: 阿里云在线小工具\n  desc: \n  link: https://developer.aliyun.com/skills/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# jar包下载\n\n阿里云\n\n下载几乎所有jar包\n\nmaven中央仓库\n\n下载jar包\n\n- name: 阿里云\n  desc: 下载几乎所有jar包\n  link: https://developer.aliyun.com/mvn/guide\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: maven中央仓库\n  desc: 下载jar包\n  link: https://mvnrepository.com/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n# 数据库通用客户端工具\n\ndbeaver\n\n免费的多平台数据库工具，为开发人员，数据库管理员，分析师和所有需要与数据库工作的人。支持所有流行的数据库。\n\n- name: dbeaver\n  desc: 免费的多平台数据库工具，为开发人员，数据库管理员，分析师和所有需要与数据库工作的人。支持所有流行的数据库。\n  link: https://dbeaver.io/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 自动化部署\n\njenkins\n\njava语言开发，用于监控持续重复的工作，包括：持续的软件版本发布/测试项目，监控外部调用执行的工作。\n\n- name: jenkins\n  desc: java语言开发，用于监控持续重复的工作，包括：持续的软件版本发布/测试项目，监控外部调用执行的工作。\n  link: http://www.jenkins.org.cn/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 接口测试\n\napifox\n\napi 文档、api 调试、api mock、api 自动化测试（postman + swagger + mock + jmeter）\n\neolink\n\neolink 是国内起步较早的api全生命周期管理平台。产品能力覆盖api开发-运维-开放交易，实现api研发管理、api快速测试、api自动化测试、api监控、api微服务网关、api对外开放等企业深度场景。\n\n- name: apifox\n  desc: api 文档、api 调试、api mock、api 自动化测试（postman + swagger + mock + jmeter）\n  link: https://www.apifox.cn/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: eolink\n  desc: eolink 是国内起步较早的api全生命周期管理平台。产品能力覆盖api开发-运维-开放交易，实现api研发管理、api快速测试、api自动化测试、api监控、api微服务网关、api对外开放等企业深度场景。\n  link: https://www.eolink.com/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n# 元数据管理\n\napache atlas\n\n元数据管理和数据治理平台，是hadoop社区为解决hadoop生态系统的元数据治理问题而产生的开源项目，它为hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心能力。\n\nsqlflow\n\nsqlflow是一个可视化的在线处理sql对象依赖关系的工具，只需要上传你的sql脚本，它可以自动分析sql里的数据对象，包括database、schema、table、view、column、procedure、function、trigger等等，并且能够分析这些数据对象之间的依赖关系，并将这些依赖关系可视化展现出来。\n\npdmaner\n\npdmaner元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具\n\n- name: apache atlas\n  desc: 元数据管理和数据治理平台，是hadoop社区为解决hadoop生态系统的元数据治理问题而产生的开源项目，它为hadoop集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心能力。\n  link: https://atlas.apache.org/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: sqlflow\n  desc: sqlflow是一个可视化的在线处理sql对象依赖关系的工具，只需要上传你的sql脚本，它可以自动分析sql里的数据对象，包括database、schema、table、view、column、procedure、function、trigger等等，并且能够分析这些数据对象之间的依赖关系，并将这些依赖关系可视化展现出来。\n  link: https://github.com/sql-machine-learning/sqlflow\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: pdmaner\n  desc: pdmaner元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具\n  link: https://gitee.com/robergroup/pdmaner\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 资源下载\n\n华为云镜像\n\n华为开源镜像站(mirrors)是由华为云提供的开源组件、开源操作系统及开源devops工具镜像站\n\nmacwk\n\n解决mac0s下软件难的问题，让你简单又粗暴的下载软件\n\n- name: 华为云镜像\n  desc: 华为开源镜像站(mirrors)是由华为云提供的开源组件、开源操作系统及开源devops工具镜像站\n  link: https://mirrors.huaweicloud.com/home\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: macwk\n  desc: 解决mac0s下软件难的问题，让你简单又粗暴的下载软件\n  link: https://macwk.com/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n# 学习网站\n\n哔哩哔哩\n\nbilibili\n\n菜鸟教程\n\n编程知识\n\nitpub技术论坛\n\n我是描述\n\n- name: 哔哩哔哩\n  desc: bilibili\n  link: https://www.bilibili.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: 菜鸟教程\n  desc: 编程知识\n  link: https://www.runoob.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: itpub技术论坛\n  desc: 我是描述\n  link: http://www.itpub.net/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 云盘\n\n蓝奏云\n\n我是描述\n\n百度网盘\n\n我是描述\n\n腾讯微云\n\n我是描述\n\n阿里网盘\n\n我是描述\n\n- name: 蓝奏云\n  desc: 我是描述\n  link: https://www.lanzous.com\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: 百度网盘\n  desc: 我是描述\n  link: https://pan.baidu.com\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: 腾讯微云\n  desc: 我是描述\n  link: https://www.weiyun.com/disk\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: 阿里网盘\n  desc: 我是描述\n  link: https://www.aliyundrive.com/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n\n# 源码网站\n\n码云gitee\n\n我是描述\n\ngithub\n\n我是描述\n\n源码之家\n\n我是描述\n\naxureshop\n\naxureshop产品原型网（付费）\n\n- name: 码云gitee\n  desc: 我是描述\n  link: https://gitee.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: github\n  desc: 我是描述\n  link: https://github.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: 源码之家\n  desc: 我是描述\n  link: https://www.mycodes.net\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: axureshop\n  desc: axureshop产品原型网（付费）\n  link: http://demo.axureshop.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 大数据3d可视化\n\nthingjs\n\n我是描述\n\n- name: thingjs\n  desc: 我是描述\n  link:  http://www.thingjs.com/guide/\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n# 笔记\n\nobsidian\n\n知识整理工具（双向链接）\n\n- name: obsidian\n  desc: 知识整理工具（双向链接）\n  link: https://obsidian.md/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n有道云笔记\n\n我是描述\n\n印象笔记\n\n我是描述\n\n博客园\n\n我是描述\n\ncsdn\n\n我是描述\n\n- name: 有道云笔记\n  desc: 我是描述\n  link:  http://note.youdao.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: 印象笔记\n  desc: 我是描述\n  link: https://www.yinxiang.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: 博客园\n  desc: 我是描述\n  link: https://www.cnblogs.com\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: csdn\n  desc: 我是描述\n  link: https://www.csdn.net\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 作图\n\n百度脑图\n\n我是描述\n\nprocesson\n\n我是描述\n\n在线思维导图(模板)\n\n我是描述\n\n软件\n\nvisio、staruml、谷歌浏览器插件gliffy、balsamiq mockups 3\n\n- name: 百度脑图\n  desc: 我是描述\n  link:  https://naotu.baidu.com\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: processon\n  desc: 我是描述\n  link: https://www.processon.com\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: 在线思维导图(模板)\n  desc: 我是描述\n  link: https://mm.edrawsoft.cn\n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n- name: 软件\n  desc: visio、staruml、谷歌浏览器插件gliffy、balsamiq mockups 3\n  link: \n  bgcolor: '#f0dfb1'\n  textcolor: '#2a3344'\n\n\n\n# 科学\n\nanycast\n\n我是描述\n\npigcha\n\n我是描述\n\n- name: anycast\n  desc: 我是描述\n  link:  http://s.anyjs2.com/share/mfekij | http://www.d1kuai.com/#/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: pigcha\n  desc: 我是描述\n  link: https://github.com/pigpigchacha\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 电脑必备工具\n\nsublime text\n\n最好用的文本编辑器之一\n\nobsidian\n\n这款免费灵活的应用程序可以让你随心所欲地思考。\n\ntrafficmonitor\n\n一个用于显示当前网速、cpu及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。\n\nlistary\n\nwindows 革命性的文件搜索工具。listary 使得查找文件和启动应用程序变得异常迅速，无论是对普通用户还是高级用户都是如此！\n\nquicker\n\n您的指尖工具箱\n\nmemreduct\n\n轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。\n\nf.lux\n\nf.lux 使你的电脑屏幕看起来像你所在的房间，始终如此。当太阳落山时，它使你的电脑看起来像室内灯光。早晨，它又使事物看起来像阳光\n\nkeyfreeze\n\nkeyfreeze 是一款免费的 windows 应用程序，它可以在不 “锁定” 屏幕的情况下锁定您的键盘和鼠标。这样您的孩子就可以安全地观看动画片，或者与他们的祖父母进行视频聊天，并随心所欲地敲击键盘。\n\npdmaner\n\npdmaner元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具，相对于powerdesigner，他具备界面简洁美观，操作简单，上手容易等特点。支持windows,mac,linux等操作系统，也能够支持国产操作系统\n\nfiddler\n\nfiddler是一个http协议调试代理工具。\n\nsnipaste\n\n截图、贴图工具\n\nwinrar\n\n压缩工具\n\n图吧工具箱\n\n图吧工具箱，是开源、免费、绿色、纯净的硬件检测工具合集，专为所有计算机硬件极客、diy爱好者、各路大神及小白制作。集成大量常见硬件检测、评分工具，一键下载、方便使用。\n\nfolcolor\n\n给你的 windows 文件夹涂色可以帮助你整理和提高工作效率。你的文件夹可以通过颜色立即识别，而不是需要停下来阅读标签。\n\n- name: sublime text\n  desc: 最好用的文本编辑器之一\n  link: https://www.sublimetext.com/\n  link2: https://sublimetext.p2hp.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: obsidian\n  desc: 这款免费灵活的应用程序可以让你随心所欲地思考。\n  link: https://obsidian.md/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: trafficmonitor\n  desc: 一个用于显示当前网速、cpu及内存利用率的桌面悬浮窗软件，并支持任务栏显示，支持更换皮肤。\n  link: https://github.com/zhongyang219/trafficmonitor\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: listary\n  desc: windows 革命性的文件搜索工具。listary 使得查找文件和启动应用程序变得异常迅速，无论是对普通用户还是高级用户都是如此！\n  link: https://www.listary.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: quicker\n  desc: 您的指尖工具箱\n  link: https://getquicker.net/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: memreduct\n  desc: 轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。\n  link: https://github.com/henrypp/memreduct\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: f.lux\n  desc: f.lux 使你的电脑屏幕看起来像你所在的房间，始终如此。当太阳落山时，它使你的电脑看起来像室内灯光。早晨，它又使事物看起来像阳光\n  link: https://justgetflux.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: keyfreeze\n  desc: keyfreeze 是一款免费的 windows 应用程序，它可以在不 “锁定” 屏幕的情况下锁定您的键盘和鼠标。这样您的孩子就可以安全地观看动画片，或者与他们的祖父母进行视频聊天，并随心所欲地敲击键盘。\n  link: https://www.keyfreeze.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: pdmaner\n  desc: pdmaner元数建模，是一款多操作系统开源免费的桌面版关系数据库模型建模工具，相对于powerdesigner，他具备界面简洁美观，操作简单，上手容易等特点。支持windows,mac,linux等操作系统，也能够支持国产操作系统\n  link: https://gitee.com/robergroup/pdmaner\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: fiddler\n  desc: fiddler是一个http协议调试代理工具。\n  link: https://www.fiddler.net.cn/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: snipaste\n  desc: 截图、贴图工具\n  link: https://www.snipaste.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: winrar\n  desc: 压缩工具\n  link: https://www.winrar.com.cn/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: 图吧工具箱\n  desc: 图吧工具箱，是开源、免费、绿色、纯净的硬件检测工具合集，专为所有计算机硬件极客、diy爱好者、各路大神及小白制作。集成大量常见硬件检测、评分工具，一键下载、方便使用。\n  link: https://www.tbtool.cn/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: folcolor\n  desc: 给你的 windows 文件夹涂色可以帮助你整理和提高工作效率。你的文件夹可以通过颜色立即识别，而不是需要停下来阅读标签。\n  link: http://www.folcolor.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n\n\n\n# 电脑常用收费工具\n\nwallpaper engine\n\n基于steam平台的壁纸软件\n\nbeyond compare\n\nbeyond compare 是数据比较的专业选择。比较文件夹、文本文件、图像和表格。高效审查差异并自信地合并更改。\n\nsecurecrt\n\n适用于 windows、macos 和 linux 的 securecrt 客户端为计算专业人员提供了坚实的终端仿真。\n\ninternet download manager\n\n互联网下载管理器 (idm) 是一种下载加速器，可将下载速度提高多达 8 倍，用于恢复、组织和安排下载。\n\nmydockfinder\n\nmydockfinder是一款系统快速启动和控制查看系统功能的软件。可以拖拽添加自己喜好的程序或文件，拖拽直接使用程序打开文件，基于winui使用gpu渲染，流畅的动画效果，贝塞尔曲线圆角模糊，可以调节模糊强度。管理系统所有窗口的最小化动画。\n\n- name: wallpaper engine\n  desc: 基于steam平台的壁纸软件\n  link: https://www.wallpaperengine.io/zh-hans\n  bgcolor: '#dfeee7'\n  textcolor: '#2a3344'\n- name: beyond compare\n  desc: beyond compare 是数据比较的专业选择。比较文件夹、文本文件、图像和表格。高效审查差异并自信地合并更改。\n  link: https://bcompare.cn/\n  bgcolor: '#dfeee7'\n  textcolor: '#d98765'\n- name: securecrt\n  desc: 适用于 windows、macos 和 linux 的 securecrt 客户端为计算专业人员提供了坚实的终端仿真。\n  link: https://www.vandyke.com/products/securecrt/\n  bgcolor: '#dfeee7'\n  textcolor: '#d98765'\n- name: internet download manager\n  desc: 互联网下载管理器 (idm) 是一种下载加速器，可将下载速度提高多达 8 倍，用于恢复、组织和安排下载。\n  link: https://www.internetdownloadmanager.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#d98765'\n- name: mydockfinder\n  desc: mydockfinder是一款系统快速启动和控制查看系统功能的软件。可以拖拽添加自己喜好的程序或文件，拖拽直接使用程序打开文件，基于winui使用gpu渲染，流畅的动画效果，贝塞尔曲线圆角模糊，可以调节模糊强度。管理系统所有窗口的最小化动画。\n  link: https://www.mydockfinder.com/\n  bgcolor: '#dfeee7'\n  textcolor: '#d98765'\n",charsets:{cjk:!0},lastUpdated:"2025/07/06, 23:26:24",lastUpdatedTimestamp:1751815584e3},{title:"快捷键",frontmatter:{title:"快捷键",date:"2022-04-02T14:56:18.000Z",permalink:"/pages/378bb1/",categories:["其他","杂记"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/99.%E6%9D%82%E8%AE%B0/03.%E5%BF%AB%E6%8D%B7%E9%94%AE.html",relativePath:"04.其他/99.杂记/03.快捷键.md",key:"v-acb49e1a",path:"/pages/378bb1/",headers:[{level:3,title:"Sublime快捷键",slug:"sublime快捷键",normalizedTitle:"sublime快捷键",charIndex:2},{level:3,title:"IDEA快捷键",slug:"idea快捷键",normalizedTitle:"idea快捷键",charIndex:726}],headersStr:"Sublime快捷键 IDEA快捷键",content:'# Sublime快捷键\n\n# 列编辑\nCtrl + Shift + L\n\n# 大小写转换\nCtrl + K + U   # 大写\nCtrl + K + L   # 小写\n\n# 命令行\nCtrl + Shift + P\n\n# 快速查找 匹配括号\nCtrl+R         # 快速查找函数\nCtrl+M         # 跳转到另一半括号\nCtrl+Shift+M   # 快速匹配括号内容\nCtrl+Shift+[   # 折叠代码\nCtrl+Shift+]   # 展开代码\nAlt+-          # 回到上一次编辑的地方，多次按可以追溯到编辑轨迹\nShift+Alt+-    # 对应的返回下一编辑处，直到最终编辑的地方。这里说的编辑处，实际上就是指的光标所在的地方\nCtrl+;         # 查找变量名（也会显示函数名称）\n\n# 文件\n["ctrl+shift+n"]\t\t# 新建窗口\n["ctrl+shift+w"]\t\t# 关闭窗口\n["ctrl+o"]\t\t        # 提示打开文件\n["ctrl+shift+t"]\t\t# 重新打开最后关闭的文件\n["ctrl+n"]\t\t        # 新建文件\n["ctrl+s"]\t\t        # 保存文件\n["ctrl+shift+s"]\t\t# 另存为\n["ctrl+w"]\t\t        # 关闭文件\n\n# 窗口内\n["ctrl+k", "ctrl+b"]\t\t# 侧边栏\n["f11"]\t\t                # 切换全屏\n["shift+f11"]               # toggle_distraction_free\n\n\n\n# IDEA快捷键\n\n# 常用快捷键\nCtrl + X          # 删除行\nCtrl + D          # 复制行\nCtrl + /          # 或 Ctrl+Shift+/ 注释（// 或者/…/ ）\nCtrl + E          # 最近打开的文件\nCtrl + H          # 显示类结构图\nCtrl + F          # 搜索\nCtrl + N          # 查找类\nCtrl + G        # 跳转到某一行\nAlt + 1           # 快速打开或隐藏工程面板\nAlt +  left/right # 切换打开的文件视图\nAlt +  Up/Down    # 在方法间快速移动定位\nAlt + 回车         # 导入包,自动修正\nctrl + h        # 查找实现?\n\n代码补全\t\nCtrl + Alt + V   # 自动补全变量名及类型。例如把括号内的SQL赋成一个变量 点击setting勾选Local definition可以自动补全变量类型\n',normalizedContent:'# sublime快捷键\n\n# 列编辑\nctrl + shift + l\n\n# 大小写转换\nctrl + k + u   # 大写\nctrl + k + l   # 小写\n\n# 命令行\nctrl + shift + p\n\n# 快速查找 匹配括号\nctrl+r         # 快速查找函数\nctrl+m         # 跳转到另一半括号\nctrl+shift+m   # 快速匹配括号内容\nctrl+shift+[   # 折叠代码\nctrl+shift+]   # 展开代码\nalt+-          # 回到上一次编辑的地方，多次按可以追溯到编辑轨迹\nshift+alt+-    # 对应的返回下一编辑处，直到最终编辑的地方。这里说的编辑处，实际上就是指的光标所在的地方\nctrl+;         # 查找变量名（也会显示函数名称）\n\n# 文件\n["ctrl+shift+n"]\t\t# 新建窗口\n["ctrl+shift+w"]\t\t# 关闭窗口\n["ctrl+o"]\t\t        # 提示打开文件\n["ctrl+shift+t"]\t\t# 重新打开最后关闭的文件\n["ctrl+n"]\t\t        # 新建文件\n["ctrl+s"]\t\t        # 保存文件\n["ctrl+shift+s"]\t\t# 另存为\n["ctrl+w"]\t\t        # 关闭文件\n\n# 窗口内\n["ctrl+k", "ctrl+b"]\t\t# 侧边栏\n["f11"]\t\t                # 切换全屏\n["shift+f11"]               # toggle_distraction_free\n\n\n\n# idea快捷键\n\n# 常用快捷键\nctrl + x          # 删除行\nctrl + d          # 复制行\nctrl + /          # 或 ctrl+shift+/ 注释（// 或者/…/ ）\nctrl + e          # 最近打开的文件\nctrl + h          # 显示类结构图\nctrl + f          # 搜索\nctrl + n          # 查找类\nctrl + g        # 跳转到某一行\nalt + 1           # 快速打开或隐藏工程面板\nalt +  left/right # 切换打开的文件视图\nalt +  up/down    # 在方法间快速移动定位\nalt + 回车         # 导入包,自动修正\nctrl + h        # 查找实现?\n\n代码补全\t\nctrl + alt + v   # 自动补全变量名及类型。例如把括号内的sql赋成一个变量 点击setting勾选local definition可以自动补全变量类型\n',charsets:{cjk:!0},lastUpdated:"2022/07/06, 17:52:56",lastUpdatedTimestamp:1657101176e3},{title:"琐碎知识",frontmatter:{title:"琐碎知识",date:"2022-03-08T09:53:01.000Z",permalink:"/pages/c0e729/",categories:["其他","杂记"],tags:[null]},regularPath:"/04.%E5%85%B6%E4%BB%96/99.%E6%9D%82%E8%AE%B0/02.%E7%90%90%E7%A2%8E%E7%9F%A5%E8%AF%86.html",relativePath:"04.其他/99.杂记/02.琐碎知识.md",key:"v-90e7de80",path:"/pages/c0e729/",headers:[{level:3,title:"1、英文缩写",slug:"_1、英文缩写",normalizedTitle:"1、英文缩写",charIndex:2},{level:4,title:"Python",slug:"python",normalizedTitle:"python",charIndex:12},{level:4,title:"Oracle",slug:"oracle",normalizedTitle:"oracle",charIndex:67},{level:3,title:"服务器",slug:"服务器",normalizedTitle:"服务器",charIndex:146},{level:3,title:"2、html实体",slug:"_2、html实体",normalizedTitle:"2、html实体",charIndex:217},{level:3,title:"3、位运算的运用",slug:"_3、位运算的运用",normalizedTitle:"3、位运算的运用",charIndex:250},{level:4,title:"与运算",slug:"与运算",normalizedTitle:"与运算",charIndex:262},{level:5,title:"判断奇偶",slug:"判断奇偶",normalizedTitle:"判断奇偶",charIndex:269},{level:5,title:"取数指定位（指定位置0）",slug:"取数指定位-指定位置0",normalizedTitle:"取数指定位（指定位置0）",charIndex:329},{level:5,title:"平均值",slug:"平均值",normalizedTitle:"平均值",charIndex:521},{level:5,title:"判断整数是不是2的幂",slug:"判断整数是不是2的幂",normalizedTitle:"判断整数是不是2的幂",charIndex:601},{level:4,title:"或运算",slug:"或运算",normalizedTitle:"或运算",charIndex:692},{level:5,title:"对数指定位置1",slug:"对数指定位置1",normalizedTitle:"对数指定位置1",charIndex:699},{level:4,title:"非运算",slug:"非运算",normalizedTitle:"非运算",charIndex:827},{level:5,title:"最低位置零",slug:"最低位置零",normalizedTitle:"最低位置零",charIndex:834},{level:4,title:"异或运算",slug:"异或运算",normalizedTitle:"异或运算",charIndex:964},{level:5,title:"翻转指定位",slug:"翻转指定位",normalizedTitle:"翻转指定位",charIndex:1076},{level:5,title:"两数相等",slug:"两数相等",normalizedTitle:"两数相等",charIndex:1193},{level:5,title:"交换两个数",slug:"交换两个数",normalizedTitle:"交换两个数",charIndex:1223},{level:5,title:"绝对值",slug:"绝对值",normalizedTitle:"绝对值",charIndex:1312},{level:4,title:"移位运算",slug:"移位运算",normalizedTitle:"移位运算",charIndex:1416},{level:5,title:"乘、除、取模运算",slug:"乘、除、取模运算",normalizedTitle:"乘、除、取模运算",charIndex:1424},{level:3,title:"4、日期格式化中的yyyy和YYYY（JAVA）",slug:"_4、日期格式化中的yyyy和yyyy-java",normalizedTitle:"4、日期格式化中的yyyy和yyyy（java）",charIndex:1615},{level:4,title:"常见的时间格式化字符串",slug:"常见的时间格式化字符串",normalizedTitle:"常见的时间格式化字符串",charIndex:1765},{level:3,title:"5、windows上使用Linux命令",slug:"_5、windows上使用linux命令",normalizedTitle:"5、windows上使用linux命令",charIndex:4484},{level:4,title:"虚拟机",slug:"虚拟机",normalizedTitle:"虚拟机",charIndex:4507},{level:5,title:"VMware问题",slug:"vmware问题",normalizedTitle:"vmware问题",charIndex:4528},{level:4,title:"git命令行",slug:"git命令行",normalizedTitle:"git命令行",charIndex:4826},{level:4,title:"WSL",slug:"wsl",normalizedTitle:"wsl",charIndex:4836},{level:4,title:"Docker是不是也可以",slug:"docker是不是也可以",normalizedTitle:"docker是不是也可以",charIndex:5549},{level:3,title:"6、安装jar包(手动下载)",slug:"_6、安装jar包-手动下载",normalizedTitle:"6、安装jar包(手动下载)",charIndex:5566},{level:3,title:"7、搜索引擎语法",slug:"_7、搜索引擎语法",normalizedTitle:"7、搜索引擎语法",charIndex:6504},{level:3,title:"8、JDK源码导入idea",slug:"_8、jdk源码导入idea",normalizedTitle:"8、jdk源码导入idea",charIndex:7610},{level:3,title:"9、文档编写（中文文案排版指北）",slug:"_9、文档编写-中文文案排版指北",normalizedTitle:"9、文档编写（中文文案排版指北）",charIndex:7931},{level:3,title:"10、字符编码",slug:"_10、字符编码",normalizedTitle:"10、字符编码",charIndex:8155},{level:4,title:"编码",slug:"编码",normalizedTitle:"编码",charIndex:8160},{level:4,title:"字符转换工具",slug:"字符转换工具",normalizedTitle:"字符转换工具",charIndex:10028},{level:4,title:"现代编码模型",slug:"现代编码模型",normalizedTitle:"现代编码模型",charIndex:10677}],headersStr:"1、英文缩写 Python Oracle 服务器 2、html实体 3、位运算的运用 与运算 判断奇偶 取数指定位（指定位置0） 平均值 判断整数是不是2的幂 或运算 对数指定位置1 非运算 最低位置零 异或运算 翻转指定位 两数相等 交换两个数 绝对值 移位运算 乘、除、取模运算 4、日期格式化中的yyyy和YYYY（JAVA） 常见的时间格式化字符串 5、windows上使用Linux命令 虚拟机 VMware问题 git命令行 WSL Docker是不是也可以 6、安装jar包(手动下载) 7、搜索引擎语法 8、JDK源码导入idea 9、文档编写（中文文案排版指北） 10、字符编码 编码 字符转换工具 现代编码模型",content:'# 1、英文缩写\n\n# Python\n\n简称    全称\npip   package installer for python\n\n# Oracle\n\n简称     全称\nCLOB   Character Large Object\nBLOB   binary large object\n\n\n# 服务器\n\n简称    全称\nNTP   网络时间协议，英文名称：Network Time Protocol（NTP）\n\nNTP 配置\n\n\n# 2、html实体\n\n&amp; &lt;等字符 参考链接\n\n\n# 3、位运算的运用\n\n# 与运算\n\n# 判断奇偶\n\n判断int型变量a是奇数还是偶数\n\na & 1 = 0 // 偶数\na & 1 = 1 // 奇数\n\n\n# 取数指定位（指定位置0）\n\n取一个数的指定位\n\n// 1. 取int型变量a（二进制）的第k位\na >> k & 1  // 先右移k位，与1后取出第k位\n\n// 2. \n// 比如取数 X=1010 1110 的低4位，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行按位与运算（X&Y=0000 1110）即可得到X的指定位。\n\n\n# 平均值\n\n整数的平均值\n\nint average(int x, int y)\n{   \n     return (x&y)+((x^y)>>1);\n}\n\n\n# 判断整数是不是2的幂\n\n判断一个整数是不是2的幂\n\nboolean power2(int x)\n{\n    return ((x&(x-1))==0)&&(x!=0);\n}\n\n\n# 或运算\n\n# 对数指定位置1\n\n判断一个整数是不是2的幂\n\n// 比如将数 X=1010 1110 的低4位设置为1，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行按位或运算（X|Y=1010 1111）即可得到。\n\n\n# 非运算\n\n# 最低位置零\n\n使一个数的最低位为零\n\n// 使a的最低位为0，可以表示为：a & ~1。~1的值为 1111 1111 1111 1110，再按"与"运算，最低位一定为0。因为" ~"运算符的优先级比算术运算符、关系运算符、逻辑运算符和其他运算符都高\n\n\n# 异或运算\n\n> 异或的几条性质\n> \n>  1. 交换律\n>  2. 结合律 (a^b)^c == a^(b^c)\n>  3. 对于任何数x，都有 x^x=0，x^0=x\n>  4. 自反性: a^b^b=a^0=a\n\n# 翻转指定位\n\n翻转指定位\n\n// 比如将数 X=1010 1110 的低4位进行翻转，只需要另找一个数Y，令Y的低4位为1，其余位为0，即Y=0000 1111，然后将X与Y进行异或运算（X^Y=1010 0001）即可得到\n\n\n# 两数相等\n\n判断两个整数相等\n\na ^ 1 = 0\n\n\n# 交换两个数\n\n用位运算符交换两个整数\n\nvoid swap(int x , int y)\n{\n    x ^= y;\n    y ^= x;\n    x ^= y;\n}\n\n\n# 绝对值\n\n计算绝对值\n\nint abs( int x )\n{\n  int y ;\n  y = x >> 31 ;\n  return (x^y)-y ;        // or: (x+y)^y\n}\n\n\n# 移位运算\n\n# 乘、除、取模运算\n\n乘、除、取模运算转化成位运算 (在不产生溢出的情况下)\n\n// 乘法运算转化成位运算\na * (2^n)      等价于     a << n\n\n// 除法运算转化成位运算\na / (2^n)      等价于     a >> n\n\n// 取模运算转化成位运算\na % (2^n)      等价于     a & (2^n - 1)\n\n\n原文地址\n\n\n# 4、日期格式化中的yyyy和YYYY（JAVA）\n\n 1. y 是Year, Y 表示的是Week year，Week year 意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，那么这周就算入下一年。\n 2. 大写的DD代表的是处于这一年中那一天，不是处于这个月的那一天\n\n# 常见的时间格式化字符串\n\n 1. yyyy-MM-dd HH24:mi:ss\n\n格式        描述\nY         年的最后一位数字，如：5\nYY        年的最后两位数字，如：15\nYYY       年的最后三位数字，如：015\nYYYY      年，如：2015\nY,YYY     年用逗号分割\nSYYYY     年\nYEAR      年拼写，如：TWENTY FIFTEEN\nSYEAR     年拼写，如：TWENTY FIFTEEN\nI         ISO年的最后一位数字，如：5\nIY        ISO年的最后两位数字，如：15\nIYY       ISO年的最后三位数字，如：015\nIYYY      ISO年，如：2015\nRR        两位数字年，如：15\nRRRR      四位数字年，如：2015\nMM        Month (01-12)\nMON       月份简称，如：JUN\nMONTH     月份全称，如：JUNE\nRM        罗马数字月份\nD         Day of week (1-7)\nDD        Day of month (1-31)\nDDD       Day of year (1-366)\nHH        Hour of day (1-12)\nHH12      Hour of day (1-12)\nHH24      Hour of day (0-23)\nMI        Minute (0-59)\nSS        Second (0-59)\nSSSSS     Seconds past midnight\nFF[1…9]   毫秒\nDS        日期简称，如：6/12/2015\nDL        日期全称，如：Friday, June 12, 2015\nTS        时间简称，如：5:18:03 PM\nCC        世纪，如：21\nSCC       世纪，如：21\nQ         Quarter of year (1, 2, 3, 4)\nW         Week of month (1-5)\nWW        Week of year (1-53)\nIW        ISO Week of year (1-52 or 1-53)\nDY        星期简称，如：Fri\nDAY       星期全称，如：Friday\nAM        A.M.\nPM        P.M.\nAD        A.D.\nBC        B.C.\nTZD       夏令时\nTZR       时区\nTZH       时区之时差\nTZM       时区之分钟差\nEE        era 全称\nE         era 简称\nJ         The number of days since January 1, 4712 BC\nFM        去掉首尾空格\nFX        精确匹配\nX         秒和毫秒分隔符\nTH        DDTH --\x3e 4th\nSP        DDSP --\x3eFOUR\nSPTH      DDSPTH --\x3e FOURTH\nTHSP      DDTHSP --\x3e FOURTH\n\n 2. %Y-%m-%d %H:%i:%s\n\n格式   描述\n%a   缩写星期名\n%b   缩写月名\n%c   月，数值\n%D   带有英文前缀的月中的天\n%d   月的天，数值(00-31)\n%e   月的天，数值(0-31)\n%f   微秒\n%H   小时 (00-23)\n%h   小时 (01-12)\n%I   小时 (01-12)\n%i   分钟，数值(00-59)\n%j   年的天 (001-366)\n%k   小时 (0-23)\n%l   小时 (1-12)\n%M   月名\n%m   月，数值(00-12)\n%p   AM 或 PM\n%r   时间，12-小时（hh:mm:ss AM 或 PM）\n%S   秒(00-59)\n%s   秒(00-59)\n%T   时间, 24-小时 (hh:mm:ss)\n%U   周 (00-53) 星期日是一周的第一天\n%u   周 (00-53) 星期一是一周的第一天\n%V   周 (01-53) 星期日是一周的第一天，与 %X 使用\n%v   周 (01-53) 星期一是一周的第一天，与 %x 使用\n%W   星期名\n%w   周的天 （0=星期日, 6=星期六）\n%X   年，其中的星期日是周的第一天，4 位，与 %V 使用\n%x   年，其中的星期一是周的第一天，4 位，与 %v 使用\n%Y   年，4 位\n%y   年，2 位\n\n转字符串\n\nSELECT to_char(sysdate, \'DD-MON-YYYY HH24:MI:SS\') FROM dual;          -- 10-AUG-2022 17:11:53\nSELECT to_char(sysdate, \'MON-YY-DD HH:MI:SS AM\') FROM dual;           -- AUG-22-10 05:02:49 PM\nSELECT to_char(current_timestamp, \'HH24:MI:SS\') FROM dual;            -- 17:06:10\nSELECT to_char(current_timestamp,\'HH12:MI:SS\') FROM dual ;            -- 05:03:01\nSELECT to_char(current_timestamp,\'FMHH12:FMMI:FMSS\') FROM dual;       -- 5:03:11\n\n\n转时间戳\n\nSELECT to_timestamp(\'-1\',\'SYYYY\') FROM dual;\nSELECT to_timestamp(\'98\',\'RR\') FROM dual;\nSELECT to_timestamp(\'01\',\'RR\') FROM dual;\nSELECT to_timestamp(\'12-Sep-10 14:10:10.123000\',\'DD-Mon-YY HH24:MI:SS.FF\') FROM dual;   -- 12-SEP-10 02.10.10.123000000 PM\n\n\n\n# 5、windows上使用Linux命令\n\n# 虚拟机\n\n类似于VMWare等软件\n\n# VMware问题\n\n 1. 解决 VMware 中 CentOS 7 没有ens33网卡的问题\n    * 首先设置在系统启动时激活网卡 vim /etc/sysconfig/network-scripts/ifcfg-ens33 将ONBOOT=no改为ONBOOT=yes\n    * 执行ifconfig ens33 up，此时ifconfig 显示有了ens33网卡，但没有ip\n    * 执行 systemctl stop NetworkManager ifup ens33\n    * 重启网络 systemctl restart network.service\n\n原文链接\n\n# git命令行\n\n# WSL\n\n适用于Linux的windows子系统（WSL：Windows Subsystem for Linux）\n\n 1. 移动WSL默认位置\n\n# 下载LxRunOffline，下载文件LxRunOffline-vxxxx.zip\nhttps://github.com/DDoSolitary/LxRunOffline/releases\n\n# 查看子系统(linux)版本号(cmd执行, 注意要么配置环境变量, 要么在LxRunOffline.exe所在目录打开cmd)\nLxRunOffline list\n\n# 将Linux移动到指定的目录\nLxRunOffline move -n {version} -d {dir}\nLxRunOffline move -n Ubuntu-18.04 -d D:\\VMware\\LxRunOffline-v3.5.0-msvc\\Linux\n\n\n 2. 固定ip\n\n参考链接\n\n 3. 使用\n\n使用命令行工具连接WSL\n\n# 生成秘钥\nsudo ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key\nsudo ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key\nsudo ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key\n\n# 修改/etc/ssh/sshd_config的PasswordAuthentication项为yes\n\n# 重启ssh\nsudo service ssh restart\n\n# 使用命令行工具连接\n\n\n# Docker是不是也可以\n\n\n# 6、安装jar包(手动下载)\n\n阿里云maven包下载\n\nmvn install:install-file -Dfile=jar包的位置 -DgroupId=上面的groupId -DartifactId=上面的artifactId -Dversion=上面的version -Dpackaging=jar\n\nmvn install:install-file -Dfile=./pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar -DgroupId=org.pentaho -DartifactId=pentaho-aggdesigner-algorithm -Dversion=5.1.5-jhyde -Dpackaging=jar\nmvn install:install-file -Dfile=./eigenbase-properties-1.1.4.jar -DgroupId=eigenbase -DartifactId=eigenbase-properties -Dversion=1.1.4 -Dpackaging=jar\n\n\n# 还是不行, 每次maven还会去中央仓库找jar包\n# 解决方法 删除本地仓库中该jar包下:  _remote.repositories 和 以.lastUpdated结尾的文件(还有_maven.repositories ?)\n# 搞错目录了, 本地有两个maven仓库, 安装到另一个下面去了, 终于解决了!!!\n\n\n引入项目目录下的jar包\n\n<dependency>\n    <groupId >com.dameng.common</groupId>\n    <artifactId>common-aop</artifactId>\n    <version>${dm-aop.version}</version>\n    <scope>system</scope>\n    <systemPath>${basedir}\\lib\\com.dameng.common.aop_${dm-aop.version}.jar</systemPath>\n</dependency>\n\n\n\n# 7、搜索引擎语法\n\n搜索指令        功能                     示例\n@           搜索社交媒体                 @twitter\n$           搜索特定价格                 camera $400\n#           搜索 # 标签                #throwbackthursday\n-           从搜索结果中排除特定字词           "kafka3.0" -特性 site:csdn.net\n+           从搜索结果中获取特定字词           "kafka3.0" +特性 site:csdn.net\nfiletype:   精确搜索文件类型               filetype:chm "java"\n""          搜索完全匹配的结果              "kafka3.0新特性"\n..          在某个数字范围内执行搜索           camera $50..$100\nOR（大写）      组合搜索                   marathon OR race\nsite:       搜索特定网站                 "kafka3.0新特性" site:csdn.net\nrelated:    搜索相关网站                 related:time.com\ninfo:       获取网站详情                 info:giffox.com\ncache:      查看网站的 Google 缓存版本      cache:google.com\n\\           效用等同于 OR               apple\\google, apple OR google\n*           泛搜索，表征未知部分，只适用于英文      * is the mother of success\n《》          只查询图书、影视作品，只适用于中文      《钢铁是怎样炼成的》\ndef:        查询关键词的定义               def:diversity / google def:\ninurl       查找在 URL 地址里有搜索关键词的页面   inurl:download inurl:book 雪中悍刀行\nintitle     查找在网页标题里有搜索关键词的页面      intitle:kafka3.0\n\n\n# 8、JDK源码导入idea\n\n * 将jdk安装目录下的src.zip导入idea项目，将jdk下的lib/tools.jar加入到Project Structure的Libraries，新建测试类测试，在 报错参考\n * debug时jdk源码受保护: Settings -> Debugger -> Stepping -> Do not step into the classes\n * 调大编译堆内存: Settings -> Build,Execution,Deployment -> Compiler -> Build process heap size (Mbytes):\n * SDK中src.zip换成自己的代码路径\n\n\n# 9、文档编写（中文文案排版指北）\n\n<iframe src="https://github.com/sparanoid/chinese-copywriting-guidelines/blob/master/README.zh-Hans.md" width="100%" height="600" frameborder="0" scrolling="Yes" leftmargin="0" topmargin="0"></iframe>\n\n\n\n# 10、字符编码\n\n# 编码\n\n点击查看\n\n摩尔斯电码\n\n> 摩尔斯电码（英语：Morse code）是一种时通时断的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。是由美国发明家萨缪尔·摩尔斯及其助手艾尔菲德·维尔在1836年发明。\n> 摩尔斯电码是一种早期的数字化通信形式，但是它不同于现代只使用0和1两种状态的二进制代码，它的代码包括五种：\n> 1.点（·）：1\n> 2.划（-）：111\n> 3.字符内部的停顿（在点和划之间）：0\n> 4.字符之间的停顿：000\n> 5.单词之间的停顿：0000000\n\nASCII\n\n> ASCII（发音： /ˈæski/ ASS-kee，American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。它主要用于显示现代英语，而其扩展版本延伸美国标准信息交换码则可以部分支持其他西欧语言，并等同于国际标准ISO/IEC 646。\n> 美国信息交换标准代码是这套编码系统的传统命名，互联网号码分配局现在更倾向于使用它的新名字US-ASCII。\n> 美国信息交换标准代码是美国电气和电子工程师协会里程碑之一。\n> ASCII 由电报码发展而来。第一版标准发布于1963年，1967年经历了一次主要修订，最后一次更新则是在1986年，至今为止共定义了128个字符；其中33个字符无法显示（一些终端提供了扩展，使得这些字符可显示为诸如笑脸、扑克牌花式等8-bit符号），且这33个字符多数都已是陈废的控制字符。控制字符的用途主要是用来操控已经处理过的文字。在33个字符之外的是95个可显示的字符。用键盘敲下空白键所产生的空白字符也算1个可显示字符（显示为空白）。\n\n在计算机技术发展的早期，如ASCII（1963年）和EBCDIC（1964年）这样的字符集逐渐成为标准。但这些字符集的局限很快就变得明显，于是人们开发了许多方法来扩展它们。对于支持包括东亚CJK字符家族在内的写作系统的要求能支持更大量的字符，并且需要一种系统而不是临时的方法实现这些字符的编码。\n\nEBCDIC\n\n> EBCDIC（英语：Extended Binary Coded Decimal Interchange Code，扩增二进式十进交换码），为IBM于1963年－1964年间推出的字符编码表，根据早期打孔机式的二进化十进数（BCD，Binary Coded Decimal）排列而成。是IBM迷尔级以上电脑的标准码。\n> 它的缺点是：英文字母不是连续地排列，中间出现多次断续，为撰写程序的人带来了一些困难。\n\n其他\n\n西欧标准\n\n * ISO-8859-1\n * ISO-8859-5\n * ISO-8859-6\n * ISO-8859-7\n * ISO-8859-11\n * ISO-8859-15\n * ISO/IEC 646\n\nDOS字符集（又称IBM代码页）\n\n * CP437\n * CP737\n * CP850\n * CP852\n * CP855\n * CP857\n * CP858\n * CP860\n * CP861\n * CP863\n * CP865\n * CP866\n * CP869\n\nWindows字符集\n\n * Windows-1250\n * Windows-1251：用于西里尔字母表\n * Windows-1252\n * Windows-1253\n * Windows-1254\n * Windows-1255：用于希伯莱语\n * Windows-1256：用于阿拉伯语\n * Windows-1257\n * Windows-1258：用于越南语\n\n台湾\n\n * 大五码\n * 中文信息交换码（CCCII）\n * 中文标准交换码（CNS 11643）\n * EUC\n\n日本\n\n * ISO/IEC 2022\n * Shift JIS\n * EUC\n\n中国大陆及港澳\n\n * GB 2312\n * EUC\n * GBK（规定文件为GB13000）\n * GB 18030\n * 香港增补字符集\n\n朝鲜半岛\n\n * EUC\n * KOI8-R\n * KOI8-U\n * KOI7\n * MIK\n\n越南\n\n * 越南信息交换标准代码\n\n印度\n\n * 印度文字信息交换码\n\nUnicode\n\n * Unicode\n * UTF-7\n * UTF-8\n * UTF-16\n * UTF-32\n\n# 字符转换工具\n\n由于有很多种字符编码方法被使用，从一种字符编码转换到另一种，需要一些工具。\n\n点击查看\n\n跨平台：\n\n * 网页浏览器–大多数现代的网页浏览器都具有此功能。一般是在菜单"查看"（View）/"字符编码"（Character Encoding）\n * iconv –程序与编程API，用于字符编码转换\n * convert_encoding.py –基于Python的转换工具.\n * decodeh.py –用于启发性猜测编码方案的算法与模块.\n * International Components for Unicode –一套C语言与Java语言的开源库，由IBM提供，用于Unicode等多语言编码的转换、实现.\n * chardet – Mozilla的编码自动检测代码的Python语言实现.\n * 新版本的Unix命令File做字符编码的检测.（cygwin与mac都有此命令）\n\nLinux:\n\n * recode –\n * utrac – 将整个文件内容从一种字符编码转换到另外一种\n * cstocs –\n * convmv –转换文件名.\n * enca –分析编码模式.\n\nMicrosoft Windows:\n\n * Encoding.Convert – .NET API\n * MultiByteToWideChar/WideCharToMultiByte – Windows API\n * cscvt –转换工具\n * enca –分析编码方法\n\n# 现代编码模型\n\n点击查看\n\n由统一码和通用字符集所构成的现代字符编码模型则没有跟从简单字符集的观点。它们将字符编码的概念分为：有哪些字符、它们的编号、这些编号如何编码成一系列的“码元”（有限大小的数字）以及最后这些单元如何组成八位字节流。区分这些概念的核心思想是创建一个能够用不同方法来编码的一个通用字符集。为了正确地表示这个模型需要更多比“字符集”和“字符编码”更为精确的术语表示。在Unicode Technical Report (UTR) #17中，现代编码模型分为5个层次，所用的术语列在下面：\n\n 1. 抽象字符表（Abstract character repertoire）是一个系统支持的所有抽象字符的集合。字符表可以是封闭的，即除非创建一个新的标准（ASCII和多数ISO/IEC 8859系列都是这样的例子），否则不允许添加新的符号；字符表也可以是开放的，即允许添加新的符号（统一码和一定程度上代码页是这方面的例子）。特定字符表中的字符反映了如何将书写系统分解成线性信息单元的决定。例如拉丁、希腊和斯拉夫字母表分为字母、数字、变音符号、标点和如空格这样的一些少数特殊字符，它们都能按照一种简单的线性序列排列（尽管对它们的处理需要另外的规则，如带有变音符号的字母这样的特测序列如何解释——但这不属于字符表的范畴）。为了方便起见，这样的字符表可以包括预先编号的字母和变音符号的组合。其它的书写系统，如阿拉伯语和希伯莱语，由于要适应双向文字和在不同情形下按照不同方式交叉在一起的字形，就使用更为复杂的符号表表示。\n 2. 编码字符集（CCS:Coded Character Set）是将字符集{\\displaystyle C}C中每个字符映射到1个坐标（整数值对：x, y）或者表示为1个非负整数{\\displaystyle N}N。字符集及码位映射称为编码字符集。例如，在一个给定的字符表中，表示大写拉丁字母“A”的字符被赋予整数65、字符“B”是66，如此继续下去。多个编码字符集可以表示同样的字符表，例如ISO-8859-1和IBM的代码页037和代码页500含盖同样的字符表但是将字符映射为不同的整数。由此产生了编码空间（encoding space）的概念：简单说就是包含所有字符的表的维度。可以用一对整数来描述，例如：GB 2312的汉字编码空间是94 x 94。可以用一个整数来描述，例如：ISO-8859-1的编码空间是256。也可以用字符的存储单元尺寸来描述，例如：ISO-8859-1是一个8比特的编码空间。编码空间还可以用其子集来表述，如行、列、面（plane）等。编码空间中的一个位置（position）称为码位（code point）。一个字符所占用的码位称为码位值（code point value）。1个编码字符集就是把抽象字符映射为码位值。\n 3. 字符编码表（CEF:Character Encoding Form），也称为"storage format"，是将编码字符集的非负整数值（即抽象的码位）转换成有限比特长度的整型值（称为码元code units）的序列。这对于定长编码来说是个到自身的映射（null mapping），但对于变长编码来说，该映射比较复杂，把一些码位映射到一个码元，把另外一些码位映射到由多个码元组成的序列。例如，使用16比特长的存储单元保存数字信息，系统每个单元只能够直接表示从0到65,535的数值，但是如果使用多个16位单元就能够表示更大的整数。这就是CEF的作用，它可以把Unicode从0到140万的码空间范围的每个码位映射到单个或多个在0到65,5356范围内的码值。最简单的字符编码表就是单纯地选择足够大的单位，以保证编码字符集中的所有数值能够直接编码（一个码位对应一个码值）。这对于能够用使用八比特组来表示的编码字符集（如多数传统的非CJK的字符集编码）是合理的，对于能够使用十六比特来表示的编码字符集（如早期版本的Unicode）来说也足够合理。但是，随着编码字符集的大小增加（例如，现在的Unicode的字符集至少需要21位才能全部表示），这种直接表示法变得越来越没有效率，并且很难让现有计算机系统适应更大的码值。因此，许多使用新近版本Unicode的系统，或者将Unicode码位对应为可变长度的8位字节序列的UTF-8，或者将码位对应为可变长度的16位序列的UTF-16。\n 4. 字符编码方案（CES:Character Encoding Scheme），也称作"serialization format"。将定长的整型值（即码元）映射到8位字节序列，以便编码后的数据的文件存储或网络传输。在使用Unicode的场合，使用一个简单的字符来指定字节顺序是大端序或者小端序（但对于UTF-8来说并不需要专门指明字节序）。然而，有些复杂的字符编码机制（如ISO/IEC 2022）使用控制字符转义序列在几种编码字符集或者用于减小每个单元所用字节数的压缩机制（如SCSU、BOCU和Punycode）之间切换。\n 5. 传输编码语法（transfer encoding syntax），用于处理上一层次的字符编码方案提供的字节序列。一般其功能包括两种：一是把字节序列的值映射到一套更受限制的值域内，以满足传输环境的限制，例如Email传输时Base64或者quoted-printable，都是把8位的字节编码为7位长的数据；另一是压缩字节序列的值，如LZW或者行程长度编码等无损压缩技术。\n\n高层机制（higher level protocol）提供了额外信息，用于选择Unicode字符的特定变种，如XML属性xml:lang\n\n字符映射（character map）在Unicode中保持了其传统意义：从字符序列到编码后的字节序列的映射，包括了上述的CCS, CEF, CES层次。\n\n维基百科\n\nJDK9为何要将String的底层实现由char[]改成了byte[]?',normalizedContent:'# 1、英文缩写\n\n# python\n\n简称    全称\npip   package installer for python\n\n# oracle\n\n简称     全称\nclob   character large object\nblob   binary large object\n\n\n# 服务器\n\n简称    全称\nntp   网络时间协议，英文名称：network time protocol（ntp）\n\nntp 配置\n\n\n# 2、html实体\n\n&amp; &lt;等字符 参考链接\n\n\n# 3、位运算的运用\n\n# 与运算\n\n# 判断奇偶\n\n判断int型变量a是奇数还是偶数\n\na & 1 = 0 // 偶数\na & 1 = 1 // 奇数\n\n\n# 取数指定位（指定位置0）\n\n取一个数的指定位\n\n// 1. 取int型变量a（二进制）的第k位\na >> k & 1  // 先右移k位，与1后取出第k位\n\n// 2. \n// 比如取数 x=1010 1110 的低4位，只需要另找一个数y，令y的低4位为1，其余位为0，即y=0000 1111，然后将x与y进行按位与运算（x&y=0000 1110）即可得到x的指定位。\n\n\n# 平均值\n\n整数的平均值\n\nint average(int x, int y)\n{   \n     return (x&y)+((x^y)>>1);\n}\n\n\n# 判断整数是不是2的幂\n\n判断一个整数是不是2的幂\n\nboolean power2(int x)\n{\n    return ((x&(x-1))==0)&&(x!=0);\n}\n\n\n# 或运算\n\n# 对数指定位置1\n\n判断一个整数是不是2的幂\n\n// 比如将数 x=1010 1110 的低4位设置为1，只需要另找一个数y，令y的低4位为1，其余位为0，即y=0000 1111，然后将x与y进行按位或运算（x|y=1010 1111）即可得到。\n\n\n# 非运算\n\n# 最低位置零\n\n使一个数的最低位为零\n\n// 使a的最低位为0，可以表示为：a & ~1。~1的值为 1111 1111 1111 1110，再按"与"运算，最低位一定为0。因为" ~"运算符的优先级比算术运算符、关系运算符、逻辑运算符和其他运算符都高\n\n\n# 异或运算\n\n> 异或的几条性质\n> \n>  1. 交换律\n>  2. 结合律 (a^b)^c == a^(b^c)\n>  3. 对于任何数x，都有 x^x=0，x^0=x\n>  4. 自反性: a^b^b=a^0=a\n\n# 翻转指定位\n\n翻转指定位\n\n// 比如将数 x=1010 1110 的低4位进行翻转，只需要另找一个数y，令y的低4位为1，其余位为0，即y=0000 1111，然后将x与y进行异或运算（x^y=1010 0001）即可得到\n\n\n# 两数相等\n\n判断两个整数相等\n\na ^ 1 = 0\n\n\n# 交换两个数\n\n用位运算符交换两个整数\n\nvoid swap(int x , int y)\n{\n    x ^= y;\n    y ^= x;\n    x ^= y;\n}\n\n\n# 绝对值\n\n计算绝对值\n\nint abs( int x )\n{\n  int y ;\n  y = x >> 31 ;\n  return (x^y)-y ;        // or: (x+y)^y\n}\n\n\n# 移位运算\n\n# 乘、除、取模运算\n\n乘、除、取模运算转化成位运算 (在不产生溢出的情况下)\n\n// 乘法运算转化成位运算\na * (2^n)      等价于     a << n\n\n// 除法运算转化成位运算\na / (2^n)      等价于     a >> n\n\n// 取模运算转化成位运算\na % (2^n)      等价于     a & (2^n - 1)\n\n\n原文地址\n\n\n# 4、日期格式化中的yyyy和yyyy（java）\n\n 1. y 是year, y 表示的是week year，week year 意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，那么这周就算入下一年。\n 2. 大写的dd代表的是处于这一年中那一天，不是处于这个月的那一天\n\n# 常见的时间格式化字符串\n\n 1. yyyy-mm-dd hh24:mi:ss\n\n格式        描述\ny         年的最后一位数字，如：5\nyy        年的最后两位数字，如：15\nyyy       年的最后三位数字，如：015\nyyyy      年，如：2015\ny,yyy     年用逗号分割\nsyyyy     年\nyear      年拼写，如：twenty fifteen\nsyear     年拼写，如：twenty fifteen\ni         iso年的最后一位数字，如：5\niy        iso年的最后两位数字，如：15\niyy       iso年的最后三位数字，如：015\niyyy      iso年，如：2015\nrr        两位数字年，如：15\nrrrr      四位数字年，如：2015\nmm        month (01-12)\nmon       月份简称，如：jun\nmonth     月份全称，如：june\nrm        罗马数字月份\nd         day of week (1-7)\ndd        day of month (1-31)\nddd       day of year (1-366)\nhh        hour of day (1-12)\nhh12      hour of day (1-12)\nhh24      hour of day (0-23)\nmi        minute (0-59)\nss        second (0-59)\nsssss     seconds past midnight\nff[1…9]   毫秒\nds        日期简称，如：6/12/2015\ndl        日期全称，如：friday, june 12, 2015\nts        时间简称，如：5:18:03 pm\ncc        世纪，如：21\nscc       世纪，如：21\nq         quarter of year (1, 2, 3, 4)\nw         week of month (1-5)\nww        week of year (1-53)\niw        iso week of year (1-52 or 1-53)\ndy        星期简称，如：fri\nday       星期全称，如：friday\nam        a.m.\npm        p.m.\nad        a.d.\nbc        b.c.\ntzd       夏令时\ntzr       时区\ntzh       时区之时差\ntzm       时区之分钟差\nee        era 全称\ne         era 简称\nj         the number of days since january 1, 4712 bc\nfm        去掉首尾空格\nfx        精确匹配\nx         秒和毫秒分隔符\nth        ddth --\x3e 4th\nsp        ddsp --\x3efour\nspth      ddspth --\x3e fourth\nthsp      ddthsp --\x3e fourth\n\n 2. %y-%m-%d %h:%i:%s\n\n格式   描述\n%a   缩写星期名\n%b   缩写月名\n%c   月，数值\n%d   带有英文前缀的月中的天\n%d   月的天，数值(00-31)\n%e   月的天，数值(0-31)\n%f   微秒\n%h   小时 (00-23)\n%h   小时 (01-12)\n%i   小时 (01-12)\n%i   分钟，数值(00-59)\n%j   年的天 (001-366)\n%k   小时 (0-23)\n%l   小时 (1-12)\n%m   月名\n%m   月，数值(00-12)\n%p   am 或 pm\n%r   时间，12-小时（hh:mm:ss am 或 pm）\n%s   秒(00-59)\n%s   秒(00-59)\n%t   时间, 24-小时 (hh:mm:ss)\n%u   周 (00-53) 星期日是一周的第一天\n%u   周 (00-53) 星期一是一周的第一天\n%v   周 (01-53) 星期日是一周的第一天，与 %x 使用\n%v   周 (01-53) 星期一是一周的第一天，与 %x 使用\n%w   星期名\n%w   周的天 （0=星期日, 6=星期六）\n%x   年，其中的星期日是周的第一天，4 位，与 %v 使用\n%x   年，其中的星期一是周的第一天，4 位，与 %v 使用\n%y   年，4 位\n%y   年，2 位\n\n转字符串\n\nselect to_char(sysdate, \'dd-mon-yyyy hh24:mi:ss\') from dual;          -- 10-aug-2022 17:11:53\nselect to_char(sysdate, \'mon-yy-dd hh:mi:ss am\') from dual;           -- aug-22-10 05:02:49 pm\nselect to_char(current_timestamp, \'hh24:mi:ss\') from dual;            -- 17:06:10\nselect to_char(current_timestamp,\'hh12:mi:ss\') from dual ;            -- 05:03:01\nselect to_char(current_timestamp,\'fmhh12:fmmi:fmss\') from dual;       -- 5:03:11\n\n\n转时间戳\n\nselect to_timestamp(\'-1\',\'syyyy\') from dual;\nselect to_timestamp(\'98\',\'rr\') from dual;\nselect to_timestamp(\'01\',\'rr\') from dual;\nselect to_timestamp(\'12-sep-10 14:10:10.123000\',\'dd-mon-yy hh24:mi:ss.ff\') from dual;   -- 12-sep-10 02.10.10.123000000 pm\n\n\n\n# 5、windows上使用linux命令\n\n# 虚拟机\n\n类似于vmware等软件\n\n# vmware问题\n\n 1. 解决 vmware 中 centos 7 没有ens33网卡的问题\n    * 首先设置在系统启动时激活网卡 vim /etc/sysconfig/network-scripts/ifcfg-ens33 将onboot=no改为onboot=yes\n    * 执行ifconfig ens33 up，此时ifconfig 显示有了ens33网卡，但没有ip\n    * 执行 systemctl stop networkmanager ifup ens33\n    * 重启网络 systemctl restart network.service\n\n原文链接\n\n# git命令行\n\n# wsl\n\n适用于linux的windows子系统（wsl：windows subsystem for linux）\n\n 1. 移动wsl默认位置\n\n# 下载lxrunoffline，下载文件lxrunoffline-vxxxx.zip\nhttps://github.com/ddosolitary/lxrunoffline/releases\n\n# 查看子系统(linux)版本号(cmd执行, 注意要么配置环境变量, 要么在lxrunoffline.exe所在目录打开cmd)\nlxrunoffline list\n\n# 将linux移动到指定的目录\nlxrunoffline move -n {version} -d {dir}\nlxrunoffline move -n ubuntu-18.04 -d d:\\vmware\\lxrunoffline-v3.5.0-msvc\\linux\n\n\n 2. 固定ip\n\n参考链接\n\n 3. 使用\n\n使用命令行工具连接wsl\n\n# 生成秘钥\nsudo ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key\nsudo ssh-keygen -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key\nsudo ssh-keygen -t ed25519 -f /etc/ssh/ssh_host_ed25519_key\n\n# 修改/etc/ssh/sshd_config的passwordauthentication项为yes\n\n# 重启ssh\nsudo service ssh restart\n\n# 使用命令行工具连接\n\n\n# docker是不是也可以\n\n\n# 6、安装jar包(手动下载)\n\n阿里云maven包下载\n\nmvn install:install-file -dfile=jar包的位置 -dgroupid=上面的groupid -dartifactid=上面的artifactid -dversion=上面的version -dpackaging=jar\n\nmvn install:install-file -dfile=./pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar -dgroupid=org.pentaho -dartifactid=pentaho-aggdesigner-algorithm -dversion=5.1.5-jhyde -dpackaging=jar\nmvn install:install-file -dfile=./eigenbase-properties-1.1.4.jar -dgroupid=eigenbase -dartifactid=eigenbase-properties -dversion=1.1.4 -dpackaging=jar\n\n\n# 还是不行, 每次maven还会去中央仓库找jar包\n# 解决方法 删除本地仓库中该jar包下:  _remote.repositories 和 以.lastupdated结尾的文件(还有_maven.repositories ?)\n# 搞错目录了, 本地有两个maven仓库, 安装到另一个下面去了, 终于解决了!!!\n\n\n引入项目目录下的jar包\n\n<dependency>\n    <groupid >com.dameng.common</groupid>\n    <artifactid>common-aop</artifactid>\n    <version>${dm-aop.version}</version>\n    <scope>system</scope>\n    <systempath>${basedir}\\lib\\com.dameng.common.aop_${dm-aop.version}.jar</systempath>\n</dependency>\n\n\n\n# 7、搜索引擎语法\n\n搜索指令        功能                     示例\n@           搜索社交媒体                 @twitter\n$           搜索特定价格                 camera $400\n#           搜索 # 标签                #throwbackthursday\n-           从搜索结果中排除特定字词           "kafka3.0" -特性 site:csdn.net\n+           从搜索结果中获取特定字词           "kafka3.0" +特性 site:csdn.net\nfiletype:   精确搜索文件类型               filetype:chm "java"\n""          搜索完全匹配的结果              "kafka3.0新特性"\n..          在某个数字范围内执行搜索           camera $50..$100\nor（大写）      组合搜索                   marathon or race\nsite:       搜索特定网站                 "kafka3.0新特性" site:csdn.net\nrelated:    搜索相关网站                 related:time.com\ninfo:       获取网站详情                 info:giffox.com\ncache:      查看网站的 google 缓存版本      cache:google.com\n\\           效用等同于 or               apple\\google, apple or google\n*           泛搜索，表征未知部分，只适用于英文      * is the mother of success\n《》          只查询图书、影视作品，只适用于中文      《钢铁是怎样炼成的》\ndef:        查询关键词的定义               def:diversity / google def:\ninurl       查找在 url 地址里有搜索关键词的页面   inurl:download inurl:book 雪中悍刀行\nintitle     查找在网页标题里有搜索关键词的页面      intitle:kafka3.0\n\n\n# 8、jdk源码导入idea\n\n * 将jdk安装目录下的src.zip导入idea项目，将jdk下的lib/tools.jar加入到project structure的libraries，新建测试类测试，在 报错参考\n * debug时jdk源码受保护: settings -> debugger -> stepping -> do not step into the classes\n * 调大编译堆内存: settings -> build,execution,deployment -> compiler -> build process heap size (mbytes):\n * sdk中src.zip换成自己的代码路径\n\n\n# 9、文档编写（中文文案排版指北）\n\n<iframe src="https://github.com/sparanoid/chinese-copywriting-guidelines/blob/master/readme.zh-hans.md" width="100%" height="600" frameborder="0" scrolling="yes" leftmargin="0" topmargin="0"></iframe>\n\n\n\n# 10、字符编码\n\n# 编码\n\n点击查看\n\n摩尔斯电码\n\n> 摩尔斯电码（英语：morse code）是一种时通时断的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。是由美国发明家萨缪尔·摩尔斯及其助手艾尔菲德·维尔在1836年发明。\n> 摩尔斯电码是一种早期的数字化通信形式，但是它不同于现代只使用0和1两种状态的二进制代码，它的代码包括五种：\n> 1.点（·）：1\n> 2.划（-）：111\n> 3.字符内部的停顿（在点和划之间）：0\n> 4.字符之间的停顿：000\n> 5.单词之间的停顿：0000000\n\nascii\n\n> ascii（发音： /ˈæski/ ass-kee，american standard code for information interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。它主要用于显示现代英语，而其扩展版本延伸美国标准信息交换码则可以部分支持其他西欧语言，并等同于国际标准iso/iec 646。\n> 美国信息交换标准代码是这套编码系统的传统命名，互联网号码分配局现在更倾向于使用它的新名字us-ascii。\n> 美国信息交换标准代码是美国电气和电子工程师协会里程碑之一。\n> ascii 由电报码发展而来。第一版标准发布于1963年，1967年经历了一次主要修订，最后一次更新则是在1986年，至今为止共定义了128个字符；其中33个字符无法显示（一些终端提供了扩展，使得这些字符可显示为诸如笑脸、扑克牌花式等8-bit符号），且这33个字符多数都已是陈废的控制字符。控制字符的用途主要是用来操控已经处理过的文字。在33个字符之外的是95个可显示的字符。用键盘敲下空白键所产生的空白字符也算1个可显示字符（显示为空白）。\n\n在计算机技术发展的早期，如ascii（1963年）和ebcdic（1964年）这样的字符集逐渐成为标准。但这些字符集的局限很快就变得明显，于是人们开发了许多方法来扩展它们。对于支持包括东亚cjk字符家族在内的写作系统的要求能支持更大量的字符，并且需要一种系统而不是临时的方法实现这些字符的编码。\n\nebcdic\n\n> ebcdic（英语：extended binary coded decimal interchange code，扩增二进式十进交换码），为ibm于1963年－1964年间推出的字符编码表，根据早期打孔机式的二进化十进数（bcd，binary coded decimal）排列而成。是ibm迷尔级以上电脑的标准码。\n> 它的缺点是：英文字母不是连续地排列，中间出现多次断续，为撰写程序的人带来了一些困难。\n\n其他\n\n西欧标准\n\n * iso-8859-1\n * iso-8859-5\n * iso-8859-6\n * iso-8859-7\n * iso-8859-11\n * iso-8859-15\n * iso/iec 646\n\ndos字符集（又称ibm代码页）\n\n * cp437\n * cp737\n * cp850\n * cp852\n * cp855\n * cp857\n * cp858\n * cp860\n * cp861\n * cp863\n * cp865\n * cp866\n * cp869\n\nwindows字符集\n\n * windows-1250\n * windows-1251：用于西里尔字母表\n * windows-1252\n * windows-1253\n * windows-1254\n * windows-1255：用于希伯莱语\n * windows-1256：用于阿拉伯语\n * windows-1257\n * windows-1258：用于越南语\n\n台湾\n\n * 大五码\n * 中文信息交换码（cccii）\n * 中文标准交换码（cns 11643）\n * euc\n\n日本\n\n * iso/iec 2022\n * shift jis\n * euc\n\n中国大陆及港澳\n\n * gb 2312\n * euc\n * gbk（规定文件为gb13000）\n * gb 18030\n * 香港增补字符集\n\n朝鲜半岛\n\n * euc\n * koi8-r\n * koi8-u\n * koi7\n * mik\n\n越南\n\n * 越南信息交换标准代码\n\n印度\n\n * 印度文字信息交换码\n\nunicode\n\n * unicode\n * utf-7\n * utf-8\n * utf-16\n * utf-32\n\n# 字符转换工具\n\n由于有很多种字符编码方法被使用，从一种字符编码转换到另一种，需要一些工具。\n\n点击查看\n\n跨平台：\n\n * 网页浏览器–大多数现代的网页浏览器都具有此功能。一般是在菜单"查看"（view）/"字符编码"（character encoding）\n * iconv –程序与编程api，用于字符编码转换\n * convert_encoding.py –基于python的转换工具.\n * decodeh.py –用于启发性猜测编码方案的算法与模块.\n * international components for unicode –一套c语言与java语言的开源库，由ibm提供，用于unicode等多语言编码的转换、实现.\n * chardet – mozilla的编码自动检测代码的python语言实现.\n * 新版本的unix命令file做字符编码的检测.（cygwin与mac都有此命令）\n\nlinux:\n\n * recode –\n * utrac – 将整个文件内容从一种字符编码转换到另外一种\n * cstocs –\n * convmv –转换文件名.\n * enca –分析编码模式.\n\nmicrosoft windows:\n\n * encoding.convert – .net api\n * multibytetowidechar/widechartomultibyte – windows api\n * cscvt –转换工具\n * enca –分析编码方法\n\n# 现代编码模型\n\n点击查看\n\n由统一码和通用字符集所构成的现代字符编码模型则没有跟从简单字符集的观点。它们将字符编码的概念分为：有哪些字符、它们的编号、这些编号如何编码成一系列的“码元”（有限大小的数字）以及最后这些单元如何组成八位字节流。区分这些概念的核心思想是创建一个能够用不同方法来编码的一个通用字符集。为了正确地表示这个模型需要更多比“字符集”和“字符编码”更为精确的术语表示。在unicode technical report (utr) #17中，现代编码模型分为5个层次，所用的术语列在下面：\n\n 1. 抽象字符表（abstract character repertoire）是一个系统支持的所有抽象字符的集合。字符表可以是封闭的，即除非创建一个新的标准（ascii和多数iso/iec 8859系列都是这样的例子），否则不允许添加新的符号；字符表也可以是开放的，即允许添加新的符号（统一码和一定程度上代码页是这方面的例子）。特定字符表中的字符反映了如何将书写系统分解成线性信息单元的决定。例如拉丁、希腊和斯拉夫字母表分为字母、数字、变音符号、标点和如空格这样的一些少数特殊字符，它们都能按照一种简单的线性序列排列（尽管对它们的处理需要另外的规则，如带有变音符号的字母这样的特测序列如何解释——但这不属于字符表的范畴）。为了方便起见，这样的字符表可以包括预先编号的字母和变音符号的组合。其它的书写系统，如阿拉伯语和希伯莱语，由于要适应双向文字和在不同情形下按照不同方式交叉在一起的字形，就使用更为复杂的符号表表示。\n 2. 编码字符集（ccs:coded character set）是将字符集{\\displaystyle c}c中每个字符映射到1个坐标（整数值对：x, y）或者表示为1个非负整数{\\displaystyle n}n。字符集及码位映射称为编码字符集。例如，在一个给定的字符表中，表示大写拉丁字母“a”的字符被赋予整数65、字符“b”是66，如此继续下去。多个编码字符集可以表示同样的字符表，例如iso-8859-1和ibm的代码页037和代码页500含盖同样的字符表但是将字符映射为不同的整数。由此产生了编码空间（encoding space）的概念：简单说就是包含所有字符的表的维度。可以用一对整数来描述，例如：gb 2312的汉字编码空间是94 x 94。可以用一个整数来描述，例如：iso-8859-1的编码空间是256。也可以用字符的存储单元尺寸来描述，例如：iso-8859-1是一个8比特的编码空间。编码空间还可以用其子集来表述，如行、列、面（plane）等。编码空间中的一个位置（position）称为码位（code point）。一个字符所占用的码位称为码位值（code point value）。1个编码字符集就是把抽象字符映射为码位值。\n 3. 字符编码表（cef:character encoding form），也称为"storage format"，是将编码字符集的非负整数值（即抽象的码位）转换成有限比特长度的整型值（称为码元code units）的序列。这对于定长编码来说是个到自身的映射（null mapping），但对于变长编码来说，该映射比较复杂，把一些码位映射到一个码元，把另外一些码位映射到由多个码元组成的序列。例如，使用16比特长的存储单元保存数字信息，系统每个单元只能够直接表示从0到65,535的数值，但是如果使用多个16位单元就能够表示更大的整数。这就是cef的作用，它可以把unicode从0到140万的码空间范围的每个码位映射到单个或多个在0到65,5356范围内的码值。最简单的字符编码表就是单纯地选择足够大的单位，以保证编码字符集中的所有数值能够直接编码（一个码位对应一个码值）。这对于能够用使用八比特组来表示的编码字符集（如多数传统的非cjk的字符集编码）是合理的，对于能够使用十六比特来表示的编码字符集（如早期版本的unicode）来说也足够合理。但是，随着编码字符集的大小增加（例如，现在的unicode的字符集至少需要21位才能全部表示），这种直接表示法变得越来越没有效率，并且很难让现有计算机系统适应更大的码值。因此，许多使用新近版本unicode的系统，或者将unicode码位对应为可变长度的8位字节序列的utf-8，或者将码位对应为可变长度的16位序列的utf-16。\n 4. 字符编码方案（ces:character encoding scheme），也称作"serialization format"。将定长的整型值（即码元）映射到8位字节序列，以便编码后的数据的文件存储或网络传输。在使用unicode的场合，使用一个简单的字符来指定字节顺序是大端序或者小端序（但对于utf-8来说并不需要专门指明字节序）。然而，有些复杂的字符编码机制（如iso/iec 2022）使用控制字符转义序列在几种编码字符集或者用于减小每个单元所用字节数的压缩机制（如scsu、bocu和punycode）之间切换。\n 5. 传输编码语法（transfer encoding syntax），用于处理上一层次的字符编码方案提供的字节序列。一般其功能包括两种：一是把字节序列的值映射到一套更受限制的值域内，以满足传输环境的限制，例如email传输时base64或者quoted-printable，都是把8位的字节编码为7位长的数据；另一是压缩字节序列的值，如lzw或者行程长度编码等无损压缩技术。\n\n高层机制（higher level protocol）提供了额外信息，用于选择unicode字符的特定变种，如xml属性xml:lang\n\n字符映射（character map）在unicode中保持了其传统意义：从字符序列到编码后的字节序列的映射，包括了上述的ccs, cef, ces层次。\n\n维基百科\n\njdk9为何要将string的底层实现由char[]改成了byte[]?',charsets:{cjk:!0},lastUpdated:"2025/04/18, 12:12:36",lastUpdatedTimestamp:1744949556e3},{title:"FAQ",frontmatter:{title:"FAQ",date:"2024-08-30T10:51:07.000Z",permalink:"/pages/3cec6c/"},regularPath:"/04.%E5%85%B6%E4%BB%96/99.%E6%9D%82%E8%AE%B0/10.FAQ.html",relativePath:"04.其他/99.杂记/10.FAQ.md",key:"v-447f8646",path:"/pages/3cec6c/",headers:[{level:3,title:"虚拟机",slug:"虚拟机",normalizedTitle:"虚拟机",charIndex:2},{level:4,title:"虚拟机移动或其他原因不显示 ens33 网卡",slug:"虚拟机移动或其他原因不显示-ens33-网卡",normalizedTitle:"虚拟机移动或其他原因不显示 ens33 网卡",charIndex:9},{level:4,title:"SecureFX中文乱码",slug:"securefx中文乱码",normalizedTitle:"securefx中文乱码",charIndex:212},{level:3,title:"CDH",slug:"cdh",normalizedTitle:"cdh",charIndex:467},{level:4,title:"问题排查",slug:"问题排查",normalizedTitle:"问题排查",charIndex:474}],headersStr:"虚拟机 虚拟机移动或其他原因不显示 ens33 网卡 SecureFX中文乱码 CDH 问题排查",content:"# 虚拟机\n\n# 虚拟机移动或其他原因不显示 ens33 网卡\n\n# 配置好网卡文件\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n\nsystemctl stop NetworkManager  # 关闭掉网络管理\nsystemctl disable NetworkManager  # 将网络管理禁用\nservice network restart  # 重启网卡\n\n\n# SecureFX中文乱码\n\n * Options -> Session Option -> Terminal(Appearance) 修改 Character encoding 为 UTF-8（正常修改这个就可以，不正常看下一条）\n * 找到工具配置文件路径%AppData%\\VanDyke\\Config\\Sessions，找到对应服务器或虚拟机的 ip.ini 文件然后打开，搜索配置项 Filenames Always Use UTF8 将 00000000 改为 00000001 ，保存退出\n\n\n# CDH\n\n# 问题排查\n\n结果：因为 NameNode 节点（主节点20 Roles）只启动了 cloudera-scm-server 服务，没有启动 cloudera-scm-agent 服务。导致 cmf UI 界面可以进去，查看主机时不显示 N01 节点状态，且 HDFS 等服务启动失败。Zookeeper 启动时报错 Command aborted because of exception: Command timed-out after 150 seconds。\n\n# 启动方式1\nsystemctl start cloudera-scm-agent\n#systemctl start cloudera-scm-server   # 只需启动一台服务器\n\n\n# 启动方式2 （使用 systemctl 找不到服务时）\nsu - root\ncd /home/CM/cm-5.14.1/etc/init.d  # 路径可能不一样\n./cloudera-scm-agent status\n./cloudera-scm-agent start\n#./cloudera-scm-server start  # 只需启动一台服务器\n",normalizedContent:"# 虚拟机\n\n# 虚拟机移动或其他原因不显示 ens33 网卡\n\n# 配置好网卡文件\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\n\nsystemctl stop networkmanager  # 关闭掉网络管理\nsystemctl disable networkmanager  # 将网络管理禁用\nservice network restart  # 重启网卡\n\n\n# securefx中文乱码\n\n * options -> session option -> terminal(appearance) 修改 character encoding 为 utf-8（正常修改这个就可以，不正常看下一条）\n * 找到工具配置文件路径%appdata%\\vandyke\\config\\sessions，找到对应服务器或虚拟机的 ip.ini 文件然后打开，搜索配置项 filenames always use utf8 将 00000000 改为 00000001 ，保存退出\n\n\n# cdh\n\n# 问题排查\n\n结果：因为 namenode 节点（主节点20 roles）只启动了 cloudera-scm-server 服务，没有启动 cloudera-scm-agent 服务。导致 cmf ui 界面可以进去，查看主机时不显示 n01 节点状态，且 hdfs 等服务启动失败。zookeeper 启动时报错 command aborted because of exception: command timed-out after 150 seconds。\n\n# 启动方式1\nsystemctl start cloudera-scm-agent\n#systemctl start cloudera-scm-server   # 只需启动一台服务器\n\n\n# 启动方式2 （使用 systemctl 找不到服务时）\nsu - root\ncd /home/cm/cm-5.14.1/etc/init.d  # 路径可能不一样\n./cloudera-scm-agent status\n./cloudera-scm-agent start\n#./cloudera-scm-server start  # 只需启动一台服务器\n",charsets:{cjk:!0},lastUpdated:"2025/03/28, 16:25:58",lastUpdatedTimestamp:1743150358e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-460c88ea",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/10, 19:46:54",lastUpdatedTimestamp:1657453614e3},{title:"Home",frontmatter:{home:!0,heroImage:"img/gif/panda.jpg",heroText:"唐宋元明清",tagline:"用来记录遇到的点点滴滴，琐碎知识",actionText:"现在开始 →",actionLink:"/pages/5d76a5/",bannerBg:"none",features:[{title:"知识管理",details:"包含三种典型的知识管理形态：结构化、碎片化、体系化。轻松打造属于你自己的知识管理平台"},{title:"简洁高效",details:"以 Markdown 为中心的项目结构，内置自动化工具，以更少的配置完成更多的事。配合多维索引快速定位每个知识点"},{title:"沉浸式阅读",details:"专为阅读设计的UI，配合多种颜色模式、可关闭的侧边栏和导航栏，带给你一种沉浸式阅读体验"}],postList:"none"},regularPath:"/",relativePath:"index.md",key:"v-5111c592",path:"/",headers:[{level:2,title:"目录视图",slug:"目录视图",normalizedTitle:"目录视图",charIndex:91},{level:2,title:"🎖卡片视图",slug:"🎖卡片视图",normalizedTitle:"🎖卡片视图",charIndex:249}],headersStr:"目录视图 🎖卡片视图",content:"balabalabala\n\n黑神话 · 悟空\n别有世间曾未见，一行一步，一花新。\n愿你历经九九八十一难，归来仍是那只石头憨憨。\n黑夜给了我火眼金睛， 我要用它，看穿宿命。\n\n\n\n# 目录视图\n\n<iframe :src=\"$withBase('/markmap/markmap.html')\" width=\"100%\" height=\"400\" frameborder=\"0\" scrolling=\"No\" leftmargin=\"0\" topmargin=\"0\"></iframe>\n\n\n\n\n# 🎖卡片视图\n\nJava\n\nJava相关的知识点\n\n大数据\n\n🚀大数据相关组件的搭建（注意版本）及基本用法\n\n数据库\n\n数据库的相关知识点\n\n其他\n\n其他编程语言及杂记\n\n- name: Java\n  desc: Java相关的知识点\n  link: /pages/768c32/\n  bgColor: '#f1f1f1'\n  textColor: '#2A3344'\n- name: 大数据\n  desc: 🚀大数据相关组件的搭建（注意版本）及基本用法\n  link: /pages/5d76a5/\n  bgColor: '#f1f1f1'\n  textColor: '#2A3344'\n- name: 数据库\n  desc: 数据库的相关知识点\n  link: /pages/7e6951/\n  bgColor: '#f1f1f1'\n  textColor: '#2A3344'\n- name: 其他\n  desc: 其他编程语言及杂记\n  link: /pages/f2a340/\n  bgColor: '#f1f1f1'\n  textColor: '#2A3344'\n\n\n\n",normalizedContent:"balabalabala\n\n黑神话 · 悟空\n别有世间曾未见，一行一步，一花新。\n愿你历经九九八十一难，归来仍是那只石头憨憨。\n黑夜给了我火眼金睛， 我要用它，看穿宿命。\n\n\n\n# 目录视图\n\n<iframe :src=\"$withbase('/markmap/markmap.html')\" width=\"100%\" height=\"400\" frameborder=\"0\" scrolling=\"no\" leftmargin=\"0\" topmargin=\"0\"></iframe>\n\n\n\n\n# 🎖卡片视图\n\njava\n\njava相关的知识点\n\n大数据\n\n🚀大数据相关组件的搭建（注意版本）及基本用法\n\n数据库\n\n数据库的相关知识点\n\n其他\n\n其他编程语言及杂记\n\n- name: java\n  desc: java相关的知识点\n  link: /pages/768c32/\n  bgcolor: '#f1f1f1'\n  textcolor: '#2a3344'\n- name: 大数据\n  desc: 🚀大数据相关组件的搭建（注意版本）及基本用法\n  link: /pages/5d76a5/\n  bgcolor: '#f1f1f1'\n  textcolor: '#2a3344'\n- name: 数据库\n  desc: 数据库的相关知识点\n  link: /pages/7e6951/\n  bgcolor: '#f1f1f1'\n  textcolor: '#2a3344'\n- name: 其他\n  desc: 其他编程语言及杂记\n  link: /pages/f2a340/\n  bgcolor: '#f1f1f1'\n  textcolor: '#2a3344'\n\n\n\n",charsets:{cjk:!0},lastUpdated:"2022/08/22, 21:13:20",lastUpdatedTimestamp:1661174e6}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"Java",link:"/pages/de9b5e/",items:[{text:"基础",items:[{text:"Java基础",link:"/pages/768c32/"}]},{text:"工具",items:[{text:"hutool",link:"/pages/1d1863/"},{text:"commons",link:"/pages/1d1864/"}]},{text:"框架",items:[{text:"Spring Boot相关",link:"/pages/1e9420/"}]},{text:"设计模式",items:[{text:"设计模式入门",link:"/pages/bdceb5/"}]}]},{text:"大数据",items:[{text:"Hadoop",items:[{text:"Hadoop分布式搭建",link:"/pages/5d76a5/"},{text:"Hadoop高可用搭建",link:"/pages/f9f70f/"},{text:"集群端口",link:"/pages/3e77b2/"},{text:"代码demo",link:"/pages/03a2bd/"}]},{text:"Zookeeper",items:[{text:"Zookeeper集群搭建",link:"/pages/e2226d/"}]},{text:"Hive",items:[{text:"Hive集群搭建",link:"/pages/edf4cb/"},{text:"Hive相关",link:"/pages/dd806a/"},{text:"HSQL",link:"/pages/dd807a/"}]},{text:"Kafka",items:[{text:"Kafka集群搭建",link:"/pages/bfa383/"}]},{text:"HBase",items:[{text:"HBase集群搭建",link:"/pages/b22228/"},{text:"HBase基础学习",link:"/pages/e15afa/"}]},{text:"Spark",items:[{text:"Spark环境搭建",link:"/pages/7d157d/"},{text:"Spark相关知识",link:"/pages/b3ba00/"}]},{text:"Flink",items:[{text:"Flink环境搭建",link:"/pages/415096/"},{text:"Flink学习",link:"/pages/415097/"}]},{text:"Flume",items:[{text:"Flume安装配置",link:"/pages/e4166e/"},{text:"Flume高可用集群安装",link:"/pages/0376ec/"},{text:"Flume相关学习",link:"/pages/3408a8/"}]},{text:"Sqoop",items:[{text:"Sqoop安装配置",link:"/pages/60b3d7/"},{text:"Sqoop使用",link:"/pages/40f7a3/"}]},{text:"其他",items:[{text:"docker",link:"/pages/d89b45/"}]}]},{text:"数据库",link:"/pages/e0cc49/",items:[{text:"Oracle",items:[{text:"Oracle相关知识杂记",link:"/pages/7e6951/"},{text:"系统函数篇",link:"/pages/b5c27a/"},{text:"与MySQL语法区别",link:"/pages/c2df29/"}]},{text:"MySQL",items:[{text:"MySQL知识点",link:"/pages/36476d/"}]}]},{text:"其他",items:[{text:"Python",items:[{text:"Python简单语法",link:"/pages/f2a330/"},{text:"Python操作Office",link:"/pages/f2a340/"},{text:"Python类库学习",link:"/pages/f2a341/"},{text:"Python爬虫",link:"/pages/f799c7/"}]},{text:"Shell",items:[{text:"Shell基础",link:"/pages/5704cc/"},{text:"Shell命令行",link:"/pages/5765cc/"}]},{text:"Scala",items:[{text:"语法学习",link:"/pages/c917bd/"}]},{text:"正则表达式",items:[{text:"正则基础",link:"/pages/e4e158/"}]},{text:"调度",items:[{text:"调度工具",link:"/pages/a04438/"}]},{text:"前端",items:[{text:"前端相关",link:"/pages/gxfmrs/"}]},{text:"杂记",items:[{text:"常用工具或网站",link:"/pages/414e9c/"},{text:"琐碎知识",link:"/pages/c0e729/"}]},{text:"摘录",items:[{text:"摘录",link:"/pages/AXI4oJ/"}]}]}],sidebarDepth:2,logo:"https://i.postimg.cc/2yr3430s/panda.jpg",repo:"user-h/hdata-doc",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!0,editLinkText:"编辑",sidebar:{"/01.Java相关/":[["00.Java相关知识.md","Java相关知识","/pages/de9b5e/"],{title:"基础",collapsable:!1,children:[["01.基础/01.Java基础.md","Java基础","/pages/768c32/"],["01.基础/02.Java扩展.md","Java扩展","/pages/035171/"]]},{title:"工具",collapsable:!1,children:[["02.工具/001.hutool工具包.md","hutool工具包","/pages/1d1863/"],["02.工具/002.Apache Commons工具包.md","Commons类库","/pages/1d1864/"],["02.工具/010.SQL解析工具.md","SQL解析工具","/pages/2e9bb7/"]]},{title:"框架",collapsable:!1,children:[["03.框架/01.Spring Boot相关.md","Spring Boot相关","/pages/1e9420/"]]},{title:"设计模式",collapsable:!1,children:[["04.设计模式/006.设计模式入门.md","设计模式入门","/pages/bdceb5/"],["04.设计模式/011.策略模式.md","策略模式","/pages/676d02/"],["04.设计模式/020.观察者模式.md","观察者模式","/pages/d0e23d/"],["04.设计模式/030.装饰者模式.md","装饰者模式","/pages/116f8a/"],["04.设计模式/040.工厂模式.md","工厂模式","/pages/668a2b/"],["04.设计模式/050.单例模式.md","单例模式","/pages/4e0678/"],["04.设计模式/060.命令模式.md","命令模式","/pages/5d365c/"],["04.设计模式/070.适配器模式与外观模式.md","适配器模式与外观模式","/pages/c7cf8b/"],["04.设计模式/080.模板方法模式.md","模板方法模式","/pages/93ef90/"],["04.设计模式/090.迭代器与组合模式.md","迭代器与组合模式","/pages/4372f2/"],["04.设计模式/110.状态模式.md","State 模式","/pages/463f44/"],["04.设计模式/120.代理模式.md","代理模式","/pages/cb203f/"]]}],catalogue:{},"/02.大数据/":[{title:"Hadoop",collapsable:!1,children:[["01.Hadoop/01.Hadoop分布式搭建.md","Hadoop分布式搭建","/pages/5d76a5/"],["01.Hadoop/02.Hadoop高可用搭建.md","Hadoop高可用搭建","/pages/f9f70f/"],["01.Hadoop/03.集群端口.md","集群端口","/pages/3e77b2/"],["01.Hadoop/04.代码demo（mr hbase hive redis）.md","代码demo（mr hbase hive redis）","/pages/03a2bd/"]]},{title:"Zookeeper",collapsable:!1,children:[["02.Zookeeper/01.Zookeeper集群搭建.md","Zookeeper集群搭建","/pages/e2226d/"]]},{title:"Hive",collapsable:!1,children:[["03.Hive/01.Hive集群搭建.md","Hive集群搭建","/pages/edf4cb/"],["03.Hive/02.Hive相关.md","Hive相关","/pages/dd806a/"],["03.Hive/03.HSQL.md","HSQL","/pages/dd807a/"]]},{title:"Kafka",collapsable:!1,children:[["04.Kafka/01.Kafka集群搭建.md","Kafka集群搭建","/pages/bfa383/"]]},{title:"HBase",collapsable:!1,children:[["05.HBase/01.HBase集群搭建.md","HBase集群搭建","/pages/b22228/"],["05.HBase/02.HBase基础学习.md","HBase基础学习","/pages/e15afa/"]]},{title:"Spark",collapsable:!1,children:[["06.Spark/01.Spark环境搭建.md","Spark环境搭建","/pages/7d157d/"],["06.Spark/02.Spark相关知识.md","Spark相关知识","/pages/b3ba00/"],["06.Spark/10.Spark内核学习.md","Spark内核学习","/pages/70f03f/"]]},{title:"Flink",collapsable:!1,children:[["07.Flink/01.Flink环境搭建.md","Flink环境搭建","/pages/415096/"],["07.Flink/02.Flink学习.md","Flink学习","/pages/415097/"]]},{title:"Flume",collapsable:!1,children:[["10.Flume/01.Flume安装配置.md","Flume安装配置","/pages/e4166e/"],["10.Flume/02.Flume高可用集群安装.md","Flume高可用集群安装","/pages/0376ec/"],["10.Flume/03.Flume相关学习.md","Flume相关学习","/pages/3408a8/"],["10.Flume/04.Flume把数据导入hive（文件方式）.md","Flume把数据导入hive（文件方式）","/pages/eeda49/"]]},{title:"数据集成工具",collapsable:!1,children:[["11.数据集成工具/01.Sqoop安装配置.md","Sqoop安装配置","/pages/60b3d7/"],["11.数据集成工具/02.Sqoop使用.md","Sqoop使用","/pages/40f7a3/"],["11.数据集成工具/09.数据集成框架.md","其他ETL工具","/pages/b76fc1/"]]},{title:" Impala",collapsable:!1,children:[["12. Impala/01.Impala.md","Impala","/pages/4d39ac/"]]},{title:"调度",collapsable:!1,children:[["16.调度/01.调度工具.md","调度工具","/pages/a04438/"]]},{title:"其他",collapsable:!1,children:[["20.其他/01.docker.md","docker","/pages/d89b45/"]]}],"/03.数据库/":[{title:"Oracle",collapsable:!1,children:[["01.Oracle/01.Oracle相关知识杂记.md","Oracle相关知识杂记","/pages/7e6951/"],["01.Oracle/02.系统函数篇.md","系统函数篇","/pages/b5c27a/"],["01.Oracle/06.与MySQL语法区别.md","与MySQL语法区别","/pages/c2df29/"]]},{title:"MySQL",collapsable:!1,children:[["02.MySQL/02.MySQL琐碎知识点.md","MySQL琐碎知识点","/pages/36476d/"]]},{title:"国产数据库",collapsable:!1,children:[["06.国产数据库/03.达梦数据库.md","达梦数据库","/pages/086761/"],["06.国产数据库/09.华为高斯数据库.md","华为高斯数据库","/pages/e461e3/"]]},{title:"Redis",collapsable:!1,children:[["09.Redis/01.Redis命令学习.md","Redis命令学习","/pages/ca5c12/"]]},{title:"Excel",collapsable:!1,children:[["10.Excel/01.Excel技巧.md","Excel技巧","/pages/265b1a/"]]},["0101.数据库.md","数据库","/pages/e0cc49/"],["1000.SQL非常规用法集锦.md","SQL非常规用法","/pages/e02b49/"],["1006.SQL练习题.md","SQL练习题","/pages/d5b8e9/"]],"/04.其他/":[{title:"Python",collapsable:!1,children:[["01.Python/01.Python简单语法学习.md","Python简单语法学习","/pages/f2a330/"],["01.Python/02.Python操作Office.md","Python操作Office","/pages/f2a340/"],["01.Python/03.Python类库学习.md","Python类库学习","/pages/f2a341/"],["01.Python/04.自己写的python程序.md","自己写的python程序（减少工作量）","/pages/c2b99b/"],["01.Python/05.Python爬虫.md","Python爬虫","/pages/f799c7/"]]},{title:"Shell",collapsable:!1,children:[["02.Shell/01.Shell基础.md","Shell基础","/pages/5704cc/"],["02.Shell/02.Shell小工具.md","Shell命令行","/pages/5765cc/"]]},{title:"Scala",collapsable:!1,children:[["03.Scala/01.语法学习.md","语法学习","/pages/c917bd/"]]},{title:"正则表达式",collapsable:!1,children:[["04.正则表达式/01.正则基础.md","正则基础","/pages/e4e158/"]]},{title:"前端",collapsable:!1,children:[["06.前端/01.前端相关.md","前端相关","/pages/gxfmrs/"]]},{title:"资料",collapsable:!1,children:[["98.资料/98.资料.md","资料","/pages/e6d5cb/"]]},{title:"杂记",collapsable:!1,children:[["99.杂记/01.常用工具或网站.md","常用工具或网站","/pages/414e9c/"],["99.杂记/02.琐碎知识.md","琐碎知识","/pages/c0e729/"],["99.杂记/03.快捷键.md","快捷键","/pages/378bb1/"],["99.杂记/10.FAQ.md","FAQ","/pages/3cec6c/"]]},{title:"摘录",collapsable:!1,children:[["100.摘录/01.摘录.md","摘录","/pages/AXI4oJ/"]]}]},updateBar:{showToArticle:!1},category:!1,tag:!1,author:{name:"Ai",href:"https://github.com/user-h"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:1033078928@qq.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/user-h"},{iconClass:"icon-gitee",title:"Gitee",link:"https://gitee.com/aihb"},{iconClass:"icon-erji",title:"听音乐",link:"https://music.163.com"},{iconClass:"icon-bilibili",title:"哔哩哔哩",link:"https://bilibili.com"},{iconClass:"icon-douyin",title:"抖音",link:"https://douyin.com/"},{iconClass:"icon-mao",title:"猫咪",link:""}]},footer:{createYear:2022,copyrightInfo:"Ai | MIT License"},htmlModules:{pageB:'\n  <div class="wwads-cn wwads-horizontal pageB" data-id="136" style="width:100%;max-height:80px;min-height:auto;"></div>\n  <style>\n    .pageB img{width:80px!important;}\n    .wwads-horizontal .wwads-text, .wwads-content .wwads-text{line-height:1;}\n  </style>\n  ',windowRB:'\n    <div class="wwads-cn wwads-vertical windowRB" data-id="136" style="max-width:160px;\n    min-width: auto;min-height:auto;"></div>\n    <style>\n      .windowRB{ padding: 0;}\n      .windowRB .wwads-img{margin-top: 10px;}\n      .windowRB .wwads-content{margin: 0 10px 10px 10px;}\n      .custom-html-window-rb .close-but{\n        display: none;\n      }\n    </style>\n  '}}};var yl=t(86),vl=t.n(yl),_l=t(94),xl=t(95),kl=t(11);var Sl={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:a}}=n;return!(e||!1===t||!0===a)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,a=e.frontmatter.sticky;return t&&a?t==a?Object(kl.a)(n,e):t-a:t&&!a?-1:!t&&a?1:Object(kl.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(kl.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let a=0,r=n.length;a<r;a++){const{frontmatter:{categories:r,tags:i}}=n[a];"array"===Object(kl.n)(r)&&r.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[a]))}),"array"===Object(kl.n)(i)&&i.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[a]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Ht.component(_l.default),Ht.component(xl.default);function wl(n){return n.toString().padStart(2,"0")}t(237);Ht.component("Badge",()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,412))),Ht.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,95))),Ht.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,94)));t(238);var El={props:{color:{required:!1,default:"rgb(66, 185, 131)"}}},Tl=(t(239),Object(hl.a)(El,(function(){return(0,this._self._c)("div",{staticClass:"spinner",style:{background:this.color}})}),[],!1,null,"1bbcb91a",null).exports);const Il={name:"Mermaid",props:{id:{type:String,required:!1,default:()=>"diagram_"+Date.now()},graph:{type:String,required:!1}},data:()=>({svg:void 0}),computed:{graphData(){return this.graph?this.graph:this.$slots.default[0].text}},render(n){return void 0===this.svg?n("Loading"):n("div",{class:["mermaid-diagram"],domProps:{innerHTML:this.svg,style:"width: 100%"}})},mounted(){t.e(79).then(t.t.bind(null,335,7)).then(n=>{n.initialize({startOnLoad:!0}),n.render(this.id,this.graphData,n=>{this.svg=n})})},components:{Loading:Tl}};var Al=[vl.a,({Vue:n,options:e,router:t,siteData:a})=>{a.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${wl(n.getUTCMonth()+1)}-${wl(n.getUTCDate())} ${wl(n.getUTCHours())}:${wl(n.getUTCMinutes())}:${wl(n.getUTCSeconds())}`}(e)),t?n.author=t:a.themeConfig.author&&(n.author=a.themeConfig.author)}),n.mixin(Sl)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},()=>{"undefined"!=typeof window&&function(n,e,t){function a(n){var t=e.createElement("div");t.className="heart",r.push({el:t,x:n.clientX-5,y:n.clientY-5,scale:1,alpha:1,color:"rgb(220,173,248)"}),e.body.appendChild(t)}var r=[];n.requestAnimationFrame=n.requestAnimationFrame||n.webkitRequestAnimationFrame||n.mozRequestAnimationFrame||n.oRequestAnimationFrame||n.msRequestAnimationFrame||function(n){setTimeout(n,1e3/60)},function(n){var t=e.createElement("style");t.type="text/css";try{t.appendChild(e.createTextNode(n))}catch(e){t.styleSheet.cssText=n}e.getElementsByTagName("head")[0].appendChild(t)}(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"),function(){var e="function"==typeof n.onclick&&n.onclick;n.onclick=function(n){let t=!0;n.path&&n.path.forEach(n=>{1===n.nodeType&&"string"==typeof n.className&&n.className.indexOf("theme-vdoing-content")>-1&&(t=!1)}),t&&(e&&e(),a(n))}}(),function n(){for(var t=0;t<r.length;t++)r[t].alpha<=0?(e.body.removeChild(r[t].el),r.splice(t,1)):(r[t].y--,r[t].scale+=.004,r[t].alpha-=.013,r[t].el.style.cssText="left:"+r[t].x+"px;top:"+r[t].y+"px;opacity:"+r[t].alpha+";transform:scale("+r[t].scale+","+r[t].scale+") rotate(45deg);background:"+r[t].color+";z-index:99999");requestAnimationFrame(n)}()}(window,document)},({Vue:n})=>{n.component(Il.name,Il)},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?01293bffa6c3962016c08ba685c79d78";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))}],jl=[];class zl extends class{constructor(){this.store=new Ht({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Ht.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(zl.prototype,{getPageAsyncComponent:to,getLayoutAsyncComponent:ao,getAsyncComponent:ro,getVueComponent:io});var Ol={install(n){const e=new zl;n.$vuepress=e,n.prototype.$vuepress=e}};function Cl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Dl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return oo("pageKey",e),Ht.component(e)||Ht.component(e,to(e)),Ht.component(e)?n(e):n("")}},Nl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Ll={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Ml=(t(240),t(241),Object(hl.a)(Ll,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Rl={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Ht.config.productionTip=!1,Ht.use(Fs),Ht.use(Ol),Ht.mixin(function(n,e,t=Ht){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const a=new(n(t.$vuepress.$get("siteData"))),r=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(a)),i={};return Object.keys(r).reduce((n,e)=>(e.startsWith("$")&&(n[e]=r[e].get),n),i),{computed:i}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const a in n)"/"===a?t=n[a]:0===this.$page.path.indexOf(a)&&(e=n[a]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,a=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?a?a+" | "+t:t:a||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const a=n[t];if(a.path.toLowerCase()===e.toLowerCase())return a}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},bl)),Ht.component("Content",Dl),Ht.component("ContentSlotsDistributor",Nl),Ht.component("OutboundLink",Ml),Ht.component("ClientOnly",Rl),Ht.component("Layout",ao("Layout")),Ht.component("NotFound",ao("NotFound")),Ht.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.7",hash:"5c72014"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:bl.routerBase||bl.base,t=new Fs({base:e,mode:"history",fallback:!1,routes:gl,scrollBehavior:(n,e,t)=>t||(n.hash?!Ht.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,a)=>{if(Cl(n,e.path))a();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Cl(n,t)?a(t):a()}else a();else{const t=e.path+"/",r=e.path+".html";Cl(n,r)?a(r):Cl(n,t)?a(t):a()}})}(t);const a={};try{await Promise.all(Al.filter(n=>"function"==typeof n).map(e=>e({Vue:Ht,options:a,router:t,siteData:bl,isServer:n})))}catch(n){console.error(n)}return{app:new Ht(Object.assign(a,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},jl.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);