<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark相关知识 | 唐宋元明清</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/hdata-doc/img/favicon.ico">
    <meta name="description" content="">
    <meta name="keywords" content="vuepress,theme,blog,vdoing">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/hdata-doc/assets/css/0.styles.ce16c74b.css" as="style"><link rel="preload" href="/hdata-doc/assets/js/app.37e4fbb6.js" as="script"><link rel="preload" href="/hdata-doc/assets/js/2.82afd9cb.js" as="script"><link rel="preload" href="/hdata-doc/assets/js/8.a242d330.js" as="script"><link rel="prefetch" href="/hdata-doc/assets/js/10.7b061388.js"><link rel="prefetch" href="/hdata-doc/assets/js/11.3d84b622.js"><link rel="prefetch" href="/hdata-doc/assets/js/12.f524e450.js"><link rel="prefetch" href="/hdata-doc/assets/js/13.b3ff7d26.js"><link rel="prefetch" href="/hdata-doc/assets/js/14.3675e190.js"><link rel="prefetch" href="/hdata-doc/assets/js/15.676eac9f.js"><link rel="prefetch" href="/hdata-doc/assets/js/16.c546644f.js"><link rel="prefetch" href="/hdata-doc/assets/js/17.d80c3241.js"><link rel="prefetch" href="/hdata-doc/assets/js/18.bfa024db.js"><link rel="prefetch" href="/hdata-doc/assets/js/19.c4ebe893.js"><link rel="prefetch" href="/hdata-doc/assets/js/20.0c06c705.js"><link rel="prefetch" href="/hdata-doc/assets/js/21.e586d4fc.js"><link rel="prefetch" href="/hdata-doc/assets/js/22.d4747bce.js"><link rel="prefetch" href="/hdata-doc/assets/js/23.cfa91ca4.js"><link rel="prefetch" href="/hdata-doc/assets/js/24.77c960d1.js"><link rel="prefetch" href="/hdata-doc/assets/js/25.cc923a02.js"><link rel="prefetch" href="/hdata-doc/assets/js/26.432e9cf4.js"><link rel="prefetch" href="/hdata-doc/assets/js/27.3248ab2a.js"><link rel="prefetch" href="/hdata-doc/assets/js/28.67efb541.js"><link rel="prefetch" href="/hdata-doc/assets/js/29.e500a45f.js"><link rel="prefetch" href="/hdata-doc/assets/js/3.5c0f818a.js"><link rel="prefetch" href="/hdata-doc/assets/js/30.27916467.js"><link rel="prefetch" href="/hdata-doc/assets/js/31.db03022b.js"><link rel="prefetch" href="/hdata-doc/assets/js/32.40451343.js"><link rel="prefetch" href="/hdata-doc/assets/js/33.57a8afa5.js"><link rel="prefetch" href="/hdata-doc/assets/js/34.e8da6dc5.js"><link rel="prefetch" href="/hdata-doc/assets/js/35.25dea1e4.js"><link rel="prefetch" href="/hdata-doc/assets/js/36.ecc28683.js"><link rel="prefetch" href="/hdata-doc/assets/js/37.976e826a.js"><link rel="prefetch" href="/hdata-doc/assets/js/38.f1f7e891.js"><link rel="prefetch" href="/hdata-doc/assets/js/39.6daaca2d.js"><link rel="prefetch" href="/hdata-doc/assets/js/4.528973e8.js"><link rel="prefetch" href="/hdata-doc/assets/js/40.3766a207.js"><link rel="prefetch" href="/hdata-doc/assets/js/41.515be286.js"><link rel="prefetch" href="/hdata-doc/assets/js/42.87e45d55.js"><link rel="prefetch" href="/hdata-doc/assets/js/43.0eea2c15.js"><link rel="prefetch" href="/hdata-doc/assets/js/44.f5a1989e.js"><link rel="prefetch" href="/hdata-doc/assets/js/45.96eaa743.js"><link rel="prefetch" href="/hdata-doc/assets/js/46.6db88dae.js"><link rel="prefetch" href="/hdata-doc/assets/js/47.f3e98870.js"><link rel="prefetch" href="/hdata-doc/assets/js/48.138b9428.js"><link rel="prefetch" href="/hdata-doc/assets/js/49.b4e2bdb7.js"><link rel="prefetch" href="/hdata-doc/assets/js/5.53dd3ef1.js"><link rel="prefetch" href="/hdata-doc/assets/js/50.6624a71f.js"><link rel="prefetch" href="/hdata-doc/assets/js/51.4273468b.js"><link rel="prefetch" href="/hdata-doc/assets/js/52.d69c448e.js"><link rel="prefetch" href="/hdata-doc/assets/js/53.3e61789b.js"><link rel="prefetch" href="/hdata-doc/assets/js/54.ed81b599.js"><link rel="prefetch" href="/hdata-doc/assets/js/55.a2edf6d0.js"><link rel="prefetch" href="/hdata-doc/assets/js/56.324986ae.js"><link rel="prefetch" href="/hdata-doc/assets/js/57.640caf90.js"><link rel="prefetch" href="/hdata-doc/assets/js/58.344d4730.js"><link rel="prefetch" href="/hdata-doc/assets/js/59.d9078674.js"><link rel="prefetch" href="/hdata-doc/assets/js/6.22885e2c.js"><link rel="prefetch" href="/hdata-doc/assets/js/60.2afcb1b9.js"><link rel="prefetch" href="/hdata-doc/assets/js/61.996c28ca.js"><link rel="prefetch" href="/hdata-doc/assets/js/62.cb5e8bee.js"><link rel="prefetch" href="/hdata-doc/assets/js/63.146ed62c.js"><link rel="prefetch" href="/hdata-doc/assets/js/64.8bb9c50a.js"><link rel="prefetch" href="/hdata-doc/assets/js/65.460effd7.js"><link rel="prefetch" href="/hdata-doc/assets/js/66.f5294e94.js"><link rel="prefetch" href="/hdata-doc/assets/js/67.0da1dddd.js"><link rel="prefetch" href="/hdata-doc/assets/js/68.64117a5a.js"><link rel="prefetch" href="/hdata-doc/assets/js/69.ed33359f.js"><link rel="prefetch" href="/hdata-doc/assets/js/7.814d9e01.js"><link rel="prefetch" href="/hdata-doc/assets/js/70.1250ab19.js"><link rel="prefetch" href="/hdata-doc/assets/js/71.f6a79a2a.js"><link rel="prefetch" href="/hdata-doc/assets/js/72.683057b4.js"><link rel="prefetch" href="/hdata-doc/assets/js/73.94e5450b.js"><link rel="prefetch" href="/hdata-doc/assets/js/74.fa587d94.js"><link rel="prefetch" href="/hdata-doc/assets/js/75.48871ae9.js"><link rel="prefetch" href="/hdata-doc/assets/js/76.447894b5.js"><link rel="prefetch" href="/hdata-doc/assets/js/77.da5dadf2.js"><link rel="prefetch" href="/hdata-doc/assets/js/78.a8553a08.js"><link rel="prefetch" href="/hdata-doc/assets/js/79.bd712952.js"><link rel="prefetch" href="/hdata-doc/assets/js/9.c7938acd.js">
    <link rel="stylesheet" href="/hdata-doc/assets/css/0.styles.ce16c74b.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/hdata-doc/" class="home-link router-link-active"><img src="https://i.postimg.cc/2yr3430s/panda.jpg" alt="唐宋元明清" class="logo"> <span class="site-name can-hide">唐宋元明清</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hdata-doc/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java" class="dropdown-title"><a href="/hdata-doc/pages/de9b5e/" class="link-title">Java</a> <span class="title" style="display:none;">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>基础</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/768c32/" class="nav-link">Java基础</a></li></ul></li><li class="dropdown-item"><h4>工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/1d1863/" class="nav-link">hutool</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/1d1864/" class="nav-link">commons</a></li></ul></li><li class="dropdown-item"><h4>框架</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/1e9420/" class="nav-link">Spring Boot相关</a></li></ul></li><li class="dropdown-item"><h4>设计模式</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/bdceb5/" class="nav-link">设计模式入门</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Hadoop</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/5d76a5/" class="nav-link">Hadoop分布式搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f9f70f/" class="nav-link">Hadoop高可用搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/3e77b2/" class="nav-link">集群端口</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/03a2bd/" class="nav-link">代码demo</a></li></ul></li><li class="dropdown-item"><h4>Zookeeper</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e2226d/" class="nav-link">Zookeeper集群搭建</a></li></ul></li><li class="dropdown-item"><h4>Hive</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/edf4cb/" class="nav-link">Hive集群搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/dd806a/" class="nav-link">Hive相关</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/dd807a/" class="nav-link">HSQL</a></li></ul></li><li class="dropdown-item"><h4>Kafka</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/bfa383/" class="nav-link">Kafka集群搭建</a></li></ul></li><li class="dropdown-item"><h4>HBase</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/b22228/" class="nav-link">HBase集群搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/e15afa/" class="nav-link">HBase基础学习</a></li></ul></li><li class="dropdown-item"><h4>Spark</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/7d157d/" class="nav-link">Spark环境搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/b3ba00/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Spark相关知识</a></li></ul></li><li class="dropdown-item"><h4>Flink</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/415096/" class="nav-link">Flink环境搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/415097/" class="nav-link">Flink学习</a></li></ul></li><li class="dropdown-item"><h4>Flume</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e4166e/" class="nav-link">Flume安装配置</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/0376ec/" class="nav-link">Flume高可用集群安装</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/3408a8/" class="nav-link">Flume相关学习</a></li></ul></li><li class="dropdown-item"><h4>Sqoop</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/60b3d7/" class="nav-link">Sqoop安装配置</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/40f7a3/" class="nav-link">Sqoop使用</a></li></ul></li><li class="dropdown-item"><h4>其他</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/d89b45/" class="nav-link">docker</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据库" class="dropdown-title"><a href="/hdata-doc/pages/e0cc49/" class="link-title">数据库</a> <span class="title" style="display:none;">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Oracle</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/7e6951/" class="nav-link">Oracle相关知识杂记</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/b5c27a/" class="nav-link">系统函数篇</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/c2df29/" class="nav-link">与MySQL语法区别</a></li></ul></li><li class="dropdown-item"><h4>MySQL</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/36476d/" class="nav-link">MySQL知识点</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a330/" class="nav-link">Python简单语法</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a340/" class="nav-link">Python操作Office</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a341/" class="nav-link">Python类库学习</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f799c7/" class="nav-link">Python爬虫</a></li></ul></li><li class="dropdown-item"><h4>Shell</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/5704cc/" class="nav-link">Shell基础</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/5765cc/" class="nav-link">Shell命令行</a></li></ul></li><li class="dropdown-item"><h4>Scala</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/c917bd/" class="nav-link">语法学习</a></li></ul></li><li class="dropdown-item"><h4>正则表达式</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e4e158/" class="nav-link">正则基础</a></li></ul></li><li class="dropdown-item"><h4>调度</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/a04438/" class="nav-link">调度工具</a></li></ul></li><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/gxfmrs/" class="nav-link">前端相关</a></li></ul></li><li class="dropdown-item"><h4>杂记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/414e9c/" class="nav-link">常用工具或网站</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/c0e729/" class="nav-link">琐碎知识</a></li></ul></li><li class="dropdown-item"><h4>摘录</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/AXI4oJ/" class="nav-link">摘录</a></li></ul></li></ul></div></div> <a href="https://github.com/user-h/hdata-doc" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/hdata-doc/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java" class="dropdown-title"><a href="/hdata-doc/pages/de9b5e/" class="link-title">Java</a> <span class="title" style="display:none;">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>基础</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/768c32/" class="nav-link">Java基础</a></li></ul></li><li class="dropdown-item"><h4>工具</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/1d1863/" class="nav-link">hutool</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/1d1864/" class="nav-link">commons</a></li></ul></li><li class="dropdown-item"><h4>框架</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/1e9420/" class="nav-link">Spring Boot相关</a></li></ul></li><li class="dropdown-item"><h4>设计模式</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/bdceb5/" class="nav-link">设计模式入门</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="大数据" class="dropdown-title"><!----> <span class="title" style="display:;">大数据</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Hadoop</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/5d76a5/" class="nav-link">Hadoop分布式搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f9f70f/" class="nav-link">Hadoop高可用搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/3e77b2/" class="nav-link">集群端口</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/03a2bd/" class="nav-link">代码demo</a></li></ul></li><li class="dropdown-item"><h4>Zookeeper</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e2226d/" class="nav-link">Zookeeper集群搭建</a></li></ul></li><li class="dropdown-item"><h4>Hive</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/edf4cb/" class="nav-link">Hive集群搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/dd806a/" class="nav-link">Hive相关</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/dd807a/" class="nav-link">HSQL</a></li></ul></li><li class="dropdown-item"><h4>Kafka</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/bfa383/" class="nav-link">Kafka集群搭建</a></li></ul></li><li class="dropdown-item"><h4>HBase</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/b22228/" class="nav-link">HBase集群搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/e15afa/" class="nav-link">HBase基础学习</a></li></ul></li><li class="dropdown-item"><h4>Spark</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/7d157d/" class="nav-link">Spark环境搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/b3ba00/" aria-current="page" class="nav-link router-link-exact-active router-link-active">Spark相关知识</a></li></ul></li><li class="dropdown-item"><h4>Flink</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/415096/" class="nav-link">Flink环境搭建</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/415097/" class="nav-link">Flink学习</a></li></ul></li><li class="dropdown-item"><h4>Flume</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e4166e/" class="nav-link">Flume安装配置</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/0376ec/" class="nav-link">Flume高可用集群安装</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/3408a8/" class="nav-link">Flume相关学习</a></li></ul></li><li class="dropdown-item"><h4>Sqoop</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/60b3d7/" class="nav-link">Sqoop安装配置</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/40f7a3/" class="nav-link">Sqoop使用</a></li></ul></li><li class="dropdown-item"><h4>其他</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/d89b45/" class="nav-link">docker</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据库" class="dropdown-title"><a href="/hdata-doc/pages/e0cc49/" class="link-title">数据库</a> <span class="title" style="display:none;">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Oracle</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/7e6951/" class="nav-link">Oracle相关知识杂记</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/b5c27a/" class="nav-link">系统函数篇</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/c2df29/" class="nav-link">与MySQL语法区别</a></li></ul></li><li class="dropdown-item"><h4>MySQL</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/36476d/" class="nav-link">MySQL知识点</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="其他" class="dropdown-title"><!----> <span class="title" style="display:;">其他</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>Python</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a330/" class="nav-link">Python简单语法</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a340/" class="nav-link">Python操作Office</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f2a341/" class="nav-link">Python类库学习</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/f799c7/" class="nav-link">Python爬虫</a></li></ul></li><li class="dropdown-item"><h4>Shell</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/5704cc/" class="nav-link">Shell基础</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/5765cc/" class="nav-link">Shell命令行</a></li></ul></li><li class="dropdown-item"><h4>Scala</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/c917bd/" class="nav-link">语法学习</a></li></ul></li><li class="dropdown-item"><h4>正则表达式</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/e4e158/" class="nav-link">正则基础</a></li></ul></li><li class="dropdown-item"><h4>调度</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/a04438/" class="nav-link">调度工具</a></li></ul></li><li class="dropdown-item"><h4>前端</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/gxfmrs/" class="nav-link">前端相关</a></li></ul></li><li class="dropdown-item"><h4>杂记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/414e9c/" class="nav-link">常用工具或网站</a></li><li class="dropdown-subitem"><a href="/hdata-doc/pages/c0e729/" class="nav-link">琐碎知识</a></li></ul></li><li class="dropdown-item"><h4>摘录</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/hdata-doc/pages/AXI4oJ/" class="nav-link">摘录</a></li></ul></li></ul></div></div> <a href="https://github.com/user-h/hdata-doc" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hadoop</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/5d76a5/" class="sidebar-link">Hadoop分布式搭建</a></li><li><a href="/hdata-doc/pages/f9f70f/" class="sidebar-link">Hadoop高可用搭建</a></li><li><a href="/hdata-doc/pages/3e77b2/" class="sidebar-link">集群端口</a></li><li><a href="/hdata-doc/pages/03a2bd/" class="sidebar-link">代码demo（mr hbase hive redis）</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Zookeeper</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/e2226d/" class="sidebar-link">Zookeeper集群搭建</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Hive</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/edf4cb/" class="sidebar-link">Hive集群搭建</a></li><li><a href="/hdata-doc/pages/dd806a/" class="sidebar-link">Hive相关</a></li><li><a href="/hdata-doc/pages/dd807a/" class="sidebar-link">HSQL</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Kafka</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/bfa383/" class="sidebar-link">Kafka集群搭建</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>HBase</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/b22228/" class="sidebar-link">HBase集群搭建</a></li><li><a href="/hdata-doc/pages/e15afa/" class="sidebar-link">HBase基础学习</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Spark</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/7d157d/" class="sidebar-link">Spark环境搭建</a></li><li><a href="/hdata-doc/pages/b3ba00/" aria-current="page" class="active sidebar-link">Spark相关知识</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/hdata-doc/pages/b3ba00/#spark-sql可调参数" class="sidebar-link">spark-sql可调参数</a></li><li class="sidebar-sub-header level2"><a href="/hdata-doc/pages/b3ba00/#spark数据类型" class="sidebar-link">Spark数据类型</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#rdd、dataframe、dataset创建-及相互转换" class="sidebar-link">RDD、DataFrame、DataSet创建,及相互转换</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/hdata-doc/pages/b3ba00/#spark代码学习" class="sidebar-link">Spark代码学习</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#第一个spark程序" class="sidebar-link">第一个spark程序</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#wordcount" class="sidebar-link">WordCount</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/hdata-doc/pages/b3ba00/#spark-sql-sqlcontext" class="sidebar-link">Spark SQL（sqlContext）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#第一个例子" class="sidebar-link">第一个例子</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#sparksql-cli-hivecontext" class="sidebar-link">SparkSQL CLI(hiveContext)</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/hdata-doc/pages/b3ba00/#spark-streaming知识点" class="sidebar-link">Spark Streaming知识点</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#dstream基础" class="sidebar-link">Dstream基础</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#高级来源" class="sidebar-link">高级来源</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#文件数据源-文件系统" class="sidebar-link">文件数据源(文件系统)</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#mysql-队列-数据源" class="sidebar-link">mysql(队列)数据源</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#自定义数据源" class="sidebar-link">自定义数据源</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#有状态数据统计updatestatebykey" class="sidebar-link">有状态数据统计UpdateStateByKey</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#window滑动" class="sidebar-link">Window滑动</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#转换-transfrom" class="sidebar-link">转换 transfrom</a></li><li class="sidebar-sub-header level3"><a href="/hdata-doc/pages/b3ba00/#dstream-foreachrdd-dstream输出" class="sidebar-link">DStream.foreachRDD(DStream输出)</a></li></ul></li></ul></li><li><a href="/hdata-doc/pages/70f03f/" class="sidebar-link">Spark内核学习</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Flink</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/415096/" class="sidebar-link">Flink环境搭建</a></li><li><a href="/hdata-doc/pages/415097/" class="sidebar-link">Flink学习</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Flume</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/e4166e/" class="sidebar-link">Flume安装配置</a></li><li><a href="/hdata-doc/pages/0376ec/" class="sidebar-link">Flume高可用集群安装</a></li><li><a href="/hdata-doc/pages/3408a8/" class="sidebar-link">Flume相关学习</a></li><li><a href="/hdata-doc/pages/eeda49/" class="sidebar-link">Flume把数据导入hive（文件方式）</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>数据集成工具</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/60b3d7/" class="sidebar-link">Sqoop安装配置</a></li><li><a href="/hdata-doc/pages/40f7a3/" class="sidebar-link">Sqoop使用</a></li><li><a href="/hdata-doc/pages/b76fc1/" class="sidebar-link">其他ETL工具</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span> Impala</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/4d39ac/" class="sidebar-link">Impala</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>调度</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/a04438/" class="sidebar-link">调度工具</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>其他</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hdata-doc/pages/d89b45/" class="sidebar-link">docker</a></li></ul></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/hdata-doc/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><span data-v-06225672>大数据</span></li><li data-v-06225672><span data-v-06225672>Spark</span></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/user-h" target="_blank" title="作者" class="beLink" data-v-06225672>Ai</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-02-27</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">Spark相关知识<!----></h1>  <div class="theme-vdoing-content content__default"><h2 id="spark-sql可调参数"><a href="#spark-sql可调参数" class="header-anchor">#</a> spark-sql可调参数</h2> <hr> <div class="language-properties extra-class"><pre class="language-properties"><code><span class="token comment">#Job ID /Name</span>
<span class="token key attr-name">spark.app.name</span><span class="token punctuation">=</span><span class="token value attr-value">clsfd_ad_attr_map_w_mvca_ins</span>

<span class="token comment">#yarn 进行调度，也可以是mesos，yarn，以及standalone</span>

<span class="token comment">#一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。</span>
<span class="token key attr-name">spark.master</span><span class="token punctuation">=</span><span class="token value attr-value">yarn</span>

<span class="token comment">#激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。</span>
<span class="token comment">#需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。</span>
<span class="token comment">#对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor</span>
<span class="token key attr-name">spark.shuffle.service.enabled</span><span class="token punctuation">=</span><span class="token value attr-value">true</span>

<span class="token comment">#在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。</span>
<span class="token key attr-name">spark.dynamicAllocation.enabled</span><span class="token punctuation">=</span><span class="token value attr-value">true</span>

<span class="token comment"># 如果所有的executor都移除了，重新请求时启动的初始executor数</span>
<span class="token key attr-name">spark.dynamicAllocation.initialExecutors</span><span class="token punctuation">=</span><span class="token value attr-value">20</span>

<span class="token comment"># 最少保留的executor数</span>
<span class="token key attr-name">spark.dynamicAllocation.minExecutors</span><span class="token punctuation">=</span><span class="token value attr-value">10</span>

<span class="token comment"># 最多使用的executor数，默认为你申请的最大executor数</span>
<span class="token key attr-name">spark.dynamicAllocation.maxExecutors</span><span class="token punctuation">=</span><span class="token value attr-value">100</span>

<span class="token comment"># 可以是cluster也可以是Client</span>
<span class="token key attr-name">spark.submit.deployMode</span><span class="token punctuation">=</span><span class="token value attr-value">cluster</span>

<span class="token comment"># 指定提交到Yarn的资源池</span>
<span class="token key attr-name">spark.yarn.queue</span><span class="token punctuation">=</span><span class="token value attr-value">hdlq-data-batch-low</span>

<span class="token comment"># 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。</span>
<span class="token key attr-name">spark.driver.memory</span><span class="token punctuation">=</span><span class="token value attr-value">8g</span>
<span class="token comment"># excutor的核心数</span>
<span class="token key attr-name">spark.executor.cores</span><span class="token punctuation">=</span><span class="token value attr-value">16</span>
<span class="token comment"># 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead</span>
<span class="token key attr-name">spark.executor.memory</span><span class="token punctuation">=</span><span class="token value attr-value">32g</span>
<span class="token key attr-name">spark.yarn.executor.memoryOverhead</span><span class="token punctuation">=</span><span class="token value attr-value">2g</span>

<span class="token comment"># shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。</span>
<span class="token key attr-name">spark.sql.shuffle.partitions</span><span class="token punctuation">=</span><span class="token value attr-value">100</span>

<span class="token comment"># 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize </span>
<span class="token comment"># 这个参数只适用于未加工的RDD不适用于dataframe</span>
<span class="token comment"># 没有join和聚合计算操作，这个参数将是无效设置</span>
spark.default.parallelism

<span class="token comment"># 打包传入一个分区的最大字节，在读取文件的时候。</span>
<span class="token key attr-name">spark.sql.files.maxPartitionBytes</span><span class="token punctuation">=</span><span class="token value attr-value">128MB</span>

<span class="token comment"># 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。</span>
<span class="token comment"># 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。</span>
<span class="token key attr-name">spark.sql.files.openCostInBytes</span><span class="token punctuation">=</span><span class="token value attr-value">4MB</span>

<span class="token comment"># Spark 事件总线是SparkListenerEvent事件的阻塞队列大小</span>
<span class="token key attr-name">spark.scheduler.listenerbus.eventqueue.size</span><span class="token punctuation">=</span><span class="token value attr-value">100000</span>

<span class="token comment"># 是否启动推测机制</span>
<span class="token key attr-name">spark.speculation</span><span class="token punctuation">=</span><span class="token value attr-value">false</span>

<span class="token comment"># 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。</span>
<span class="token comment"># 2表示比其他task慢两倍时，启动推测机制</span>
<span class="token key attr-name">spark.speculation.multiplier</span><span class="token punctuation">=</span><span class="token value attr-value">2</span>

<span class="token comment"># 推测机制的检测周期</span>
<span class="token key attr-name">spark.speculation.interval</span><span class="token punctuation">=</span><span class="token value attr-value">5000ms</span>

<span class="token comment"># 完成task的百分比时启动推测</span>
<span class="token key attr-name">spark.speculation.quantile</span><span class="token punctuation">=</span><span class="token value attr-value">0.6</span>

<span class="token comment"># 最多允许失败的Executor数量。</span>
<span class="token key attr-name">spark.task.maxFailures</span><span class="token punctuation">=</span><span class="token value attr-value">10</span>

<span class="token comment"># spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用.</span>
<span class="token key attr-name">spark.serializer</span><span class="token punctuation">=</span><span class="token value attr-value">org.apache.spark.serializer.KryoSerializer</span>

<span class="token comment"># 因为spark是基于内存的机制，所以默认是开启RDD的压缩</span>
<span class="token key attr-name">spark.rdd.compress</span><span class="token punctuation">=</span><span class="token value attr-value">true</span>

<span class="token comment"># Spark的安全管理</span>
<span class="token comment">#https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala</span>
<span class="token key attr-name">spark.ui.view.acls</span><span class="token punctuation">=</span><span class="token value attr-value">*</span>
<span class="token key attr-name">spark.ui.view.acls.groups</span><span class="token punctuation">=</span><span class="token value attr-value">*</span>

<span class="token comment"># 表示配置GC线程数为3</span>
<span class="token key attr-name">spark.executor.extraJavaOptions</span><span class="token punctuation">=</span><span class="token value attr-value">&quot;-XX:ParallelGCThreads=3&quot;</span>

<span class="token comment"># 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB</span>
<span class="token key attr-name">spark.sql.autoBroadcastJoinThreshold</span><span class="token punctuation">=</span><span class="token value attr-value">104857600</span>

<span class="token comment"># 广播等待超时，这里单位是秒</span>
<span class="token key attr-name">spark.sql.broadcastTimeout</span><span class="token punctuation">=</span><span class="token value attr-value">300</span>

<span class="token comment"># 心跳检测间隔</span>
<span class="token key attr-name">spark.yarn.scheduler.heartbeat.interval-ms</span><span class="token punctuation">=</span><span class="token value attr-value">10000</span>

spark.sql.broadcastTimeout

<span class="token comment">#缓存表问题</span>
<span class="token comment">#spark2.+采用：</span>
<span class="token comment">#spark.catalog.cacheTable(&quot;tableName&quot;)缓存表，spark.catalog.uncacheTable(&quot;tableName&quot;)解除缓存。</span>
<span class="token comment">#spark 1.+采用：</span>
<span class="token comment">#sqlContext.cacheTable(&quot;tableName&quot;)缓存，sqlContext.uncacheTable(&quot;tableName&quot;) 解除缓存</span>
<span class="token comment">#Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。</span>

<span class="token comment">#假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。</span>
<span class="token key attr-name">spark.sql.inMemoryColumnarStorage.compressed</span><span class="token punctuation">=</span><span class="token value attr-value">true</span>

<span class="token comment">#控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险</span>
<span class="token key attr-name">spark.sql.inMemoryColumnarStorage.batchSize</span><span class="token punctuation">=</span><span class="token value attr-value">10000</span>
</code></pre></div><h2 id="spark数据类型"><a href="#spark数据类型" class="header-anchor">#</a> Spark数据类型</h2> <h3 id="rdd、dataframe、dataset创建-及相互转换"><a href="#rdd、dataframe、dataset创建-及相互转换" class="header-anchor">#</a> RDD、DataFrame、DataSet创建,及相互转换</h3> <p><strong>RDD创建(RDD整体上分为Value类型和Key-Value类型)</strong></p> <ul><li>从内存(集合)创建</li></ul> <div class="language-java extra-class"><pre class="language-java"><code>val rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">parallelize</span><span class="token punctuation">(</span><span class="token class-name">Array</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
val rdd1 <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">makeRDD</span><span class="token punctuation">(</span><span class="token class-name">Array</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>从磁盘创建</li></ul> <div class="language-java extra-class"><pre class="language-java"><code>val rdd2<span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token string">&quot;hdfs://hadoop102:9000/RELEASE&quot;</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>从其他RDD转化</li></ul> <p><strong>DataFrame创建(SparkSession是创建DataFrame和执行SQL的入口)</strong></p> <ul><li>通过Spark的数据源进行创建；</li></ul> <div class="language-java extra-class"><pre class="language-java"><code>val df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token function">json</span><span class="token punctuation">(</span><span class="token string">&quot;/opt/module/spark/examples/src/main/resources/people.json&quot;</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>从一个存在的RDD进行转换；</li> <li>还可以从Hive Table进行查询返回</li></ul> <p><strong>DataSet创建(Dataset是具有强类型的数据集合，需要提供对应的类型信息)</strong></p> <ul><li>内存创建
1）创建一个样例类</li></ul> <div class="language-shell script extra-class"><pre class="language-shell"><code>  scala<span class="token operator">&gt;</span> <span class="token keyword">case</span> class Person<span class="token punctuation">(</span>name: String, age: Long<span class="token punctuation">)</span>
  defined class Person
</code></pre></div><p>2）创建DataSet</p> <div class="language-shell script extra-class"><pre class="language-shell"><code>  scala<span class="token operator">&gt;</span> val caseClassDS <span class="token operator">=</span> Seq<span class="token punctuation">(</span>Person<span class="token punctuation">(</span><span class="token string">&quot;Andy&quot;</span>, <span class="token number">32</span><span class="token punctuation">))</span>.toDS<span class="token punctuation">(</span><span class="token punctuation">)</span>
  caseClassDS: org.apache.spark.sql.Dataset<span class="token punctuation">[</span>Person<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>name: string, age: bigint<span class="token punctuation">]</span>
</code></pre></div><ul><li>通过DataFrame或RDD转化</li></ul> <p><strong>相互转化</strong>
![](rdd df ds相互转换.jpg)</p> <p><strong>待扩展</strong>
三者共性和区别
用户自定义函数
Spark数据源</p> <h2 id="spark代码学习"><a href="#spark代码学习" class="header-anchor">#</a> Spark代码学习</h2> <hr> <h3 id="第一个spark程序"><a href="#第一个spark程序" class="header-anchor">#</a> 第一个spark程序</h3> <div class="language-java extra-class"><pre class="language-java"><code> <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">SparkConf</span><span class="token punctuation">,</span> <span class="token class-name">SparkContext</span><span class="token punctuation">}</span>
 
 object <span class="token class-name">FirstSpark</span> <span class="token punctuation">{</span>
   def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
 <span class="token comment">//        println(&quot;hello spark!&quot;)</span>
     val conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;mySpark&quot;</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local&quot;</span><span class="token punctuation">)</span> <span class="token comment">//本机的park就用local.远端的就写ip，因为我的park环境是在云端连接不方便这里我先用local</span>
     <span class="token comment">//如果是打成jar包运行则需要去掉setMaster(&quot;local&quot;)因为在参数中会指定。</span>
 
     <span class="token comment">//sc对象为spark运行时的上下文</span>
     val sc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
     <span class="token comment">//使用list初始化1个RDD并使用map函数*3</span>
     val rdd <span class="token operator">=</span> sc<span class="token punctuation">.</span><span class="token function">parallelize</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>_ <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span>
     <span class="token comment">//取出大于10的元素</span>
     val mappedRDD <span class="token operator">=</span> rdd<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>_ <span class="token operator">&gt;</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token comment">//对集合求和</span>
     <span class="token function">println</span><span class="token punctuation">(</span>rdd<span class="token punctuation">.</span><span class="token function">reduce</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span><span class="token punctuation">)</span>
     <span class="token comment">//输出大于10的元素</span>
     <span class="token keyword">for</span> <span class="token punctuation">(</span>arg <span class="token operator">&lt;</span><span class="token operator">-</span> mappedRDD<span class="token punctuation">)</span>
       <span class="token function">print</span><span class="token punctuation">(</span>arg <span class="token operator">+</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">)</span>
     <span class="token function">println</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;run success&quot;</span><span class="token punctuation">)</span>
 
     sc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre></div><h3 id="wordcount"><a href="#wordcount" class="header-anchor">#</a> WordCount</h3> <div class="language-java extra-class"><pre class="language-java"><code> <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">SparkConf</span><span class="token punctuation">,</span> <span class="token class-name">SparkContext</span><span class="token punctuation">}</span>
 
 object <span class="token class-name">WordCount</span> <span class="token punctuation">{</span>
   def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
     <span class="token comment">/**
     第一步：创建spark的配置对象sparkconf,设置spark程序的运行时的配置信息，例如说通过setMaster来设置程序
       链接spark集群的master的URL，如果设置为local，则代表spark程序在本地运行，
      */</span>
     val conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment">//创建SparkConf对象</span>
     <span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;WordCount&quot;</span><span class="token punctuation">)</span>    <span class="token comment">//设置应用程序的名称,在程序运行的监控界面可以看到这个名字</span>
     <span class="token comment">//conf.setMaster(&quot;local&quot;)//此时，程序在本地执行，不需要安装spark集群</span>
     <span class="token comment">//&quot;spark://192.168.1.100:7077&quot;</span>
     <span class="token comment">//conf.setMaster(args(0))//指定spark运行是集群模式 一般我们不在代码中指定，我们在提交的时候指定</span>
     <span class="token comment">/**
     第二步：创建SparkContext对象，
     SparkContext是spark程序所有功能的唯一入口，无论是采用Scala，Java，Python，R等都必须有一个SparkContext
     SparkContext核心作用：初始化spark应用程序运行时候所需要的核心组件，包括DAGScheduler，TaskScheduler,SchedulerBackend
     同时还会负责Spark程序往Master注册程序等
     SparkContext是整个spark应用程序中最为至关重要的一个对象
      */</span>
     val sc<span class="token operator">=</span><span class="token keyword">new</span> <span class="token class-name">SparkContext</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span>   <span class="token comment">//创建SparkContext对象，通过传入SparkContext实例来定制Spark运行的具体参数和配置信息</span>
     <span class="token comment">/**
     第3步：根据具体的数据来源 (HDFS,HBase,Local等)通过SparkContext来创建RDD
     RDD的创建有3种方式，外部的数据来源，根据scala集合，由其他的RDD操作
     数据会被RDD划分成为一系列的Partitions,分配到每个Partition的数据属于一个Task的处理范畴
      */</span>
     val line<span class="token operator">=</span>sc<span class="token punctuation">.</span><span class="token function">textFile</span><span class="token punctuation">(</span><span class="token function">args</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment">//读取本地的一个文件并且设置为1个partition</span>
     <span class="token comment">//val line =sc.textFile(&quot;hdfs://192.168.18.140:9000/input/LICENSE.txt&quot;)   //指定HDFS的路径，这个也可以到时候在参数传入</span>
     <span class="token comment">/**
     第4步：对初始的RDD进行Transformation级别的处理，例如Map、filter等高阶函数等的编程来进行具体的数据计算
      在对每一行的字符串拆分成单个单词
      在单词的拆分的基础上对每个单词实例计算为1，也就是word=&gt;(word,1)
      在对每个单词实例计数为1基础上统计每个单词在文件中出现的总次数
      */</span>
     val words<span class="token operator">=</span>line<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
     val pairs<span class="token operator">=</span>words<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>word<span class="token operator">=</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
     val wordcounts<span class="token operator">=</span>pairs<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
 
     <span class="token comment">//key value反转，按key排序，再反转回来</span>
     val sortWords <span class="token operator">=</span> wordcounts<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sortByKey</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>_2<span class="token punctuation">,</span>x<span class="token punctuation">.</span>_1<span class="token punctuation">)</span><span class="token punctuation">)</span>
     sortWords<span class="token punctuation">.</span><span class="token function">saveAsTextFile</span><span class="token punctuation">(</span><span class="token function">args</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//存储到文件系统</span>
 
     <span class="token comment">//sortWords.foreach(wordNum=&gt;println(wordNum._1+&quot;:&quot;+wordNum._2)) //本地模式用这个打印</span>
     sortWords<span class="token punctuation">.</span><span class="token function">collect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">foreach</span><span class="token punctuation">(</span>wordNum<span class="token operator">=</span><span class="token operator">&gt;</span><span class="token function">println</span><span class="token punctuation">(</span>wordNum<span class="token punctuation">.</span>_1<span class="token operator">+</span><span class="token string">&quot;:&quot;</span><span class="token operator">+</span>wordNum<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
     sc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre></div><h2 id="spark-sql-sqlcontext"><a href="#spark-sql-sqlcontext" class="header-anchor">#</a> Spark SQL（sqlContext）</h2> <h3 id="第一个例子"><a href="#第一个例子" class="header-anchor">#</a> 第一个例子</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkSQL</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">DataFrame</span><span class="token punctuation">,</span> <span class="token class-name">SparkSession</span><span class="token punctuation">}</span>

object <span class="token class-name">SparkSqlJson</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">//在代码中使用sparkSql,我们只需要一个SparkSession即可搞定</span>
    <span class="token comment">//创建一个SparkSession实例</span>
    val sparkSession<span class="token operator">:</span> <span class="token class-name">SparkSession</span> <span class="token operator">=</span> <span class="token class-name">SparkSession</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//创建 SparkSession.Builder，初始化SparkSession.</span>
      <span class="token punctuation">.</span><span class="token function">appName</span><span class="token punctuation">(</span><span class="token string">&quot;spark SQL basic example&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">master</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span> <span class="token comment">//在idea里设置master为local</span>
      <span class="token punctuation">.</span><span class="token function">getOrCreate</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">//当SparkSession.GetOrCreate()被调用，SparkSession发生变化，将会返回一个线程和它的子线程。这将会确定给定的线程接受带有隔离会话的SparkSession，而不是全局的context。</span>

    <span class="token comment">//读入数据文件,该文件是从spark example中拷贝的,具体路径spark/examples/src/main/resources/下</span>
    val dataFrame<span class="token operator">:</span> <span class="token class-name">DataFrame</span> <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read<span class="token punctuation">.</span><span class="token function">json</span><span class="token punctuation">(</span><span class="token function">args</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//&quot;data\\people.json&quot;</span>

    <span class="token comment">//显示数据集</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------1.显示数据集--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//显示数据集的模式</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------2.显示数据集的模式--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">printSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//查询name列并显示</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------3.查询name列并显示--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>


    <span class="token comment">//引入spark的隐式转换功能,我们可以使用$符号+列名的形式对列进行计算</span>
    <span class="token comment">//这里的sparkSession不是某个包下面的东西，而是我们SparkSession.builder()对应的变量值</span>
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
    <span class="token comment">//查询姓名,并age+1后显示</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------4.查询姓名,并age+1后显示--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">select</span><span class="token punctuation">(</span>$<span class="token string">&quot;name&quot;</span><span class="token punctuation">,</span> $<span class="token string">&quot;age&quot;</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//过滤年龄大于21的并显示</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------5.过滤年龄大于21的并显示--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>$<span class="token string">&quot;age&quot;</span> <span class="token operator">&gt;</span> <span class="token number">21</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//以年龄分组并计算每组的人数</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------6.以年龄分组并计算每组的人数--------------------------&quot;</span><span class="token punctuation">)</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">groupBy</span><span class="token punctuation">(</span><span class="token string">&quot;age&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//将dataframe注册为临时表people</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">createOrReplaceTempView</span><span class="token punctuation">(</span><span class="token string">&quot;people&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//直接使用sql语句查询people表</span>
    val sqlDF<span class="token operator">:</span> <span class="token class-name">DataFrame</span> <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span><span class="token function">sql</span><span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM people&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//显示结果集</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------7.查询临时表,显示结果集--------------------------&quot;</span><span class="token punctuation">)</span>
    sqlDF<span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//创建全局表</span>
    dataFrame<span class="token punctuation">.</span><span class="token function">createGlobalTempView</span><span class="token punctuation">(</span><span class="token string">&quot;people&quot;</span><span class="token punctuation">)</span>
    <span class="token comment">//查询全局people表</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------8.查询全局people表--------------------------&quot;</span><span class="token punctuation">)</span>
    sparkSession<span class="token punctuation">.</span><span class="token function">sql</span><span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM global_temp.people&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//全局表是可以跨session的</span>
    <span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;----------------9.全局表跨session查询--------------------------&quot;</span><span class="token punctuation">)</span>
    sparkSession<span class="token punctuation">.</span><span class="token function">newSession</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">sql</span><span class="token punctuation">(</span><span class="token string">&quot;SELECT * FROM global_temp.people&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><p>添加依赖</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span><span class="token class-name">SparkSQL</span>添加依赖<span class="token operator">--</span><span class="token operator">&gt;</span>
<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>parquet<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>parquet<span class="token operator">-</span>jackson<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span><span class="token number">1.10</span><span class="token number">.1</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre></div><p>打jar包测试</p> <div class="language-shell script extra-class"><pre class="language-shell"><code>bin/spark-submit <span class="token punctuation">\</span>
--class sparkSQL.SparkSqlJson <span class="token punctuation">\</span>
--master spark://hadoop1:7077 <span class="token punctuation">\</span>
--executor-memory 1G <span class="token punctuation">\</span>
--total-executor-cores <span class="token number">1</span> <span class="token punctuation">\</span>
./myjar/SparkSQLJson.jar <span class="token punctuation">\</span>
file:///soft/spark/examples/src/main/resources/people.json
</code></pre></div><h3 id="sparksql-cli-hivecontext"><a href="#sparksql-cli-hivecontext" class="header-anchor">#</a> SparkSQL CLI(hiveContext)</h3> <p>在spark下链接hadoop的core-site.xml 以及配置hive-site.xml的hive.metastore.uris并链接</p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token generics"><span class="token punctuation">&lt;</span>configuration<span class="token punctuation">&gt;</span></span>
  <span class="token generics"><span class="token punctuation">&lt;</span>property<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>name<span class="token punctuation">&gt;</span></span>hive<span class="token punctuation">.</span>metastore<span class="token punctuation">.</span>uris<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>value<span class="token punctuation">&gt;</span></span>thrift<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop100<span class="token operator">:</span><span class="token number">9083</span><span class="token operator">&lt;</span><span class="token operator">/</span>value<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>description<span class="token punctuation">&gt;</span></span><span class="token class-name">Thrift</span> URI <span class="token keyword">for</span> the remote <span class="token class-name"><span class="token namespace">metastore<span class="token punctuation">.</span></span> Used</span> by metastore client <span class="token keyword">to</span> <span class="token namespace">connect</span> <span class="token keyword">to</span> <span class="token namespace">remote</span> metastore<span class="token punctuation">.</span>&lt;<span class="token operator">/</span>description<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>configuration<span class="token operator">&gt;</span>

ln <span class="token operator">-</span>s <span class="token operator">/</span>soft<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">2.9</span><span class="token number">.2</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>core<span class="token operator">-</span>site<span class="token punctuation">.</span>xml <span class="token operator">/</span>soft<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>spark<span class="token operator">/</span>conf<span class="token operator">/</span>core<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
ln <span class="token operator">-</span>s <span class="token operator">/</span>soft<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>hive<span class="token operator">/</span>conf<span class="token operator">/</span>hive<span class="token operator">-</span>site<span class="token punctuation">.</span>xml <span class="token operator">/</span>soft<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>spark<span class="token operator">/</span>conf<span class="token operator">/</span>hive<span class="token operator">-</span>site<span class="token punctuation">.</span>xml

然后启动hive的metastore服务，使用nohup命令后台启动
nohup hive <span class="token operator">--</span>service metastore <span class="token operator">&gt;</span> metastore<span class="token punctuation">.</span>log <span class="token number">2</span><span class="token operator">&gt;</span><span class="token operator">&amp;</span><span class="token number">1</span> <span class="token operator">&amp;</span>

启动spark<span class="token operator">-</span>sql
<span class="token operator">/</span>soft<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>spark<span class="token operator">/</span>bin<span class="token operator">/</span>spark<span class="token operator">-</span>sql
</code></pre></div><h2 id="spark-streaming知识点"><a href="#spark-streaming知识点" class="header-anchor">#</a> Spark Streaming知识点</h2> <hr> <h3 id="dstream基础"><a href="#dstream基础" class="header-anchor">#</a> Dstream基础</h3> <ul><li>ssc.socketTextStream()方法 TCP套接字连接 (截图在命令行练习)</li> <li>streamingContext.fileStream(dataDirectory)方法, 可以从任何文件系统(如：HDFS、S3、NFS等）的文件中读取数据，然后创建一个DStream。</li></ul> <blockquote><p>需要注意的是：读取的必须是具有相同的数据格式的文件；创建的文件必须在dataDirectory目录下，并通过自动移动或重命名成数据目录；文件一旦移动就不能被改变，如果文件被不断追加,新的数据将不会被阅读。</p></blockquote> <ul><li>对于简单的文本文件，可以使用一个简单的方法streamingContext.textFileStream(dataDirectory)来读取数据</li></ul> <h3 id="高级来源"><a href="#高级来源" class="header-anchor">#</a> 高级来源</h3> <p>Spark Streaming原生支持一些不同的数据源。一些“核心”数据源已经被打包到Spark Streaming 的 Maven 工件中，而其他的一些则可以通过 spark-streaming-kafka 等附加工件获取。</p> <p>每个接收器都以 Spark 执行器程序中一个长期运行的任务的形式运行，因此会占据分配给应用的 CPU 核心。这意味着如果要运行多个接收器，就必须至少有和接收器数目相同的核心数，还要加上用来完成计算所需要的核心数。(意思是核心数 &gt;= 接收器数n + 1)</p> <p><strong>官方示例WordCount</strong></p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>
<span class="token comment">//import org.apache.spark.streaming.StreamingContext._</span>

<span class="token comment">/**
 * 官方示例WordCount
 */</span>
object <span class="token class-name">SparkStreaming</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

    <span class="token comment">//1.初始化Spark配置信息</span>
    val conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[2]&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;NetworkWordCount&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//2.初始化SparkStreamingContext</span>
    val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">//以5s为时间窗口进行数据处理</span>

    <span class="token comment">//3.通过监控端口创建DStream，读进来的数据为一行行</span>
    val lines <span class="token operator">=</span> ssc<span class="token punctuation">.</span><span class="token function">socketTextStream</span><span class="token punctuation">(</span><span class="token string">&quot;hadoop1&quot;</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span>

    <span class="token comment">//将每一行数据做切分，形成一个个单词</span>
    val words <span class="token operator">=</span> lines<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


    <span class="token comment">//将单词映射成元组（word,1）</span>
    val pairs <span class="token operator">=</span> words<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>word <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//将相同的单词次数做统计</span>
    val wordCounts <span class="token operator">=</span> pairs<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">// Print the first ten elements of each RDD generated in this DStream to the console</span>
    <span class="token comment">//打印</span>
    wordCounts<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token comment">// Start the computation</span>
    ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">// Wait for the computation to terminate</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="文件数据源-文件系统"><a href="#文件数据源-文件系统" class="header-anchor">#</a> 文件数据源(文件系统)</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token class-name">DStream</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>

<span class="token comment">/**
 * 文件数据源(文件系统)
 */</span>
object <span class="token class-name">FileSource</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token comment">//1.初始化Spark配置信息</span>

    val sparkConf<span class="token operator">:</span> <span class="token class-name">SparkConf</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;Stream WordCount&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//2.初始化Spark StreamingContext</span>
    val ssc<span class="token operator">:</span> <span class="token class-name">StreamingContext</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//3.监控文件夹创建DStream</span>
    val dirStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span><span class="token function">textFileStream</span><span class="token punctuation">(</span><span class="token string">&quot;hdfs://hadoop1:9000/fileStream&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//4.将每一行数据做切分, 形成一个个单词</span>
    val wordStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> dirStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//5.将单词映射为元组</span>
    val wordAndOneStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//6.将相同的单词做次数统计</span>
    val wordAndCountStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordAndOneStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">//7.打印</span>
    wordAndCountStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//8.启动StreamContext</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">// 调用StreamingContext的awaitTermination()方法， 来等待应用程序的终止。</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="mysql-队列-数据源"><a href="#mysql-队列-数据源" class="header-anchor">#</a> mysql(队列)数据源</h3> <p><strong>添加依赖</strong></p> <div class="language-java extra-class"><pre class="language-java"><code><span class="token operator">&lt;</span><span class="token operator">!</span><span class="token operator">--</span>连接mysql添加依赖<span class="token operator">--</span><span class="token operator">&gt;</span>
<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
    <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>mysql<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>mysql<span class="token operator">-</span>connector<span class="token operator">-</span>java<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
    <span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span><span class="token number">8.0</span><span class="token number">.17</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre></div><div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming<span class="token punctuation">.</span>mysqlandqueue</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Connection</span><span class="token punctuation">,</span> <span class="token class-name">DriverManager</span><span class="token punctuation">,</span> <span class="token class-name">ResultSet</span><span class="token punctuation">,</span> <span class="token class-name">Statement</span><span class="token punctuation">}</span>

object DB <span class="token punctuation">{</span>

  <span class="token comment">//初始化数据连接</span>
  <span class="token keyword">var</span> connection<span class="token operator">:</span> <span class="token class-name">Connection</span> <span class="token operator">=</span> _
  <span class="token keyword">var</span> statement <span class="token operator">:</span> <span class="token class-name">Statement</span> <span class="token operator">=</span> _

  def conn <span class="token punctuation">{</span>
    <span class="token comment">// 访问本地MySQL服务器，通过3306端口访问mysql数据库</span>
    val url <span class="token operator">=</span> <span class="token string">&quot;jdbc:mysql://localhost:3306/demo-3?useUnicode=true&amp;characterEncoding=utf-8&amp;serverTimezone=GMT%2B8&amp;useSSL=false&quot;</span>
    <span class="token comment">//驱动名称</span>
    val driver <span class="token operator">=</span> <span class="token string">&quot;com.mysql.cj.jdbc.Driver&quot;</span>

    val username <span class="token operator">=</span> <span class="token string">&quot;root&quot;</span>
    val password <span class="token operator">=</span> <span class="token string">&quot;123456789&quot;</span>


    <span class="token class-name">Class</span><span class="token punctuation">.</span><span class="token function">forName</span><span class="token punctuation">(</span>driver<span class="token punctuation">)</span> <span class="token comment">//.newInstance()</span>
    connection <span class="token operator">=</span> <span class="token class-name">DriverManager</span><span class="token punctuation">.</span><span class="token function">getConnection</span><span class="token punctuation">(</span>url<span class="token punctuation">,</span> username<span class="token punctuation">,</span> password<span class="token punctuation">)</span>
    statement <span class="token operator">=</span> connection<span class="token punctuation">.</span>createStatement <span class="token comment">//(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY)</span>
  <span class="token punctuation">}</span>

  <span class="token comment">//从数据库中取出每个用户的名字，是个String有序队列</span>
  def getMessage <span class="token operator">:</span> <span class="token class-name">Seq</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    conn
    <span class="token keyword">var</span> setName <span class="token operator">=</span> <span class="token class-name">Seq</span><span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>
    <span class="token keyword">try</span> <span class="token punctuation">{</span>
      <span class="token comment">// Execute Query，查询用户表 sec_user 是我的用户表，有name属性。</span>
      val rs <span class="token operator">=</span> statement<span class="token punctuation">.</span><span class="token function">executeQuery</span><span class="token punctuation">(</span><span class="token string">&quot;select ci_id, ci_name from city&quot;</span><span class="token punctuation">)</span>
      <span class="token comment">// Iterate Over ResultSet</span>
      <span class="token keyword">while</span> <span class="token punctuation">(</span>rs<span class="token punctuation">.</span>next<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token comment">// 返回行号</span>
        <span class="token comment">// println(rs.getRow)</span>
        val ci_name <span class="token operator">=</span> rs<span class="token punctuation">.</span><span class="token function">getString</span><span class="token punctuation">(</span><span class="token string">&quot;ci_name&quot;</span><span class="token punctuation">)</span>
        setName <span class="token operator">=</span> setName <span class="token operator">:</span><span class="token operator">+</span> ci_name
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span> <span class="token keyword">finally</span> <span class="token punctuation">{</span>
      close
    <span class="token punctuation">}</span>
    <span class="token keyword">return</span> setName
  <span class="token punctuation">}</span>

  def close<span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>
    connection<span class="token punctuation">.</span>close
  <span class="token punctuation">}</span>
<span class="token comment">//  def main(args: Array[String]): Unit = {</span>
<span class="token comment">//    println(getMessage)</span>
<span class="token comment">//  }</span>
<span class="token punctuation">}</span>
</code></pre></div><div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming<span class="token punctuation">.</span>mysqlandqueue</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">DStream</span><span class="token punctuation">,</span> <span class="token class-name">InputDStream</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable</span>

<span class="token comment">/**
 * RDD队列数据源 + mysql
 */</span>
object <span class="token class-name">MySparkStreaming</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>

    <span class="token comment">// 1.创建spark实例</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;QueueStream&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// 2.初始化sparkStreamingContext ，Seconds是多久去Rdd中取一次数据。</span>
    val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 3.创建RDD队列</span>
    val rddQueue <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name"><span class="token namespace">mutable<span class="token punctuation">.</span></span>Queue</span><span class="token punctuation">[</span>RDD<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 4.创建QueueInputStream, 从rdd队列中读取输入流</span>
    val inputStream<span class="token operator">:</span> <span class="token class-name">InputDStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> ssc<span class="token punctuation">.</span><span class="token function">queueStream</span><span class="token punctuation">(</span>rddQueue<span class="token punctuation">)</span>

    <span class="token comment">// 5.处理队列中的RDD数据</span>
    <span class="token comment">//将输入流中的每个元素（每个元素都是一个String）后面添加一个“a“字符，并返回一个新的rdd。</span>
    val mappedStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> inputStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>x <span class="token operator">+</span> <span class="token string">&quot;*&quot;</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">// reduceByKey(_ + _)对每个元素统计次数。map(x =&gt; (x._2,x._1))是将map的key和value 交换位置。</span>
    <span class="token comment">// 后边是过滤次数超过1次的且String 相等于“testa“</span>
    val reducedStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mappedStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token function">filter</span><span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> x<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>length<span class="token operator">&gt;</span><span class="token number">4</span><span class="token punctuation">)</span>
      <span class="token comment">//.map(x =&gt; (x._2, x._1)).filter((x) =&gt; x._1 &gt; 1).filter((x) =&gt; x._2.equals(&quot;testa&quot;))</span>

    <span class="token comment">// 6.打印结果</span>
    reducedStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//将每次计算的结果存储在./out/resulted处。</span>
    <span class="token comment">//reducedStream.saveAsTextFiles(&quot;data/resulted&quot;)</span>

    <span class="token comment">// 7.启动任务</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//从数据库中查出每个用户的姓名，返回的是一个String有序队列seq，因为生成RDD的对象必须是seq。</span>
    val seq <span class="token operator">=</span> DB<span class="token punctuation">.</span>getMessage
    <span class="token comment">//println(seq)</span>

    <span class="token comment">// 8.创建循环并向RDD队列中放入RDD</span>
    <span class="token comment">// 将seq生成RDD然后放入Spark的Streaming的RDD队列，作为输入流。</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span><span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">to</span> <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      rddQueue<span class="token punctuation">.</span><span class="token keyword">synchronized</span> <span class="token punctuation">{</span>
        rddQueue <span class="token operator">+=</span> ssc<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span><span class="token function">makeRDD</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token comment">// 打印到控制台</span>
        <span class="token comment">//rddQueue.foreach(rdd =&gt; rdd.foreach(println(_)))</span>
      <span class="token punctuation">}</span>
      <span class="token class-name">Thread</span><span class="token punctuation">.</span><span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">3000</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    ssc<span class="token punctuation">.</span><span class="token function">stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//ssc.awaitTermination() // 调用StreamingContext的awaitTermination()方法， 来等待应用程序的终止。</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="自定义数据源"><a href="#自定义数据源" class="header-anchor">#</a> 自定义数据源</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming<span class="token punctuation">.</span>udsource</span>

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">BufferedReader</span><span class="token punctuation">,</span> <span class="token class-name">InputStreamReader</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>net<span class="token punctuation">.</span></span><span class="token class-name">Socket</span>
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>charset<span class="token punctuation">.</span></span><span class="token class-name">StandardCharsets</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span></span><span class="token class-name">StorageLevel</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>receiver<span class="token punctuation">.</span></span><span class="token class-name">Receiver</span>

<span class="token comment">/**
 * 自定义数据源
 * 需要继承Receiver 并实现onStart onStop方法
 */</span>
<span class="token keyword">class</span> <span class="token class-name">CustomerReceiver</span><span class="token punctuation">(</span>host<span class="token operator">:</span><span class="token class-name">String</span><span class="token punctuation">,</span> port<span class="token operator">:</span><span class="token class-name">Int</span><span class="token punctuation">)</span> <span class="token keyword">extends</span> <span class="token class-name">Receiver</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token class-name">StorageLevel</span><span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span><span class="token punctuation">{</span>
  <span class="token comment">//最初启动的时候，调用该方法，作用为：读数据并将数据发送给Spark</span>
  override def <span class="token function">onStart</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token keyword">new</span> <span class="token class-name">Thread</span><span class="token punctuation">(</span><span class="token string">&quot;Socket Receiver&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      override def <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">receive</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

  <span class="token comment">//读数据并将数据发送给Spark</span>
  def <span class="token function">receive</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

    <span class="token comment">//创建一个Socket</span>
    <span class="token keyword">var</span> socket<span class="token operator">:</span> <span class="token class-name">Socket</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Socket</span><span class="token punctuation">(</span>host<span class="token punctuation">,</span> port<span class="token punctuation">)</span>

    <span class="token comment">//定义一个变量，用来接收端口传过来的数据</span>
    <span class="token keyword">var</span> input<span class="token operator">:</span> <span class="token class-name">String</span> <span class="token operator">=</span> <span class="token keyword">null</span>

    <span class="token comment">//创建一个BufferedReader用于读取端口传来的数据</span>
    val reader <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">BufferedReader</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">InputStreamReader</span><span class="token punctuation">(</span>socket<span class="token punctuation">.</span>getInputStream<span class="token punctuation">,</span> <span class="token class-name">StandardCharsets</span><span class="token punctuation">.</span>UTF_8<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//读取数据</span>
    input <span class="token operator">=</span> reader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//当receiver没有关闭并且输入数据不为空，则循环发送数据给Spark</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">isStopped</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> input <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
      <span class="token function">store</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span>
      input <span class="token operator">=</span> reader<span class="token punctuation">.</span><span class="token function">readLine</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    <span class="token comment">//跳出循环则关闭资源</span>
    reader<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    socket<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//重启任务</span>
    <span class="token function">restart</span><span class="token punctuation">(</span><span class="token string">&quot;restart&quot;</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>


  override def <span class="token function">onStop</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">sparkstreaming<span class="token punctuation">.</span>udsource</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>

object <span class="token class-name">UDSource</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>

    <span class="token comment">//1.初始化Spark配置信息</span>
    val sparkConf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;StreamWordCount&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">//2.初始化SparkStreamingContext</span>
    val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//3.创建自定义receiver的Streaming</span>
    val lineStream <span class="token operator">=</span> ssc<span class="token punctuation">.</span><span class="token function">receiverStream</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">CustomerReceiver</span><span class="token punctuation">(</span><span class="token string">&quot;hadoop102&quot;</span><span class="token punctuation">,</span> <span class="token number">9999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//4.将每一行数据做切分，形成一个个单词</span>
    val wordStreams <span class="token operator">=</span> lineStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>_<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot;\t&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//5.将单词映射成元组（word,1）</span>
    val wordAndOneStreams <span class="token operator">=</span> wordStreams<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">//6.将相同的单词次数做统计</span>
    val wordAndCountStreams <span class="token operator">=</span> wordAndOneStreams<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token comment">//7.打印</span>
    wordAndCountStreams<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//8.启动SparkStreamingContext</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="有状态数据统计updatestatebykey"><a href="#有状态数据统计updatestatebykey" class="header-anchor">#</a> 有状态数据统计UpdateStateByKey</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hrbu</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">SparkSession</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">DStream</span><span class="token punctuation">,</span> <span class="token class-name">InputDStream</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">ConsumerStrategies</span><span class="token punctuation">,</span> <span class="token class-name">KafkaUtils</span><span class="token punctuation">,</span> <span class="token class-name">LocationStrategies</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">SparkConf</span><span class="token punctuation">,</span> <span class="token class-name">SparkContext</span><span class="token punctuation">}</span>

<span class="token comment">/**
 * @title 有状态数据统计
 * 有状态转化操作  (UpdateStateByKey)  类似UDAF的Buffer???
 * 对之前的数据也有更新
 * 保存到文件(数据大  防止宕机)
 */</span>
object <span class="token class-name">DataStreaming_02</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    val config <span class="token operator">=</span> <span class="token class-name">Map</span><span class="token punctuation">(</span>
      <span class="token string">&quot;spark.cores&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;kafka.topic&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;datastreaming&quot;</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 创建配置对象</span>
    val sparkConf<span class="token operator">:</span> <span class="token class-name">SparkConf</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;DataStreaming&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token function">config</span><span class="token punctuation">(</span><span class="token string">&quot;spark.cores&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">// 创建SparkSession</span>
    val spark<span class="token operator">:</span> <span class="token class-name">SparkSession</span> <span class="token operator">=</span> <span class="token class-name">SparkSession</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">config</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrCreate</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 创建sparkContext</span>
    val sc<span class="token operator">:</span> <span class="token class-name">SparkContext</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext
    <span class="token comment">// 创建spark StreamingContext</span>
    val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sc<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 保存数据状态 需要设置检查点路径</span>
    sc<span class="token punctuation">.</span><span class="token function">setCheckpointDir</span><span class="token punctuation">(</span><span class="token string">&quot;checkpoint&quot;</span><span class="token punctuation">)</span>

    <span class="token comment">// 创建到Kafka的连接</span>
    val kafkaPara <span class="token operator">=</span> <span class="token class-name">Map</span><span class="token punctuation">(</span>
      <span class="token string">&quot;bootstrap.servers&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;hadoop1:9092&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;key.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;value.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;auto.offset.reset&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;latest&quot;</span>
    <span class="token punctuation">)</span>

    val kafkaStream<span class="token operator">:</span> <span class="token class-name">InputDStream</span><span class="token punctuation">[</span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token class-name">KafkaUtils</span><span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      <span class="token class-name">LocationStrategies<span class="token punctuation">.</span>PreferConsistent</span><span class="token punctuation">,</span>
      <span class="token class-name">ConsumerStrategies<span class="token punctuation">.</span>Subscribe</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token class-name">Array</span><span class="token punctuation">(</span><span class="token function">config</span><span class="token punctuation">(</span><span class="token string">&quot;kafka.topic&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kafkaPara<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 取到消息队列里的值</span>
    val valueDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> kafkaStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>t <span class="token operator">=</span><span class="token operator">&gt;</span> t<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    val mapDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> valueDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 将转换结构后的数据进行聚合处理</span>
    val stateDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapDStream<span class="token punctuation">.</span>updateStateByKey <span class="token punctuation">{</span>
      <span class="token keyword">case</span> <span class="token punctuation">(</span>seq<span class="token punctuation">,</span> buffer<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">{</span>
        val sum<span class="token operator">:</span> <span class="token class-name">Int</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span><span class="token function">getOrElse</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> seq<span class="token punctuation">.</span>sum
        <span class="token class-name">Option</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    stateDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 对读入的DStream进行分析</span>


    <span class="token comment">// 启动采集器</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 等待采集器停止</span>
    ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="window滑动"><a href="#window滑动" class="header-anchor">#</a> Window滑动</h3> <div class="language-java extra-class"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>hrbu</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerRecord</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token class-name">SparkSession</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">DStream</span><span class="token punctuation">,</span> <span class="token class-name">InputDStream</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">ConsumerStrategies</span><span class="token punctuation">,</span> <span class="token class-name">KafkaUtils</span><span class="token punctuation">,</span> <span class="token class-name">LocationStrategies</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{</span><span class="token class-name">SparkConf</span><span class="token punctuation">,</span> <span class="token class-name">SparkContext</span><span class="token punctuation">}</span>


object <span class="token class-name">DataStreaming03_Window</span> <span class="token punctuation">{</span>
  def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token class-name">TestScala</span>
  <span class="token punctuation">}</span>

  def <span class="token class-name">TestScala</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span><span class="token punctuation">{</span>
    <span class="token comment">// Scala语法</span>
    val ints <span class="token operator">=</span> <span class="token class-name">List</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
    <span class="token comment">// 滑动窗口函数(窗口大小 步长)</span>
    val iter<span class="token operator">:</span> <span class="token class-name">Iterator</span><span class="token punctuation">[</span><span class="token class-name">List</span><span class="token punctuation">[</span><span class="token class-name">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> ints<span class="token punctuation">.</span><span class="token function">sliding</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span><span class="token punctuation">(</span> list <span class="token operator">&lt;</span><span class="token operator">-</span> iter<span class="token punctuation">)</span><span class="token punctuation">{</span>
      <span class="token function">println</span><span class="token punctuation">(</span>list<span class="token punctuation">.</span><span class="token function">mkString</span><span class="token punctuation">(</span><span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>

  <span class="token comment">// 随时间改变(随时间推移  少一部分  多一部分)</span>
  def <span class="token function">sparkMain</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    val config <span class="token operator">=</span> <span class="token class-name">Map</span><span class="token punctuation">(</span>
      <span class="token string">&quot;spark.cores&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;local[*]&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;kafka.topic&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;datastreaming&quot;</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 创建配置对象</span>
    val sparkConf<span class="token operator">:</span> <span class="token class-name">SparkConf</span> <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">&quot;DataStreaming&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token function">config</span><span class="token punctuation">(</span><span class="token string">&quot;spark.cores&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">// 创建SparkSession</span>
    val spark<span class="token operator">:</span> <span class="token class-name">SparkSession</span> <span class="token operator">=</span> <span class="token class-name">SparkSession</span><span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">config</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOrCreate</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 创建sparkContext</span>
    val sc<span class="token operator">:</span> <span class="token class-name">SparkContext</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext
    <span class="token comment">// 创建spark StreamingContext</span>
    val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sc<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 创建到Kafka的连接</span>
    val kafkaPara <span class="token operator">=</span> <span class="token class-name">Map</span><span class="token punctuation">(</span>
      <span class="token string">&quot;bootstrap.servers&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;hadoop1:9092&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;key.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;value.deserializer&quot;</span> <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">&quot;group.id&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span>
      <span class="token string">&quot;auto.offset.reset&quot;</span> <span class="token operator">-&gt;</span> <span class="token string">&quot;latest&quot;</span>
    <span class="token punctuation">)</span>

    val kafkaStream<span class="token operator">:</span> <span class="token class-name">InputDStream</span><span class="token punctuation">[</span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token class-name">KafkaUtils</span><span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      <span class="token class-name">LocationStrategies<span class="token punctuation">.</span>PreferConsistent</span><span class="token punctuation">,</span>
      <span class="token class-name">ConsumerStrategies<span class="token punctuation">.</span>Subscribe</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token class-name">Array</span><span class="token punctuation">(</span><span class="token function">config</span><span class="token punctuation">(</span><span class="token string">&quot;kafka.topic&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kafkaPara<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// 窗口大小为采集周期的整数倍 窗口滑动步长也应该为采集周期的整数倍</span>
    val windowDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> kafkaStream<span class="token punctuation">.</span><span class="token function">window</span><span class="token punctuation">(</span><span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 取到消息队列里的值</span>
    val valueDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> windowDStream<span class="token punctuation">.</span><span class="token function">flatMap</span><span class="token punctuation">(</span>t <span class="token operator">=</span><span class="token operator">&gt;</span> t<span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot; &quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    val mapDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> valueDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// 数据聚合处理</span>
    val reduceDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> mapDStream<span class="token punctuation">.</span><span class="token function">reduceByKey</span><span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    reduceDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 启动采集器</span>
    ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">// 等待采集器停止</span>
    ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="转换-transfrom"><a href="#转换-transfrom" class="header-anchor">#</a> 转换 transfrom</h3> <p><img src="/hdata-doc/assets/img/spark_i1.1e0ccbf5.png" alt=""></p> <h3 id="dstream-foreachrdd-dstream输出"><a href="#dstream-foreachrdd-dstream输出" class="header-anchor">#</a> DStream.foreachRDD(DStream输出)</h3> <p>一个DStream包含一个或多个RDD</p> <p>通用的输出操作foreachRDD()，它用来对DStream中的RDD运行任意计算。这和transform() 有些类似，都可以让我们访问任意RDD。在foreachRDD()中，可以重用我们在Spark中实现的所有行动操作。
比如，常见的用例之一是把数据写到诸如MySQL的外部数据库中。 注意：
（1）连接不能写在driver层面；
（2）如果写在foreach则每个RDD都创建，得不偿失；
（3）增加foreachPartition，在分区创建。</p></div></div> <div class="page-slot page-slot-bottom">
  <div class="wwads-cn wwads-horizontal pageB" data-id="136" style="width:100%;max-height:80px;min-height:auto;"></div>
  <style>
    .pageB img{width:80px!important;}
    .wwads-horizontal .wwads-text, .wwads-content .wwads-text{line-height:1;}
  </style>
  </div> <div class="page-edit"><div class="edit-link"><a href="https://github.com/user-h/hdata-doc/edit/master/docs/02.大数据/06.Spark/02.Spark相关知识.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/03/28, 17:04:32</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/hdata-doc/pages/7d157d/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Spark环境搭建</div></a> <a href="/hdata-doc/pages/70f03f/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Spark内核学习</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/hdata-doc/pages/7d157d/" class="prev">Spark环境搭建</a></span> <span class="next"><a href="/hdata-doc/pages/70f03f/">Spark内核学习</a>→
      </span></p></div></div></div> <!----></main></div> <div class="footer"><div class="icons"><a href="mailto:1033078928@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/user-h" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://gitee.com/aihb" title="Gitee" target="_blank" class="iconfont icon-gitee"></a><a href="https://music.163.com" title="听音乐" target="_blank" class="iconfont icon-erji"></a><a href="https://bilibili.com" title="哔哩哔哩" target="_blank" class="iconfont icon-bilibili"></a><a href="https://douyin.com/" title="抖音" target="_blank" class="iconfont icon-douyin"></a><a href="" title="猫咪" target="_blank" class="iconfont icon-mao"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2025
    <span>Ai | MIT License</span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><span class="close-but">×</span> <div>
    <div class="wwads-cn wwads-vertical windowRB" data-id="136" style="max-width:160px;
    min-width: auto;min-height:auto;"></div>
    <style>
      .windowRB{ padding: 0;}
      .windowRB .wwads-img{margin-top: 10px;}
      .windowRB .wwads-content{margin: 0 10px 10px 10px;}
      .custom-html-window-rb .close-but{
        display: none;
      }
    </style>
  </div></div></div></div><div class="global-ui"></div></div>
    <script src="/hdata-doc/assets/js/app.37e4fbb6.js" defer></script><script src="/hdata-doc/assets/js/2.82afd9cb.js" defer></script><script src="/hdata-doc/assets/js/8.a242d330.js" defer></script>
  </body>
</html>
